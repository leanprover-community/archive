---
layout: archive
title: Lean Prover Zulip Chat Archive
permalink: archive/219941MachineLearningforTheoremProving/29276PaperTacticLearningandProvingfortheCoqProofAssista.html
---

<h2>Stream: <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/index.html">Machine Learning for Theorem Proving</a>
<h3>Topic: <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/29276PaperTacticLearningandProvingfortheCoqProofAssista.html">Paper: Tactic Learning and Proving for the Coq Proof Assista</a></h3>

<hr>

<base href="https://leanprover.zulipchat.com">

{% raw %}
<a name="192752855"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/Paper%3A%20Tactic%20Learning%20and%20Proving%20for%20the%20Coq%20Proof%20Assista/near/192752855" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/29276PaperTacticLearningandProvingfortheCoqProofAssista.html#192752855">Jason Rute (Apr 03 2020 at 02:54)</a>:</h4>
<p>A paper recently came out on applying machine learning to Coq: <a href="https://arxiv.org/abs/2003.09140" title="https://arxiv.org/abs/2003.09140">Tactic Learning and Proving for the Coq Proof Assistant</a> by Lasse Blaauwbroek, Josef Urban, and Herman Geuvers.  <a href="https://zenodo.org/record/3693760#.XoXfhi-ZPOQ" title="https://zenodo.org/record/3693760#.XoXfhi-ZPOQ">Artifacts of Tactic Learning and Proving for the Coq Proof Assistant</a> also includes datasets and Coq configurations for the project (but I don’t think it contains usable code to recreate one’s own Coq AI or to use theirs).</p>

<a name="192752858"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/Paper%3A%20Tactic%20Learning%20and%20Proving%20for%20the%20Coq%20Proof%20Assista/near/192752858" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/29276PaperTacticLearningandProvingfortheCoqProofAssista.html#192752858">Jason Rute (Apr 03 2020 at 02:54)</a>:</h4>
<p>It has been mentioned on the <a href="https://coq.discourse.group/t/machine-learning-and-hammers-for-coq/303/17" title="https://coq.discourse.group/t/machine-learning-and-hammers-for-coq/303/17">Coq discourse</a>, but there is no discussion so far, so I’d like to start a discussion here.</p>

<a name="192752864"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/Paper%3A%20Tactic%20Learning%20and%20Proving%20for%20the%20Coq%20Proof%20Assista/near/192752864" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/29276PaperTacticLearningandProvingfortheCoqProofAssista.html#192752864">Jason Rute (Apr 03 2020 at 02:55)</a>:</h4>
<p>In short, the paper is <a href="https://arxiv.org/abs/1804.00596" title="https://arxiv.org/abs/1804.00596">TacticToe</a>, but for Coq.  (TacticToe was one of the first competitive applications of machine learning for ITP and was originally for HOL4.  See <a href="#narrow/stream/113488-general/topic/AI.20and.20theorem.20proving/near/166056603" title="#narrow/stream/113488-general/topic/AI.20and.20theorem.20proving/near/166056603">my notes on it here</a>.)  This project follows a similar methodology to TacticToe, and since they don’t give it a name, I’m going to call it TacticToe for Coq.  Let me mention some of the highlights of the paper.</p>

<a name="192752868"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/Paper%3A%20Tactic%20Learning%20and%20Proving%20for%20the%20Coq%20Proof%20Assista/near/192752868" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/29276PaperTacticLearningandProvingfortheCoqProofAssista.html#192752868">Jason Rute (Apr 03 2020 at 02:55)</a>:</h4>
<p>TacticToe for Coq is actually the third machine learning based theorem prover for Coq.  The other two projects are <a href="https://arxiv.org/abs/1905.09381" title="https://arxiv.org/abs/1905.09381">CoqGym/ASTactic</a> and <a href="https://arxiv.org/abs/1907.07794" title="https://arxiv.org/abs/1907.07794">Proverbot9001</a>.  (See some of my notes on the two projects <a href="#narrow/stream/113488-general/topic/AI.20and.20theorem.20proving/near/171889226" title="#narrow/stream/113488-general/topic/AI.20and.20theorem.20proving/near/171889226">here</a>.)  Annoyingly, they don’t mention Proverbot9001 even though they cite earlier papers and Proverbot9001 seems to be far and away the state of the art in machine learning applied to Coq.  I’ll mention how this project compares to the others in a bit, but as usual, the lack of standard benchmarks makes such a comparison difficult.</p>

<a name="192752875"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/Paper%3A%20Tactic%20Learning%20and%20Proving%20for%20the%20Coq%20Proof%20Assista/near/192752875" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/29276PaperTacticLearningandProvingfortheCoqProofAssista.html#192752875">Jason Rute (Apr 03 2020 at 02:55)</a>:</h4>
<p>They make a big deal out of the fact that TacticToe for Coq is built using OCaml (the language Coq is implemented in).  I agree.  While Python is better for rapid prototyping and getting ML researchers involved, OCaml makes it more likely that this tool will eventually be available to the working proof engineer.  So even if this project isn’t the state of the art, it may be the most likely tool that Coq engineers will actually use.  However, I don’t think it is publicly available yet.</p>

<a name="192752879"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/Paper%3A%20Tactic%20Learning%20and%20Proving%20for%20the%20Coq%20Proof%20Assista/near/192752879" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/29276PaperTacticLearningandProvingfortheCoqProofAssista.html#192752879">Jason Rute (Apr 03 2020 at 02:55)</a>:</h4>
<p>They implement their own proof recording.  I think it is completely separate to the proof recording used for the other two Coq projects.  The techniques are similar to <a href="#narrow/stream/219941-Machine-Learning.20for.20Theorem.20Proving/topic/ML.20for.20Lean.3A.20How.20to.20do.20it.3F" title="#narrow/stream/219941-Machine-Learning.20for.20Theorem.20Proving/topic/ML.20for.20Lean.3A.20How.20to.20do.20it.3F">what I’m playing around with in Lean</a>.  They record all goal-state-tactic pairs and use those as a dataset to train a supervised algorithm.</p>

<a name="192752882"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/Paper%3A%20Tactic%20Learning%20and%20Proving%20for%20the%20Coq%20Proof%20Assista/near/192752882" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/29276PaperTacticLearningandProvingfortheCoqProofAssista.html#192752882">Jason Rute (Apr 03 2020 at 02:55)</a>:</h4>
<p>Unlike other Coq provers, this project doesn’t use neural networks.  Instead they predict tactics by using k-nearest neighbors (k-NN) similar to the original TacticToe.  If you are not familiar, the idea of k-NN that they take all goal-tactic pairs in the training set and encode the goals as vectors.  Then for any new goal one finds the goal (in the training set) closest (in some metric) to the new goal.  From that they can figure out which tactic to apply.  Some more technical details about this part:</p>
<ul>
<li>Since pure k-NN requires searching through all the training data every time, they use a faster approximate version called LSHF.</li>
<li>They use a variation of TF-IDF for formulas to encode the vectors.  The distance metric is similar to cosine distance, but a bit different.</li>
<li>They don’t mention tactic argument selection (e.g. premise selection), but if it is similar to TacticToe for HOL4, then I think they find premises which are closest to the current goal in some metric (probably similar to the metric used for tactic selection).</li>
<li>They also don’t mention the list of tactics they use, but I’m sure it is pared down from the full list.</li>
</ul>

<a name="192752888"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/Paper%3A%20Tactic%20Learning%20and%20Proving%20for%20the%20Coq%20Proof%20Assista/near/192752888" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/29276PaperTacticLearningandProvingfortheCoqProofAssista.html#192752888">Jason Rute (Apr 03 2020 at 02:55)</a>:</h4>
<p>They also use a proof search where the most likely tactics are explored more than less likely tactics.  It seems similar to beam search or some tree searches which use a notion of “fuel”.</p>

<a name="192752891"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/Paper%3A%20Tactic%20Learning%20and%20Proving%20for%20the%20Coq%20Proof%20Assista/near/192752891" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/29276PaperTacticLearningandProvingfortheCoqProofAssista.html#192752891">Jason Rute (Apr 03 2020 at 02:55)</a>:</h4>
<p>Ok, now onto results!  I’ve learned by now that pure percentages of solved theorems don’t mean a lot in isolation and it is difficult to compare results across theorem provers—and even within the same prover.  However, TacticToe for Coq solves ~39% of the theorems in the Coq standard library.  (I would have liked more discussion about test/train split, but I’ll give them the benefit of the doubt that they did this sufficiently.)  On the other hand, CoqHammer solves about ~40-42% of theorems in the standard library (when you combine Vampire, E, and Z3).</p>

<a name="192752928"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/Paper%3A%20Tactic%20Learning%20and%20Proving%20for%20the%20Coq%20Proof%20Assista/near/192752928" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/29276PaperTacticLearningandProvingfortheCoqProofAssista.html#192752928">Jason Rute (Apr 03 2020 at 02:56)</a>:</h4>
<p>First, let’s compare this to TacticToe for HOL4 which solves 66.4% of the theorems in the HOL4 standard library (twice as much as the E prover on HOL4).  I think this shows how similar ML strategies can have very different numbers for different theorem proving libraries.  I don’t know if this means that HOL-based provers are more amenable to automation than dependent type theorem logics, or if the HOL4 tactics are more powerful, or if just the libraries are different.</p>

<a name="192752931"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/Paper%3A%20Tactic%20Learning%20and%20Proving%20for%20the%20Coq%20Proof%20Assista/near/192752931" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/29276PaperTacticLearningandProvingfortheCoqProofAssista.html#192752931">Jason Rute (Apr 03 2020 at 02:56)</a>:</h4>
<p>Second, let’s compare it to CoqGym/ASTactic and Proverbot9001.  One problem is that all three projects use different test and training sets.  TacticToe for Coq uses the Coq standard library.  CoqGym uses the standard library and the packages listed on the Coq Package Index.  Proverbot9001 trains on CompCert and test on different projects (they were also kind enough to retrain and retest CoqGym/ASTactic on their dataset).  The saving grace of these three projects is that they all compare their results to CoqHammer.  Assuming that the CoqHammer configurations are similar between the three projects (which honestly they might not be), we can hammer-normalize the solve rates.  Specifically, in this paper, TacticToe for Coq solves 3240 theorems while CoqHammer solves 3534 theorems.  Dividing the two numbers gives a hammer-normalized score of 0.92.  Here are the hammer normalized scores for the three provers:</p>
<ul>
<li>ASTactic: 0.69 in CoqGym paper, 0.62 in Proverbot9001 paper</li>
<li>Proverbot9001: 2.62</li>
<li>TacticToe for Coq: 0.91</li>
</ul>

<a name="192752934"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/Paper%3A%20Tactic%20Learning%20and%20Proving%20for%20the%20Coq%20Proof%20Assista/near/192752934" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/29276PaperTacticLearningandProvingfortheCoqProofAssista.html#192752934">Jason Rute (Apr 03 2020 at 02:56)</a>:</h4>
<p>So it seems like Proverbot9001 is (far and away) better than the others, but a lot of caution is needed (especially since the test set for Proverbot9001 was much smaller).  Really, this highlights the needs for uniform benchmarks, not only within a theorem prover, but across theorem provers as well.  (I would love to see the TacticToe algorithm applied to HOL Light, Isabelle and Lean.)</p>

<a name="192752943"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/Paper%3A%20Tactic%20Learning%20and%20Proving%20for%20the%20Coq%20Proof%20Assista/near/192752943" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/29276PaperTacticLearningandProvingfortheCoqProofAssista.html#192752943">Jason Rute (Apr 03 2020 at 02:56)</a>:</h4>
<p>Finally, if the authors are reading this (e.g. <span class="user-mention" data-user-id="223577">@Josef Urban</span>), I think I found a small error/typo.  I don’t see where <code>eq_z</code> and <code>eq_x</code> come from in the feature set example on the bottom of page 3. I might not understand what a 2-shingle is, but if I do, <code>x</code> and <code>z</code> are not next to <code>=</code> in the syntax tree of the example formula.</p>

<a name="192886288"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/Paper%3A%20Tactic%20Learning%20and%20Proving%20for%20the%20Coq%20Proof%20Assista/near/192886288" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/29276PaperTacticLearningandProvingfortheCoqProofAssista.html#192886288">Scott Morrison (Apr 04 2020 at 03:05)</a>:</h4>
<p>Thanks for the great summary!</p>

<a name="192991265"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/Paper%3A%20Tactic%20Learning%20and%20Proving%20for%20the%20Coq%20Proof%20Assista/near/192991265" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/29276PaperTacticLearningandProvingfortheCoqProofAssista.html#192991265">Rongmin Lu (Apr 06 2020 at 03:02)</a>:</h4>
<p>(deleted)</p>


{% endraw %}

{% include archive_update.html %}