[
    {
        "content": "<p>Suppose we allow +, -, *, / on arbitrary precision numbers in one op:<br>\nConsider a vec of n elemes, each of log n bits. We can encode this as a big number of (n log n) bits in O(n) time.<br>\nWe can take the dot product of two Vecs in O(1) time: amortize the encoding time, do regular integer mul on two (n log n) bit numbers, use mod to read off answer.<br>\nThis would allow multiplying two NxN matrices, each with O(log n) bit number, in O(n^2 time):</p>\n<ol>\n<li>encode all the rows of matrix A in O(n) time</li>\n<li>encode all the rows of matrix B in O(n) time</li>\n<li>for each cell of output, do dot product of corresponding row/col in O(1) time</li>\n</ol>\n<p>How does Query Model prevent such a formalization?</p>\n<p>[RAM model breaks this because we can only multiply , for some fixed constant c, (c log n) * (c log n) mul in O(1) time; a [n log n]-big number would be forced to take atleast [n/c] cells].</p>",
        "id": 562257287,
        "sender_full_name": "TongKe Xue",
        "timestamp": 1765045498
    },
    {
        "content": "<p>What queries are you using?</p>",
        "id": 562257326,
        "sender_full_name": "Shreyas Srinivas",
        "timestamp": 1765045538
    },
    {
        "content": "<p>you keep speaking of \"the query model\". It's actually many models wrapped into one. If you provide a matrixMult query with input matrices, then you could even accomplish it in one query.</p>",
        "id": 562257421,
        "sender_full_name": "Shreyas Srinivas",
        "timestamp": 1765045660
    },
    {
        "content": "<p>When you want to reason about matrix multiplication, you would fix a parameter <code>w</code> for word size and allow input entries to range from 0 to <code>2^w - 1</code></p>",
        "id": 562257477,
        "sender_full_name": "Shreyas Srinivas",
        "timestamp": 1765045722
    },
    {
        "content": "<p>You are not going to get some big gotcha with encoding tricks since you'd have to choose the right kind of queries to get the result you seek</p>",
        "id": 562257569,
        "sender_full_name": "Shreyas Srinivas",
        "timestamp": 1765045812
    },
    {
        "content": "<blockquote>\n<p>You are not going to get some big gotcha with encoding tricks since you'd have to choose the right kind of queries to get the result you seek</p>\n</blockquote>\n<p>I disagree with this. With the CLRS-RAM model, you only have to get the model right once.</p>\n<p>With the \"many different queery model\", it seems every time you define a new \"query model\", you have to make sure that model defines \"ticks\" correctly (limit on wordsize, for example).</p>",
        "id": 562257703,
        "sender_full_name": "TongKe Xue",
        "timestamp": 1765045961
    },
    {
        "content": "<p>I hate to break it to you but that's how algorithms theory works. I admit that we don't teach these levels of abstraction in undergrad since we are not particularly concerned about these translations. The combinatorial stuff is much more central to the subject. You can get even more gotchas with the knapsack NP Hardness result. The knapsack problem is NP Hard but has a pseudopolynomial algorithm. This is fine. We know when we need to care about these representation issues and when we don't</p>",
        "id": 562257938,
        "sender_full_name": "Shreyas Srinivas",
        "timestamp": 1765046189
    },
    {
        "content": "<p>There are a gazillion models and variants out there</p>",
        "id": 562257956,
        "sender_full_name": "Shreyas Srinivas",
        "timestamp": 1765046212
    },
    {
        "content": "<p>Btw, there's something called the pointer machine model. Check out how much time integer multiplication takes there</p>",
        "id": 562258659,
        "sender_full_name": "Shreyas Srinivas",
        "timestamp": 1765047026
    },
    {
        "content": "<p>Philosohically:</p>\n<ol>\n<li>I want a tiny \"trusted\" base (ex: CLRS style RAM model).</li>\n<li>I do <strong>NOT</strong> want to have a new \"trusted\" base for every class of algorithms where we manually assign costs to constructors and then make an informal argument that it is correct.</li>\n<li>I believe the way to avoid (2) is to have everyone agree on a CLRS-style RAM model, and then for new \"model creators\" to provide lean4 verifiable formal proofs their model \"compiles down\" to CLRS-style RAM models for time/memory costs.</li>\n</ol>",
        "id": 562260212,
        "sender_full_name": "TongKe Xue",
        "timestamp": 1765048679
    },
    {
        "content": "<p>3 is not happening. Sorry.</p>",
        "id": 562262370,
        "sender_full_name": "Shreyas Srinivas",
        "timestamp": 1765051102
    },
    {
        "content": "<p>Many of those models have useful purposes.</p>",
        "id": 562262387,
        "sender_full_name": "Shreyas Srinivas",
        "timestamp": 1765051123
    },
    {
        "content": "<p>The queries framework is the best way to capture all of them. One can always define translations between queries to do reductions for example.</p>",
        "id": 562262434,
        "sender_full_name": "Shreyas Srinivas",
        "timestamp": 1765051159
    },
    {
        "content": "<p>But the idea of “everyone agreeing to a strict definition of a ram model” and agreeing to write their algorithms fully formally in it is just not happening. Informally everybody agrees in some agnostic notion of a RAM model, but even there many other models exist for good reasons.</p>",
        "id": 562262515,
        "sender_full_name": "Shreyas Srinivas",
        "timestamp": 1765051241
    },
    {
        "content": "<p>I agree with 99% of your idea. The only part I disagree on is this notion that for each Query Model, humans assign a cost to each constructor, and there is some informal, socially accepted \"proof\" that the cost of each constructor is correct.</p>\n<p>I believe this \"informal + socially accepted proof\" should be replaced by a Lean4 verified \"mini compiler\" that targets some commonly accepted CLRS-style RAM model, and that we prove in lean4 that each of the constructor indeed only take X computation and Y memory.</p>\n<p>I think this is an accurate stance on what we agree/disagree on (and it appears neither of us will convince the other of whether there should be a formal lean4 proof of the cost of each constructor of each query model.)</p>",
        "id": 562263035,
        "sender_full_name": "TongKe Xue",
        "timestamp": 1765051857
    },
    {
        "content": "<p>You are misunderstanding the purpose of this subject. It is not to produce implementable algorithms. That’s a nice added bonus every theorist will like, but not enough to put in the necessary grunt work that offers no fundamentally new insights. The evidence lies in how many procedures of the last 20 years are actually simple enough to be implementable, let alone implemented. Even where implementation is possible, it can be done at a different level of abstraction so as to not obscure the key insights of an algorithm.</p>",
        "id": 562263823,
        "sender_full_name": "Shreyas Srinivas",
        "timestamp": 1765052865
    },
    {
        "content": "<p>What is of interest is “given a set of basic operations, what can I compute with so and so complexity”</p>",
        "id": 562263950,
        "sender_full_name": "Shreyas Srinivas",
        "timestamp": 1765053015
    },
    {
        "content": "<p>For example, given matrix multiplication, can I maintain such and such data structures dynamically ?</p>",
        "id": 562264049,
        "sender_full_name": "Shreyas Srinivas",
        "timestamp": 1765053131
    },
    {
        "content": "<p>Would it be possible to formalize the Zeno machines as a query model?  If yes, let’s do that and collapse all those pesky complexity classes to O(1) and bring the whole field of algorithm design to a successful conclusion. (Needless to say, the preceding paragraph is not meant to be taken seriously.)</p>",
        "id": 562266016,
        "sender_full_name": "Ching-Tsun Chou",
        "timestamp": 1765055498
    },
    {
        "content": "<p>It’s also not a great argument.</p>",
        "id": 562266063,
        "sender_full_name": "Shreyas Srinivas",
        "timestamp": 1765055570
    },
    {
        "content": "<p>I want:</p>\n<ol>\n<li>assume X</li>\n<li>we can show that algorithm i has running time t(i) and memory usage s(i)</li>\n</ol>\n<p>You want:</p>\n<ol>\n<li>for i = 0, ... ; assume model_i</li>\n<li>then for algorithm A_j in query_model_i, it uses time t(j) and memory usage s(j)</li>\n</ol>\n<p>In the above, X = CLRS style ram model.</p>\n<p>You want lots of \"islands\" each with their own assumptions. I just want a single assumption.</p>\n<p>I think that is the core of our difference, and neither of us will convince the other.</p>",
        "id": 562266820,
        "sender_full_name": "TongKe Xue",
        "timestamp": 1765056639
    },
    {
        "content": "<p>those islands can be related by someone who wants them related</p>",
        "id": 562266911,
        "sender_full_name": "Shreyas Srinivas",
        "timestamp": 1765056782
    },
    {
        "content": "<p>Others can continue building their islands</p>",
        "id": 562266922,
        "sender_full_name": "Shreyas Srinivas",
        "timestamp": 1765056794
    },
    {
        "content": "<p>Typically you will find that there are many ways to link those islands.</p>",
        "id": 562266929,
        "sender_full_name": "Shreyas Srinivas",
        "timestamp": 1765056807
    },
    {
        "content": "<p>That' s for the interested person to solve</p>",
        "id": 562266941,
        "sender_full_name": "Shreyas Srinivas",
        "timestamp": 1765056822
    },
    {
        "content": "<p>Both approaches seems compatible to me, we develop the query meta-model, and on top of it we develop the RAM model … and other models.</p>\n<p>Then everyone can work on the part they care the most! In particular a lot of the algorithms will be developed for the RAM model due to its practical importance, but connections between models can be made anyway.</p>",
        "id": 562337336,
        "sender_full_name": "Marcelo Fornet",
        "timestamp": 1765139867
    },
    {
        "content": "<p>Exactly. If anything this might introduce a tower of abstractions connected through layers of interpretation functions.</p>",
        "id": 562344303,
        "sender_full_name": "Shreyas Srinivas",
        "timestamp": 1765141496
    },
    {
        "content": "<p>The query complexity design ought to permit something like \"evaluate the queries using this RAM model\"</p>",
        "id": 562344407,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1765141533
    },
    {
        "content": "<p>It doesn’t forbid it</p>",
        "id": 562344480,
        "sender_full_name": "Shreyas Srinivas",
        "timestamp": 1765141551
    },
    {
        "content": "<p>I don't remember if <code>FreeM</code> already has a monadic <code>run</code> that lets you implement the queries in another monad; but it would be easy enough to add it if it is missing.</p>",
        "id": 562344703,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1765141606
    },
    {
        "content": "<p>You can always translate from one query model to another. The point is, both conceptually and for formalisation, I think it is the  abstraction that works best.</p>",
        "id": 562344707,
        "sender_full_name": "Shreyas Srinivas",
        "timestamp": 1765141608
    },
    {
        "content": "<p>it cleanly separates algorithmic insights for a particular algorithm in a model from insights into how its  primitives can be implemented. There are bound to be many ways for the latter. So you can also structure the library to allow multiple complexity theorems for each algorithm corresponding to different translations.</p>",
        "id": 562345940,
        "sender_full_name": "Shreyas Srinivas",
        "timestamp": 1765141886
    },
    {
        "content": "<p>This separation is incidentally only implicit in the manual tick model, but will be automatic in the query model (by the query type)</p>",
        "id": 562346673,
        "sender_full_name": "Shreyas Srinivas",
        "timestamp": 1765142049
    },
    {
        "content": "<p>One thing that is hard with the query model is space complexity, since you can't prevent the implementation using storage in the Lean type theory</p>",
        "id": 562346769,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1765142070
    },
    {
        "content": "<p>This is out of my area of expertise, but probably systems with more exotic things like linear types can protect against this.</p>",
        "id": 562347290,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1765142198
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"1001511\">TongKe Xue</span> <a href=\"#narrow/channel/513188-CSLib/topic/Does.20Query.20Model.20allow.20matrix.20mul.20in.20O.28N.5E2.29.20time.20.3F/near/562266820\">said</a>:</p>\n<blockquote>\n<p>I want:</p>\n<ol>\n<li>assume X</li>\n<li>we can show that algorithm i has running time t(i) and memory usage s(i)</li>\n</ol>\n<p>You want:</p>\n<ol>\n<li>for i = 0, ... ; assume model_i</li>\n<li>then for algorithm A_j in query_model_i, it uses time t(j) and memory usage s(j)</li>\n</ol>\n</blockquote>\n<p>Shreyas' view reflects the literature, see for example <a href=\"https://arxiv.org/pdf/1402.1811\">https://arxiv.org/pdf/1402.1811</a><br>\nIn American-style theoretical computer science there are many, many computation models floating around. Each sub-area has its own computational model. I don't know anybody bothered to chart all of them.</p>",
        "id": 567687461,
        "sender_full_name": "Yuval Filmus",
        "timestamp": 1768282610
    },
    {
        "content": "<p>A single model dominates over half of <a href=\"https://en.wikipedia.org/wiki/Introduction_to_Algorithms\">https://en.wikipedia.org/wiki/Introduction_to_Algorithms</a> . Let's just use that model. And if anyone wants to use some new model K, they can implement a compiler/VM for K on the CLRS model.</p>\n<p>This, the \"trusted kernel\" is just the CLRS model, instead of every model out there.</p>",
        "id": 567696370,
        "sender_full_name": "TongKe Xue",
        "timestamp": 1768288334
    },
    {
        "content": "<p>This will make CSLib useless for theoretical computer science.<br>\nWould you similarly suggest that Mathlib be built on some particular \"Calculus 101\" textbook and be useless for mathematicians?</p>",
        "id": 567700334,
        "sender_full_name": "Yuval Filmus",
        "timestamp": 1768290371
    },
    {
        "content": "<p>Since the infrastructure is only going to be developed once, you have to get it right the first time.</p>",
        "id": 567700370,
        "sender_full_name": "Yuval Filmus",
        "timestamp": 1768290390
    },
    {
        "content": "<p>My point is this. There should be a tiny, fixed, trusted \"kernel\" for Time/Space called K.</p>\n<p>Then, if Bob wants to use some new query model M_i, the burden is on Bob to write a compiler from M_i to K and prove properties. Bob does not get to say \"M_i has properties P1, P2, P3, ... trust me bro.\"</p>",
        "id": 567702944,
        "sender_full_name": "TongKe Xue",
        "timestamp": 1768291478
    },
    {
        "content": "<p>That’s just not how these models work.<br>\nThe machine model isn’t supposed to reflect the complexity in some universal CPU.<br>\nIf I consider real arithmetic to have unit cost (common in computational geometry), I am abstracting away irrelevant details, without claiming that I can actually implement these operations in constant time.</p>",
        "id": 567704089,
        "sender_full_name": "Yuval Filmus",
        "timestamp": 1768291942
    },
    {
        "content": "<p>Here’s another example. In optimization, the objective function (and sometimes the constraints) are given as oracles. When measuring the running time, we’re interested both in the cost of computation per se and in the number of oracle calls.</p>",
        "id": 567705231,
        "sender_full_name": "Yuval Filmus",
        "timestamp": 1768292377
    },
    {
        "content": "<p>It sounds like your view is leaning towards: Before doing actual work, let's find a model that can formalize all of theoretical CS / optimization.</p>\n<p>Whereas my view is: I just want something that I can formalize core CLRS + algorithms + NP completeness reductions + crypto reductions.</p>\n<p>I.e. I'm not nearly as ambitious as you (and you raised many interesting theoretical results that are not within the realm of what I wish to formalize.)</p>",
        "id": 567715451,
        "sender_full_name": "TongKe Xue",
        "timestamp": 1768295723
    },
    {
        "content": "<p>It’s actually the other way around. Producing implementable algorithms is both more tedious (and challenging) and less conceptually useful</p>",
        "id": 567730487,
        "sender_full_name": "Shreyas Srinivas",
        "timestamp": 1768300511
    },
    {
        "content": "<p>Also the whole point  is to allow a family of models with one overarching (meta?) model (queries), not a single model as you suggest</p>",
        "id": 567730668,
        "sender_full_name": "Shreyas Srinivas",
        "timestamp": 1768300571
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"1001511\">TongKe Xue</span> <a href=\"#narrow/channel/513188-CSLib/topic/Does.20Query.20Model.20allow.20matrix.20mul.20in.20O.28N.5E2.29.20time.20.3F/near/567715451\">said</a>:</p>\n<blockquote>\n<p>It sounds like your view is leaning towards: Before doing actual work, let's find a model that can formalize all of theoretical CS / optimization.</p>\n</blockquote>\n<p>The phrase \"actual work\" implies that finding a good model is not actual work. Finding good definitions that work for the field is the heart of formalisation.  So this is definitely \"actual work\". Secondly we have figured out a model that works. I am actually implementing it (within  severe time constraints). </p>\n<blockquote>\n<p>Whereas my view is: I just want something that I can formalize core CLRS + algorithms + NP completeness reductions + crypto reductions.</p>\n</blockquote>\n<p>And what would the point of this formalisation of CLRS be if it is useless for anything beyond textbook level?</p>\n<blockquote>\n<p>I.e. I'm not nearly as ambitious as you (and you raised many interesting theoretical results that are not within the realm of what I wish to formalize.)</p>\n</blockquote>\n<p>You are welcome to do so. CSLib must however pick good definitions from the beginning if it is to serve its purpose and not become a chaotic forest like AFP. This is also true in mathlib where  the discussion on how to encode planar graphs has been happening for months now.</p>",
        "id": 567776396,
        "sender_full_name": "Shreyas Srinivas",
        "timestamp": 1768314088
    },
    {
        "content": "<p>In short, coming up with proper definitions that can soundly express theorems we care about is \"actual work\"</p>",
        "id": 567776535,
        "sender_full_name": "Shreyas Srinivas",
        "timestamp": 1768314128
    },
    {
        "content": "<p>I recently watched <a href=\"https://www.youtube.com/watch?v=KeX9JqepgiM\">this</a> short talk about <a class=\"stream-topic\" data-stream-id=\"423402\" href=\"/#narrow/channel/423402-PrimeNumberTheorem.2B/topic/Update.20on.20tertiary.20estimate.20projects/with/567065289\">#PrimeNumberTheorem+ &gt; Update on tertiary estimate projects</a>  , and I found it inspiring and perhaps relevant to this discussion, in the sense that it suggests infrastructure can be built that helps us manage transitions between models and upgrade our understanding as more fine-grained details in the lower level theory are worked out.</p>\n<div class=\"youtube-video message_inline_image\"><a data-id=\"KeX9JqepgiM\" href=\"https://www.youtube.com/watch?v=KeX9JqepgiM\"><img src=\"https://uploads.zulipusercontent.net/580b5bad15f4f089e7a75db541d54e32c2669ab3/68747470733a2f2f692e7974696d672e636f6d2f76692f4b6558394a71657067694d2f6d7164656661756c742e6a7067\"></a></div>",
        "id": 567881529,
        "sender_full_name": "Bolton Bailey",
        "timestamp": 1768349196
    },
    {
        "content": "<p>There is some intuitive parallel there yes</p>",
        "id": 567885470,
        "sender_full_name": "Shreyas Srinivas",
        "timestamp": 1768351880
    },
    {
        "content": "<p>I think we can drop this debate. It is fairly clear that:</p>\n<ol>\n<li>you and I have different objectives</li>\n<li>neither of us is going to convince the other</li>\n<li>this is a waste of both our time</li>\n</ol>\n<p>Whether CSLib adopts a foundation closer to your views or closer to my views, I'm okay with both outcomes.</p>\n<p>Cheers.</p>\n<p><span class=\"user-mention silent\" data-user-id=\"466334\">Shreyas Srinivas</span> <a href=\"#narrow/channel/513188-CSLib/topic/Does.20Query.20Model.20allow.20matrix.20mul.20in.20O.28N.5E2.29.20time.20.3F/near/567776396\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"1001511\">TongKe Xue</span> <a href=\"#narrow/channel/513188-CSLib/topic/Does.20Query.20Model.20allow.20matrix.20mul.20in.20O.28N.5E2.29.20time.20.3F/near/567715451\">said</a>:</p>\n<blockquote>\n<p>It sounds like your view is leaning towards: Before doing actual work, let's find a model that can formalize all of theoretical CS / optimization.</p>\n</blockquote>\n<p>The phrase \"actual work\" implies that finding a good model is not actual work. Finding good definitions that work for the field is the heart of formalisation.  So this is definitely \"actual work\". Secondly we have figured out a model that works. I am actually implementing it (within  severe time constraints). </p>\n<blockquote>\n<p>Whereas my view is: I just want something that I can formalize core CLRS + algorithms + NP completeness reductions + crypto reductions.</p>\n</blockquote>\n<p>And what would the point of this formalisation of CLRS be if it is useless for anything beyond textbook level?</p>\n<blockquote>\n<p>I.e. I'm not nearly as ambitious as you (and you raised many interesting theoretical results that are not within the realm of what I wish to formalize.)</p>\n</blockquote>\n<p>You are welcome to do so. CSLib must however pick good definitions from the beginning if it is to serve its purpose and not become a chaotic forest like AFP. This is also true in mathlib where  the discussion on how to encode planar graphs has been happening for months now.</p>\n</blockquote>",
        "id": 567895777,
        "sender_full_name": "TongKe Xue",
        "timestamp": 1768360024
    },
    {
        "content": "<p>Fwiw <span class=\"user-mention\" data-user-id=\"1001511\">@TongKe Xue</span> your question is also applicable to the TimeM model which is even less specific about what it counts, to a point where you can’t even state proper models and reduction theorems between them or even count different operations separately. </p>\n<p>Basically in algorithms we don’t actually care about some specific RAM model directly (indirectly we all love pretending that our sequential algorithms work on RAM but don’t care too much about the details). Algorithms theory is fundamentally answering questions of the form:</p>\n<p>Given operations X Y and Z as primitives, how many calls of each operation do we need to compute operation W.</p>",
        "id": 568096405,
        "sender_full_name": "Shreyas Srinivas",
        "timestamp": 1768432142
    },
    {
        "content": "<p>Let's drop this.</p>\n<p><span class=\"user-mention silent\" data-user-id=\"466334\">Shreyas Srinivas</span> <a href=\"#narrow/channel/513188-CSLib/topic/Does.20Query.20Model.20allow.20matrix.20mul.20in.20O.28N.5E2.29.20time.20.3F/near/568096405\">said</a>:</p>\n<blockquote>\n<p>Fwiw <span class=\"user-mention silent\" data-user-id=\"1001511\">TongKe Xue</span> your question is also applicable to the TimeM model which is even less specific about what it counts, to a point where you can’t even state proper models and reduction theorems between them or even count different operations separately. </p>\n<p>Basically in algorithms we don’t actually care about some specific RAM model directly (indirectly we all love pretending that our sequential algorithms work on RAM but don’t care too much about the details). Algorithms theory is fundamentally answering questions of the form:</p>\n<p>Given operations X Y and Z as primitives, how many calls of each operation do we need to compute operation W.</p>\n</blockquote>",
        "id": 568142356,
        "sender_full_name": "TongKe Xue",
        "timestamp": 1768463901
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"1001511\">TongKe Xue</span> <a href=\"#narrow/channel/513188-CSLib/topic/Does.20Query.20Model.20allow.20matrix.20mul.20in.20O.28N.5E2.29.20time.20.3F/near/562266820\">said</a>:</p>\n<blockquote>\n<p>I want:</p>\n<ol>\n<li>assume X</li>\n<li>we can show that algorithm i has running time t(i) and memory usage s(i)</li>\n</ol>\n<p>You want:</p>\n<ol>\n<li>for i = 0, ... ; assume model_i</li>\n<li>then for algorithm A_j in query_model_i, it uses time t(j) and memory usage s(j)</li>\n</ol>\n<p>In the above, X = CLRS style ram model.</p>\n<p>You want lots of \"islands\" each with their own assumptions. I just want a single assumption.</p>\n<p>I think that is the core of our difference, and neither of us will convince the other.</p>\n</blockquote>\n<p>But I want to assume Y. Why shouldn’t you write a converter from X to Y?</p>",
        "id": 568295017,
        "sender_full_name": "Alok Singh",
        "timestamp": 1768505093
    },
    {
        "content": "<p>Because you are not Emperor. If you want to assume Y, you go write a converter from Y to X. It's not the rest of the world's job to serve you.</p>\n<p><span class=\"user-mention silent\" data-user-id=\"337670\">Alok Singh</span> <a href=\"#narrow/channel/513188-CSLib/topic/Does.20Query.20Model.20allow.20matrix.20mul.20in.20O.28N.5E2.29.20time.20.3F/near/568295017\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"1001511\">TongKe Xue</span> <a href=\"#narrow/channel/513188-CSLib/topic/Does.20Query.20Model.20allow.20matrix.20mul.20in.20O.28N.5E2.29.20time.20.3F/near/562266820\">said</a>:</p>\n<blockquote>\n<p>I want:</p>\n<ol>\n<li>assume X</li>\n<li>we can show that algorithm i has running time t(i) and memory usage s(i)</li>\n</ol>\n<p>You want:</p>\n<ol>\n<li>for i = 0, ... ; assume model_i</li>\n<li>then for algorithm A_j in query_model_i, it uses time t(j) and memory usage s(j)</li>\n</ol>\n<p>In the above, X = CLRS style ram model.</p>\n<p>You want lots of \"islands\" each with their own assumptions. I just want a single assumption.</p>\n<p>I think that is the core of our difference, and neither of us will convince the other.</p>\n</blockquote>\n<p>But I want to assume Y. Why shouldn’t you write a converter from X to Y?</p>\n</blockquote>",
        "id": 568318531,
        "sender_full_name": "TongKe Xue",
        "timestamp": 1768514396
    },
    {
        "content": "<p>Please keep the conversation respectful.</p>",
        "id": 568319923,
        "sender_full_name": "Chris Henson",
        "timestamp": 1768515013
    },
    {
        "content": "<p>I've gone ahead and muted the topic. I feel like I'm getting reply quoted by people who just want to argue/debate in an online forum. DM me if you know of cool projects making progress on the CLRS/RAM world view. Cheers.</p>",
        "id": 568322508,
        "sender_full_name": "TongKe Xue",
        "timestamp": 1768516131
    }
]