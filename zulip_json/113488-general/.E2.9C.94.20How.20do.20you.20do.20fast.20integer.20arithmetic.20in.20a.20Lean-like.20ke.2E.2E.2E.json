[
    {
        "content": "<p>Computer-implementable general math kernels (say of a proof assistant) are usually implemented in a one-to-one correspondence (in data structures) with a certain formalized theory of types.</p>\n<p>But they usually define the naturals, and then then integers, in such a way that doing things 100% one-to-one would result in an extremely inefficient algorithm for say adding two arbitrary integers.</p>\n<p>Since most programming language standard libraries have a built-in BigInt (D does, Python's is part of the language), and the most basic datatype the computer works with is the integral bit, and stringing these together leads to quotient rings $\\Bbb{Z}/{2^k}$, in particular of the integers, it seems like BigInt is a good candidate for the first kind of built-in I would try to add to a theory.</p>\n<p>So my question is, how do you perform this seamless integration of a high-level built-in type $\\Bbb{Z}$.  That is, not all of its operations are formalized / verified at least at runtime.  This is sort of like having \"managed\" and \"unmanaged\" portions of code in the same C# project.</p>\n<p>So a better question would be what does Lean do to deal with this problem?  Say if I were searching for a proof, I would not want to \"verify everything always\", I would probably want to treat certain things atomically.</p>",
        "id": 263625779,
        "sender_full_name": "Daniel Donnelly",
        "timestamp": 1638559429
    },
    {
        "content": "<p>It's hard for me to tell what you're asking for, but as a guess maybe the lean answer is \"generalize away all the implementation details:</p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"kd\">example</span> <span class=\"o\">{</span><span class=\"n\">Z</span> <span class=\"o\">:</span> <span class=\"kt\">Type</span><span class=\"bp\">*</span><span class=\"o\">}</span> <span class=\"o\">[</span><span class=\"n\">ring</span> <span class=\"n\">Z</span><span class=\"o\">]</span> <span class=\"o\">:</span> <span class=\"o\">(</span><span class=\"mi\">3</span> <span class=\"bp\">*</span> <span class=\"mi\">7</span> <span class=\"o\">:</span> <span class=\"n\">Z</span><span class=\"o\">)</span> <span class=\"bp\">=</span> <span class=\"mi\">21</span> <span class=\"o\">:=</span> <span class=\"kd\">by</span> <span class=\"n\">norm_num</span>\n<span class=\"c1\">-- I don't know if this proof works!</span>\n</code></pre></div>",
        "id": 263627168,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1638560080
    },
    {
        "content": "<p>Note that here <code>3</code> is syntactically <code>(bit1 (bit1 0))</code>, and lean just prints it nicely</p>",
        "id": 263627280,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1638560151
    },
    {
        "content": "<p>Since Lean is also a programming language, surely there is some use of it that would require fast BigInt operations, so I'm wondering how does Lean perform the operations quickly enough to be comparable with a C++ BigInt implementation?  But only do so where it absolutely needs to and should, perhaps the user could tell it when to...</p>",
        "id": 263628148,
        "sender_full_name": "Daniel Donnelly",
        "timestamp": 1638560601
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"236489\">@Daniel Donnelly</span> are you interested particularly in Lean3 or is Lean 4 also on the table? As it stands, Lean 4 actually does use a C++ implementation of big numbers to do numeric operations (either GMP or a custom version).</p>",
        "id": 263628539,
        "sender_full_name": "Mac",
        "timestamp": 1638560777
    },
    {
        "content": "<p>There are a couple levels to Lean, which makes answering this not so straightforward. There's the kernel, which is what does the final check that a proof is correct (and its version of the naturals is the inductive type), there's the evaluator, which is what things like tactic scripts run in (and as I understand it, it uses an efficient big natural number library), and for Lean 4 there's compiled code, which uses GMP for natural numbers (Mac beat me to mentioning it while I was writing).</p>",
        "id": 263628716,
        "sender_full_name": "Kyle Miller",
        "timestamp": 1638560874
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"315577\">@Mac</span> Yes, lean4, okay so Lean does it properly by now.  Just wondering!  I'm messing around with some code in D right now. :)</p>",
        "id": 263628772,
        "sender_full_name": "Daniel Donnelly",
        "timestamp": 1638560885
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"306601\">@Kyle Miller</span> the Lean 4 kernel also uses C++ big numbers as well though (it has special added support for this).</p>",
        "id": 263628845,
        "sender_full_name": "Mac",
        "timestamp": 1638560933
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"315577\">@Mac</span>  I guess it's up to the Lean designer's discretion when determining which method to use.</p>",
        "id": 263629051,
        "sender_full_name": "Daniel Donnelly",
        "timestamp": 1638561018
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"315577\">@Mac</span> Does the kernel also do this for other types with an extern implementation? like arrays?</p>",
        "id": 263629110,
        "sender_full_name": "Kyle Miller",
        "timestamp": 1638561055
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"306601\">@Kyle Miller</span> no,  the kernel just has special support for natural numbers.</p>",
        "id": 263629359,
        "sender_full_name": "Mac",
        "timestamp": 1638561161
    },
    {
        "content": "<p>Is there any way to base a type theory off of integers so that you don't have to verify that the arithmetic is correct, but you assume it is?</p>",
        "id": 263629642,
        "sender_full_name": "Daniel Donnelly",
        "timestamp": 1638561301
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"236489\">Daniel Donnelly</span> <a href=\"#narrow/stream/113488-general/topic/How.20do.20you.20do.20fast.20integer.20arithmetic.20in.20a.20Lean-like.20kernel.3F/near/263629642\">said</a>:</p>\n<blockquote>\n<p>Is there any way to base a type theory off of integers so that you don't have to verify that the arithmetic is correct, but you assume it is?</p>\n</blockquote>\n<p>I would not imagine so, no. I don't see how exactly type theory would ever get you arithmetic for free.</p>",
        "id": 263629784,
        "sender_full_name": "Mac",
        "timestamp": 1638561372
    },
    {
        "content": "<p>But I am not really an expert on such formal methods, so don't quote me on that.</p>",
        "id": 263629844,
        "sender_full_name": "Mac",
        "timestamp": 1638561409
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"315577\">@Mac</span> Not just any arithmetic, only arithmetic of the integers is built-in.  It seems appropriate since it is a most-basic type in a lot of senses and the computer's natural datatype.</p>",
        "id": 263630341,
        "sender_full_name": "Daniel Donnelly",
        "timestamp": 1638561651
    },
    {
        "content": "<p>I'm not sure what you're looking for here; maybe one answer is that you define anything with <code>axiom</code>s.  However, you lose niceties that come with an inductive type definition that are helpful for proving things.</p>\n<p>With Lean 4 and natural numbers in the kernel, I think an idea is that with inductive types, the underlying implementation can be anything that satisfies the axioms, so non-negative GMP natural numbers can be used perfectly well in place of the generic implementation, supposing you trust they are implemented correctly. (A complication is that you would probably also want to also replace basic arithmetic operations with their GMP counterparts.) I don't see why you can't do the same for integers and GMP integers.</p>",
        "id": 263631898,
        "sender_full_name": "Kyle Miller",
        "timestamp": 1638562505
    },
    {
        "content": "<p>The current implementation of lean 4 puts GMP in the trusted computing base, which not everyone is comfortable with. Moving bignum arithmetic to the kernel also has consequences for proof export, since anyone consuming the proof also has to support the same operations.</p>",
        "id": 263659507,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1638569163
    },
    {
        "content": "<p>Note that you can get within a constant multiplicative factor of optimal even without any fancy bignum support; this is what lean 3 <code>norm_num</code> does, it implements everything with <code>bit0</code> and <code>bit1</code> functions. These are simple and portable, but the constant cost is large, probably on the order of 100 to 1000, which is good enough for numbers with, say, 50 digits but not if you want to deal with 100000 digit numbers</p>",
        "id": 263659878,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1638569387
    },
    {
        "content": "<p>I think there are very few problems in verification which need such large numbers, and <code>norm_num</code> is generally not the bottleneck of mathlib</p>",
        "id": 263659987,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1638569442
    },
    {
        "content": "<p>But certainly there are certain domains where fast large number computation is important and having bignum arithmetic support opens those areas</p>",
        "id": 263660079,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1638569509
    },
    {
        "content": "<p>Personally, I think the sweet spot is built in kernel computations on fixed size words, say 64 bit numbers, and make the user write anything on top of that themselves (i.e. they have to write the bignum package). It's usually not that hard to justify operations on integers which are part of the underlying memory model</p>",
        "id": 263660423,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1638569632
    },
    {
        "content": "<p>There are two issues, right?  Issue 1 is that we want access to the speed and power of, say, x86 processors (with efficient arithmetic operations on fixed sized integers and efficient array storage).  Issue 2 is that we want nice mathematical definitions (like the unary definition of natural numbers), but we want fast algorithms for computing these definitions.  Right?</p>",
        "id": 263671816,
        "sender_full_name": "Jason Rute",
        "timestamp": 1638578511
    },
    {
        "content": "<p>So Mario's sweet spot would address a good part of issue 1 since you would now be able to do fast computations on words of size 64 using built in machine operations (like 64-bit integer addition), right?  It would then be possible to implement fast algorithms on standard mathematical objects using those operations which the kernel would trust.  (I guess it wouldn't be that unsafe to extend this to arrays of various fixed sizes too, right?)  Further, with what Mario are doing in say, MM0, one could prove that a particular machine code implementation of the kernel implements the operations according to the specification and that these implementations would give the same result as more purely type theoretic definitions?</p>",
        "id": 263671826,
        "sender_full_name": "Jason Rute",
        "timestamp": 1638578520
    },
    {
        "content": "<p>As for the other issue, there are two general options.  In option A, you are transparent about everything.  So <code>+</code> just means the usual unary addition operator, and if you want a fast addition operator, you use either use a different function or wrap your term in some norm_num thing which reduces it in a more efficient manner.   Option B is that you do this non-transparently, so that + looks like unary addition in proofs, but behaves like fast addition in algorithms, tactics, and reduction of type expressions.  I guess there are then two more sub-options to B:  In Option B1, the kernel has a way to justify these replacements, where one has to prove that the replacement algorithm is an equivalent function.  The other option B2: the swap happens without a kernel-level justification.  So either there are only a few built-in \"safe\" swaps (like Lean 4 and bignum), or swaps only happen for execution of algorithms and not proofs or type checking (like Lean's FFI).</p>",
        "id": 263671846,
        "sender_full_name": "Jason Rute",
        "timestamp": 1638578524
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110049\">Mario Carneiro</span> <a href=\"#narrow/stream/113488-general/topic/.E2.9C.94.20How.20do.20you.20do.20fast.20integer.20arithmetic.20in.20a.20Lean-like.20ke.2E.2E.2E/near/263659507\">said</a>:</p>\n<blockquote>\n<p>The current implementation of lean 4 puts GMP in the trusted computing base, which not everyone is comfortable with. </p>\n</blockquote>\n<p>Just to add a data point here, culturally in mathematics it now seems to be completely acceptable to claim that you have proved a theorem even if your proof uses unverified computer calculations. For example Helfgott's proof of weak Goldbach essentially uses <a href=\"https://arxiv.org/abs/1305.3062\">this work</a>. All the claims in the introduction of that paper saying that various things have been \"showed\" or \"numerically verified\" mean \"showed using unverified software\". So I think that at least as far as working mathematicians are concerned, adding GMP to the trusted computing base is not a big deal. I can completely appreciate that there might be some other people who are less comfortable with this, however I wonder how many of these people actually use big integers in their work.</p>",
        "id": 263699806,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1638616735
    },
    {
        "content": "<blockquote>\n<p>I can completely appreciate that there might be some other people who are less comfortable with this, however I wonder how many of these people actually use big integers in their work.</p>\n</blockquote>\n<p>Of course, you get used to the level of rigor of your environment. If you are doing paper mathematics, then the level of rigor of regular paper proofs seems fine. If you are doing experimental or computational mathematics where everyone in your field uses GAP / Sage / Mathematica, then this also seems fine, because it's what the experts in your area are doing. If you are doing formal verification, then those other methods aren't fine anymore and the gold standard is to push a proof through the kernel. And even between different systems people might have different palates for the complexity of the kernel, driven largely by how complex the one they happen to use is.</p>\n<p>It's even possible to be in more than one of these camps at the same time. I wear a lot of hats, and my level of paranoia adapts to the context under discussion. I don't even think I am unique in doing so. This is just how human communication works. But it does tend to desensitize you to potential areas of improvement, and I think this is one of the reasons why things like formal verification are slow to catch on, because maths seems to be doing just fine without our help.</p>",
        "id": 263711427,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1638628633
    },
    {
        "content": "<p>Here is another point of view about theorem prover kernels.  Because of the trustworthiness of theorem proving kernels, we can say statements like \"If the kernel accepts it, it is a valid proof\", \"one can't prove false\", \"one can be absolutely certain there is no mistake\", etc.  I've seen people when they hear those statements get defensive and say \"all software has bugs\" and treat it like a challenge.  It's hard to convince them that the kernel really is trustworthy.  Every new feature added to the kernel creates the possibility for a soundness bug and makes it harder to say this convincingly, and if nothing else that is an embarrassment.  I think Leo is very proud to say there has never been a soundness bug in Lean 3.  But for Lean 4, already this GMP stuff introduced a <a href=\"#narrow/stream/270676-lean4/topic/Contradiction.3F\">very very short lived soundness bug involving <code>% 0</code></a> in a beta nightly version which was fixed immediately and now makes that statement a bit harder to say for Lean4 without at least a few qualifiers.  (If this statement is somehow not accurate, I'll remove it.)</p>",
        "id": 263714248,
        "sender_full_name": "Jason Rute",
        "timestamp": 1638631993
    },
    {
        "content": "<p>We know from experience in theorem proving that even if there is a bug in the kernel it is likely not too serious, since the human entering the code has good intent (and at least for formalizing published math, there is already a lot of trust that the math is correct).   But as we introduce more automated proof tools, including AI and brute force search (a la four color theorem and Kepler conjecture proofs), then it is more possible for soundness bugs to be exploited (and go unnoticed).</p>",
        "id": 263714255,
        "sender_full_name": "Jason Rute",
        "timestamp": 1638632009
    },
    {
        "content": "<p>For the record, I support what Leo is doing with GMP and Lean4, but I also support brainstorming alternative proposals like Mario's which try to move the bar closer to trustworthiness.</p>",
        "id": 263714260,
        "sender_full_name": "Jason Rute",
        "timestamp": 1638632023
    },
    {
        "content": "<p>Maybe use WhyMP :) <a href=\"https://hal.inria.fr/hal-02566654v2/document\">https://hal.inria.fr/hal-02566654v2/document</a></p>\n<p>More seriously, I think the world is ready for some verified bignum arithmetic down to the metal, but it's notoriously tough to beat GMP, obviously.</p>",
        "id": 263718356,
        "sender_full_name": "Cody Roux",
        "timestamp": 1638636695
    },
    {
        "content": "<p>While we're at it I may as well plug <a href=\"https://github.com/awslabs/s2n-bignum/\">https://github.com/awslabs/s2n-bignum/</a> (I preferred the original name \"littlebignum\"), a project I worked on with John Harrison while at AWS to write formally verified constant-time (in the crypto sense) bignum arithmetic routines in assembly, in HOL light. (I think there is a paper somewhere about it but I can't find it now.)</p>",
        "id": 263724596,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1638643202
    },
    {
        "content": "<p>It is important to note that Lean 4's current goal is to move away from GMP, so Leo may be open to some of these alternative ideas.</p>",
        "id": 263733050,
        "sender_full_name": "Mac",
        "timestamp": 1638654064
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"115715\">Jason Rute</span> <a href=\"#narrow/stream/113488-general/topic/.E2.9C.94.20How.20do.20you.20do.20fast.20integer.20arithmetic.20in.20a.20Lean-like.20ke.2E.2E.2E/near/263714248\">said</a>:</p>\n<blockquote>\n<p>But for Lean 4, already this GMP stuff introduced a <a href=\"#narrow/stream/270676-lean4/topic/Contradiction.3F\">very very short lived soundness bug involving <code>% 0</code></a> in a beta nightly version which was fixed immediately and now makes that statement a bit harder to say for Lean4 without at least a few qualifiers. </p>\n</blockquote>\n<p>It is important to note that the Lean 4 is not officially released yet and the nightly is very bleeding edge and thus has weaker guarantees. I imagine by the time Lean 4 proper releases it will have been more rigorously tested and verified so the situation will be more like Lean 3.</p>",
        "id": 263733212,
        "sender_full_name": "Mac",
        "timestamp": 1638654321
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110038\">Kevin Buzzard</span> <a href=\"#narrow/stream/113488-general/topic/.E2.9C.94.20How.20do.20you.20do.20fast.20integer.20arithmetic.20in.20a.20Lean-like.20ke.2E.2E.2E/near/263699806\">said</a>:</p>\n<blockquote>\n<p>So I think that at least as far as working mathematicians are concerned, adding GMP to the trusted computing base is not a big deal. I can completely appreciate that there might be some other people who are less comfortable with this, however I wonder how many of these people actually use big integers in their work.</p>\n</blockquote>\n<p>Maybe some people less comfortable with it have found correctness bugs in GMP in the past.</p>\n<p>(I've never found a correctness bug in GMP, but I've found several correctness bugs over the years in MPFR and MPC which build on GMP to implement correctly-rounded arbitrary precision floating-point arithmetic.)</p>",
        "id": 263739860,
        "sender_full_name": "Joseph Myers",
        "timestamp": 1638663678
    }
]