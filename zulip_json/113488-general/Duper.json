[
    {
        "content": "<p>Where should we discuss Duper on Zulip?</p>",
        "id": 408638265,
        "sender_full_name": "Jason Rute",
        "timestamp": 1702914544
    },
    {
        "content": "<p>I would say the general stream. It is a very general purpose tool that is not limited to Mathlib and not really about Lean 4 itself so not suitable for the Lean 4 stream.</p>",
        "id": 408638773,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1702914704
    },
    {
        "content": "<p>Place to talk about <a class=\"stream-topic\" data-stream-id=\"113486\" href=\"/#narrow/stream/113486-announce/topic/Duper\">#announce &gt; Duper</a>.</p>",
        "id": 408641357,
        "sender_full_name": "Jason Rute",
        "timestamp": 1702915464
    },
    {
        "content": "<p>I made a place <a class=\"stream-topic\" data-stream-id=\"113488\" href=\"/#narrow/stream/113488-general/topic/Duper\">#general &gt; Duper</a> but don't have permission to move the messages above.</p>",
        "id": 408641539,
        "sender_full_name": "Jason Rute",
        "timestamp": 1702915528
    },
    {
        "content": "<p>This is really interesting.  Do you have any idea how good it is alone?  For example <span class=\"user-mention\" data-user-id=\"110087\">@Scott Morrison</span> made a way to benchmark solvers like this.  I'd love a comparison to Aesop and to AI-based tools like LLM-Step and Lean Copilot.  (And yes, it is tricky to compare AI tools since they have been trained.)</p>",
        "id": 408641947,
        "sender_full_name": "Jason Rute",
        "timestamp": 1702915659
    },
    {
        "content": "<p>Also, you talk about making a Sledgehammer clone, but have you also thought about a MagnusHammer (<a class=\"stream-topic\" data-stream-id=\"219941\" href=\"/#narrow/stream/219941-Machine-Learning-for-Theorem-Proving/topic/New.20paper.3A.20Magnushammer\">#Machine Learning for Theorem Proving &gt; New paper: Magnushammer</a>) clone as well?  Instead of using an ATP to find lemmas and reconstructing proofs with Duper, MagnusHammer just uses an AI-based lemma selection tool directly.  If I read the MagnusHammer paper correctly, it is much better than SledgeHammer (although I'm annoyed at them for not putting a Venn diagram or similar so I don't know if solves similar theorems or if there is still an advantage to SledgeHammer).  The simplest approach would be to hook up the lemma selection tool in <span class=\"user-mention\" data-user-id=\"584504\">@Kaiyu Yang</span>'s Lean Copilot (<a class=\"stream-topic\" data-stream-id=\"219941\" href=\"/#narrow/stream/219941-Machine-Learning-for-Theorem-Proving/topic/LeanCopilot\">#Machine Learning for Theorem Proving &gt; LeanCopilot</a>).  Although a lemma selector trained to work with Duper might be better, but unlike Isabelle you don't have any existing data for this since Duper has never been used in practice.</p>",
        "id": 408643100,
        "sender_full_name": "Jason Rute",
        "timestamp": 1702916026
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"115715\">Jason Rute</span> <a href=\"#narrow/stream/113488-general/topic/Duper/near/408641539\">said</a>:</p>\n<blockquote>\n<p>I made a place <a class=\"stream-topic\" data-stream-id=\"113488\" href=\"/#narrow/stream/113488-general/topic/Duper\">#general &gt; Duper</a> but don't have permission to move the messages above.</p>\n</blockquote>\n<p>Moved.</p>",
        "id": 408643929,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1702916280
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"110031\">@Patrick Massot</span> Thanks, but there is no link from <a class=\"stream-topic\" data-stream-id=\"113486\" href=\"/#narrow/stream/113486-announce/topic/Duper\">#announce &gt; Duper</a> back to this topic now.</p>",
        "id": 408644185,
        "sender_full_name": "Jason Rute",
        "timestamp": 1702916353
    },
    {
        "content": "<p>Jason, do you know about <a href=\"https://github.com/leanprover-community/lean-auto\">lean-auto</a>? It is currently then main user of Duper towards a full hammer pipeline.</p>",
        "id": 408644202,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1702916357
    },
    {
        "content": "<p>No.  I'm out of the loop.  So Duper is a component of lean-auto?  Is lean-auto like a Sledgehammer converting the goal and a large list of possible lemmas to FOL, sending it to an ATP, reading the lemmas needed to solve the goal, and reconstructing the proof with Duper and the selected lemmas?</p>",
        "id": 408644963,
        "sender_full_name": "Jason Rute",
        "timestamp": 1702916572
    },
    {
        "content": "<p>That's the plan. It is not yet complete.</p>",
        "id": 408645108,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1702916621
    },
    {
        "content": "<p>Teaser: you will learn a lot more during LT2024 which features a double talk on duper and auto.</p>",
        "id": 408645246,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1702916651
    },
    {
        "content": "<p>I have a very naive question (coming from my lack of a good conceptual model of how github really works).  For a collaborative formalization project run out of a Github repository, would each participant need to install such a tool separately, or is the installation done entirely within the repository, so that once an administrator installs the tool in the master repository, all participants automatically gain access to the tool after synchronizing with the master?  One could imagine a division of labor emerging in a large project where some participants (who for whatever reason are not able or willing to use these tools) would speed up their coding by leaving lots of <code>sorry</code>s for routine \"this is obvious\" steps, and having other participants who are expert in these automated tools (and have the GPUs to run them quickly) then come in and try to fill them in efficiently.</p>",
        "id": 408647695,
        "sender_full_name": "Terence Tao",
        "timestamp": 1702917442
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"115715\">Jason Rute</span> <a href=\"#narrow/stream/113488-general/topic/Duper/near/408641947\">said</a>:</p>\n<blockquote>\n<p>This is really interesting.  Do you have any idea how good it is alone?  For example <span class=\"user-mention silent\" data-user-id=\"110087\">Scott Morrison</span> made a way to benchmark solvers like this.  I'd love a comparison to Aesop and to AI-based tools like LLM-Step and Lean Copilot.  (And yes, it is tricky to compare AI tools since they have been trained.)</p>\n</blockquote>\n<p>I'm not familiar with the technique of Scott's that you're referring to, but would be happy to look into it if you send a link. I haven't interacted much with LLM-Step or Lean Copilot, so I couldn't speak to that comparison at all at this point. I've used Aesop a little bit, but I understand that Aesop benefits a lot from knowing how to tweak options and add rules, so I wouldn't claim to be using Aesop to its full potential.</p>\n<p>Still, in my anecdotal experience, I think that currently, Aesop and Duper excel on different sorts of problems. I would expect Aesop to be better than Duper on problems that are particularly far from first or higher order logic (e.g. problems centering on inductive types) and I would expect Duper to be better on problems that require a significant amount of native reasoning (e.g. problems that involve combining hypotheses in a variety of ways as opposed to primarily applying rules to the target).</p>",
        "id": 408647980,
        "sender_full_name": "Josh Clune",
        "timestamp": 1702917543
    },
    {
        "content": "<p>It's a global per-project install. It's like importing a file, but with extra steps. I don't think we can avoid rerunning <code>duper</code> incantations for some users only, though (except by telling them not to open/recompile the files containing the incantations). Certainly if you want to give it a try in PFR I can add it.</p>",
        "id": 408648178,
        "sender_full_name": "Yaël Dillies",
        "timestamp": 1702917611
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"657719\">@Terence Tao</span> Some of these tools replace the tool call with proofs that run without the tool, so one doesn't need the tool to run the proof.  This is especially important if the tool takes a long time, or uses external software like an automatied theorem prover or a neural network.  I think Isabelle's sledgehammer does this for example, and the AI theorem provers like Lean Copilot also do this.  Now, some of these generated proofs are more readable and maintainable than others.  I imagine (without knowing for sure) that lean-auto calls will be replaced with duper tactics, but that will still require having duper installed which isn't as bad as lean-auto since it doesn't use any external tools.</p>",
        "id": 408648613,
        "sender_full_name": "Jason Rute",
        "timestamp": 1702917782
    },
    {
        "content": "<p>I think I'll start a separate thread in PFR to gauge interest amongst the contributors if they want to experiment with Duper or any other automation tool.  Given that PFR has already achieved its primary goal and is now just pursuing secondary goals, I think we can afford to try some experimental tools even if there is a risk that the project could be slowed down or temporarily broken due to a botched install or something.</p>",
        "id": 408648862,
        "sender_full_name": "Terence Tao",
        "timestamp": 1702917872
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"115715\">Jason Rute</span> <a href=\"#narrow/stream/113488-general/topic/Duper/near/408648613\">said</a>:</p>\n<blockquote>\n<p>I imagine (without knowing for sure) that lean-auto calls will be replaced with duper tactics, but that will still require having duper installed which isn't as bad as lean-auto since it doesn't use any external tools.</p>\n</blockquote>\n<p>I can confirm that eventually, <code>auto</code> calls (from lean-auto) should be transformable into Duper calls. Using <code>auto</code> would likely require having and installing external tools, but using Duper wouldn't, so although there might be some individuals that can more easily use <code>auto</code> (because they have the external tools), once the <code>auto</code> calls are transformed to <code>duper</code> calls, any Lean user should be able to use the file.</p>",
        "id": 408649783,
        "sender_full_name": "Josh Clune",
        "timestamp": 1702918219
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"657719\">@Terence Tao</span>  Also, you mention GPUs, but to be clear, I don't think duper or lean-auto use GPUs at all since they don't use neural networks.  Duper is just a tactic I think.  Lean-auto uses external first-order logic automated theorem provers.  Lean Copilot (<a class=\"stream-topic\" data-stream-id=\"219941\" href=\"/#narrow/stream/219941-Machine-Learning-for-Theorem-Proving/topic/LeanCopilot\">#Machine Learning for Theorem Proving &gt; LeanCopilot</a>) and <a href=\"https://github.com/wellecks/llmstep\">LLM-step</a> can however use GPUs if I understand correctly since they are based on locally running large language models.  They are two very different approaches to the same problem, automating the \"easy stuff\".</p>",
        "id": 408649969,
        "sender_full_name": "Jason Rute",
        "timestamp": 1702918293
    },
    {
        "content": "<p>Ah thanks for clarifying.  If it is \"just\" a tactic then it seems like there is less downside to including it in a project where many of the contributors may not actually want to use the tool and don't want the project to accidentally melt their laptops through excessive CPU usage or something.</p>",
        "id": 408650408,
        "sender_full_name": "Terence Tao",
        "timestamp": 1702918463
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"115715\">Jason Rute</span> <a href=\"#narrow/stream/113488-general/topic/Duper/near/408643100\">said</a>:</p>\n<blockquote>\n<p>Also, you talk about making a Sledgehammer clone, but have you also thought about a MagnusHammer (<a class=\"stream-topic\" data-stream-id=\"219941\" href=\"/#narrow/stream/219941-Machine-Learning-for-Theorem-Proving/topic/New.20paper.3A.20Magnushammer\">#Machine Learning for Theorem Proving &gt; New paper: Magnushammer</a>) clone as well? </p>\n</blockquote>\n<p>I wouldn't be opposed to exploring something like this down the line, but for now, I think there are good technical reasons for pursuing a sledgehammer clone before a magnushammer clone. One of the issues, as you mentioned, is that we don't have any existing data of Duper being used. Another issue is that currently, Duper is pretty sensitive to receiving just the facts that it needs to prove the goal (given too many facts, Duper can very easily spend all of its time proving irrelevant things and time out). That's an aspect of Duper I'm currently working to improve, but as long as that's the case, I expect that a sledgehammer which is able to provide the exact list of facts an external prover needed is more likely to successfully call Duper than just a lemma selection tool.</p>",
        "id": 408651190,
        "sender_full_name": "Josh Clune",
        "timestamp": 1702918719
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"436568\">@Josh Clune</span> Is that different than what Sledgehammer uses?  Is the METIS tactic (or whatever) behind Sledgehammer less susceptible to extra premises?</p>",
        "id": 408651595,
        "sender_full_name": "Jason Rute",
        "timestamp": 1702918854
    },
    {
        "content": "<p>Currently, yes. I think that has more to do with tuning and heuristics that Metis has that Duper doesn't yet have rather than any fundamental difference in approach though. My hope and intention is that Duper will get better on this front.</p>",
        "id": 408652367,
        "sender_full_name": "Josh Clune",
        "timestamp": 1702919048
    },
    {
        "content": "<p>Sorry for the naive question: I have no idea what Isabelle's Metis tactic does or what we can expect <code>duper</code> to do, and I don't know what a \"superposition solver\" is. My mental model of <code>aesop</code> is that it will <code>rewrite</code> or <code>apply</code> lemmas which have been tagged with <code>aesop_rule</code>. What should my mental model of a superposition solver be?</p>",
        "id": 408657705,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1702920946
    },
    {
        "content": "<p>My mental model is: you give it (explicitly) a bag of lemmas, and it proves the goal using them.</p>",
        "id": 408657949,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1702921025
    },
    {
        "content": "<p>(Or fails, if you gave a bag that is too small or too large.)</p>",
        "id": 408657993,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1702921042
    },
    {
        "content": "<p>So what's the difference between it and <code>aesop</code>?</p>",
        "id": 408658018,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1702921053
    },
    {
        "content": "<p>In Isabelle, you typically use sledgehammer to find a good bag of lemmas, and sledgehammer will spit out a line of the form <code>metis [lemma_1, ..., lemma_10]</code>.</p>",
        "id": 408658138,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1702921094
    },
    {
        "content": "<p>I'm not the right person to comment on the different between <code>aesop</code> and <code>duper</code>.</p>",
        "id": 408658211,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1702921124
    },
    {
        "content": "<p>I think it also has to follow from first order reasoning.  I don't think it will do induction or anything else higher order even if it is trivial (but that is just a guess from similar tactics I've seen in HOL Light).</p>",
        "id": 408660396,
        "sender_full_name": "Jason Rute",
        "timestamp": 1702921929
    },
    {
        "content": "<p>Duper has some higher order capabilities.</p>",
        "id": 408660510,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1702921980
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110038\">Kevin Buzzard</span> <a href=\"#narrow/stream/113488-general/topic/Duper/near/408657705\">said</a>:</p>\n<blockquote>\n<p>Sorry for the naive question: I have no idea what Isabelle's Metis tactic does or what we can expect <code>duper</code> to do, and I don't know what a \"superposition solver\" is. My mental model of <code>aesop</code> is that it will <code>rewrite</code> or <code>apply</code> lemmas which have been tagged with <code>aesop_rule</code>. What should my mental model of a superposition solver be?</p>\n</blockquote>\n<p>I'm planning on giving a talk at LeanTogether 2024 that will help clarify a lot of this, but in the meantime, here's the gist: Duper will start with the facts that it is given and a target it is trying to prove. The first thing it'll do is try to transform the facts it has and the target its trying to prove into a mostly first-order problem. Then it'll assume the target's negation, take it as fact, and try to prove a contradiction. Duper will repeatedly take facts that it knows and try to combine them with a variety of rules that can be justified with mostly first order reasoning (though as Patrick said, Duper can do some higher order stuff as well). As Duper chugs along, it'll generate more and more facts until eventually, it derives a contradiction, times out, or 'saturates' (meaning it cannot generate more facts).</p>\n<p>Currently, Duper won't do any special domain-specific reasoning (unless it is explicitly provided the lemmas necessary to do so), it won't do induction, and it only knows facts that are specifically provided to it. As far as the difference between Duper and Aesop, the fundamental approach is pretty different so there are just different problems that the two tactics are well-suited for. I hesitate to make any strong claims of Aesop's capabilities because I'm not a power-user of Aesop, but my anecdotal experience is that I would expect Aesop to be better than Duper on problems that are particularly far from first or higher order logic (e.g. problems centering on inductive types) and I would expect Duper to be better on problems that require a significant amount of native reasoning (e.g. problems that involve combining hypotheses in a variety of ways as opposed to primarily applying rules to the target).</p>",
        "id": 408662941,
        "sender_full_name": "Josh Clune",
        "timestamp": 1702922735
    },
    {
        "content": "<p>Here is a comment not specific to Duper, but which harks back to Jason's recent comment on the LeanCopilot thread that we have all been \"spoiled by github copilot\". If I am using my serious home desktop to write Lean code then I would love to have <code>hint</code> running in the background and literally interrupting me (as GH Copilot does) saying \"how about this?\". However in contrast to Copilot it could only interrupt when it has actually found a proof, so basically telling me \"OK I can close the goal from here\". </p>\n<p>However it seems to me that <code>duper</code> as it stands would not be a good fit for this, because I need to feed it the right lemmas, and this is what Isabelle's Sledgehammer does (and what we currently don't have). Is that correct? So, for example, right now to use <code>duper</code> to good effect I need to manually tell it all the lemmas which I think might be useful?</p>",
        "id": 408663636,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1702922971
    },
    {
        "content": "<p>I agree that Duper as it currently stands wouldn't be a good fit for this, but that down the line, <code>auto</code> from lean-auto might be.</p>",
        "id": 408663891,
        "sender_full_name": "Josh Clune",
        "timestamp": 1702923080
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110038\">Kevin Buzzard</span> <a href=\"#narrow/stream/113488-general/topic/Duper/near/408663636\">said</a>:</p>\n<blockquote>\n<p>Here is a comment not specific to Duper, but which harks back to Jason's recent comment on the LeanCopilot thread that we have all been \"spoiled by github copilot\". If I am using my serious home desktop to write Lean code then I would love to have <code>hint</code> running in the background and literally interrupting me (as GH Copilot does) saying \"how about this?\". However in contrast to Copilot it could only interrupt when it has actually found a proof, so basically telling me \"OK I can close the goal from here\". </p>\n<p>However it seems to me that <code>duper</code> as it stands would not be a good fit for this, because I need to feed it the right lemmas, and this is what Isabelle's Sledgehammer does (and what we currently don't have). Is that correct? So, for example, right now to use <code>duper</code> to good effect I need to manually tell it all the lemmas which I think might be useful?</p>\n</blockquote>\n<p>yes, roughly speaking sledgehammer in Isabelle works like this: take Isabelle theorem statement and translate it to an SMT problem (SMT is basically \"smoosh together a whole lot of automated, domain specific and general reasoning procedures in a single tool\"). Then they run that problem against an SMT solver like Z3 and based on its results (these results have no formal proof attached so we cannot trust them) feed a superposition prover (for Isabelle that's metis, for us that will be duper as I understand) with a list of theorems to use. And then that superposition prover spits out an Isabelle proof that their kernel can check.</p>\n<p>I don't know about the intentions of the people working on this stuff but I would guess that some similar architecture might be planned, given the sledgehammer success? Maybe someone can comment on that.</p>",
        "id": 408666893,
        "sender_full_name": "Henrik Böving",
        "timestamp": 1702924337
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"395550\">Henrik Böving</span> <a href=\"#narrow/stream/113488-general/topic/Duper/near/408666893\">said</a>:</p>\n<blockquote>\n<p>I don't know about the intentions of the people working on this stuff but I would guess that some similar architecture might be planned, given the sledgehammer success? Maybe someone can comment on that.</p>\n</blockquote>\n<p>Yes, <code>auto</code> from <a href=\"https://github.com/leanprover-community/lean-auto/\">lean-auto</a> is working in that direction.</p>",
        "id": 408667499,
        "sender_full_name": "Josh Clune",
        "timestamp": 1702924576
    },
    {
        "content": "<p>But auto is a bit different in that it is trying to reconstruct a proof from Z3 directly without duper right?</p>",
        "id": 408667596,
        "sender_full_name": "Henrik Böving",
        "timestamp": 1702924627
    },
    {
        "content": "<p>That is also a direction that's being explored, but <code>auto</code> can already call Duper itself. Directly reconstructing proofs from external provers is strictly more work than gaining enough information from external provers to call Duper, so in the long run, one goal is to have <code>auto</code> be the analogue to sledgehammer with Duper as the analogue to Metis, and another (perhaps subsequent) goal is to have <code>auto</code> capable of directly reconstructing proofs from external provers. I don't anticipate a future where the latter goal is possible but the former isn't.</p>",
        "id": 408668929,
        "sender_full_name": "Josh Clune",
        "timestamp": 1702925239
    },
    {
        "content": "<p>Just a quick question about naming, is <code>duper</code> meant to be <code>dependent + super</code>, or have I missed the boat completely?</p>",
        "id": 408669744,
        "sender_full_name": "Jireh Loreaux",
        "timestamp": 1702925605
    },
    {
        "content": "<p>That would make a lot of sense, but no. Duper is named that just because it's the spiritual successor to Lean 3's <a href=\"https://github.com/leanprover/super\">super</a> and the phrase \"super duper\" exists. It's not deep at all, but maybe I'll retroactively decide that the d in Duper stands for dependent.</p>",
        "id": 408670159,
        "sender_full_name": "Josh Clune",
        "timestamp": 1702925781
    },
    {
        "content": "<p>Re: the tactic benchmarking tool mentioned above.</p>\n<p>What I have right now is a lame prototype. In January I'm hoping to write something much better.</p>\n<p>What currently exists is documented in the <a href=\"https://github.com/semorrison/lean-training-data?tab=readme-ov-file#tactic_benchmark\"><code>lean-training-data</code></a> repository.</p>\n<p>It allows you to run a specified tactic against every declaration in a file, or the whole library.</p>\n<p>Sample output running on a single file:</p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"bp\">%</span> <span class=\"n\">lake</span> <span class=\"n\">exe</span> <span class=\"n\">tactic_benchmark</span> <span class=\"c1\">--aesop Mathlib.Topology.ContinuousFunction.Ordered</span>\n<span class=\"n\">Mathlib.Topology.ContinuousFunction.Ordered</span> <span class=\"mi\">7</span> <span class=\"mi\">21</span>\n<span class=\"bp\">❌</span> <span class=\"n\">ContinuousMap.abs</span> <span class=\"o\">(</span><span class=\"mi\">0</span><span class=\"bp\">.</span><span class=\"mi\">006912</span><span class=\"n\">s</span><span class=\"o\">)</span> <span class=\"o\">(</span><span class=\"mi\">111</span> <span class=\"n\">heartbeats</span><span class=\"o\">)</span>\n<span class=\"bp\">❌</span> <span class=\"n\">ContinuousMap.instAbsContinuousMap</span> <span class=\"o\">(</span><span class=\"mi\">0</span><span class=\"bp\">.</span><span class=\"mi\">007926</span><span class=\"n\">s</span><span class=\"o\">)</span> <span class=\"o\">(</span><span class=\"mi\">115</span> <span class=\"n\">heartbeats</span><span class=\"o\">)</span>\n<span class=\"bp\">✅</span> <span class=\"n\">ContinuousMap.abs_apply</span> <span class=\"o\">(</span><span class=\"mi\">0</span><span class=\"bp\">.</span><span class=\"mi\">027873</span><span class=\"n\">s</span><span class=\"o\">)</span> <span class=\"o\">(</span><span class=\"mi\">401</span> <span class=\"n\">heartbeats</span><span class=\"o\">)</span>\n<span class=\"bp\">❌</span> <span class=\"n\">ContinuousMap.partialOrder</span> <span class=\"o\">(</span><span class=\"mi\">0</span><span class=\"bp\">.</span><span class=\"mi\">008932</span><span class=\"n\">s</span><span class=\"o\">)</span> <span class=\"o\">(</span><span class=\"mi\">105</span> <span class=\"n\">heartbeats</span><span class=\"o\">)</span>\n<span class=\"bp\">✅</span> <span class=\"n\">ContinuousMap.le_def</span> <span class=\"o\">(</span><span class=\"mi\">0</span><span class=\"bp\">.</span><span class=\"mi\">071422</span><span class=\"n\">s</span><span class=\"o\">)</span> <span class=\"o\">(</span><span class=\"mi\">984</span> <span class=\"n\">heartbeats</span><span class=\"o\">)</span>\n<span class=\"bp\">...</span>\n</code></pre></div>\n<p>(Here the <code>7 21</code> on the first output line is cryptically saying that <code>aesop</code> can generate a term of the specified type for 7 out of the 21 declarations in <code>Mathlib.Topology.ContinuousFunction.Ordered</code>. Note that it is trying to prove <code>def</code>s<code> as well as </code>theorem`s!)</p>\n<p>Running on an entire library you can get output like:</p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"n\">Solved</span> <span class=\"kd\">by</span> <span class=\"n\">aesop</span><span class=\"o\">:</span>  <span class=\"mi\">21013</span> <span class=\"bp\">/</span> <span class=\"mi\">151756</span>  <span class=\"k\">in</span>  <span class=\"mi\">19938</span><span class=\"n\">s</span>\n  <span class=\"n\">but</span> <span class=\"n\">not</span> <span class=\"n\">exact</span><span class=\"bp\">?</span><span class=\"o\">:</span>  <span class=\"mi\">5466</span>\n  <span class=\"n\">but</span> <span class=\"n\">not</span> <span class=\"n\">rfl</span><span class=\"o\">:</span>  <span class=\"mi\">6731</span>\n  <span class=\"n\">but</span> <span class=\"n\">not</span> <span class=\"n\">simp_all</span><span class=\"o\">:</span>  <span class=\"mi\">15106</span>\n</code></pre></div>\n<p>Future improvements:</p>\n<ul>\n<li>Currently this only runs at declaration level, but we should run at every goal.</li>\n<li>Currently testing new tactics requires modifying the executable!</li>\n<li>Currently there is no way to filter goals (either by properties of the goal itself, or properties of how it was closed in the library)</li>\n<li>Currently you just get the binary information \"did it succeed\", and can't get answers to questions like \"is <code>aesop</code> or <code>hint</code> faster on this goal?\"</li>\n</ul>\n<p>I want to make all of these improvements, and make it easy to ask questions like:</p>\n<ul>\n<li>Of all goals appearing in the library, which ones are closed by <code>auto</code> <em>faster</em> than the existing proof.</li>\n<li>Of all goals appearing in the library which are solved by a <code>simp only</code>, which ones still work replacing <code>simp only</code> with <code>simp_rw</code></li>\n<li>...</li>\n</ul>",
        "id": 408704081,
        "sender_full_name": "Scott Morrison",
        "timestamp": 1702943171
    },
    {
        "content": "<p>5 messages were moved from this topic to <a class=\"stream-topic\" data-stream-id=\"113488\" href=\"/#narrow/stream/113488-general/topic/Duper.20on.20v4.2E4.2E0-rc1\">#general &gt; Duper on v4.4.0-rc1</a> by <span class=\"user-mention silent\" data-user-id=\"296911\">Utensil Song</span>.</p>",
        "id": 408781122,
        "sender_full_name": "Notification Bot",
        "timestamp": 1702963076
    },
    {
        "content": "<p>It looks like Lean's not differentiating between architectures has come back to bite a little here: I am on ARM64 MacOS, but the cloud release downloaded by Lake seems to have been built on x86. Importing Duper fails with a linker error, and the solution is a bit roundabout: <code>rm -r .lake/packages/Duper/.lake/build/lib</code>.</p>",
        "id": 409021173,
        "sender_full_name": "Wojciech Nawrocki",
        "timestamp": 1703022463
    },
    {
        "content": "<p>Yikes! Thanks for posting about it. I've removed the most recent MacOS asset so hopefully, even if it takes longer to build the first time, others that try to build on an ARM64 Mac won't encounter any errors.</p>",
        "id": 409046467,
        "sender_full_name": "Josh Clune",
        "timestamp": 1703034232
    }
]