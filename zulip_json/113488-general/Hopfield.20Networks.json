[
    {
        "content": "<p>Hi!</p>\n<p>I'd like to share my repository NeuralNetworks, which formalizes Hopfield networks in Lean 4.</p>\n<p>(J. Hopfield showed in 1982 that \"Computational properties of use to biological organisms or to the construction of computers can emerge as collective properties of systems having a large number of simple equivalent components (or neurons)...\" and won the 2024 Nobel prize in physics for this, jointly with G. Hinton). </p>\n<p><a href=\"https://github.com/or4nge19/NeuralNetworks\">https://github.com/or4nge19/NeuralNetworks</a></p>\n<p>The core contribution is a collection of sorry-free proofs establishing fundamental properties of discrete deterministic symmetric Hopfield networks, specifically:</p>\n<ol>\n<li>Monotonic energy decrease during network updates</li>\n<li>Convergence to stable states under the assumptions of zero thresholds</li>\n</ol>\n<p>The formalization introduces a framework with:</p>\n<ul>\n<li>A <code>SpinState</code> type for neural activation states</li>\n<li><code>HopfieldState</code> configurations with associated energy functions</li>\n<li>Update sequences with well-founded termination arguments</li>\n<li>Proofs of fixed-point stability using energy Lyapunov functions</li>\n</ul>\n<p>Here's a summary of key files and their status:<br>\n<strong>Sorry-Free Core Files:</strong></p>\n<ul>\n<li><code>Hopfield/Basic.lean</code>: Defines the fundamental structures (SpinState, HopfieldState, HopfieldNetwork) with metrics and operations</li>\n<li><code>Hopfield/Energy.lean</code>: Proves energy monotonicity theorems for symmetric networks with zero thresholds</li>\n<li><code>Hopfield/Convergence.lean</code>: Proves convergence to fixed points using well-founded induction on the energy function</li>\n<li>\n<p><code>Hopfield/StochasticUpdate.lean</code>: Provides the foundational stochastic update framework using probability mass functions (implementation is complete but not yet connected to convergence results)<br>\n<strong>In-Progress Extensions:</strong></p>\n</li>\n<li>\n<p><code>Hopfield/Biased.lean</code>: Generalizes to non-zero thresholds (partially complete)</p>\n</li>\n<li><code>Hopfield/Hebbian/*.lean</code>: Implements Hebbian learning with pattern storage theorems (contains sorries for capacity bounds)</li>\n<li><code>Hopfield/Asymmetric.lean</code>: Addresses asymmetric weight matrices with stability analysis</li>\n<li><code>ForMathlib/MetropolisHastings.lean</code>: Generalizes sampling algorithms (contains sorries in measure-theoretic proofs)</li>\n</ul>\n<p>While the energy functions and update sequences are currently noncomputable, I believe (hope?) they could be made computable with <span class=\"user-mention\" data-user-id=\"448405\">@Alex Meiburg</span>  's ComputableReals library, enabling simulations within Lean .</p>\n<p>To my knowledge, this represents the first formalization of Hopfield networks in a theorem prover. I'm drafting a manuscript on this work and would welcome critical feedback from the community. Contributions are most welcome, particularly in extending the formalization to broader neural network classes or making components executable.<br>\nThanks to <span class=\"user-mention\" data-user-id=\"749593\">@Britt Anderson</span>  for sparking the idea (here: <a class=\"stream-topic\" data-stream-id=\"113488\" href=\"/#narrow/channel/113488-general/topic/Computational.20Neuroscience.20in.20Lean.3F/with/469405916\">#general &gt; Computational Neuroscience in Lean?</a> ) and for encouragement during the development.</p>",
        "id": 505876337,
        "sender_full_name": "Matteo Cipollina",
        "timestamp": 1742065546
    },
    {
        "content": "<p>Interesting to see this! We have also formalized Hopfield networks with a different approach. Repo here: <a href=\"https://github.com/mkaratarakis/HopfieldNet\">https://github.com/mkaratarakis/HopfieldNet</a>. Happy to discuss further!</p>",
        "id": 505887199,
        "sender_full_name": "Michail Karatarakis",
        "timestamp": 1742074120
    },
    {
        "content": "<p>Same here! At a quick glance the two repos seems complementary which would be great, mine more abstract and yours showing a rich implementation of hebbian rule.</p>",
        "id": 505891289,
        "sender_full_name": "Matteo Cipollina",
        "timestamp": 1742077589
    },
    {
        "content": "<p>Here are a few impressions after going through the HopfieldNet repo. <br>\nIt seems to complement well and that we have saved each other time in our next development steps: mine has an emphasis on building a strictly hopfield framework as powerful, flexible and mathlib integrated as possible and with an eye on mathematical 'depth' though not yet 'generality' (this allowed me to build more extensions like stochastic and not be constrained to the specific proofs chosen by a specific text), yours follows a cohesive and self-contained textbook implementation (but perhaps more constrained), where hopfield networks are restriction of general networks defined in terms of graphs. I have chosen to generalize towards category theory afterwards, as well as towards statistical mechanics (Isin spin glasses, etc), possibly contributing that t PhysLib. <br>\nIn this view these definitely need to be unified. While merging would be the ultimate goal, for the time being, I will try to prove equivalence lemmas between the two. For possible proof of isomorphism, I need to work out an implementation of ComputableReals but still equivalence should be enough.</p>\n<p>In short and with some simplifications how I see the integration is: \"here is the Theory\" (modular, felxible to adapt formalization of specific research level models)(my NeuralNetworks.Hopfield); \"here is a self-contained and workable classic Hopfield model with full parameters to run (your HN); plus your NN as Core.lean file pointing towards Category Theory</p>",
        "id": 506162248,
        "sender_full_name": "Matteo Cipollina",
        "timestamp": 1742220425
    },
    {
        "content": "<p>I'm happy to help if you want to use ComputableReals! but I will caution that I'm not sure they will do well for your purpose - and, I'm not sure exactly what your goal is.</p>\n<p>Is your goal to make a Lean program that can train and run a Hopfield network? Because in that sense, proofs in Lean (the programming language) are \"optional\" in the end. More likely than not, using Mathlib's <code>Real</code> type will be the wrong choice, since you probably want some finite data representation of things, like rational numbers maybe.</p>\n<p>If you want to accompany that with proofs, then you'll need to think about whether the update sequence is deterministic or random - and if it's random, then how you source the randomness (in a 'safe' provable way).</p>\n<p>ComputableReal was designed for tasks of the form, \"I want to prove such-and-such real inequality is true\". I could forsee it being useful if you want to <em>prove</em> that some particular rational-number implementation correctly reflects a real-number theory, or if the definition of your system has reals really baked in. For instance, if you wanted to implement a Boltzmann machine, then you can't really avoid using <code>Real.exp</code>, which is inherently going to mean that you need to use reals.</p>\n<p>Unless I'm mistaken, though, Hopfield networks can be nicely described entirely using rational numbers and rational arithmetic. If you have an eye towards producing an implementation, I might start by looking at whether you can change Real to Rat everywhere, and see if anything breaks.</p>",
        "id": 506168131,
        "sender_full_name": "Alex Meiburg",
        "timestamp": 1742221663
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"448405\">Alex Meiburg</span> <a href=\"#narrow/channel/113488-general/topic/Hopfield.20Networks/near/506168131\">ha scritto</a>:</p>\n<blockquote>\n<p>For instance, if you wanted to implement a Boltzmann machine, then you can't really avoid using <code>Real.exp</code>, which is inherently going to mean that you need to use reals.</p>\n</blockquote>\n<p>Indeed this is the reason I'm hoping to make use of ComputableReals, to be able to formalize and somewhat at some point run also Boltzmann Machines (extending hopfield ones) and in general advanced stochastic models. From my side, I wanted to have a code framework which is as powerful as possible from the start so I need reals (Michail did differently). (you can see I have started a framework of implementation for stochastic update).</p>",
        "id": 506171156,
        "sender_full_name": "Matteo Cipollina",
        "timestamp": 1742222273
    },
    {
        "content": "<p>Ah, I see it now, ok! Well then I think the biggest hurdle will be integrating a random number generator (I guess using <a href=\"https://leanprover-community.github.io/mathlib4_docs/find/?pattern=Random#doc\">docs#Random</a> ) and then the whole run will be some monad, either over <code>IO</code> or at least over a <code>RandomGen</code>. And then you can prove that, assuming the random number generator is uniformly random and iid, this is all correct?</p>\n<p>I actually don't see anything in Batteries/Mathlib about \"correctness\" of random number generators, which is kind of surprising - maybe that can be found in some other downstream crypto-oriented library though. (The crypto-lean4 library <a href=\"https://github.com/search?q=repo%3Afunctionally%2Fcrypto-lean4%20random&amp;type=code\">looks promising</a>.)</p>\n<p>I guess I could add a <code>BoundedRandom Real</code> based on <code>split</code>ting the random number generator, and then there would be a <code>ComputableReal</code> instance for such reals. And then values like <code>Real.exp (Random.randReal ...)</code>could be processed too. I don't know much about this API though.</p>",
        "id": 506181828,
        "sender_full_name": "Alex Meiburg",
        "timestamp": 1742224516
    },
    {
        "content": "<p>How much are you hoping that the randomness is provably correct? vs. just proving the theoretical properties of Hopfield networks, and just plugging in _some_ source of randomness?</p>",
        "id": 506181943,
        "sender_full_name": "Alex Meiburg",
        "timestamp": 1742224545
    },
    {
        "content": "<p>Are there any statements of correctness of random number generators that aren't either false or imply <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>P</mi><mo mathvariant=\"normal\">≠</mo><mi>N</mi><mi>P</mi></mrow><annotation encoding=\"application/x-tex\">P \\ne NP</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">P</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\"><span class=\"mrel\"><span class=\"mord vbox\"><span class=\"thinbox\"><span class=\"rlap\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"inner\"><span class=\"mord\"><span class=\"mrel\"></span></span></span><span class=\"fix\"></span></span></span></span></span><span class=\"mrel\">=</span></span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">NP</span></span></span></span> if true? PRNGs are a myth AFAICT</p>",
        "id": 506183737,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1742224908
    },
    {
        "content": "<p>\"Correctness\" in the sense that \"If the <code>RandomGen</code> instance produced iid uniformly random bits, then this function produces iid values from distribution <code>f</code>.\" Like, the <a href=\"https://leanprover-community.github.io/mathlib4_docs/find/?pattern=Random.instBoundedRandomFin#doc\">docs#Random.instBoundedRandomFin</a> appears to have no such guarantees proved anywhere -- I could easily make an instance that always returned the minimum value of the range, which would be a \"bad\" <code>Random</code> instance.</p>\n<p>(The actual implementations in Init/Mathlib all appear 'correct' in this sense, but it's just not stated anywhere.)</p>",
        "id": 506184180,
        "sender_full_name": "Alex Meiburg",
        "timestamp": 1742225007
    },
    {
        "content": "<p>There is something sort of in this direction at <a href=\"https://github.com/dtumad/VCV-io/blob/62413c72b84b57f8c1332237c81bf99977dc8567/VCVio/OracleComp/DistSemantics/EvalDist.lean\">https://github.com/dtumad/VCV-io/blob/62413c72b84b57f8c1332237c81bf99977dc8567/VCVio/OracleComp/DistSemantics/EvalDist.lean</a> but that is mostly using the <code>PMF</code> API to describe crypto operations more \"in theory\", afaict.</p>",
        "id": 506200520,
        "sender_full_name": "Alex Meiburg",
        "timestamp": 1742228187
    },
    {
        "content": "<p>I just realized that essentially the same topic is underway at <a class=\"stream-topic\" data-stream-id=\"113488\" href=\"/#narrow/channel/113488-general/topic/Proving.20things.20about.20functions.20using.20a.20PRNG.2E/with/505782698\">#general &gt; Proving things about functions using a PRNG.</a></p>\n<p>Someone there linked SampCert, which has exactly the kinds of proofs I was talking about: <a href=\"https://github.com/leanprover/SampCert/blob/main/SampCert/Samplers/Geometric/Properties.lean#L368\">https://github.com/leanprover/SampCert/blob/main/SampCert/Samplers/Geometric/Properties.lean#L368</a></p>",
        "id": 506216414,
        "sender_full_name": "Alex Meiburg",
        "timestamp": 1742232099
    },
    {
        "content": "<p>Thanks <span class=\"user-mention\" data-user-id=\"448405\">@Alex Meiburg</span> ! The current (sorry-free but idle) extension in Hopfield.StochasticUpdate and the WIP ForMathlib.MetropolisHastings do not connect (yet) to a sample random generator. <br>\n<code>neuronUpdatePMF</code> in in Hopfield.StochasticUpdate constructs probability distributions over spin states using the Boltzmann distribution<br>\nIn general, I believe developing a <code>BoundedRandom ComputableReal</code> instance to support the transcendental functions needed for Boltzmann machines could work here.<br>\nInteresting examples in the links, let's see if I can come up with a meaningful <code>RandomMonad</code> typeclass along the lines of what you suggest!</p>",
        "id": 506219587,
        "sender_full_name": "Matteo Cipollina",
        "timestamp": 1742232928
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"779253\">@Matteo Cipollina</span> this is great work!</p>",
        "id": 506369774,
        "sender_full_name": "Robert Joseph",
        "timestamp": 1742277079
    }
]