[
    {
        "content": "<p>Have people here already discussed the implications of the performance of Large Transformer models for Lean?<br>\nI believe applying this to Lean would immediately make formal proof verification the standard for mathematicians all over the world. It would absolutely abolish the rather steep learning curve Lean has.</p>\n<p>Recently Openai Codex/GitHub Copilot has been released. It is afaik a GPT trained on large databases of code in various languages together with natural langlish descriptions/comments.<br>\nIt shows remarkable capability of turning low to medium complexity natural language instructions into functioning code.<br>\nOn their youtube channel they have some demonstrations.</p>\n<p>Openai Codex has been said to excel at assisting with the small, fiddly details of programming.<br>\nFor programmers it seems like so far this is not ground breaking. My impressions are that the reasons are the following:<br>\n1) Programmers DON'T REALLY MIND dealing with these small details. They are fundamentally used to writing syntactically correct and semantically precise code.<br>\n2) The Model might write code that contains bugs. The programmer can not immediately verify that the model has succeeded at its task.<br>\n3) The Model might write code that is not very readable and general doesn't follow the practices the programmer uses.</p>\n<p>I believe that for mathematicians, all these three points are absolute non-issues!</p>\n<p>1) Mathematicians are the exact opposite, they usually ONLY talk in natural language about mathematics. 99% of mathematicians never even learn how to use a formal language.<br>\nAfter I learned basic lean, the biggest hurdle towards actually using it in practice for me was the fact that doing very simple things is fiddly and difficult. Using a continuity lemma or just rewriting a fraction can be really tought if you don't have the practice. Most mathematicians won't want to put in this practice. <br>\nBut in terms of understanding exactly these things are rather simple tasks for a Model like Openai Codex.</p>\n<p>2) In formal mathematics it can be immediately verified if the Model has managed to produce code that achieves the subgoal. The programmer does have to carefully check if the theorem and definition statements are correct, but if any proof works, then it just works. There are no bugs in Lean in this sense.</p>\n<p>3) I had the impression so far that code readability is not exactly seen as having a high priority in the lean community.</p>\n<p>So, what is needed to make this work? Obviously, a large database of formalized code.<br>\nFrom what I understand, it is important that the theorems and proof sit in juxtaposition with comments that describe in natural language what is going on. This helps the model learn to translate between natural language mathematics, and formal lean mathematics.<br>\nI'm sure Openai Codex/Github copilot was trained on an absolutely stupendously large codebase, but I think that with a few years of more data in the mathlib and more data efficient transformers, a first version can be running.</p>\n<p>Another extremely important point as to why Lean is in my opinion the perfect application for these large transformer models is that automatic data generation is possible.<br>\nWe have a small d of database of lean code but an enormous database of LaTeX files.<br>\nHaving a first version of such a transformer model working somewhat reliably, one can start to feed in textbooks and papers in LaTeX or some other typesetting language to turn them iinto formalized code. Correct formalization of theorems and definitions ahs to be manually verified, but proofs can be automatically checked. If the model manages to correctly formalize most of the proofs, a human only has to formalize the rest of them. In this sense the model can be used to generate more data on which it can be trained.</p>\n<p>I may be a little optimistic here, but I genuinely think that in terms of complexity, given a reasonable amount of data juxtaposing natural language mathematics, latex mathematics, and formal lean mathematics, the amount of understanding Openai Codex/Github copilot has demonstrated it can extract is easily sufficient to allow mathematicians to write lean code just by giving instructions like: \"Let epsilon be greater than zero and let x in X. Apply the previous lemma on  x and use continuity of F to take the limit.\"</p>\n<p>What do you think?</p>",
        "id": 250457839,
        "sender_full_name": "Golol",
        "timestamp": 1629795143
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"243838\">Golol</span> <a href=\"#narrow/stream/113488-general/topic/OpenAI.20Codex.20and.20Lean/near/250457839\">said</a>:</p>\n<blockquote>\n<p>2) In formal mathematics it can be immediately verified if the Model has managed to produce code that achieves the subgoal. The programmer does have to carefully check if the theorem and definition statements are correct, but if any proof works, then it just works. There are no bugs in Lean in this sense.</p>\n</blockquote>\n<p>Mostly yes, but definitions escape that pattern. It's very hard to know whether you got the right definition before proving what you want about it.</p>",
        "id": 250460471,
        "sender_full_name": "Yaël Dillies",
        "timestamp": 1629796918
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"387244\">Yaël Dillies</span> <a href=\"#narrow/stream/113488-general/topic/OpenAI.20Codex.20and.20Lean/near/250460471\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"243838\">Golol</span> <a href=\"#narrow/stream/113488-general/topic/OpenAI.20Codex.20and.20Lean/near/250457839\">said</a>:</p>\n<blockquote>\n<p>2) In formal mathematics it can be immediately verified if the Model has managed to produce code that achieves the subgoal. The programmer does have to carefully check if the theorem and definition statements are correct, but if any proof works, then it just works. There are no bugs in Lean in this sense.</p>\n</blockquote>\n<p>Mostly yes, but definitions escape that pattern. It's very hard to know whether you got the right definition before proving what you want about it.</p>\n</blockquote>\n<p>Do you mean this for creating new definitions, or formalizing existing definitions in lean?</p>",
        "id": 250461184,
        "sender_full_name": "Golol",
        "timestamp": 1629797421
    },
    {
        "content": "<p>Either. Mathematical definitions often have to undergo some adaptation due to technicalities.</p>",
        "id": 250462734,
        "sender_full_name": "Yaël Dillies",
        "timestamp": 1629798534
    },
    {
        "content": "<p>I think if you are just trying to port existing definitions into lean and you have already laid out the foundation of a theory, i.e. decided how the basic objects will look exactly in lean, making sure that the definitions in the rest of the theory are correct is not so hard.</p>",
        "id": 250464610,
        "sender_full_name": "Golol",
        "timestamp": 1629799846
    },
    {
        "content": "<p>This whole thing has been discussed many times already.</p>",
        "id": 250464736,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1629799954
    },
    {
        "content": "<p>Particularly in the context of recent advances with large transformer models? If not then I think it is worth a new discussion with this in mind. There is a difference to what I am saying and just \"Let's use machine learning on mathlib\".<br>\nThe point is not to use AI to generate proofs. The point is that it has now been demonstrated that these models can translate back and forth between natural language and several syntactic/formal languages (for statements with reasonable complexity).<br>\nI'd love to read previois discussions on this.<br>\nedit: Ah great, I've found it with search</p>",
        "id": 250465186,
        "sender_full_name": "Golol",
        "timestamp": 1629800336
    },
    {
        "content": "<p>Just to make this easier to find, the relevant prior discussions are in these places:</p>\n<ul>\n<li><a class=\"stream\" data-stream-id=\"219941\" href=\"/#narrow/stream/219941-Machine-Learning-for-Theorem-Proving\">#Machine Learning for Theorem Proving</a>  (Probably the best place to have these conversations)</li>\n<li><a class=\"stream\" data-stream-id=\"274007\" href=\"/#narrow/stream/274007-lean-gptf\">#lean-gptf</a> An application of large language models to Lean.  (Best location to discuss this particular project.)</li>\n<li>Search for \"codex\" to see similar discussions on OpenAI Codex and OpenAI copilot (as well as TabNine).  <a class=\"stream-topic\" data-stream-id=\"113488\" href=\"/#narrow/stream/113488-general/topic/github.20copilot\">#general &gt; github copilot</a> in particular has some good comments by Stan Polu at OpenAI about continuing support for Lean.</li>\n</ul>",
        "id": 250472442,
        "sender_full_name": "Jason Rute",
        "timestamp": 1629805556
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"115715\">Jason Rute</span> <a href=\"#narrow/stream/113488-general/topic/GPT-3.20codex.20for.20maths.3F/near/249314509\">said</a>:</p>\n<blockquote>\n<p>I don’t know enough about Codex yet, but you may be interested in Lean gpt-f which itself is a collaboration with Stan Polu at OpenAI.  Stan and Jesse Han and others are working on a number of projects applying AI to theorem proving.  Here are some resources on Lean gpt-f.</p>\n<ul>\n<li>stream: <a class=\"stream\" data-stream-id=\"274007\" href=\"/#narrow/stream/274007-lean-gptf\">#lean-gptf</a> </li>\n<li>paper: <a href=\"https://arxiv.org/abs/2102.06203\">https://arxiv.org/abs/2102.06203</a></li>\n<li>repo: <a href=\"https://github.com/jesse-michael-han/lean-gptf\">https://github.com/jesse-michael-han/lean-gptf</a></li>\n<li>short talk: <a href=\"https://iclr.cc/virtual/2021/workshop/2124#collapse-sl-3634\">https://iclr.cc/virtual/2021/workshop/2124#collapse-sl-3634</a></li>\n<li>long talk: <a href=\"https://m.youtube.com/watch?v=EXpmbAfBNnw\">https://m.youtube.com/watch?v=EXpmbAfBNnw</a></li>\n</ul>\n</blockquote>",
        "id": 250472541,
        "sender_full_name": "Jason Rute",
        "timestamp": 1629805610
    },
    {
        "content": "<p>Thanks! I am really happy to hear that this is being worked on. I really think that this is the key to Lean being widely adopted. I hope that this will allow future mathematicians to formalize proofs after only a very brief introduction into type theory.</p>",
        "id": 250476729,
        "sender_full_name": "Golol",
        "timestamp": 1629808018
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"243838\">Golol</span> <a href=\"#narrow/stream/113488-general/topic/Large.20transformer.20models.20like.20OpenAI.20Codex.20and.20Lean/near/250476729\">said</a>:</p>\n<blockquote>\n<p>I hope that this will allow future mathematicians to formalize proofs after only a very brief introduction into type theory.</p>\n</blockquote>\n<p>I have my doubts about this tbh, at least for the short to medium term. The idea that a future lean user won't have to think about all the small technical details anymore and just let a transformer model translate his natural language descriptions into valid lean code certainly is exciting. But what happens when the proof produced by the model doesn't work (as it certainly will at some point)? Then you'll have to start debugging, and for that you need a lot of experience in lean and type theory.</p>\n<p>I guess my point is: To use such a transformer model effectively, you'll need to have a very good intuition about what it can and can't do. I.e: Is this proof, written in natural language, precise enough so that this model can fill in the gaps and give me valid lean code? Or does it need more explaining? If so, which parts should I try to explain differently (more precisely), so that it works? To build this intuition requires lots of experience of dealing with small \"annoying\" details in a theorem prover. Details that a normal mathematician never thinks about, hence has no experience with explaining in a formal style. I myself consider myself very much at the beginning of building such an intuition, and I've been formalizing in lean for about half a year. So I believe the entry barrier will remain quite high, but I'd love to be proven wrong.</p>",
        "id": 250596497,
        "sender_full_name": "Justus Springer",
        "timestamp": 1629883182
    },
    {
        "content": "<p>I'm sure nothing of what I just wrote is new or hasn't already been said many times here in other discussions. I just felt compelled to counterbalance your arguments (which are certainly interesting) and say that, from what I've seen, evidence that AI can significantly lower the entry barrier for theorem provers is yet to be provided.</p>",
        "id": 250597933,
        "sender_full_name": "Justus Springer",
        "timestamp": 1629884187
    },
    {
        "content": "<p>Thanks, I didn't quite think about it like that. This of course also happens in programming. In this case people usually break down the problem into smaller pieces and give more detailled descriptions. So I could say the way I believe this would work in the end ideally is that<br>\n1) 19/20 times with moderately detailled proofs (Beginning/Medium undergread level) The model manages to prove your subgoal.<br>\n2) In the remaining cases, 19/20 times the model manages to prove your subgoal after you sat down and tried to break it into really small pieces.<br>\n3) For that 1 tricky proof out of 400 in the paper you'e trying to formalize you ask a Lean specialist friend.<br>\nOf course this is not an argument as we don't have any clear evidence. Just a description of how I think things could work. We'll find out I suppose.</p>",
        "id": 250736470,
        "sender_full_name": "Golol",
        "timestamp": 1629964528
    },
    {
        "content": "<p>By the way, you could replace ML by sledgehammer or other ATP in that description as well. It seems to work fairly well for the isabelle folks, but I don't think isabelle users are fooling themselves into thinking it's just like informal maths</p>",
        "id": 250736752,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1629964732
    },
    {
        "content": "<p>That's also a good point. I'd just like to emphasize once more that the core difference between a language model and other ATPs is that an ATP work with two things: A collection of known truths and a subgoal.<br>\nA natural language model works with three things: A collection of known truths, a subgoal, and a natural language instruction by the user.<br>\nThe task can be made easier for an ATP by increasing the known truths or simplifying the subgoal. For a natural language model you can also make it easier by giving more detailled instructions.</p>",
        "id": 250739806,
        "sender_full_name": "Golol",
        "timestamp": 1629966661
    },
    {
        "content": "<p>This point about \"instruction by the user\" is an excellent reminder that if we write good comments in all of our (formal) proofs, this good training data for ML models, as well as helpful for the humans today.</p>\n<p>In particular, if we hope to be able to give natural language prompts to descendants of lean-gptf, it is going to need (want?) aligned training data: interspersed NL comments and formal tactic invocations are perfect.</p>",
        "id": 250741971,
        "sender_full_name": "Scott Morrison",
        "timestamp": 1629967909
    },
    {
        "content": "<p>I think we should rather have a tool that produces the natural language comments from the tactic scripts (including variations), probably rather in Lean 4 than in Lean 3. If this isn't possible because our tactics do too many different things (to the point that even a meta-program that has access to the goal before and after running the tactic can't write a sentence about it) then I interpret it as a signal that our tactics are too versatile and we should use more specialized versions that would be nicer even for regular readers.</p>",
        "id": 250742472,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1629968209
    },
    {
        "content": "<p>Independently from machine learning, generating that kind of text is part of my big dream of a next generation math document anyway.</p>",
        "id": 250742547,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1629968263
    }
]