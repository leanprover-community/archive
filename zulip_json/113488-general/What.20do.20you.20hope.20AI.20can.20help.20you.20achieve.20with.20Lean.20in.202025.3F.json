[
    {
        "content": "<p>What do you hope AI can help you achieve with Lean in 2025? e.g. code completion, documentation, code refactoring, etc. These suggestions will provide valuable guidance to developers of AI systems for Lean. <span aria-label=\"smile\" class=\"emoji emoji-1f642\" role=\"img\" title=\"smile\">:smile:</span></p>",
        "id": 489818457,
        "sender_full_name": "Huajian Xin",
        "timestamp": 1734546717
    },
    {
        "content": "<p>Some sort ai based refactoring and metaproggraming capabilities. so that we can feed in a paper and get a bunch of preliminary definitions that can be distilled and refactored by us soup computers</p>",
        "id": 489818705,
        "sender_full_name": "Frederick Pu",
        "timestamp": 1734546796
    },
    {
        "content": "<p>Here's hoping for powerful translation of human mathematics into Lean. Not only will it help me get FLT done quicker, but it will help us to make much bigger math databases for AI to train on. Mathlib is in some sense an extremely high-quality dataset, we just need a lot more of it.</p>",
        "id": 489818736,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1734546810
    },
    {
        "content": "<p>or using Lean for model based RL, so like train it on AIME questions for example but it needs to come up with it's formalisms from scratch with no underlying mathematics library. Would interesting to see if it's possible for it to implicitly come up with all the formalisms. That would prob be pretty far down the line since model based rl seems to be only for very small models (eg. n by n binary matrices) so far.</p>",
        "id": 489819290,
        "sender_full_name": "Frederick Pu",
        "timestamp": 1734546979
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"481527\">Huajian Xin</span> <a href=\"#narrow/stream/113488-general/topic/What.20do.20you.20hope.20AI.20can.20help.20you.20achieve.20with.20Lean.20in.202025.3F/near/489818457\">said</a>:</p>\n<blockquote>\n<p>What do you hope AI can help you achieve with Lean in 2025? e.g. code completion, documentation, code refactoring, etc. These suggestions will provide valuable guidance to developers of AI systems for Lean. <span aria-label=\"smile\" class=\"emoji emoji-1f642\" role=\"img\" title=\"smile\">:smile:</span></p>\n</blockquote>\n<p>Translate coq and Isabelle tactic proof scripts to lean tactic proof scripts</p>",
        "id": 489841745,
        "sender_full_name": "Shreyas Srinivas",
        "timestamp": 1734556175
    },
    {
        "content": "<p>In a sense it is the dynamic algorithms version of LLM proof generation: given an existing proof for another proof system, can you adapt it to a lean proof.</p>",
        "id": 489841871,
        "sender_full_name": "Shreyas Srinivas",
        "timestamp": 1734556221
    },
    {
        "content": "<p>While this sounds like a challenge for old fashioned logical methods, the jumbled mess of tactic languages makes it a more diffuse challenge. So perhaps some modern AI \"might\" help.</p>",
        "id": 489842115,
        "sender_full_name": "Shreyas Srinivas",
        "timestamp": 1734556337
    },
    {
        "content": "<p>related to the model-based RL a nice stepping-stone would be to have a bunch of valid and invalid proofs and the ai has guess the type signatures of all of the lemmas used in the proofs based on all of the tactic states</p>",
        "id": 489842511,
        "sender_full_name": "Frederick Pu",
        "timestamp": 1734556559
    },
    {
        "content": "<p>Autoformalization of mathematical statements would be really nice, and hopefully more achievable than the autoformalization of proofs. It would be nice if I give it some LaTeX of a theorem + proof, and I've already formalized the definitions in them, and it would spit out (say) a theorem + a sequence of <code>have</code> statements for the claims in the proof, all of them sorried.</p>",
        "id": 489855306,
        "sender_full_name": "Floris van Doorn",
        "timestamp": 1734562441
    },
    {
        "content": "<p>I'm not sure if this is something that AI would be good at, but I would be interested in an AI that, upon entering a theorem statement, can identify structurally similar theorem statements in Mathlib, and upon completing a proof, can identify similarly structured proofs. For example, if you entered a proof for the isomorphism theorems for modules, it might identify the isomorphism theorems for groups as having similar structure. The main uses of this would be to speed up proofs by copying existing proofs from Mathlib, and potentially identifying new abstractions.</p>",
        "id": 490241992,
        "sender_full_name": "Niels Voss",
        "timestamp": 1734735337
    },
    {
        "content": "<p>Request: train a model from <a href=\"https://speed.lean-lang.org/mathlib4/home\">benchmark data</a> to predict the change in compile time of each file from the diff. If it works well, it would save time from experiments like those I'm doing at <a href=\"https://github.com/leanprover-community/mathlib4/pull/20140\">#20140</a>.</p>",
        "id": 490250100,
        "sender_full_name": "Junyan Xu",
        "timestamp": 1734741365
    },
    {
        "content": "<p>Refactoring projects:</p>\n<p><a href=\"#narrow/channel/287929-mathlib4/topic/PNat.20powers.20in.20a.20semigroup/near/404763214\">This</a> is one of the large-scale mathlib refactoring projects that I'd like AI to help experiment with and accomplish if favorable.</p>\n<p>Some smaller-scale refactoring projects that have been discussed a lot on Zulip include:</p>\n<ol>\n<li>make <a href=\"https://leanprover-community.github.io/mathlib4_docs/find/?pattern=Finsupp#doc\">docs#Finsupp</a> and Polynomial operations computable, by making Finsupp a special case of DFinsupp.</li>\n<li>make <a href=\"https://leanprover-community.github.io/mathlib4_docs/find/?pattern=AddMonoidAlgebra#doc\">docs#AddMonoidAlgebra</a><code> k G</code> a structure with a single field <code>G ‚Üí‚ÇÄ k</code>, and make <a href=\"https://leanprover-community.github.io/mathlib4_docs/find/?pattern=Polynomial#doc\">docs#Polynomial</a><code> R</code> reducibly defeq to <code>AddMonoidAlgebra R ‚Ñï</code>.</li>\n</ol>\n<p>It's probably feasible that the human just changes a few definitions, then ask an AI agent to fix any CI errors without changing the type of or deleting any declarations.</p>",
        "id": 490250620,
        "sender_full_name": "Junyan Xu",
        "timestamp": 1734741800
    },
    {
        "content": "<p>I hope I can train smaller AI models that can prove theorems like one of the LLMs with a billion parameters</p>",
        "id": 490285418,
        "sender_full_name": "Leni Aniva",
        "timestamp": 1734775405
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"599027\">@Leni Aniva</span>  What if it was a smaller model that used the same amount of test-time compute.  There is a lot of recent work suggesting that may be possible.</p>",
        "id": 490297900,
        "sender_full_name": "Jason Rute",
        "timestamp": 1734786827
    },
    {
        "content": "<p>Make it much easier to convert scientific computing software from imperative code into Lean code, and autoformalize theorems about them!</p>",
        "id": 490308333,
        "sender_full_name": "Tyler Josephson ‚öõÔ∏è",
        "timestamp": 1734795759
    },
    {
        "content": "<p>Very good idea! Is the translation between Lean4 and Mathematica still maintained? There has been <a href=\"https://link.springer.com/article/10.1007/s10817-021-09611-1\">A Bi-Directional Extensible Interface Between Lean and Mathematica</a> for Lean 2.</p>",
        "id": 490311084,
        "sender_full_name": "Huajian Xin",
        "timestamp": 1734798040
    },
    {
        "content": "<p>I don‚Äôt really do day-to-day Lean formalization, but from listening to the community I think I‚Äôve identified the following needs:</p>",
        "id": 490311116,
        "sender_full_name": "Jason Rute",
        "timestamp": 1734798074
    },
    {
        "content": "<p>There are many large Lean projects like <a href=\"https://github.com/ImperialCollegeLondon/FLT\">FLT</a> and <a href=\"https://github.com/AlexKontorovich/PrimeNumberTheoremAnd\">PrimeNumberTheoremAnd</a>.  They proceed via a workflow using <a href=\"https://github.com/PatrickMassot/leanblueprint\">blueprints</a> which are detailed hyperlinked LaTeX outlines of the proof, with dependency graphs and references to the Lean code as it‚Äôs being written. The user slowly fills in Lean code for each lemma in the Blueprint.  It is a great visual display of progress and a place where AI could certainly help.  The most ambitious help would be to have AI convert the definitions and lemmas (and proofs?) into Lean code, completing the blueprint automatically (this is a form of practical automformalization which I think is the largest ask). But I think there are also other use-cases of AI in this process.</p>",
        "id": 490311121,
        "sender_full_name": "Jason Rute",
        "timestamp": 1734798080
    },
    {
        "content": "<p>Similarly, Lean projects take a long time and in the process there are a lot of stubbed lemmas with <code>sorry</code> in them.  The ability to fill in <code>sorry</code>s in a background process (say as part of CI or via some server which makes automatic PRs to a repo) has been a much requested feature (<a class=\"stream-topic\" data-stream-id=\"113488\" href=\"/#narrow/channel/113488-general/topic/Tactic.20worth.20running.20my.20PC.20overnight.3F\">#general &gt; Tactic worth running my PC overnight?</a>).  The closest we have come to this is <a href=\"https://arxiv.org/abs/2410.06209\">LeanAgent</a> (see the discussion in <a class=\"stream-topic\" data-stream-id=\"219941\" href=\"/#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/LeanAgent\">#Machine Learning for Theorem Proving &gt; LeanAgent</a>).  While I think LeanAgent was a bit oversold, it showed the vast potential of such a feature, even with a mediocre theorem prover.  Just being able to look up a lemma in Mathlib which matches the sorry theorem, or better yet two lemmas which need to be combined non-trivially to complete the sorry proof, could be a huge help. And if one can actually make a good theorem prover which fills in difficult <code>sorry</code>s it could be a massive game changer!  It would probably change the way people write their projects.  They would leave a lot more <code>sorry</code>s in the code in the hope that the AI would complete them.  But the discussion about LeanAgent also highlighted a bunch of other real-world challenges.  What happens if it just proves a sorry using inconsistent stubbed lemmas, or because <code>sorry</code> theorems behave wierd logically (although this is particially fixed in the newest version of Lean)?  While this is probably useful information, it could be a bit noisy to get silly PRs proving theorems with obviously inconsistent lemmas.  Also, one needs a good way to have the agent adapt in real time to the new code base which filled with new definitions and theorems.  (LeanAgent addresses this with continual learning, but there are many other approaches as I outline in <a class=\"stream-topic\" data-stream-id=\"219941\" href=\"/#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Keep.20AI.20theorem.20provers.20up-to-date\">#Machine Learning for Theorem Proving &gt; Keep AI theorem provers up-to-date</a>.)</p>",
        "id": 490311127,
        "sender_full_name": "Jason Rute",
        "timestamp": 1734798086
    },
    {
        "content": "<p>I think many Lean users just want a good assistant which can close goals for them.  Two problems with the current AI assistants for Lean are that (1) they are hard to install and therefore <strong>almost no one</strong> tries them out, and (2) they aren‚Äôt very good.  I think many who have used Isabelle feel very fondly of Isabelle‚Äôs <a href=\"https://isabelle.in.tum.de/website-Isabelle2009-1/sledgehammer.html\">SledgeHammer</a>.  And I think that is because both it is easy to install (or so I‚Äôve heard) and it is decent at completing easy goals.  I think AI is probably better now than Sledgehammer, but users haven‚Äôt seen that in real life.  As for user experience, the most user friendly system would be a VS Code plugin calling out to a (free?/cheap?) API similar to Github Copilot, Continue, Cursor, etc, but with better Lean integration.  (Of course, APIs bring privacy concerns and are not for everyone, but that paradigm is taking off.)  Another system design which also isn‚Äôt that bad are tactics which do one of three things: (1) suggest a next step, (2) complete a proof, or (3) suggest lemmas and definitions to use in the proof.  (Lean Copilot has this interface for example, and Lean has a nice ‚ÄúTry this‚Äù feature to make it easy to accept the proof or suggestion from a tactic.) They could be hosted locally or use an API.  I think there is still a lot of design room for small, fast locally hosted provers (not necessarily using transformers).</p>",
        "id": 490311129,
        "sender_full_name": "Jason Rute",
        "timestamp": 1734798093
    },
    {
        "content": "<p>The big challenge with developing these systems is a lack of good AI-Lean integration.  For people on the ML side, metaprogramming in Lean is a huge challenge and most end up doing hacky ineffecient things like just writing a new file with AI-generated Lean code and running Lean on it.  This works for benchmarks like MiniF2F (and maybe for the <code>sorry</code>-filling agent idea above), but it doesn‚Äôt work for in-the-editor Lean integration.  On the Lean side, most Lean users don‚Äôt have experience hooking up tools to Lean.  One needs better communication (both electonic communication between Lean and AI tools, and human communication between Lean experts and AI experts).</p>",
        "id": 490311135,
        "sender_full_name": "Jason Rute",
        "timestamp": 1734798100
    },
    {
        "content": "<p>I would like to see a lot more tools upstreamed to central Lean-maintained repos, which would make them usable to a variety of researchers and Lean tool designers.  Some such tools which need to be upstreamed are the following:</p>\n<ul>\n<li>Tree search: Right now Aesop provides a drop in tree search tool which can easily be hooked up to any tactic suggestion tool.  It is what Aesop and Lean Copilot use.  I think it is a bit slow and clunky, but it is a good start.  I think ABEL (<a class=\"stream-topic\" data-stream-id=\"219941\" href=\"/#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/ABEL\">#Machine Learning for Theorem Proving &gt; ABEL</a>) and if so, I‚Äôd love to see that upstreamed (<span class=\"user-mention\" data-user-id=\"210057\">@Fabian Gl√∂ckle</span>).  Having a common search tactic is better than every team/project redoing their own tree search.</li>\n<li>Data mining (especially data mining for locall or Githiub non-Mathlib projects so that you can have a custom model or a model with access to your code base)</li>\n<li>Lean/AI communication tools for tactics, plugins, and LLM tool-calling</li>\n<li>Premise/Lemma selection</li>\n<li>Ways to integrate AI with Lean‚Äôs environment. Lean has all sorts of internal discrimination trees for simp lemmas, rewrite lemmas, apply lemmas, or lemmas which can solve the current goal.  It would be great to better incorporate and make usable such datastructures to modern AI systems.  Imagine what one could do if the AI agent had much more information about what was actually available in the library.</li>\n</ul>",
        "id": 490311138,
        "sender_full_name": "Jason Rute",
        "timestamp": 1734798106
    },
    {
        "content": "<p>Also, in many ways the current AI tools are broken for silly reasons.  ChatGPT would be a good Lean assistant for autoformalization, proofs, etc. if it understood Lean 4 vs. Lean 3.  (I‚Äôve heard Sonnet 3.5 is better.)  There are good projects out there showing that one can automatically clean up a LLM generated proofs (Lyra, PALM, etc.) and auto-formalizations (LeanAide).  Or that one can use an LLM to generate stubs for a different type of AI to fill in (Draft-Sketch-Prove, etc), or use the LLM recursively to clean up broken parts of the proof (Cobblestone, DeepSeek-Prover v1.5). It would be good to make such systems usable (and the repair components tools upstreamed so others can use them easily). Or even just generate more than one suggestion and test them all (DeepSeek-Prover v1).  Honestly, many of these papers just use public APIs like GPT-3.5.  I don‚Äôt see why we can‚Äôt quickly build these systems <strong>in practice</strong> right after such a paper comes out.</p>",
        "id": 490311145,
        "sender_full_name": "Jason Rute",
        "timestamp": 1734798112
    },
    {
        "content": "<p>Overall, we just need (1) to know what approaches and tools work in real life, not just on silly benchmarks, and (2) to build those in a way that people can use them.  In many ways this shouldn‚Äôt be hard.  We probably have lots of approaches that work, we just have never taken the time to verify that they work in real life and to  make them available.</p>",
        "id": 490311154,
        "sender_full_name": "Jason Rute",
        "timestamp": 1734798118
    },
    {
        "content": "<p>Last, besides day-to-day tools, the three ultimate goals I see in this space are (1) large scale auto-formalization of real mathematics, and (2) large scale automatic verification of computer code, and (3) really powerful automated theorem proving.  I certainly think we still need to be working toward those even if the research is messy, expensive, and not ready for users.</p>",
        "id": 490311156,
        "sender_full_name": "Jason Rute",
        "timestamp": 1734798120
    },
    {
        "content": "<p>wasnt there a lean project where all the tree search is done in lean and u can just plug and play the model?</p>",
        "id": 490311366,
        "sender_full_name": "Frederick Pu",
        "timestamp": 1734798337
    },
    {
        "content": "<p>also i wonder how hard it would be to update Aesop to support rl, such as maintaining a policy and stuff. Cause doesn't Aesop already kind of do monte carlo tree search in some form?</p>",
        "id": 490311496,
        "sender_full_name": "Frederick Pu",
        "timestamp": 1734798469
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"464202\">@Felix Weilacher</span> I know of Aesop (which <span class=\"user-mention\" data-user-id=\"584504\">@Kaiyu Yang</span> added the ability to use text for tactics which Lean parses, which is what Lean Copilot uses).  Also, I don't know if Pantograph (<span class=\"user-mention\" data-user-id=\"599027\">@Leni Aniva</span>)  provides as similar tool?  And there was Sagredo (<span class=\"user-mention\" data-user-id=\"110087\">@Kim Morrison</span>).</p>",
        "id": 490311534,
        "sender_full_name": "Jason Rute",
        "timestamp": 1734798483
    },
    {
        "content": "<p>Aesop uses best-first search for which you can add your own scores (based on a value function), and ABEL (<span class=\"user-mention\" data-user-id=\"210057\">@Fabian Gl√∂ckle</span>) uses MCTS and does RL.</p>",
        "id": 490311584,
        "sender_full_name": "Jason Rute",
        "timestamp": 1734798552
    },
    {
        "content": "<p>what's ABLE</p>",
        "id": 490311594,
        "sender_full_name": "Frederick Pu",
        "timestamp": 1734798570
    },
    {
        "content": "<p>A misspelling of <a class=\"stream-topic\" data-stream-id=\"219941\" href=\"/#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/ABEL\">#Machine Learning for Theorem Proving &gt; ABEL</a>.</p>",
        "id": 490311612,
        "sender_full_name": "Jason Rute",
        "timestamp": 1734798597
    },
    {
        "content": "<p>is there a lean tactic for it or do they do hypertree search in leandojo</p>",
        "id": 490311736,
        "sender_full_name": "Frederick Pu",
        "timestamp": 1734798696
    },
    {
        "content": "<p>it?  I mentioned 5ish tools.  Aesop is a tactic, and  Lean Copilot has tactics (which use Aesop underneath).  I don't know about the others.</p>",
        "id": 490311858,
        "sender_full_name": "Jason Rute",
        "timestamp": 1734798816
    },
    {
        "content": "<p>i mean able</p>",
        "id": 490311869,
        "sender_full_name": "Frederick Pu",
        "timestamp": 1734798830
    },
    {
        "content": "<p>Maybe ABEL (not \"able\", sorry) will be a tactic on top of Aesop when released:<br>\n<span class=\"user-mention silent\" data-user-id=\"210057\">Fabian Gl√∂ckle</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/ABEL/near/476914171\">said</a>:</p>\n<blockquote>\n<p>Aesoprepl is not public yet (on it!), you'll need 200 lines on top of Aesop.</p>\n</blockquote>",
        "id": 490312090,
        "sender_full_name": "Jason Rute",
        "timestamp": 1734798991
    },
    {
        "content": "<p>it would cool if Aesop had an api for making custom search modes, certainly would be cleaner (and hopefully run quicker) then trying to implment mcts or rmax search via lean dojo</p>",
        "id": 490312746,
        "sender_full_name": "Frederick Pu",
        "timestamp": 1734799679
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"115715\">Jason Rute</span> <a href=\"#narrow/channel/113488-general/topic/What.20do.20you.20hope.20AI.20can.20help.20you.20achieve.20with.20Lean.20in.202025.3F/near/490311534\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"464202\">Felix Weilacher</span> I know of Aesop (which <span class=\"user-mention silent\" data-user-id=\"584504\">Kaiyu Yang</span> added the ability to use text for tactics which Lean parses, which is what Lean Copilot uses).  Also, I don't know if Pantograph (<span class=\"user-mention silent\" data-user-id=\"599027\">Leni Aniva</span>)  provides as similar tool?  And there was Sagredo (<span class=\"user-mention silent\" data-user-id=\"110087\">Kim Morrison</span>).</p>\n</blockquote>\n<p>What do you mean by using text for tactics? Like you can just execute <code>rw [lemma_1, lemma_2]</code> on a goal?</p>",
        "id": 490338782,
        "sender_full_name": "Leni Aniva",
        "timestamp": 1734823106
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"115715\">Jason Rute</span> <a href=\"#narrow/channel/113488-general/topic/What.20do.20you.20hope.20AI.20can.20help.20you.20achieve.20with.20Lean.20in.202025.3F/near/490297900\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"599027\">Leni Aniva</span>  What if it was a smaller model that used the same amount of test-time compute.  There is a lot of recent work suggesting that may be possible.</p>\n</blockquote>\n<p>It may be, but I'm trying non language model based solutions</p>",
        "id": 490338802,
        "sender_full_name": "Leni Aniva",
        "timestamp": 1734823128
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"599027\">Leni Aniva</span> <a href=\"#narrow/stream/113488-general/topic/What.20do.20you.20hope.20AI.20can.20help.20you.20achieve.20with.20Lean.20in.202025.3F/near/490338782\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"115715\">Jason Rute</span> <a href=\"#narrow/channel/113488-general/topic/What.20do.20you.20hope.20AI.20can.20help.20you.20achieve.20with.20Lean.20in.202025.3F/near/490311534\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"464202\">Felix Weilacher</span> I know of Aesop (which <span class=\"user-mention silent\" data-user-id=\"584504\">Kaiyu Yang</span> added the ability to use text for tactics which Lean parses, which is what Lean Copilot uses).  Also, I don't know if Pantograph (<span class=\"user-mention silent\" data-user-id=\"599027\">Leni Aniva</span>)  provides as similar tool?  And there was Sagredo (<span class=\"user-mention silent\" data-user-id=\"110087\">Kim Morrison</span>).</p>\n</blockquote>\n<p>What do you mean by using text for tactics? Like you can just execute <code>rw [lemma_1, lemma_2]</code> on a goal?</p>\n</blockquote>\n<p>Yes, exactly!  Look at this example: <a href=\"https://github.com/leanprover-community/aesop/blob/master/AesopTest/TacGen.lean\">https://github.com/leanprover-community/aesop/blob/master/AesopTest/TacGen.lean</a><br>\nI also realize <span class=\"user-mention\" data-user-id=\"256311\">@Jannis Limperg</span> added this feature and also worked on ABEL so he might have something to say.</p>",
        "id": 490346708,
        "sender_full_name": "Jason Rute",
        "timestamp": 1734831023
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"599027\">Leni Aniva</span> <a href=\"#narrow/stream/113488-general/topic/What.20do.20you.20hope.20AI.20can.20help.20you.20achieve.20with.20Lean.20in.202025.3F/near/490338802\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"115715\">Jason Rute</span> <a href=\"#narrow/channel/113488-general/topic/What.20do.20you.20hope.20AI.20can.20help.20you.20achieve.20with.20Lean.20in.202025.3F/near/490297900\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"599027\">Leni Aniva</span>  What if it was a smaller model that used the same amount of test-time compute.  There is a lot of recent work suggesting that may be possible.</p>\n</blockquote>\n<p>It may be, but I'm trying non language model based solutions</p>\n</blockquote>\n<p>You should check out my <a href=\"https://arxiv.org/abs/2401.02949\">Graph2Tac</a>.  I wish there was a Lean version.  :(  Also Tactician‚Äôs kNN (also benchmarked in that same paper).</p>",
        "id": 490346852,
        "sender_full_name": "Jason Rute",
        "timestamp": 1734831212
    },
    {
        "content": "<p>I have one wish that is about AI but without machine learning.<br>\nIs there any low-hanging fruit for what Aesop could do but doesn't because it would be too expensive?<br>\nMaybe we could have Aesop++ that is extremely slow but, when run overnight, might find proofs that Aesop fails to find.<br>\n<span class=\"user-mention\" data-user-id=\"256311\">@Jannis Limperg</span></p>",
        "id": 490512297,
        "sender_full_name": "Martin Dvo≈ô√°k",
        "timestamp": 1734957828
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"417654\">@Martin Dvo≈ô√°k</span> what is the reason to what Aesop with no ML, but still something which runs for hours? Because it is easier/cheap to run on a laptop?  Or because you have Aesop already and good ML tools seem so far away?</p>",
        "id": 490515574,
        "sender_full_name": "Jason Rute",
        "timestamp": 1734959084
    },
    {
        "content": "<p>Tbh, good ML tools no longer seem far away; AlphaProof dramatically changed my mind!<br>\nHowever, something like <code>Aesop++</code> could possibly land right now.<br>\nMaybe there is low-hanging fruit that <span class=\"user-mention\" data-user-id=\"256311\">@Jannis Limperg</span> could pick in just few hours of work.</p>",
        "id": 490515993,
        "sender_full_name": "Martin Dvo≈ô√°k",
        "timestamp": 1734959228
    },
    {
        "content": "<p>Also, one should really see what happens with Aesop when run for longer amounts of time.  What you want to see is a log-linear plot similar to what we see in new AI papers on ‚Äútest-time scaling‚Äù, but also we see in good AI for theorem proving projects.  Here is the plot in the graph2tac paper.  <a href=\"/user_uploads/3121/G54MPQmq-6uX2dNaudmkTbcD/7d140a2950b22b7b8b20e482a1d8fd375f96ec11.png\">7d140a2950b22b7b8b20e482a1d8fd375f96ec11.png</a> Every ATP paper should have this plot and I am disappointed that most don‚Äôt.  Any Aesop folks want to make it?  Maybe you already have the data.</p>\n<div class=\"message_inline_image\"><a href=\"/user_uploads/3121/G54MPQmq-6uX2dNaudmkTbcD/7d140a2950b22b7b8b20e482a1d8fd375f96ec11.png\" title=\"7d140a2950b22b7b8b20e482a1d8fd375f96ec11.png\"><img data-original-dimensions=\"2716x1196\" src=\"/user_uploads/thumbnail/3121/G54MPQmq-6uX2dNaudmkTbcD/7d140a2950b22b7b8b20e482a1d8fd375f96ec11.png/840x560.webp\"></a></div>",
        "id": 490516772,
        "sender_full_name": "Jason Rute",
        "timestamp": 1734959538
    },
    {
        "content": "<p>As I pointed out at the beginning of this year<br>\n<a class=\"message-link\" href=\"/#narrow/channel/113488-general/topic/Tactic.20worth.20running.20my.20PC.20overnight.3F/near/411344624\">#general &gt; Tactic worth running my PC overnight? @ üí¨</a> <br>\nI expect the results to be severely diminishing and I won't be disappointed if Aesop++ takes 10000x more time but solves only a little bit more than Aesop does.</p>",
        "id": 490517538,
        "sender_full_name": "Martin Dvo≈ô√°k",
        "timestamp": 1734959852
    },
    {
        "content": "<p>Again, such a plot should give you a feel for that without first having to run 10000x time.  Or on the other hand, just try yourself.  You can already change the timeout for Aesop.</p>",
        "id": 490518056,
        "sender_full_name": "Jason Rute",
        "timestamp": 1734960046
    },
    {
        "content": "<p>Yes but Aesop only tries to do some things and usually ends (successfully or not) without using up all allowed heartbeats.</p>",
        "id": 490518240,
        "sender_full_name": "Martin Dvo≈ô√°k",
        "timestamp": 1734960126
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"417654\">@Martin Dvo≈ô√°k</span> have you tried running existing tools like LeanCopilot or LLMLean for longer periods?</p>",
        "id": 490557546,
        "sender_full_name": "Jason Rute",
        "timestamp": 1734976031
    },
    {
        "content": "<p>No. Do they do search the state space?</p>",
        "id": 490558148,
        "sender_full_name": "Martin Dvo≈ô√°k",
        "timestamp": 1734976264
    },
    {
        "content": "<p>Yes.  Lean Dojo is just Aesop with machine learning picked tactics.</p>",
        "id": 490558226,
        "sender_full_name": "Jason Rute",
        "timestamp": 1734976299
    },
    {
        "content": "<p>I usually cite your post in circumstances like this, but it isn‚Äôt quite clear what more you need to be able do actual experiments with running such tools on projects for longer periods? What is stopping you from doing those experiments today?  What would make it feasible for when a new tool (like ABEL) became available for you to instantly try it on real formalization projects?</p>",
        "id": 490558317,
        "sender_full_name": "Jason Rute",
        "timestamp": 1734976331
    },
    {
        "content": "<p>I am most interested in the reverse direction of the question. What can Lean help us achieve with AI? I believe Lean (and other interactive theorem provers) can and should be a big part of addressing two of the major challenges in (generative) AI today, <a href=\"https://gasstationmanager.github.io/ai/2024/11/04/a-proposal.html\">hallucination and safety</a>. </p>\n<p>How to get there can be a bit of a chicken-and-egg problem. The current AI models are often not good at outputting correct Lean 4 syntax, nor at how best to use Lean, though that may be slowly changing. Here's hoping that as better tools (AI-based or otherwise) that helps humans are developed, they can also be used by AIs to become more proficient users of Lean.</p>",
        "id": 490716656,
        "sender_full_name": "GasStationManager",
        "timestamp": 1735076669
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"115715\">Jason Rute</span> <a href=\"#narrow/channel/113488-general/topic/What.20do.20you.20hope.20AI.20can.20help.20you.20achieve.20with.20Lean.20in.202025.3F/near/490346708\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"599027\">Leni Aniva</span> <a href=\"#narrow/stream/113488-general/topic/What.20do.20you.20hope.20AI.20can.20help.20you.20achieve.20with.20Lean.20in.202025.3F/near/490338782\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"115715\">Jason Rute</span> <a href=\"#narrow/channel/113488-general/topic/What.20do.20you.20hope.20AI.20can.20help.20you.20achieve.20with.20Lean.20in.202025.3F/near/490311534\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"464202\">Felix Weilacher</span> I know of Aesop (which <span class=\"user-mention silent\" data-user-id=\"584504\">Kaiyu Yang</span> added the ability to use text for tactics which Lean parses, which is what Lean Copilot uses).  Also, I don't know if Pantograph (<span class=\"user-mention silent\" data-user-id=\"599027\">Leni Aniva</span>)  provides as similar tool?  And there was Sagredo (<span class=\"user-mention silent\" data-user-id=\"110087\">Kim Morrison</span>).</p>\n</blockquote>\n<p>What do you mean by using text for tactics? Like you can just execute <code>rw [lemma_1, lemma_2]</code> on a goal?</p>\n</blockquote>\n<p>Yes, exactly!  Look at this example: <a href=\"https://github.com/leanprover-community/aesop/blob/master/AesopTest/TacGen.lean\">https://github.com/leanprover-community/aesop/blob/master/AesopTest/TacGen.lean</a><br>\nI also realize <span class=\"user-mention silent\" data-user-id=\"256311\">Jannis Limperg</span> added this feature and also worked on ABEL so he might have something to say.</p>\n</blockquote>\n<p>Pantograph was able to execute tactics like this since the beginning</p>",
        "id": 490726034,
        "sender_full_name": "Leni Aniva",
        "timestamp": 1735086324
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"599027\">@Leni Aniva</span> I‚Äôm not exactly sure of your point.  This feature (the ability to call the parser from inside the tactic monad) was first added to Lean 3 by Ed Ayers to support <code>lean-gptf</code> (the first neural theorem prover in Lean in thee PACT project).  Also I assume <span class=\"user-mention\" data-user-id=\"256311\">@Jannis Limperg</span>‚Äôs adjustments to Aesop came before Pantograph.  But the point I‚Äôm trying to make is not who was first, or even which tool is better, but how can we get more ML/AI tools into the Lean FRO supported projects like Batteries, Qq, and Aesop (all projects which mathlib depends on).  I think it is great that Lean Copilot and ABEL (?) use Aesop, because the Lean FRO supports Aesop (and most heavy mathlib users know how to use Aesop).  And the fact that the Lean FRO doesn‚Äôt support Lean Copilot shows.  It is often out of date and less well maintained, and not widely used.  I don‚Äôt think it necessarily makes sense to have the Lean FRO support Lean Copilot or ABEL or LLMLean since their time is limited, but I would like to see them support integral reusable components to Lean, just like how they support the tree search in Aesop and Jannis‚Äô extension to let you run tactics given as strings.  If Pantograph is better, maybe it makes sense for small reusable parts of it to become supported by the Lean FRO.  (I‚Äôd also love a side by side comparison of Pantograph‚Äôs search with Aesop‚Äôs search using the same tactic prediction model.  I don‚Äôt think the current Aesop search is fast and I don‚Äôt like that it evaluates all tactic suggestion first, before moving down the search tree.  Maybe these are fixed in ABEL‚Äôs modifications to Aesop.)</p>",
        "id": 490779537,
        "sender_full_name": "Jason Rute",
        "timestamp": 1735133288
    },
    {
        "content": "<blockquote>\n<p>because the Lean FRO supports Aesop</p>\n</blockquote>\n<p><span class=\"user-mention\" data-user-id=\"115715\">@Jason Rute</span> in what sense does the FRO support aesop?</p>",
        "id": 490779876,
        "sender_full_name": "Henrik B√∂ving",
        "timestamp": 1735133613
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"115715\">Jason Rute</span> <a href=\"#narrow/channel/113488-general/topic/What.20do.20you.20hope.20AI.20can.20help.20you.20achieve.20with.20Lean.20in.202025.3F/near/490779537\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"599027\">Leni Aniva</span> I‚Äôm not exactly sure of your point.  This feature (the ability to call the parser from inside the tactic monad) was first added to Lean 3 by Ed Ayers to support <code>lean-gptf</code> (the first neural theorem prover in Lean in thee PACT project).  Also I assume <span class=\"user-mention silent\" data-user-id=\"256311\">Jannis Limperg</span>‚Äôs adjustments to Aesop came before Pantograph.  But the point I‚Äôm trying to make is not who was first, or even which tool is better, but how can we get more ML/AI tools into the Lean FRO supported projects like Batteries, Qq, and Aesop (all projects which mathlib depends on).  I think it is great that Lean Copilot and ABEL (?) use Aesop, because the Lean FRO supports Aesop (and most heavy mathlib users know how to use Aesop).  And the fact that the Lean FRO doesn‚Äôt support Lean Copilot shows.  It is often out of date and less well maintained, and not widely used.  I don‚Äôt think it necessarily makes sense to have the Lean FRO support Lean Copilot or ABEL or LLMLean since their time is limited, but I would like to see them support integral reusable components to Lean, just like how they support the tree search in Aesop and Jannis‚Äô extension to let you run tactics given as strings.  If Pantograph is better, maybe it makes sense for small reusable parts of it to become supported by the Lean FRO.  (I‚Äôd also love a side by side comparison of Pantograph‚Äôs search with Aesop‚Äôs search using the same tactic prediction model.  I don‚Äôt think the current Aesop search is fast and I don‚Äôt like that it evaluates all tactic suggestion first, before moving down the search tree.  Maybe these are fixed in ABEL‚Äôs modifications to Aesop.)</p>\n</blockquote>\n<p>What I mean is that Pg supports calling the parser inside the tactic monad</p>",
        "id": 490779996,
        "sender_full_name": "Leni Aniva",
        "timestamp": 1735133716
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"395550\">@Henrik B√∂ving</span>  Maybe I‚Äôm using the wrong organization.  Is it more accurate to say ‚Äúthe mathlib maintainers‚Äù (some of whom are supported by the Lean FRO) at least keep Aesop up-to-date and working since it is a dependency of Mathlib?</p>",
        "id": 490780165,
        "sender_full_name": "Jason Rute",
        "timestamp": 1735133865
    },
    {
        "content": "<p>Or is that even wrong?</p>",
        "id": 490780173,
        "sender_full_name": "Jason Rute",
        "timestamp": 1735133874
    },
    {
        "content": "<p>Kim (who is a full time FRO employee) makes a version bump to the transitive closure of mathlib dependencies, including aesop, when we release a version every month. The rest of the work on aesop is almost exclusively done by Janis from the LMU.</p>",
        "id": 490780355,
        "sender_full_name": "Henrik B√∂ving",
        "timestamp": 1735134020
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"395550\">@Henrik B√∂ving</span> That isn‚Äôt nothing.  Lean Copilot for example doesn‚Äôt readily stay up-to-date with version bumps.  (And I assume you run tests and make releases as part of this version bump?) But maybe it is also just a vibe check.  Aesop seems more integrated into the Lean ecosystem and community, which is good. But you are right that I should leave the Lean FRO out of this.</p>",
        "id": 490780994,
        "sender_full_name": "Jason Rute",
        "timestamp": 1735134582
    },
    {
        "content": "<p>is aesop integration limited to only RAG based models like lean copilote. Cause I noticed that in a lot of the deepseek prover generated they never use pattern matching when doing stuff like cases but instead do the weird <code>cases with h (h) &lt;;&gt;</code> thing. Is there any way to take a proof and split it into a sequence tactic state + next rule applications so that language models like deepseek can be pretrained on mathlib4 directly instead custom curated proofs?</p>",
        "id": 490781196,
        "sender_full_name": "Frederick Pu",
        "timestamp": 1735134757
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"676310\">@Frederick Pu</span>  Aesop isn‚Äôt the tool parsing mathlib for data, but there are plenty of tools to do that at the tactic level (Lean Dojo, lean-training-data, and I assume pantograph). Also Lean Copilot (unlike ReProver) is not RAG based.  It is just an LLM predictor with no RAG.  The important thing for the current Aesop feature is that you have a model to suggest tactics as strings.  I might be possible to use DeepSeek-Prover to suggest a whole proof (if you could run it conditioned on the goal state) and then wrap that proof in something like <code>by</code> to get it to behave as a single tactic.  I don‚Äôt think you could do DeepSeek-Prover v1.5 style MCTS where you take a proof, find the errors and start repairing there.  But since many papers do this, it would probably be a good feature to support (in some tool, not necessarily Aesop).</p>",
        "id": 490782004,
        "sender_full_name": "Jason Rute",
        "timestamp": 1735135493
    },
    {
        "content": "<p>For me it is search for theorems and definitions.</p>",
        "id": 490799254,
        "sender_full_name": "IlmƒÅrs Cƒ´rulis",
        "timestamp": 1735151673
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"658873\">@Lessness</span> what do you feel that existing tools like <a href=\"https://www.moogle.ai\">https://www.moogle.ai</a> and <a href=\"https://leansearch.net\">https://leansearch.net</a> don‚Äôt offer?  (Or are you talking about another type of search like local project search?  Or lemma suggestions for the current goal?)</p>",
        "id": 490802655,
        "sender_full_name": "Jason Rute",
        "timestamp": 1735154410
    },
    {
        "content": "<p>at least from personal experience they usually don't find what im looking for, and i end up searching manually on mathlib4 docs instead</p>",
        "id": 490802898,
        "sender_full_name": "Frederick Pu",
        "timestamp": 1735154662
    },
    {
        "content": "<p>You should at least be using <a href=\"http://loogle.lean-lang.org\">loogle.lean-lang.org</a>, mathlib4 docs search is strictly weaker than it</p>",
        "id": 490803247,
        "sender_full_name": "Henrik B√∂ving",
        "timestamp": 1735154979
    },
    {
        "content": "<p>Hmm, I've found the docs search nicer when I don't know a name exactly</p>",
        "id": 490803673,
        "sender_full_name": "Ruben Van de Velde",
        "timestamp": 1735155386
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"115715\">@Jason Rute</span> I didn't know about <a href=\"http://leansearch.net\">leansearch.net</a>, will probably try it out. <a href=\"http://Moogle.ai\">Moogle.ai</a> doesn't always find what I need.</p>\n<p>Local project search would be, I believe, something nice, too. <span aria-label=\"thumbs up\" class=\"emoji emoji-1f44d\" role=\"img\" title=\"thumbs up\">:thumbs_up:</span>  A generalization of existing search tools.</p>",
        "id": 490804145,
        "sender_full_name": "IlmƒÅrs Cƒ´rulis",
        "timestamp": 1735155858
    },
    {
        "content": "<p>I really don‚Äôt understand why the search in the docs is so bad.  Why can‚Äôt they just use one of the others?  They already have the Google Site Search button.  (But I‚Äôve been complaining about this for years now, so I don‚Äôt think it will change.)</p>",
        "id": 490805388,
        "sender_full_name": "Jason Rute",
        "timestamp": 1735157203
    },
    {
        "content": "<p>Do folks like loogle?  I guess the challenge is that you have to learn a specific search grammar.</p>",
        "id": 490805425,
        "sender_full_name": "Jason Rute",
        "timestamp": 1735157259
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"115715\">Jason Rute</span> <a href=\"#narrow/channel/113488-general/topic/What.20do.20you.20hope.20AI.20can.20help.20you.20achieve.20with.20Lean.20in.202025.3F/near/490805388\">said</a>:</p>\n<blockquote>\n<p>I really don‚Äôt understand why the search in the docs is so bad.  Why can‚Äôt they just use one of the others?  They already have the Google Site Search button.  (But I‚Äôve been complaining about this for years now, so I don‚Äôt think it will change.)</p>\n</blockquote>\n<p>the hosted documentation is a frontend online site that has no backend, the search mechanism itself is made not so clever on purpose so your browser can even deal with the volume of strings it has to search through every time you type. </p>\n<p><span class=\"user-mention silent\" data-user-id=\"115715\">Jason Rute</span> <a href=\"#narrow/channel/113488-general/topic/What.20do.20you.20hope.20AI.20can.20help.20you.20achieve.20with.20Lean.20in.202025.3F/near/490805425\">said</a>:</p>\n<blockquote>\n<p>Do folks like loogle?  I guess the challenge is that you have to learn a specific search grammar.</p>\n</blockquote>\n<p>Yes, loogle is amazing, I've never felt the need to use any AI search tool to find a theorem so far.</p>",
        "id": 490805613,
        "sender_full_name": "Henrik B√∂ving",
        "timestamp": 1735157462
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"395550\">@Henrik B√∂ving</span> But there is already a search using google button.  Why not ones for leansearch, Moogle, and loogle?</p>",
        "id": 490805711,
        "sender_full_name": "Jason Rute",
        "timestamp": 1735157572
    },
    {
        "content": "<p>Moogle for example has the same search syntax as google where the query is in the url.</p>",
        "id": 490805822,
        "sender_full_name": "Jason Rute",
        "timestamp": 1735157678
    },
    {
        "content": "<p>The search for the google button is an artifact back from when doc-gen was only used for mathlib. Loogle etc. are hosted only for mathlib currently, there are projects that host documentation with doc-gen that do not have these hosted services. One could configure that through a config file for doc-gen or something it's just not something I've done yet. And as a side note, given the fact that neither leansearch nor moogle can even be set up to work with other projects currently I also don't really see why doc-gen should include them, for loogle i do see a potential point.</p>",
        "id": 490805876,
        "sender_full_name": "Henrik B√∂ving",
        "timestamp": 1735157747
    },
    {
        "content": "<p>Ok, thanks for the clarification.  I still think the situation is not ideal, but at least I see some reasoning behind it.</p>",
        "id": 490806147,
        "sender_full_name": "Jason Rute",
        "timestamp": 1735158013
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"676310\">@Frederick Pu</span> and <span class=\"user-mention\" data-user-id=\"658873\">@Lessness</span> What are examples of what you can‚Äôt find in those tools?  Is it because they are out of date, or because they don‚Äôt understand what you are looking for?</p>",
        "id": 490806186,
        "sender_full_name": "Jason Rute",
        "timestamp": 1735158091
    },
    {
        "content": "<p>(Moogle unfortunately has not been kept up-to-date last I checked.)</p>",
        "id": 490806255,
        "sender_full_name": "Jason Rute",
        "timestamp": 1735158150
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"611077\">@Jiang Jiedong</span> do you think learn search for custom projects would ever be a thing?  I guess I don‚Äôt know how it works and if that makes sense or is crazy. (Also is there any description of how it works anywhere?)</p>",
        "id": 490806439,
        "sender_full_name": "Jason Rute",
        "timestamp": 1735158377
    },
    {
        "content": "<p>i think the issue is that i usually try to search for new fields that i dont understand. so ig my queries are too vague. for example the query <code>‚Äãconditional probability</code> just returns a bunch of parser definitions.</p>",
        "id": 490810410,
        "sender_full_name": "Frederick Pu",
        "timestamp": 1735162626
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"115715\">Jason Rute</span> <a href=\"#narrow/stream/113488-general/topic/What.20do.20you.20hope.20AI.20can.20help.20you.20achieve.20with.20Lean.20in.202025.3F/near/490806439\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"611077\">Jiang Jiedong</span> do you think learn search for custom projects would ever be a thing?  I guess I don‚Äôt know how it works and if that makes sense or is crazy. (Also is there any description of how it works anywhere?)</p>\n</blockquote>\n<p>I believe this is a very good and achievable idea! Here is the paper of <a href=\"https://arxiv.org/abs/2403.13310\">LeanSearch</a></p>\n<p>The preparing process doesn‚Äôt involve training, only involves inference using some large embedding model.</p>",
        "id": 490869987,
        "sender_full_name": "Jiang Jiedong",
        "timestamp": 1735213921
    },
    {
        "content": "<p><a href=\"#narrow/channel/113488-general/topic/Decomposing.20pattern.20matching.20tactics.20for.20AI/near/490790063\">A message</a> was moved here from <a class=\"stream-topic\" data-stream-id=\"113488\" href=\"/#narrow/channel/113488-general/topic/What.20do.20you.20hope.20AI.20can.20help.20you.20achieve.20with.20Lean.20in.202025.3F\">#general &gt; What do you hope AI can help you achieve with Lean in 2025?</a> by <span class=\"user-mention silent\" data-user-id=\"115715\">Jason Rute</span>.</p>",
        "id": 490875315,
        "sender_full_name": "Notification Bot",
        "timestamp": 1735217631
    },
    {
        "content": "<p>A message was moved from this topic to <a class=\"stream-topic\" data-stream-id=\"113488\" href=\"/#narrow/channel/113488-general/topic/Decomposing.20pattern.20matching.20tactics.20for.20AI\">#general &gt; Decomposing pattern matching tactics for AI</a> by <span class=\"user-mention silent\" data-user-id=\"115715\">Jason Rute</span>.</p>",
        "id": 490875323,
        "sender_full_name": "Notification Bot",
        "timestamp": 1735217633
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"676310\">Frederick Pu</span> <a href=\"#narrow/channel/113488-general/topic/What.20do.20you.20hope.20AI.20can.20help.20you.20achieve.20with.20Lean.20in.202025.3F/near/490810410\">said</a>:</p>\n<blockquote>\n<p>i think the issue is that i usually try to search for new fields that i dont understand. so ig my queries are too vague. for example the query <code>‚Äãconditional probability</code> just returns a bunch of parser definitions.</p>\n</blockquote>\n<p>I tried this in Moogle: <a href=\"https://www.moogle.ai/search/raw?q=conditional%20probability\">https://www.moogle.ai/search/raw?q=conditional%20probability</a>  IMHO, it is better than you suggested.  The first two suggestions are indeed parser terms, but if you follow the links they are the notations for conditional probability:</p>\n<div class=\"codehilite\" data-code-language=\"Lean4\"><pre><span></span><code><span class=\"kn\">scoped</span><span class=\"w\"> </span><span class=\"kn\">notation</span><span class=\"w\"> </span><span class=\"n\">Œº</span><span class=\"w\"> </span><span class=\"s2\">\"[\"</span><span class=\"w\"> </span><span class=\"n\">s</span><span class=\"w\"> </span><span class=\"s2\">\"|\"</span><span class=\"w\"> </span><span class=\"n\">t</span><span class=\"w\"> </span><span class=\"s2\">\"]\"</span><span class=\"w\"> </span><span class=\"bp\">=&gt;</span><span class=\"w\"> </span><span class=\"n\">ProbabilityTheory</span><span class=\"bp\">.</span><span class=\"n\">cond</span><span class=\"w\"> </span><span class=\"n\">Œº</span><span class=\"w\"> </span><span class=\"n\">t</span><span class=\"w\"> </span><span class=\"n\">s</span>\n<span class=\"kn\">scoped</span><span class=\"w\"> </span><span class=\"kn\">notation</span><span class=\"o\">:</span><span class=\"mi\">60</span><span class=\"w\"> </span><span class=\"n\">Œº</span><span class=\"w\"> </span><span class=\"s2\">\"[|\"</span><span class=\"w\"> </span><span class=\"n\">t</span><span class=\"w\"> </span><span class=\"s2\">\"]\"</span><span class=\"w\"> </span><span class=\"bp\">=&gt;</span><span class=\"w\"> </span><span class=\"n\">ProbabilityTheory</span><span class=\"bp\">.</span><span class=\"n\">cond</span><span class=\"w\"> </span><span class=\"n\">Œº</span><span class=\"w\"> </span><span class=\"n\">t</span>\n</code></pre></div>\n<p>I think one of the large issues here is that notations are displayed poorly in Moogle (and in doc gen, as Moogle just uses the way they are displayed in doc gen).  But I agree that <a href=\"https://leanprover-community.github.io/mathlib4_docs/find/?pattern=ProbabilityTheory.cond#doc\">docs#ProbabilityTheory.cond</a> should appear higher and some of the other stuff on top is not related to conditional distribution.  But again, <a href=\"https://leanprover-community.github.io/mathlib4_docs/find/?pattern=ProbabilityTheory.cond#doc\">docs#ProbabilityTheory.cond</a> is still not that far down the list.  Of course, we shouldn't be content with mediocre tools.  One short-term solution is to click the <span aria-label=\"thumbs up\" class=\"emoji emoji-1f44d\" role=\"img\" title=\"thumbs up\">:thumbs_up:</span>/<span aria-label=\"thumbs down\" class=\"emoji emoji-1f44e\" role=\"img\" title=\"thumbs down\">:thumbs_down:</span> buttons as appropriate.</p>",
        "id": 490914864,
        "sender_full_name": "Jason Rute",
        "timestamp": 1735245663
    },
    {
        "content": "<p>(I wanted to try Lean Search too, but I'm getting a bad gateway error.  And last I remember it didn't cover definitions, just theorems, but maybe that has changed.  cc <span class=\"user-mention\" data-user-id=\"611077\">@Jiang Jiedong</span> )</p>",
        "id": 490914882,
        "sender_full_name": "Jason Rute",
        "timestamp": 1735245684
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"115715\">Jason Rute</span> <a href=\"#narrow/stream/113488-general/topic/What.20do.20you.20hope.20AI.20can.20help.20you.20achieve.20with.20Lean.20in.202025.3F/near/490914882\">said</a>:</p>\n<blockquote>\n<p>(I wanted to try Lean Search too, but I'm getting a bad gateway error.  And last I remember it didn't cover definitions, just theorems, but maybe that has changed.  cc <span class=\"user-mention silent\" data-user-id=\"611077\">Jiang Jiedong</span> )</p>\n</blockquote>\n<p>The current version of LeanSearch supports searching definition. This is added in the last update.</p>",
        "id": 490970476,
        "sender_full_name": "Jiang Jiedong",
        "timestamp": 1735291466
    },
    {
        "content": "<p>I tried to search ‚Äòconditional probability‚Äô using LeanSearch, the definition <a href=\"https://leanprover-community.github.io/mathlib4_docs/find/?pattern=ProbabilityTheory.cond_apply#doc\">docs#ProbabilityTheory.cond_apply</a> is at 6th place and first 5 results are theorems related to this definition like<br>\n<a href=\"https://leanprover-community.github.io/mathlib4_docs/find/?pattern=ProbabilityTheory.cond_apply#doc\">docs#ProbabilityTheory.cond_apply</a></p>",
        "id": 490971398,
        "sender_full_name": "Jiang Jiedong",
        "timestamp": 1735292145
    },
    {
        "content": "<p>If one uses query augmentation on query ‚Äòconditional probability‚ÄòÔºå the first 3 results are<br>\n<a href=\"https://leanprover-community.github.io/mathlib4_docs/find/?pattern=ProbabilityTheory.cond_apply#doc\">docs#ProbabilityTheory.cond_apply</a><br>\n<a href=\"https://leanprover-community.github.io/mathlib4_docs/find/?pattern=ProbabilityTheory.cond_apply%27#doc\">docs#ProbabilityTheory.cond_apply'</a><br>\n<a href=\"https://leanprover-community.github.io/mathlib4_docs/find/?pattern=ProbabilityTheory.cond#doc\">docs#ProbabilityTheory.cond</a></p>",
        "id": 490971552,
        "sender_full_name": "Jiang Jiedong",
        "timestamp": 1735292274
    },
    {
        "content": "<p>It is quite interesting to find out that LLM translate the first two theorems as ‚ÄúConditional Probability Axiomatic Definition‚Äù. The definition property is 'more definitional' than the Lean definition.</p>",
        "id": 490971886,
        "sender_full_name": "Jiang Jiedong",
        "timestamp": 1735292509
    },
    {
        "content": "<p>I wonder if sorting results topologically would help here (with X &lt; Y meaning that <code>type_of% Y</code> refers to <code>X</code></p>",
        "id": 491119465,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1735419174
    }
]