[
    {
        "content": "<p>Now that AIs including Aristotle, Kimina Prover, and Claude Opus 4.5 are known to produce proofs containing native_decide, we will see more of these in the wild. </p>\n<p>native_decide can be quite useful, and most of these uses of native_decide in AI proofs are benign; but as we know, it also asks us to trust the entire compiler, and has known exploits that prove false.  </p>\n<p>How do we verify that a native_decide is valid, not an exploit? My proposed solution: we say that a use of native_decide is verified if there exists another Lean proof of the same goal without using native_decide. And we ask AIs to help find such replacement proofs.</p>\n<p>In <a href=\"https://github.com/GasStationManager/ReplaceNativeDecide\">ReplaceNativeDecide</a>, I define a Claude Code subagent that takes a particular native_decide in a file, and replaces it with an explicit proof. You can prompt claude to invoke the subagent repeatedly to replace all <code>native_decide</code>s in a file.</p>\n<p>Contributions / suggestions are welcome! In particular, if you know of recipes for replacing native_decide when using frequently-used Mathlib features, that would be good candidates to include into the subagent's prompt! Try it out on your use cases, and let me know if it doesn't work.</p>",
        "id": 564895674,
        "sender_full_name": "GasStationManager",
        "timestamp": 1766325150
    },
    {
        "content": "<p>As someone who knows none of the technical details, why does native_decide even exist if sometimes it results in false proofs? Doesn't this undermine the entire point of Lean?</p>",
        "id": 564899193,
        "sender_full_name": "Thomas Bloom",
        "timestamp": 1766329879
    },
    {
        "content": "<p>The point is that it is more of an axiom <em>scheme</em> rather than a single axiom. <code>native_decide</code> means \"Trust all the non-Lean implementations of the Lean functions I use\".</p>",
        "id": 564899403,
        "sender_full_name": "Ya칢l Dillies",
        "timestamp": 1766330131
    },
    {
        "content": "<p>Lean has uses beyond mathematical proving. <code>native_decide</code> is very useful for writing fast code to do computations. You can easily cheat and get it to prove false things but conversely you can just not cheat and then get it to do fast calculations accurately in the same way that python is accurate without being formally verified.</p>",
        "id": 564899583,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1766330392
    },
    {
        "content": "<p>The key usage of native_decide is that you write a decision procedure and can then execute it with native speed without allowing a third party to inject code into the piece of code whose execution you trust. In these situations its still perfectly fine.</p>",
        "id": 564900886,
        "sender_full_name": "Henrik B칬ving",
        "timestamp": 1766332048
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"458865\">Thomas Bloom</span> <a href=\"#narrow/channel/113488-general/topic/Automated.20verification.20of.20native_decide/near/564899193\">said</a>:</p>\n<blockquote>\n<p>As someone who knows none of the technical details, why does native_decide even exist if sometimes it results in false proofs? Doesn't this undermine the entire point of Lean?</p>\n</blockquote>\n<p><span class=\"user-mention\" data-user-id=\"458865\">@Thomas Bloom</span>, you can use <code>#print axioms foo</code> to verify that a given proof doesn't use <code>native_decide</code>. Mathlib, for example, does not allow the use of <code>native_decide</code>.</p>\n<p>Unfortunately this wasn't said at the top of the thread --- perhaps it is a good habit for any thread discussing <code>native_decide</code> to include a mention of or link to these basics, to avoid unnecessary confusion.</p>",
        "id": 564908219,
        "sender_full_name": "Kim Morrison",
        "timestamp": 1766341491
    },
    {
        "content": "<p>Thanks everyone, all very helpful!</p>",
        "id": 564909317,
        "sender_full_name": "Thomas Bloom",
        "timestamp": 1766342888
    },
    {
        "content": "<p>Not sure how controversial this opinion is but I think that <code>native_decide</code> should eventually become trusted. Currently, I am aware of the following reasons why <code>native_decide</code> is not trusted</p>\n<ol>\n<li>It relies on trusting much more code than the Lean Kernel, and that code can be a bit buggy, one issue discussed <a href=\"#narrow/channel/113488-general/topic/possible.20semantics.20for.20partial.20functions/near/563942742\">here</a>.</li>\n<li>Users can define their own untrusted implementations, which is what people usually refer to when they say that you can prove <code>False</code> with it.</li>\n<li>(moreover) it can  lead to weird outcomes, like <a href=\"#narrow/channel/113488-general/topic/possible.20semantics.20for.20partial.20functions/near/562681988\">non-standard</a> natural numbers. This is not contradictory in any way, just a little weird.</li>\n</ol>\n<p>However, these issues can get in principle resolved.</p>\n<ol>\n<li>The compiler could get verified via meta-reasoning. This would be a long-term project but I don't think it is completely unrealistic.</li>\n<li><code>native_decide</code> could track which unsafe functions it relied on, possibly there could be a safe version of native decide which only runs the trusted part of the compiler.</li>\n<li>to calm down users, they can also imagine the non-standard number as 10^100, or any other number higher than any reasonable steps of computation...</li>\n</ol>\n<p>In the long-term, kernel cannot compete with fast evaluation, so it makes sense to prove things with <code>native_decide</code>. But sure, we are not yet in a stage where verifying Lean's compiler would be on the agenda, so attempts of replacing it in the proofs make a lot of sense too.</p>",
        "id": 564924822,
        "sender_full_name": "Mirek Ol코치k",
        "timestamp": 1766365094
    },
    {
        "content": "<p>If we'd like to trust native_decide, what would be the plan to prevent things like <a class=\"message-link\" href=\"/#narrow/channel/113488-general/topic/Cardinality.20model.20incompatible.20with.20Lean.20compiler/near/538013012\">#general &gt; Cardinality model incompatible with Lean compiler @ 游눫</a> ? The specific instance has been fixed, but I think there needs to be an overall scheme to prevent this if we put more trust on native_decide</p>",
        "id": 564925393,
        "sender_full_name": "Weiyi Wang",
        "timestamp": 1766365941
    },
    {
        "content": "<p>Why do we need the cardinality model?</p>",
        "id": 564925435,
        "sender_full_name": "Mirek Ol코치k",
        "timestamp": 1766365986
    },
    {
        "content": "<p>Lean already dropped homotopy type theory in the past by making some kernel decisions. I think the cardinality model can be dropped too.</p>",
        "id": 564925547,
        "sender_full_name": "Mirek Ol코치k",
        "timestamp": 1766366151
    },
    {
        "content": "<p>I don't think asking specifically about cardinality model is my point. My point is, how do we remember to ask this question when trusting the compiler?</p>",
        "id": 564925565,
        "sender_full_name": "Weiyi Wang",
        "timestamp": 1766366185
    },
    {
        "content": "<p>You mean to prevent Lean from crashing / doing weird things in runtime if proofs are wrong? Like Array overflow <code>by sorry</code></p>",
        "id": 564925655,
        "sender_full_name": "Mirek Ol코치k",
        "timestamp": 1766366309
    },
    {
        "content": "<p>Then I think you could just say that you only trust the three basic Lean's axioms (+ trusted <code>native_decide</code>) if you want to run Lean evaluation in a trusted  way too.</p>",
        "id": 564925726,
        "sender_full_name": "Mirek Ol코치k",
        "timestamp": 1766366417
    },
    {
        "content": "<p>Actually, there is a little of evaluation inconsistency</p>\n<div class=\"codehilite\" data-code-language=\"Lean4\"><pre><span></span><code><span class=\"kn\">axiom</span><span class=\"w\"> </span><span class=\"n\">mySorry</span><span class=\"w\"> </span><span class=\"o\">{</span><span class=\"n\">풤</span><span class=\"w\"> </span><span class=\"o\">:</span><span class=\"w\"> </span><span class=\"kt\">Prop</span><span class=\"o\">}</span><span class=\"w\"> </span><span class=\"o\">:</span><span class=\"w\"> </span><span class=\"n\">풤</span>\n\n<span class=\"bp\">#</span><span class=\"n\">eval</span><span class=\"w\"> </span><span class=\"k\">let</span><span class=\"w\"> </span><span class=\"n\">a</span><span class=\"w\"> </span><span class=\"o\">:=</span><span class=\"w\"> </span><span class=\"bp\">#</span><span class=\"o\">[</span><span class=\"mi\">0</span><span class=\"o\">]</span><span class=\"bp\">;</span><span class=\"w\"> </span><span class=\"n\">a</span><span class=\"o\">[</span><span class=\"mi\">0</span><span class=\"o\">]</span><span class=\"bp\">'</span><span class=\"o\">(</span><span class=\"gr\">sorry</span><span class=\"o\">)</span><span class=\"w\"> </span><span class=\"c1\">-- aborting evaluation since the expression depends on the 'sorry'</span>\n<span class=\"bp\">#</span><span class=\"n\">eval</span><span class=\"w\"> </span><span class=\"k\">let</span><span class=\"w\"> </span><span class=\"n\">a</span><span class=\"w\"> </span><span class=\"o\">:=</span><span class=\"w\"> </span><span class=\"bp\">#</span><span class=\"o\">[</span><span class=\"mi\">0</span><span class=\"o\">]</span><span class=\"bp\">;</span><span class=\"w\"> </span><span class=\"n\">a</span><span class=\"o\">[</span><span class=\"mi\">0</span><span class=\"o\">]</span><span class=\"bp\">'</span><span class=\"o\">(</span><span class=\"n\">mySorry</span><span class=\"o\">)</span><span class=\"w\"> </span><span class=\"c1\">-- 0</span>\n</code></pre></div>",
        "id": 564926181,
        "sender_full_name": "Mirek Ol코치k",
        "timestamp": 1766367235
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"133339\">@Mirek Ol코치k</span> I think I broadly agree with you; in the long term I would much prefer that more and more of the compiler become fully trusted, so that native_decide becomes safer to use, and (eventually) executable code can have provable guarantees that are as safe as other regular mathematical proofs. Perhaps a goal of this current mini-project is to show that AI-assisted proofs can have a role in this endeavor.</p>\n<p>I am not advocating to eliminate native_decide. It is perfectly reasonable to keep both the native_decide proof and the replacement proof; the former is more efficient and shorter, while the latter provides added security and peace of mind.</p>",
        "id": 564926540,
        "sender_full_name": "GasStationManager",
        "timestamp": 1766367742
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"873350\">Weiyi Wang</span> <a href=\"#narrow/channel/113488-general/topic/Automated.20verification.20of.20native_decide/near/564925565\">said</a>:</p>\n<blockquote>\n<p>I don't think asking specifically about cardinality model is my point. My point is, how do we remember to ask this question when trusting the compiler?</p>\n</blockquote>\n<p>Oh sorry, I just read the title and didn't realize you ask specifically about Aaron's example which used a specific unsafe <code>implemented_by</code>. That's what I addressed with point 2, there should be a trusted part of the compiler where people ensure there are no buggy implementations, and a <code>native_decide</code> should track if it only relies on those, or for example some user-defined code.</p>",
        "id": 564927169,
        "sender_full_name": "Mirek Ol코치k",
        "timestamp": 1766368609
    },
    {
        "content": "<blockquote>\n<ol>\n<li>The compiler could get verified via meta-reasoning. This would be a long-term project but I don't think it is completely unrealistic.</li>\n</ol>\n</blockquote>\n<p>As it stands we do not want to do this, having to fix proofs whenever we touch the compiler seems like too much of a burden. A more realistic alternative would be to introduce alternative native computation engines that can be trusted.</p>",
        "id": 564978527,
        "sender_full_name": "Henrik B칬ving",
        "timestamp": 1766400740
    },
    {
        "content": "<p>That sounds like a challenge for any provably correct software, not just (hypothetically) Lean compiler. I don't know what is the good way of developing provably correct SW but hope to see more of it in the future.</p>",
        "id": 565035464,
        "sender_full_name": "Mirek Ol코치k",
        "timestamp": 1766420653
    },
    {
        "content": "<p>But nothing against detached trusted compilers.</p>",
        "id": 565035931,
        "sender_full_name": "Mirek Ol코치k",
        "timestamp": 1766420821
    },
    {
        "content": "<p>Maybe, to evoid the <em>\"having to fix proofs whenever we touch the compiler\"</em> would be to have it as <code>native_decide?</code> that expands to the proof terms of the meta-reasoning. This way the proof is fixed in time, and changing the compiler would not impact it ?</p>",
        "id": 565039496,
        "sender_full_name": "Alfredo Moreira-Rosa",
        "timestamp": 1766422268
    },
    {
        "content": "<p>I thought the whole deal of native_decide is that it can't expand to terms?</p>",
        "id": 565041325,
        "sender_full_name": "Weiyi Wang",
        "timestamp": 1766423009
    },
    {
        "content": "<p>oh I think I see what you meant. If there is a proof for the compiler, then in principle it can be transformed into proof terms of proof generated by the said compiler. Though not sure how feasible it is</p>",
        "id": 565041635,
        "sender_full_name": "Weiyi Wang",
        "timestamp": 1766423157
    },
    {
        "content": "<p>I imagine the proof term from this will be huge</p>",
        "id": 565041820,
        "sender_full_name": "Weiyi Wang",
        "timestamp": 1766423241
    },
    {
        "content": "<p>There are speed &amp; specification issues.</p>\n<ul>\n<li>So far, I am not aware of a compiler specification that mimic<code>native_decide</code> being translated into axioms. At least non-standard numbers, and semantics of casting would have to be axiomatically solved. On the other hand, it would be fair to have it...</li>\n<li>If the proof term is big, we don't gain the speed (which is why we wanted <code>native_decide</code> in the first place). In some cases, proofs can be shorter (which is how bashing tactics work) but I am not sure if in proofs by computation.</li>\n</ul>",
        "id": 565042047,
        "sender_full_name": "Mirek Ol코치k",
        "timestamp": 1766423346
    },
    {
        "content": "<p>I don't really understand the theory behind all this but what about having a version of <code>native_decide</code> that does not allow <code>partial</code> nor <code>implementedy_by</code>(apart from very selected collection of functions that powers numbers, arrays etc.). This should exclude non standard natural numbers, no? But we could still benefit from complied speed.</p>",
        "id": 565044076,
        "sender_full_name": "Tomas Skrivan",
        "timestamp": 1766424194
    },
    {
        "content": "<p>By the way, <span class=\"user-mention\" data-user-id=\"776090\">@GasStationManager</span> , sorry for hijacking a bit your thread about prompting LLM to replace <code>native_decide</code>. Do you have examples / database of where you would like to do the replacement? Maybe that could help to figure out further methods beyond those already mentioned in <a href=\"https://github.com/GasStationManager/ReplaceNativeDecide/blob/main/.claude/agents/replace-native-decide.md\">the current prompt</a></p>",
        "id": 565046657,
        "sender_full_name": "Mirek Ol코치k",
        "timestamp": 1766425379
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"133339\">@Mirek Ol코치k</span> , no worries, these are interesting and relevant discussions. One comment that might link back to my prompt: one part of my prompt says to \"trace the computation\" when other attempts fail. This amounts to (mentally) simulating the compiler to reveal the computation steps, then verifying the computation. Are there other ways of extracting a computation trace (of native_decide) from the compiler? (e.g. perhaps show the generated C code to the LLM, or is that too confusing to read; and the LLM would still need to do the proof in Lean)</p>\n<p>So far I have tested this agent on <a href=\"https://github.com/harmonic-ai/IMO2025\">Aristotle's IMO 2025 solutions</a>, and a few of <a href=\"https://github.com/MoonshotAI/Kimina-Prover-Preview\">Kimina Prover</a>'s published MiniF2F solutions. Those proof attempts all eventually succeeded, though some took longer than others. Are there other interesting datasets of proofs containing native_decide?</p>",
        "id": 565052685,
        "sender_full_name": "GasStationManager",
        "timestamp": 1766428211
    },
    {
        "content": "<p>Are you extracting the proof state at the point of <code>native_decide</code> only, or giving the AI the full proof? I think just a local solution could work well.</p>",
        "id": 565054205,
        "sender_full_name": "Mirek Ol코치k",
        "timestamp": 1766429003
    },
    {
        "content": "<p>As far as I am aware, it is hard to follow <code>native_decide</code> proof closely with logical steps (I mean if standard <code>decide</code> fails). Then it means that the default logic of some function was replaced with another implementation which is not trusted (sometimes external).</p>",
        "id": 565054719,
        "sender_full_name": "Mirek Ol코치k",
        "timestamp": 1766429262
    },
    {
        "content": "<p>The key use case for <code>native_decide</code> is not to have some untrusted implementation or whatever but simply performance. By using native execution instead of a low performance symbolic execution through reduction, as is done by <code>decide</code>, you can get speedups of several orders of magnitude while still just running the exact same code as before.</p>",
        "id": 565058422,
        "sender_full_name": "Henrik B칬ving",
        "timestamp": 1766431152
    },
    {
        "content": "<p>For these use cases it is also not usually sensible to get a trace of the computation to verify or something like that. The trace of the computation is simply going to be too large. If you e.g. want to replay an UNSAT certificate of hunreds of megabytes ore ven gigabytes into the kernel it's not helpful if you produce a few gigabytes of trace that certify you correctly checked the certificate. The kernel will struggle processing that trace just as much as it would've struggled to consume a regular Lean translation of the certificate (which would in fact be utterly trivial to produce).</p>",
        "id": 565058865,
        "sender_full_name": "Henrik B칬ving",
        "timestamp": 1766431370
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"395550\">@Henrik B칬ving</span> that's a good point. I think the immediate use cases I have in mind are more for double-checking proofs by AIs, which (from what I've seen) tend to use native_decide for relatively small computations of base cases.</p>",
        "id": 565085302,
        "sender_full_name": "GasStationManager",
        "timestamp": 1766449702
    },
    {
        "content": "<p>I think the real solution here is to keep reminding the owners of such AIs that \"off by default\" control of whether the AI uses native_decide is desirable.</p>",
        "id": 565096090,
        "sender_full_name": "Kim Morrison",
        "timestamp": 1766462846
    },
    {
        "content": "<p>And hopefully we will have new automation next year that will cover this \"relatively small computations of base cases\" use case, producing efficient kernel checked proofs, and we can wean the AIs off native_decide.</p>",
        "id": 565113940,
        "sender_full_name": "Kim Morrison",
        "timestamp": 1766477227
    }
]