[
    {
        "content": "<p>I've recently finished a formalization of de Finetti's theorem for infinite exchangeable sequences on standard Borel spaces. Specifically, this project implements all three proofs from the beginning of Kallenberg's 2005 book <em>Probabilistic Symmetries and Invariance Principles</em>.</p>\n<ul>\n<li>repo: <a href=\"https://github.com/cameronfreer/exchangeability\">https://github.com/cameronfreer/exchangeability</a></li>\n<li>blueprint, docs, and import graphs: <a href=\"https://cameronfreer.github.io/exchangeability/\">https://cameronfreer.github.io/exchangeability/</a></li>\n</ul>\n<p>It involves ~43,500 lines of Lean over 113 files and 667 theorems/lemmas. The project took a little under 3 months, with extensive use of various Claude and GPT models along with the <a href=\"https://github.com/cameronfreer/lean4-skills\">Claude skill for Lean</a> that I've been developing (see also the earlier <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Lean.20Skill.20for.20Claude.20Code/with/547011308\">zulip discussion</a>).</p>\n<p>The three proofs each make substantial use of mathlib, though significant gaps had to be filled in each case:</p>\n<ol>\n<li><code>ViaMartingale</code>: Reverse martingale convergence (Aldous's approach). Gap: reverse martingale infrastructure</li>\n<li><code>ViaL2</code>: Elementary L² bounds (lightest dependencies). Gap: elementary detailed L² calculations for contractability</li>\n<li><code>ViaKoopman</code>: Mean Ergodic Theorem. Gap: machinery for applying mean ergodic theorem in this setting</li>\n</ol>\n<p>Next I plan to upstream some portions to mathlib. I'm aware that some aspects of the code can probably make better use of existing mathlib infrastructure, and I've started discussions with some probability maintainers about how to improve the code. There may also be some opportunities to make use of machinery developed in the recent <a href=\"https://github.com/RemyDegenne/brownian-motion\">Brownian motion</a> project.</p>\n<p>Any comments or suggestions are very welcome -- thanks!</p>",
        "id": 569060248,
        "sender_full_name": "Cameron Freer",
        "timestamp": 1768923343
    },
    {
        "content": "<p>Cameron given how critical statistics is for science, machine learning, finance, decision making, etc, but also how much statistics relies on deep math (like this theorem), what are your thoughts on formally verified statistics?  For example could we get to a point where we are making statistical inferences in a formalized way such that the statistical assumptions we are assuming easily pop out of the formalization? And if so, would that have value or would the ideal assumptions needed to apply the statistical tools be too strong and unrealistic to tell us anything useful, or so obvious that we don’t need formalization to keep track of them.</p>",
        "id": 569068749,
        "sender_full_name": "Jason Rute",
        "timestamp": 1768925188
    },
    {
        "content": "<p>In my opinion, (mathematical) statistics is clearly missing in Mathlib, but many foundations are already implemented. As an example, a <a href=\"https://en.wikipedia.org/wiki/Sufficient_statistic\">sufficient statistics</a> could be defined right away.</p>",
        "id": 569141459,
        "sender_full_name": "Peter Pfaffelhuber",
        "timestamp": 1768949263
    },
    {
        "content": "<p>I'd love to see a fourth proof via Markov <a href=\"https://arxiv.org/abs/2105.02639\">categories</a>! Their definition is already in Mathlib. I started writing the ergodic decomposition via them, but stopped to focus on my defense.</p>",
        "id": 569147910,
        "sender_full_name": "Lua Viana Reis",
        "timestamp": 1768953609
    }
]