[
    {
        "content": "<p>When using <code>trace.profiler</code> with proofs using <code>simp</code> and <code>grind</code> I have noticed that after the first trace, further traces can have significantly shorter times reported for elaboration, I assume due to caching. Are there any options to help with this?</p>",
        "id": 553716484,
        "sender_full_name": "Chris Henson",
        "timestamp": 1762290215
    },
    {
        "content": "<p>Do you mean after making an edit? I have not seen that before</p>",
        "id": 553718853,
        "sender_full_name": "Sebastian Ullrich",
        "timestamp": 1762291148
    },
    {
        "content": "<p>Yes, after making an edit. It is possible that I am misinterpreting normal variance in the times reported by the profiler, but I was suspicious because it seems to consistently report a faster elaboration time. (I'm not sure how to make an intentionally slow <code>grind</code> proof to turn this into something reproducible.)</p>",
        "id": 553721417,
        "sender_full_name": "Chris Henson",
        "timestamp": 1762292234
    },
    {
        "content": "<p>I doesn't have to be an MWE necessarily. We do have some persistent caches, but only for auxiliary declarations that, I would have assumed, do not take up significant time.</p>",
        "id": 553800974,
        "sender_full_name": "Sebastian Ullrich",
        "timestamp": 1762334277
    },
    {
        "content": "<p>Note that there is also <code>trace.profiler.useHeartbeats</code> that should give a more deterministic answer - which might or might not be helpful depending on which part you want to profile</p>",
        "id": 553801236,
        "sender_full_name": "Sebastian Ullrich",
        "timestamp": 1762334347
    },
    {
        "content": "<p>Do these persistently cached auxiliary declarations include proofs inside a <code>have</code>? If so, I think that explains it.</p>",
        "id": 553828700,
        "sender_full_name": "Chris Henson",
        "timestamp": 1762342194
    },
    {
        "content": "<p>No, they are general theorems derived from declarations such a congruence lemmas. Though if your edit is after the <code>have</code>, then of course it will only be elaborated once</p>",
        "id": 553835428,
        "sender_full_name": "Sebastian Ullrich",
        "timestamp": 1762344472
    },
    {
        "content": "<p>Hmm. Not asking you to take a look (you've been more than helpful enough with tips on using the profiler!) but in case anyone is curious, <a href=\"https://github.com/leanprover-community/mathlib4/compare/master...chenson2018:mathlib4:independence-grind\">this theorem/commit</a> is what I was looking at.</p>",
        "id": 553839935,
        "sender_full_name": "Chris Henson",
        "timestamp": 1762345436
    },
    {
        "content": "<p>If you could open a (draft) PR, I'm happy to take a look :)</p>",
        "id": 553842715,
        "sender_full_name": "Sebastian Ullrich",
        "timestamp": 1762346064
    },
    {
        "content": "<p>Okay thanks! I opened <a href=\"https://github.com/leanprover-community/mathlib4/pull/31282\">#31282</a>.</p>",
        "id": 553844125,
        "sender_full_name": "Chris Henson",
        "timestamp": 1762346465
    },
    {
        "content": "<p>Okay, I added <code>set_option trace.profiler true in</code> in front of <code>iIndepFun.indepFun_finset</code>, refreshed the file just to be sure, and got</p>\n<div class=\"codehilite\" data-code-language=\"Lean4\"><pre><span></span><code><span class=\"o\">[</span><span class=\"n\">Elab</span><span class=\"bp\">.</span><span class=\"n\">async</span><span class=\"o\">]</span><span class=\"w\"> </span><span class=\"o\">[</span><span class=\"mf\">20.839547</span><span class=\"o\">]</span><span class=\"w\"> </span><span class=\"n\">elaborating</span><span class=\"w\"> </span><span class=\"n\">proof</span><span class=\"w\"> </span><span class=\"n\">of</span><span class=\"w\"> </span><span class=\"n\">ProbabilityTheory</span><span class=\"bp\">.</span><span class=\"n\">Kernel</span><span class=\"bp\">.</span><span class=\"n\">iIndepFun</span><span class=\"bp\">.</span><span class=\"n\">indepFun_finset</span><span class=\"w\"> </span><span class=\"bp\">â–¶</span>\n</code></pre></div>\n<p>Then I added an empty line in front and got 17s, which may be explainable from additional parallel load when elaborating the full file the first time around. Does this roughly match what you're seeing?</p>",
        "id": 553850161,
        "sender_full_name": "Sebastian Ullrich",
        "timestamp": 1762348193
    },
    {
        "content": "<p>That is comparable, and I expected some difference for the first elab of the file. Would you expect to still see a difference after that, say if you just add/remove that option and then make a whitespace change?</p>",
        "id": 553851940,
        "sender_full_name": "Chris Henson",
        "timestamp": 1762348720
    },
    {
        "content": "<p>Oh, I do get 6.9s when adding another empty line, interesting!</p>",
        "id": 553852797,
        "sender_full_name": "Sebastian Ullrich",
        "timestamp": 1762348912
    },
    {
        "content": "<p>I think that's approximately what I was seeing. I spent a while trying to track down exactly where the change was with your <code>useHeartbeats</code> suggestion but didn't find exactly where the difference was. (The nature of needing to add/remove something after the first elab makes it a little annoying to compare the traces)</p>",
        "id": 553854263,
        "sender_full_name": "Chris Henson",
        "timestamp": 1762349281
    },
    {
        "content": "<p>Oh my bad, I think my machine was simply busy in the background compiling other parts of Mathlib... I now consistently get 6-7s on single-character edits as well as on restarting the file. Typing out e.g. <code>trace.profiler</code> does push it up to 13s, suggesting cancellation of previous tasks is not quite effective here yet.</p>",
        "id": 553873749,
        "sender_full_name": "Sebastian Ullrich",
        "timestamp": 1762353565
    },
    {
        "content": "<p>Hmm, maybe just a similar effect on my machine I was misinterpreting. Thanks for talking the time to look!</p>",
        "id": 553874726,
        "sender_full_name": "Chris Henson",
        "timestamp": 1762353796
    }
]