[
    {
        "content": "<p>what would it take to implement a knuth-bendix completion tactic (kb) where from available simp lemmas(if they happen to terminate), new unnamed ones are created out of critical pairs, until the equivalence to be proven can be proven by simp, and the new unnamed simp lemmas persist into later calls to kb, even in a different file (until they are named)?</p>",
        "id": 459906119,
        "sender_full_name": "Jared green",
        "timestamp": 1723392282
    },
    {
        "content": "<p>hmm, that's an interesting thought. Not sure you want this as a tactic tbh, it's probably more like a custom command. Also the idea of persisting them in a different file gives me a bit of pause, Lean already generates a bunch of stuff while elaborating (like recursors, noconfusion lemmas, equational lemmas on recursive definitions,etc), why woulnt they have a scheme like that and stay in memory?</p>\n<p>What it would take depends a lot on how familiar you are with metaprogramming, I reckon. A baseline prototype should be relatively simple, but e.g. dealing with typclasses properly might be a bit more interesting, etc.</p>\n<p>How seriously are you thinking about doing this? I've been thinking of implementing knuth bendix for a while, would be happy to help out with this</p>",
        "id": 462629699,
        "sender_full_name": "Andrés Goens",
        "timestamp": 1723752138
    },
    {
        "content": "<p>i didnt know whether or how the persistance could be done, especially through imports, though surely @[simp] and other annotations do exactly that. i have no knowledge of how to do metaprogramming, only just now reading the book on it. the thought was triggered by seeing the equality saturation<br>\n<a href=\"https://github.com/opencompl/egg-tactic-code?tab=readme-ov-file\">https://github.com/opencompl/egg-tactic-code?tab=readme-ov-file</a><br>\nwhich does a similar thing, and i wondered if in some cases knuth bendix could be more efficient, or even a combination of both.</p>",
        "id": 462634799,
        "sender_full_name": "Jared green",
        "timestamp": 1723753709
    },
    {
        "content": "<p>yeah, I think equality saturation is complementary to knuth bendix completion, knuth bendix should be better when it works (because it's a 1-off thing and gives you a set of rewrites, whereas equality saturation works for concrete terms) but often knuth bendix will not work/terminate, and there equality saturation should be better</p>",
        "id": 462710333,
        "sender_full_name": "Andrés Goens",
        "timestamp": 1723787132
    },
    {
        "content": "<p>btw, that's our old prototype repo that you linked, we've been working on a newer version based on it with <span class=\"user-mention\" data-user-id=\"372804\">@Marcus Rossel</span> <a href=\"https://github.com/marcusrossel/lean-egg\">https://github.com/marcusrossel/lean-egg</a></p>",
        "id": 462710619,
        "sender_full_name": "Andrés Goens",
        "timestamp": 1723787199
    },
    {
        "content": "<p>this one's still WIP but much more versatile (e.g. when dealing with typeclasses, etc), we should probably edit the readme on the old one to mention this</p>",
        "id": 462710830,
        "sender_full_name": "Andrés Goens",
        "timestamp": 1723787252
    },
    {
        "content": "<p>as they come, neither one terminates generally(though for different reasons). but from what i read both are 'complete' in the same way. ('if from the provided equations a given equivalence can be proven,  _ will be able to eventually prove it') only difference being that e-saturation doesn't need the initial equations to be reducing, or rely on a given ordering metric.<br>\n i have an idea for how e-saturation can stop much sooner, though im not sure whether it sacrifices completeness. it goes like this: alter the e-graph structure so that when a node is part of an e-node, all the links to its candidate parents are instead connected to the e-node. this way the same equivalence of the form x ~&gt; t(x) doesnt end up being chained twice. <br>\nas for the combination, i was thinking that (non-simp and non-orientable) equations would be handled by e-sat after simp, then for each element of the resulting equivalence class, repeat the process and then pick the least one.</p>",
        "id": 462714754,
        "sender_full_name": "Jared green",
        "timestamp": 1723788903
    },
    {
        "content": "<p>you're right, let me be more precise <span aria-label=\"sweat smile\" class=\"emoji emoji-1f605\" role=\"img\" title=\"sweat smile\">:sweat_smile:</span> in the case that the word problem for the theory defined by the set of equations is decidable and a confluent, terminating rewrite system exists, both equality saturation and knuth bendix completion will solve the word problem for that set of equations. In that case, I think knuth bendix is preferable because it just has to be done once, and then <code>simp</code> will solve the word problem more efficiently for that set of equations. </p>\n<p>I think the interesting case is the semi-decidable one. Knuth bendix will not terminate, but eqsat might. In practice, it seems eqsat always terminates way before saturation/quite quickly, or it doesn't terminate at all. In that case eqsat is preferable because it works effectively as a semi-decision procedure, whereas knuth bendix just doesn't work at all (I guess you could just stop knuth bendix at some point, take some of the equations generated byit and use them for simp as a semi-decision procedure too, that's an interesting comparison and I'm not sure what would win there)</p>",
        "id": 462745348,
        "sender_full_name": "Andrés Goens",
        "timestamp": 1723799045
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"394803\">Jared green</span> <a href=\"#narrow/stream/113488-general/topic/knuth.20bendix.20completion/near/462714754\">said</a>:</p>\n<blockquote>\n<p>i have an idea for how e-saturation can stop much sooner, though im not sure whether it sacrifices completeness. it goes like this: alter the e-graph structure so that when a node is part of an e-node, all the links to its candidate parents are instead connected to the e-node. this way the same equivalence of the form x ~&gt; t(x) doesnt end up being chained twice. </p>\n</blockquote>\n<p>not sure I quite understand this, what do you mean when a node is part of an e-node?</p>",
        "id": 462745460,
        "sender_full_name": "Andrés Goens",
        "timestamp": 1723799097
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"394803\">Jared green</span> <a href=\"#narrow/stream/113488-general/topic/knuth.20bendix.20completion/near/462714754\">said</a>:</p>\n<blockquote>\n<p>as for the combination, i was thinking that (non-simp and non-orientable) equations would be handled by e-sat after simp, then for each element of the resulting equivalence class, repeat the process and then pick the least one.</p>\n</blockquote>\n<p>oh, that's an interesting thought, using simp before eqsat! might actually be more efficient, not sure, we should test that <span aria-label=\"thinking\" class=\"emoji emoji-1f914\" role=\"img\" title=\"thinking\">:thinking:</span> but where does knuth bendix come in here?</p>",
        "id": 462745659,
        "sender_full_name": "Andrés Goens",
        "timestamp": 1723799170
    },
    {
        "content": "<p>i meant a term node, which represents either a value/variable or a function, and links to its inputs as its children. in an e-graph, term nodes are placed inside an e-node, representing an equivalence class, so that any one term in it can be switched for another, without storing full terms.<br>\nas for the combination, knuth bendix would be the outer loop, and the reductions that knuth bendix does would be done in that way.</p>",
        "id": 462788038,
        "sender_full_name": "Jared green",
        "timestamp": 1723815091
    },
    {
        "content": "<blockquote>\n<p>i meant a term node, which represents either a value/variable or a function, and links to its inputs as its children. in an e-graph, term nodes are placed inside an e-node, representing an equivalence class, so that any one term in it can be switched for another, without storing full terms.</p>\n</blockquote>\n<p>nope, not really, in an e-graph, terms are built from e-nodes, which have e-classes as children, and then e-classes have multiple e-nodes representing the equivalence classes. Full terms can then be extracted by selecting e-nodes for every e-class. What you are calling an e-node sounds like a mix of an e-class and an e-node.</p>",
        "id": 462792187,
        "sender_full_name": "Andrés Goens",
        "timestamp": 1723816333
    },
    {
        "content": "<blockquote>\n<p>as for the combination, knuth bendix would be the outer loop, and the reductions that knuth bendix does would be done in that way. </p>\n</blockquote>\n<p>So you want eqsat to prove the equations generated from knuth bendix, do I get that right?</p>",
        "id": 462792365,
        "sender_full_name": "Andrés Goens",
        "timestamp": 1723816402
    },
    {
        "content": "<p>it didnt look that way in the presentation i watched.<br>\nand no, e-sat would be used to find new terms when only non-orientable equations are applicable to a simplified term, and if any of the new terms can be further simplified, we try simplifying them.</p>",
        "id": 462793490,
        "sender_full_name": "Jared green",
        "timestamp": 1723816720
    },
    {
        "content": "<blockquote>\n<p>it didnt look that way in the presentation i watched. </p>\n</blockquote>\n<p>what presentation was that?</p>",
        "id": 462793623,
        "sender_full_name": "Andrés Goens",
        "timestamp": 1723816785
    },
    {
        "content": "<p>for knuth bendix algorithm, to prove an equivalence, each time a critical pair is found, reduction is tried on both sides of it and if they converge, thats the proof.</p>",
        "id": 462793925,
        "sender_full_name": "Jared green",
        "timestamp": 1723816880
    },
    {
        "content": "<p><a href=\"https://www.youtube.com/watch?v=ZLkHl7YmpIY\">https://www.youtube.com/watch?v=ZLkHl7YmpIY</a> 3 minutes in, i must have mispercieved it.</p>\n<div class=\"youtube-video message_inline_image\"><a data-id=\"ZLkHl7YmpIY\" href=\"https://www.youtube.com/watch?v=ZLkHl7YmpIY\"><img src=\"https://uploads.zulipusercontent.net/0dafcbfe4d71cf9e44b5caab0d70ba731b69e4fa/68747470733a2f2f692e7974696d672e636f6d2f76692f5a4c6b486c37596d7049592f64656661756c742e6a7067\"></a></div>",
        "id": 462794692,
        "sender_full_name": "Jared green",
        "timestamp": 1723817149
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"394803\">Jared green</span> <a href=\"#narrow/stream/113488-general/topic/knuth.20bendix.20completion/near/462794692\">said</a>:</p>\n<blockquote>\n<p><a href=\"https://www.youtube.com/watch?v=ZLkHl7YmpIY\">https://www.youtube.com/watch?v=ZLkHl7YmpIY</a> 3 minutes in, i must have mispercieved it.</p>\n</blockquote>\n<p>(just for context, to be sure, did you look at the author list at the beginning of that talk?)</p>",
        "id": 462795280,
        "sender_full_name": "Andrés Goens",
        "timestamp": 1723817372
    },
    {
        "content": "<p>i did now</p>",
        "id": 462795543,
        "sender_full_name": "Jared green",
        "timestamp": 1723817457
    },
    {
        "content": "<p>it's a bit confusing the terminology, so I'm still not sure what you mean with how to speed it up, but it would be cool to understand and try it out maybe!</p>",
        "id": 462796034,
        "sender_full_name": "Andrés Goens",
        "timestamp": 1723817642
    },
    {
        "content": "<p>somehow i actually remember a earlier version being different...</p>",
        "id": 462796450,
        "sender_full_name": "Jared green",
        "timestamp": 1723817813
    },
    {
        "content": "<p>the combination i suggest, im not even sure its necessarily faster than (unfailing) KB, but at least it doesnt require backtracking.</p>",
        "id": 462796722,
        "sender_full_name": "Jared green",
        "timestamp": 1723817923
    },
    {
        "content": "<p>I see, sounds interesting. If you want to give that a try I'm happy to give you a hand (also with using our eqsat tactic for that version)</p>",
        "id": 462797042,
        "sender_full_name": "Andrés Goens",
        "timestamp": 1723818035
    },
    {
        "content": "<p>if we do, what are we using as a reference implementation of KB?</p>",
        "id": 462802234,
        "sender_full_name": "Jared green",
        "timestamp": 1723819809
    },
    {
        "content": "<p>and whose github will it be on?</p>",
        "id": 462830895,
        "sender_full_name": "Jared green",
        "timestamp": 1723829920
    },
    {
        "content": "<p>it occurs to me that the combination i came up with would, instead of creating critical pairs, create critical sets of n terms from which (n-1) equations would be generated, in each iteration of its main loop.</p>",
        "id": 463014287,
        "sender_full_name": "Jared green",
        "timestamp": 1723914261
    },
    {
        "content": "<p>26 messages were moved from this topic to <a class=\"stream-topic\" data-stream-id=\"113488\" href=\"/#narrow/stream/113488-general/topic/simp.20local.20confluence.20checker\">#general &gt; simp local confluence checker</a> by <span class=\"user-mention silent\" data-user-id=\"470149\">Joachim Breitner</span>.</p>",
        "id": 463610247,
        "sender_full_name": "Notification Bot",
        "timestamp": 1724136973
    }
]