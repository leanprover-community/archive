[
    {
        "content": "<p>I was reading through <a href=\"#narrow/stream/113488-general/topic/Incomplete.20pattern.20match\">this thread</a> and was trying to think of ways to stop proofs that <code>1 - 2 = 3 - 6</code> (or something similar, I could see a variety of reasons that nat subtraction specifically shouldn't be changed). This idea probably sounded better in my head than it does on paper, but I was wondering if we could define a <code>junk_value</code> function that prevents proofs of equality, like this:</p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"n\">opaque</span> <span class=\"n\">junk_value</span> <span class=\"o\">(</span><span class=\"n\">n</span> <span class=\"n\">m</span> <span class=\"o\">:</span> <span class=\"n\">ℕ</span><span class=\"o\">)</span> <span class=\"o\">:</span> <span class=\"n\">ℕ</span> <span class=\"o\">:=</span> <span class=\"mi\">0</span>\n<span class=\"kd\">def</span> <span class=\"n\">minus</span> <span class=\"o\">(</span><span class=\"n\">n</span> <span class=\"n\">m</span> <span class=\"o\">:</span> <span class=\"n\">ℕ</span><span class=\"o\">)</span> <span class=\"o\">:</span> <span class=\"n\">ℕ</span> <span class=\"o\">:=</span> <span class=\"k\">if</span> <span class=\"n\">m</span> <span class=\"bp\">≤</span> <span class=\"n\">n</span> <span class=\"k\">then</span> <span class=\"n\">n</span> <span class=\"bp\">-</span> <span class=\"n\">m</span> <span class=\"k\">else</span> <span class=\"n\">junk_value</span> <span class=\"n\">n</span> <span class=\"n\">m</span>\n</code></pre></div>\n<p>That way, <code>1 - 2</code> reduces to <code>junk_value 1 2</code> and <code>3 - 5</code> reduces to <code>junk_value 3 5</code>, which are computationally equal, but as far as I know there's no way to prove this (except maybe <code>native_decide</code>, which I don't know how it works).</p>\n<p>A more generic <code>junk_value</code> function that works for all types could be:</p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"kd\">universe</span> <span class=\"n\">u</span> <span class=\"n\">v</span>\n<span class=\"n\">opaque</span> <span class=\"n\">junk_value</span> <span class=\"o\">{</span><span class=\"n\">α</span> <span class=\"o\">:</span> <span class=\"kt\">Type</span> <span class=\"n\">u</span><span class=\"o\">}</span> <span class=\"o\">{</span><span class=\"n\">β</span> <span class=\"o\">:</span> <span class=\"kt\">Type</span> <span class=\"n\">v</span><span class=\"o\">}</span> <span class=\"o\">[</span><span class=\"n\">Inhabited</span> <span class=\"n\">α</span><span class=\"o\">]</span> <span class=\"o\">(</span><span class=\"n\">b</span> <span class=\"o\">:</span> <span class=\"n\">β</span><span class=\"o\">)</span> <span class=\"o\">:</span> <span class=\"n\">α</span> <span class=\"o\">:=</span> <span class=\"n\">Inhabited.default</span>\n</code></pre></div>\n<p>where <code>β</code> would likely be a tuple containing the type of all arguments.</p>",
        "id": 319438942,
        "sender_full_name": "Niels Voss",
        "timestamp": 1672854380
    },
    {
        "content": "<p>One caveat is that for subtraction, it essentially has to be defined twice, once where <code>1 - 2</code> returns <code>0</code> and once where it returns <code>junk_value 1 2</code>. If you try defining it in one go, like</p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"kd\">def</span> <span class=\"n\">sub</span> <span class=\"o\">:</span> <span class=\"n\">Nat</span> <span class=\"bp\">-&gt;</span> <span class=\"n\">Nat</span> <span class=\"bp\">-&gt;</span> <span class=\"n\">Nat</span>\n<span class=\"bp\">|</span> <span class=\"mi\">0</span> <span class=\"n\">m</span> <span class=\"bp\">=&gt;</span> <span class=\"n\">junk_value</span> <span class=\"mi\">0</span> <span class=\"n\">m</span>\n<span class=\"bp\">|</span> <span class=\"n\">n</span> <span class=\"mi\">0</span> <span class=\"bp\">=&gt;</span> <span class=\"n\">n</span>\n<span class=\"bp\">|</span> <span class=\"o\">(</span><span class=\"n\">n</span><span class=\"bp\">+</span><span class=\"mi\">1</span><span class=\"o\">)</span> <span class=\"o\">(</span><span class=\"n\">m</span><span class=\"bp\">+</span><span class=\"mi\">1</span><span class=\"o\">)</span> <span class=\"bp\">=&gt;</span> <span class=\"n\">sub</span> <span class=\"n\">n</span> <span class=\"n\">m</span>\n</code></pre></div>\n<p>Then <code>1 - 5</code> and <code>2 - 6</code> both reduce to <code>junk_value 0 4</code> and can be proven equal.</p>",
        "id": 319441494,
        "sender_full_name": "Niels Voss",
        "timestamp": 1672855198
    },
    {
        "content": "<p>Is that a problem?</p>",
        "id": 319441866,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1672855318
    },
    {
        "content": "<p>Because <code>(1:ℤ) - (5:ℤ) = (2:ℤ) - (6:ℤ)</code>.</p>",
        "id": 319441955,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1672855340
    },
    {
        "content": "<p>I think it's reasonable to occasionaly have <code>junk_value a b = junk_value c d</code> if <code>a + d = c + b</code>.</p>",
        "id": 319442119,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1672855403
    },
    {
        "content": "<p>But anyway, it turns out that for applications in can be very helpful to have well-chosen junk-values.</p>",
        "id": 319442176,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1672855429
    },
    {
        "content": "<p>It can occasionally be a footgun, which is probably what you are trying to avoid. But it also saves you from checking a tonne of annoying side conditions.</p>",
        "id": 319442310,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1672855464
    },
    {
        "content": "<p>For natural number subtraction, I do agree that opaque junk values are not the way to go because having <code>1 - 2 = 0</code> is actually sometimes a useful property. I was thinking that <code>junk_value</code> would be more helpful in situations where there's not really a good junk value to choose.</p>",
        "id": 319442831,
        "sender_full_name": "Niels Voss",
        "timestamp": 1672855656
    },
    {
        "content": "<p>Why would it be helpful in such situations?</p>",
        "id": 319442883,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1672855681
    },
    {
        "content": "<p>If there's not really a good junk value to choose, then the risk for footguns is also quite small, I think.</p>",
        "id": 319443042,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1672855722
    },
    {
        "content": "<p>In which case it doesn't matter which junk value you choose.</p>",
        "id": 319443075,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1672855735
    },
    {
        "content": "<p>Do you have a concrete example in mind?</p>",
        "id": 319443144,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1672855761
    },
    {
        "content": "<p>No, I don't really have a concrete example. I guess it would help in some obscure definitions where it isn't made clear that junk values exist. I remember seeing some definition of an inverse in a ring or monoid (<a href=\"https://leanprover-community.github.io/mathlib_docs/find/ring.inverse\">docs#ring.inverse</a>) where it would return the inverse if it existed and zero if it didn't, but the function was just called <code>something.inverse</code> I think. That's not really a good example either because you can just read the doc strings, but someone looking at a lemma might see something like <code>inverse 3 = inverse 4</code> and be confused</p>",
        "id": 319443918,
        "sender_full_name": "Niels Voss",
        "timestamp": 1672856034
    },
    {
        "content": "<p>But generally, I agree that the risk is quite small</p>",
        "id": 319444062,
        "sender_full_name": "Niels Voss",
        "timestamp": 1672856070
    },
    {
        "content": "<p><a href=\"https://leanprover-community.github.io/mathlib_docs/find/ring.inverse\">docs#ring.inverse</a></p>",
        "id": 319444081,
        "sender_full_name": "Yaël Dillies",
        "timestamp": 1672856074
    },
    {
        "content": "<blockquote>\n<p>A more generic <code>junk_value</code> function that works for all types could be:</p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"kd\">universe</span> <span class=\"n\">u</span> <span class=\"n\">v</span>\n<span class=\"n\">opaque</span> <span class=\"n\">junk_value</span> <span class=\"o\">{</span><span class=\"n\">α</span> <span class=\"o\">:</span> <span class=\"kt\">Type</span> <span class=\"n\">u</span><span class=\"o\">}</span> <span class=\"o\">{</span><span class=\"n\">β</span> <span class=\"o\">:</span> <span class=\"kt\">Type</span> <span class=\"n\">v</span><span class=\"o\">}</span> <span class=\"o\">[</span><span class=\"n\">Inhabited</span> <span class=\"n\">α</span><span class=\"o\">]</span> <span class=\"o\">(</span><span class=\"n\">b</span> <span class=\"o\">:</span> <span class=\"n\">β</span><span class=\"o\">)</span> <span class=\"o\">:</span> <span class=\"n\">α</span> <span class=\"o\">:=</span> <span class=\"n\">Inhabited.default</span>\n</code></pre></div>\n<p>where <code>β</code> would likely be a tuple containing the type of all arguments.</p>\n</blockquote>\n<p>A <em>generic</em> junk value function is just as problematic as using 0, if you want to avoid \"junk\" theorems.  Because now you can prove e.g. <code>x / 0 = x % 0</code> by reflexivity.  You need to use a different opaque function for every occurrence to get truly unspecified values.</p>",
        "id": 319449267,
        "sender_full_name": "Gabriel Ebner",
        "timestamp": 1672857762
    },
    {
        "content": "<p>And even then they're merely unspecified, you can still prove all kinds of theorems about them.  Like <code>(a / b)^2 + 1 &gt; 0</code>.</p>",
        "id": 319449932,
        "sender_full_name": "Gabriel Ebner",
        "timestamp": 1672857996
    },
    {
        "content": "<p>I didn't consider the <code>x / 0 = x % 0</code> case that you mentioned. I guess a tactic could be used to generate the junk functions, or have <code>junk_value</code> take in a string containing the function name.<br>\nI don't really think there's a way to solve the second problem. At the very least, there's no way to take advantage of the specific undefined value and any theorems you prove about them essentially have to hold for every nat. It is still a bit unmathematical, but less alarming than something like <code>∀ n : ℕ, ∃ k, n / k = k</code>.</p>",
        "id": 319451841,
        "sender_full_name": "Niels Voss",
        "timestamp": 1672858567
    },
    {
        "content": "<p>On the other hand, there are useful theorems for nat.sub that you can't prove if the value is arbitrary instead of 0, like <a href=\"https://leanprover-community.github.io/mathlib_docs/find/has_ordered_sub\">docs#has_ordered_sub</a>.</p>",
        "id": 319461233,
        "sender_full_name": "Junyan Xu",
        "timestamp": 1672861864
    },
    {
        "content": "<p>Idea: mathlib should compile successfully independently of the choice of junk value for any partial function in mathlib. Why not have some kind of marker on all definitions of partial functions? Then periodically somebody goes through all these markers and changes their junk values to other junk values to test if the rest of mathlib is truly independent of these choices.</p>",
        "id": 319527101,
        "sender_full_name": "Winston Yin (尹維晨)",
        "timestamp": 1672903413
    },
    {
        "content": "<p>I remember thinking about this a few years ago and then deciding that any change that made things more complicated was hard to justify in practice.</p>",
        "id": 319527558,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1672903614
    },
    {
        "content": "<p>this is not true: we sometimes rely on junk values so that some simple theorems are true with less assumptions than in traditional maths. I don't have a good example at hand, though.</p>",
        "id": 319527659,
        "sender_full_name": "Moritz Doll",
        "timestamp": 1672903670
    },
    {
        "content": "<p>Is this something desirable if traditional mathematicians are the intended users?</p>",
        "id": 319527794,
        "sender_full_name": "Winston Yin (尹維晨)",
        "timestamp": 1672903728
    },
    {
        "content": "<p>This is definitely desirable since it leaves less assumptions to check for the user of theorems, and therefore makes the library smoother to use.</p>",
        "id": 319527998,
        "sender_full_name": "Sebastien Gouezel",
        "timestamp": 1672903820
    },
    {
        "content": "<p>it is very practiable and if it does not change the interesting mathematics, then I think nobody will object to that.</p>",
        "id": 319528018,
        "sender_full_name": "Moritz Doll",
        "timestamp": 1672903831
    },
    {
        "content": "<p>A good example is the change of variables formula <a href=\"https://leanprover-community.github.io/mathlib_docs/find/measure_theory.integral_target_eq_integral_abs_det_fderiv_smul\">docs#measure_theory.integral_target_eq_integral_abs_det_fderiv_smul</a>, where you don't need to check that the function is integrable because otherwise the same junk value <code>0</code> is used on both sides of the formula which is therefore still true.</p>",
        "id": 319528149,
        "sender_full_name": "Sebastien Gouezel",
        "timestamp": 1672903914
    },
    {
        "content": "<p>The canonical example is (a+b)/c=a/c+b/c</p>",
        "id": 319529970,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1672904857
    },
    {
        "content": "<p>Kevin has a nice blog post about this on Xena, btw. (If I was at a desk I'd look it up)</p>",
        "id": 319576075,
        "sender_full_name": "Ruben Van de Velde",
        "timestamp": 1672922138
    },
    {
        "content": "<p><a href=\"https://xenaproject.wordpress.com/2020/07/05/division-by-zero-in-type-theory-a-faq/\">https://xenaproject.wordpress.com/2020/07/05/division-by-zero-in-type-theory-a-faq/</a></p>",
        "id": 319577480,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1672922570
    },
    {
        "content": "<p>I somewhat agree with Sebastian Reichelt's comment on your post, Kevin, that the proof assistant should make the experience of using partial functions more convenient, independently of the question of the practical use of junk values. For example (maybe I'm totally misunderstanding how proof assistants work), when writing <code>real.sqrt x</code>, the proof assistant should let you keep on proving things without interruption, while silently introducing another goal <code>x ≥ 0</code> to be completed later. If such goals are showing up repeatedly throughout the proof, then a list of local \"facts\" may be declared and proven at the beginning of your proof / block, which the compiler can automatically use to discharge such goals.</p>",
        "id": 319691686,
        "sender_full_name": "Winston Yin (尹維晨)",
        "timestamp": 1672961041
    },
    {
        "content": "<p>that would be nice, but I think it is mostly wishful thinking to think that those goals would be silently created and/or discharged without interrupting the \"flow\"</p>",
        "id": 319692325,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1672961329
    },
    {
        "content": "<p>A whole series of real functions happen to have junk values defined to be equal to the real part of the (principal value of the) corresponding complex function at that argument; that applies to <code>sqrt</code>, <code>log</code>, <code>arcsin</code>, <code>arccos</code>, <code>arctan</code>, <code>rpow</code> at least (though only <code>rpow</code> has that as the definition, and we don't have the complex inverse trigonometric functions defined at all). It seems those junk values often work well together to reduce the number of times hypotheses are needed that arguments are in range.</p>",
        "id": 319703228,
        "sender_full_name": "Joseph Myers",
        "timestamp": 1672967671
    },
    {
        "content": "<p>Doesn't typing <code>suffices h : 0 &lt;= x</code> basically just keep the <code>0 &lt;= x</code> goal out of the way and force you to prove it at the end instead of immediately? I know no one uses it that way but I don't really think that Winston Yin's suggestion is infeasible with our current tactics. Discharging these goals is probably the hard part. It could perhaps be some new syntax, like two underscores or something, that you use instead of a proof to defer the proof until the end.</p>",
        "id": 319703229,
        "sender_full_name": "Niels Voss",
        "timestamp": 1672967672
    },
    {
        "content": "<blockquote>\n<p>A whole series of real functions happen to have junk values defined to be equal to the real part of the ...</p>\n</blockquote>\n<p>Then I am happy to stop calling them junk and call them unconventional instead. Seems to me they're no different than \"0! = 1\" or \"heaviside(0) = 1/2\" in spirit. From the standpoint of popularising formalisation towards mathematicians, this (philosophical) point about partial functions would have to be made clear from the beginning, probably somewhere on the path of de-conversion from set theory. Then I'll just accept that \"any practical implementation of type theory really doesn't like partial functions\".</p>",
        "id": 319720686,
        "sender_full_name": "Winston Yin (尹維晨)",
        "timestamp": 1672982992
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"521331\">@Niels Voss</span> You would still be typing more lines of proof than you have to do now. Which I would rather not.</p>",
        "id": 319720869,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1672983155
    },
    {
        "content": "<p>I guess I agree with that. Also, having read all the replies to this thread, I agree now that having <code>1 - 2</code> be <code>0</code> is probably the best that we can do in practice, though I agree with Winston Yin that this should be documented somewhere.</p>",
        "id": 319721099,
        "sender_full_name": "Niels Voss",
        "timestamp": 1672983358
    },
    {
        "content": "<p>My point is that it should not only be documented on <code>nat.sub</code>, but in any introduction to computer formalisation of maths. For me that was TPiL, but it was not clear to me then how much Lean doesn't like partial functions and subtypes.</p>",
        "id": 319721350,
        "sender_full_name": "Winston Yin (尹維晨)",
        "timestamp": 1672983544
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"112680\">Johan Commelin</span> <a href=\"#narrow/stream/113488-general/topic/Opaque.20junk.20values.20for.20partial.20functions/near/319720869\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"521331\">Niels Voss</span> You would still be typing more lines of proof than you have to do now. Which I would rather not.</p>\n</blockquote>\n<p>I think this is actually false</p>",
        "id": 319734891,
        "sender_full_name": "Reid Barton",
        "timestamp": 1672992706
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"110032\">@Reid Barton</span> Would you bundle the side conditions? Otherwise I don't see how you would save on lines.</p>",
        "id": 319735015,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1672992767
    },
    {
        "content": "<p>Unless you have some really smart automation going on.</p>",
        "id": 319735034,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1672992779
    },
    {
        "content": "<p>You basically always need to know whatever facts guarantee that what you wrote down was \"well-defined\" (else, why not just write 37 instead?) and if you make those proofs arguments to the partial functions, then they are available for later automation</p>",
        "id": 319735259,
        "sender_full_name": "Reid Barton",
        "timestamp": 1672992896
    },
    {
        "content": "<p>But that can also be done with our current strategy, right?</p>",
        "id": 319735675,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1672993121
    },
    {
        "content": "<p>You add <code>have aux1 : side condition</code> to your context, and voila, it is available to automation.</p>",
        "id": 319735702,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1672993139
    },
    {
        "content": "<p>only sufficiently local automation</p>",
        "id": 319735737,
        "sender_full_name": "Reid Barton",
        "timestamp": 1672993162
    },
    {
        "content": "<p>Anyways, I'm fairly convinced that the mathlib wisdom on this is just wrong but I don't think it will change.</p>",
        "id": 319735766,
        "sender_full_name": "Reid Barton",
        "timestamp": 1672993178
    },
    {
        "content": "<p>Are there examples of libraries (preferably with a DTT foundation) that take a different route?</p>",
        "id": 319735863,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1672993234
    },
    {
        "content": "<p>Also, if you want to pass the side condition to the partial function (which isn't what Niels was suggesting in the post I replied to) then how would you combine that with readable notation?</p>",
        "id": 319735940,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1672993275
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110043\">Gabriel Ebner</span> <a href=\"#narrow/stream/113488-general/topic/Opaque.20junk.20values.20for.20partial.20functions/near/319449932\">said</a>:</p>\n<blockquote>\n<p>And even then they're merely unspecified, you can still prove all kinds of theorems about them.  Like <code>(a / b)^2 + 1 &gt; 0</code>.</p>\n</blockquote>\n<p>That only applies to type theory. In set theory, a function is a set of ordered pairs. If called with an argument outside of the domain, the result can be any set (choice-based set parametrized with the function and the argument), which is not necessarily in the codomain. So, you couldn't prove <code>(a / b)^2 + 1 &gt; 0</code> if <code>a</code> or <code>b</code> cannot be proved to be real numbers for example.</p>",
        "id": 319737388,
        "sender_full_name": "Patrick Johnson",
        "timestamp": 1672994059
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110032\">Reid Barton</span> <a href=\"#narrow/stream/113488-general/topic/Opaque.20junk.20values.20for.20partial.20functions/near/319735259\">said</a>:</p>\n<blockquote>\n<p>You basically always need to know whatever facts guarantee that what you wrote down was \"well-defined\" (else, why not just write 37 instead?) and if you make those proofs arguments to the partial functions, then they are available for later automation</p>\n</blockquote>\n<p>Making more functions take proofs as arguments will lead to <code>rw</code> throwing <code>motive not type correct</code> all the time.</p>",
        "id": 319737617,
        "sender_full_name": "Patrick Johnson",
        "timestamp": 1672994200
    },
    {
        "content": "<p>I think the idea for having an \"unknown\" junk value (or an implicit junk value as a corollary of using <code>classical.epsilon</code>) rather than an explicit default value is to prevent us from proving nonsense theorems (such as <a href=\"https://leanprover-community.github.io/mathlib_docs/find/nat.div_zero\">docs#nat.div_zero</a>), simply because they are counter-intuitive to most mathematicians, and generally a bad advertisement for Lean. Instead, the right path would be to invent a better way of dealing with those special conditions.</p>",
        "id": 319738456,
        "sender_full_name": "Patrick Johnson",
        "timestamp": 1672994606
    },
    {
        "content": "<blockquote>\n<p>That only applies to type theory.</p>\n</blockquote>\n<p>Obviously we're only talking about Lean('s foundations) here.  There are other foundations where partiality is even \"better\" handled, and you can't even prove <code>a / b = a / b</code> (which is a junk theorem provable in set theory).</p>",
        "id": 319837755,
        "sender_full_name": "Gabriel Ebner",
        "timestamp": 1673029908
    },
    {
        "content": "<p>Do you have an example of such foundations? I'm interested to learn more about them.</p>",
        "id": 319883493,
        "sender_full_name": "Patrick Johnson",
        "timestamp": 1673049359
    },
    {
        "content": "<p>BTW, I think <code>a / b = a / b</code> would be the expected result no matter what <code>a</code> and <code>b</code> are. Most mathematicians would agree that <code>1 / 0 = 1 / 0</code>, even though <code>1 / 0</code> may not be a real number, but it is definitely \"something\", and any object is equal to itself. (Unless equality itself is a partial relation?)</p>",
        "id": 319883578,
        "sender_full_name": "Patrick Johnson",
        "timestamp": 1673049404
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110049\">Mario Carneiro</span> <a href=\"#narrow/stream/113488-general/topic/Opaque.20junk.20values.20for.20partial.20functions/near/319692325\">said</a>:</p>\n<blockquote>\n<p>that would be nice, but I think it is mostly wishful thinking to think that those goals would be silently created and/or discharged without interrupting the \"flow\"</p>\n</blockquote>\n<p>This reminds me of what I see WolframAlpha doing sometimes. For example, <a href=\"https://www.wolframalpha.com/input?i=a+x+%5E+2+%2B+b+x+%2B+c+%3D+0+solve+for+x\">https://www.wolframalpha.com/input?i=a+x+%5E+2+%2B+b+x+%2B+c+%3D+0+solve+for+x</a>. The answer depends on whether or not a and b are 0, and I didn’t specify. But I still get an answer — in fact, I get a few answers, along with the additional hypotheses needed to get to each one.</p>",
        "id": 319885540,
        "sender_full_name": "Tyler Josephson ⚛️",
        "timestamp": 1673050826
    },
    {
        "content": "<p>We have this thing called partial equivalence relations, and it is very useful in proving type theoretic theorems. Also, some constructive foundations use this (a type equipped with a PER) when you don't have good quotients and subtypes.</p>",
        "id": 319905330,
        "sender_full_name": "Trebor Huang",
        "timestamp": 1673067779
    },
    {
        "content": "<p>We have <a href=\"https://leanprover-community.github.io/mathlib_docs/find/divp\">docs#divp</a>, <a href=\"https://leanprover-community.github.io/mathlib_docs/find/has_deriv_at\">docs#has_deriv_at</a>, and <a href=\"https://leanprover-community.github.io/mathlib_docs/find/nnreal.sqrt\">docs#nnreal.sqrt</a> for people who want to avoid junk values.</p>",
        "id": 319919992,
        "sender_full_name": "Yury G. Kudryashov",
        "timestamp": 1673080094
    },
    {
        "content": "<p>After some research I have come to the conclusion: <strong>Every proof assistant that uses classical logic and formalizes real numbers have <code>x/0=0</code></strong>.</p>",
        "id": 321896751,
        "sender_full_name": "Trebor Huang",
        "timestamp": 1673979878
    },
    {
        "content": "<p>I am very happy to be proved wrong but I just haven't come across any. For constructive people, this is not an option because you can't decide whether a real number is zero, so they have to find another way.</p>",
        "id": 321896909,
        "sender_full_name": "Trebor Huang",
        "timestamp": 1673979934
    },
    {
        "content": "<p>Also, this is not restricted to type theory. Mizar does that too.</p>",
        "id": 321897075,
        "sender_full_name": "Trebor Huang",
        "timestamp": 1673979982
    },
    {
        "content": "<p>Metamath defines <code>x/0</code> to be the empty set instead of 0, but that also counts as a junk value.</p>",
        "id": 321897361,
        "sender_full_name": "Trebor Huang",
        "timestamp": 1673980080
    },
    {
        "content": "<p>I would count <em>any</em> value for <code>x/0</code> as a junk value...</p>",
        "id": 321897529,
        "sender_full_name": "Damiano Testa",
        "timestamp": 1673980130
    },
    {
        "content": "<p>No, if division returns <code>Option Real</code> and <code>x/0 = None</code> then probably not</p>",
        "id": 321897656,
        "sender_full_name": "Trebor Huang",
        "timestamp": 1673980173
    },
    {
        "content": "<p>Or if it is outright undefined, like if you have a proof obligation before you use division.</p>",
        "id": 321897812,
        "sender_full_name": "Trebor Huang",
        "timestamp": 1673980206
    },
    {
        "content": "<p>Can you add a real number to the empty set in Metamath? I think they use complex numbers?</p>",
        "id": 321897876,
        "sender_full_name": "Junyan Xu",
        "timestamp": 1673980219
    },
    {
        "content": "<p>In that case, before starting on formalizing math, I would have considered <em>all</em> values as junk values!  <span aria-label=\"upside down\" class=\"emoji emoji-1f643\" role=\"img\" title=\"upside down\">:upside_down:</span></p>",
        "id": 321897893,
        "sender_full_name": "Damiano Testa",
        "timestamp": 1673980223
    },
    {
        "content": "<p>Yes you can add anything. Nonsense addtions return the empty set.</p>",
        "id": 321898068,
        "sender_full_name": "Trebor Huang",
        "timestamp": 1673980270
    },
    {
        "content": "<p>Yeah so maybe the lesson is that junk values occur much more often in set theory than in type theory.</p>",
        "id": 321898236,
        "sender_full_name": "Junyan Xu",
        "timestamp": 1673980315
    },
    {
        "content": "<p><a href=\"https://arxiv.org/abs/0901.0823\">There's a paper</a> defining \"meadows,\" which are rings with a total inverse-like function. Fields extend to meadows if you have x/0 = 0.</p>\n<p>There's also something called a <a href=\"https://en.wikipedia.org/wiki/Von_Neumann_regular_ring\">von Neumann regular ring</a> -- I guess <a href=\"#narrow/stream/113488-general/topic/XenaProject.20blog.20posts/near/203041825\">I brought these up before</a> in this context. In a von Neumann regular ring, for every <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>x</mi></mrow><annotation encoding=\"application/x-tex\">x</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.4306em;\"></span><span class=\"mord mathnormal\">x</span></span></span></span> there exists a <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>y</mi></mrow><annotation encoding=\"application/x-tex\">y</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.1944em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">y</span></span></span></span> such that <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>x</mi><mo>=</mo><mi>x</mi><mi>y</mi><mi>x</mi></mrow><annotation encoding=\"application/x-tex\">x=xyx</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.4306em;\"></span><span class=\"mord mathnormal\">x</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.1944em;\"></span><span class=\"mord mathnormal\">x</span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">y</span><span class=\"mord mathnormal\">x</span></span></span></span>, a sort of weak inverse. If you say you want an involutive function <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>f</mi><mo>:</mo><mi>R</mi><mo>→</mo><mi>R</mi></mrow><annotation encoding=\"application/x-tex\">f:R\\to R</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10764em;\">f</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">:</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.00773em;\">R</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">→</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.00773em;\">R</span></span></span></span> that chooses a weak inverse for each element of <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>R</mi></mrow><annotation encoding=\"application/x-tex\">R</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.00773em;\">R</span></span></span></span>, then it must be the case that <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>f</mi><mo stretchy=\"false\">(</mo><mn>0</mn><mo stretchy=\"false\">)</mo><mo>=</mo><mn>0</mn></mrow><annotation encoding=\"application/x-tex\">f(0)=0</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10764em;\">f</span><span class=\"mopen\">(</span><span class=\"mord\">0</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6444em;\"></span><span class=\"mord\">0</span></span></span></span>.</p>",
        "id": 321901232,
        "sender_full_name": "Kyle Miller",
        "timestamp": 1673981275
    },
    {
        "content": "<p>I think that from an algebraic point of view, there are plenty of good reasons for <code>x/0 = 0</code>. But topologically it is of course garbáge.</p>",
        "id": 321901540,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1673981383
    },
    {
        "content": "<blockquote>\n<p>Metamath defines <code>x/0</code> to be the empty set instead of 0, but that also counts as a junk value.<br>\nNonsense additions return the empty set.</p>\n</blockquote>\n<p>In the classical set theory (also applies to mizar) it would be much better if they defined addition and division of real numbers using Hilbert's epsilon, so that the result of <code>x / 0</code> can be any set that could possibly exist, not necessarily a real number. Then create an appropriate API for using division and all lemmas that use division <code>a / b</code> would have an assumption <code>b ≠ 0</code>. From the implementational point of view, this additional assumption can be proved automatically from the local context in most cases (just like Lean's type class resolution).</p>",
        "id": 321912748,
        "sender_full_name": "Patrick Johnson",
        "timestamp": 1673984778
    },
    {
        "content": "<p>Unfortunately, metamath lacks automation and mizar is no longer actively developed (and more importantly not open source). I'm wondering what could be the reason there are no good set-theoretic theorem provers out there.</p>",
        "id": 321913271,
        "sender_full_name": "Patrick Johnson",
        "timestamp": 1673984994
    },
    {
        "content": "<p>Metamath must have something going for it, if Mario can prove the prime number theorem in it.</p>",
        "id": 321920221,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1673987411
    },
    {
        "content": "<p>That thing is probably Mario...</p>",
        "id": 321922002,
        "sender_full_name": "Damiano Testa",
        "timestamp": 1673988040
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110032\">Reid Barton</span> <a href=\"#narrow/stream/113488-general/topic/Opaque.20junk.20values.20for.20partial.20functions/near/319735259\">said</a>:</p>\n<blockquote>\n<p>You basically always need to know whatever facts guarantee that what you wrote down was \"well-defined\" (else, why not just write 37 instead?) and if you make those proofs arguments to the partial functions, then they are available for later automation</p>\n</blockquote>\n<p>A good example of where this approach is useful is <a href=\"https://leanprover-community.github.io/mathlib_docs/find/finset.cons\">docs#finset.cons</a> / <a href=\"https://leanprover-community.github.io/mathlib_docs/find/finset.disj_union\">docs#finset.disj_union</a> vs <a href=\"https://leanprover-community.github.io/mathlib_docs/find/finset.has_insert\">docs#finset.has_insert</a> / <a href=\"https://leanprover-community.github.io/mathlib_docs/find/finset.has_union\">docs#finset.has_union</a>. When working with sums, the first pair has an obvious lemma with no side conditions.</p>",
        "id": 321962644,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1674008192
    },
    {
        "content": "<p>One downside of this approach is that you often need two versions of every lemma, one with the free hypothesis variables on the RHS, and one with them on the LHS; <a href=\"https://leanprover-community.github.io/mathlib_docs/find/finset.singleton_disj_union\">docs#finset.singleton_disj_union</a> doesn't automatically populate the side condition when rewriting backwards.</p>",
        "id": 321962796,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1674008328
    },
    {
        "content": "<p>For division we have <code>/ₚ</code>. It requires the denominator to be a unit.</p>",
        "id": 321962997,
        "sender_full_name": "Yury G. Kudryashov",
        "timestamp": 1674008508
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"404479\">Trebor Huang</span> <a href=\"#narrow/stream/113488-general/topic/Opaque.20junk.20values.20for.20partial.20functions/near/321896751\">said</a>:</p>\n<blockquote>\n<p>After some research I have come to the conclusion: <strong>Every proof assistant that uses classical logic and formalizes real numbers have <code>x/0=0</code></strong>.</p>\n</blockquote>\n<p>Metamath does not define the division function at zero. The function properly has the domain <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi mathvariant=\"double-struck\">C</mi><mo>×</mo><mo stretchy=\"false\">(</mo><mi mathvariant=\"double-struck\">C</mi><mo>∖</mo><mo stretchy=\"false\">{</mo><mn>0</mn><mo stretchy=\"false\">}</mo><mo stretchy=\"false\">)</mo><mo>→</mo><mi mathvariant=\"double-struck\">C</mi></mrow><annotation encoding=\"application/x-tex\">\\mathbb{C}\\times(\\mathbb{C}\\setminus\\{0\\})\\to \\mathbb{C}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.7722em;vertical-align:-0.0833em;\"></span><span class=\"mord mathbb\">C</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">×</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">(</span><span class=\"mord mathbb\">C</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">∖</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">{</span><span class=\"mord\">0</span><span class=\"mclose\">})</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">→</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6889em;\"></span><span class=\"mord mathbb\">C</span></span></span></span>. It is true that if you evaluate <code>( x / 0 )</code> you get the empty set but that's because this is what happens when you use the \"function value\" operator on a ZFC function out of domain, not because division was defined that way.</p>",
        "id": 321982709,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1674024448
    },
    {
        "content": "<p>Even more interestingly, there is a new metamath database <a href=\"https://us.metamath.org/ileuni/mmil.html\">iset.mm</a> (for intuitionistic set theory) which has gotten a lot of recent work done on it thanks to Jim Kingdon, and while it tries to follow <a href=\"https://us.metamath.org/mpeuni/mmset.html\">set.mm</a> where possible you just flat out cannot prove that the \"function value\" operation makes any sense without an assumption that the input is in the function's domain. It gets as far as the real numbers, and division again has the same definition (well, I think you need the denominator to be apart from zero but w/e), but you definitely don't have <code>x/0 = 0</code> there. (Although, you did head this off by qualifying \"classical logic\" so I suppose that doesn't count against your claim.)</p>",
        "id": 321983467,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1674024991
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"456794\">Patrick Johnson</span> <a href=\"#narrow/stream/113488-general/topic/Opaque.20junk.20values.20for.20partial.20functions/near/321913271\">said</a>:</p>\n<blockquote>\n<p>Unfortunately, metamath lacks automation and mizar is no longer actively developed (and more importantly not open source). I'm wondering what could be the reason there are no good set-theoretic theorem provers out there.</p>\n</blockquote>\n<p>Just in case it wasn't obvious, this is basically asking \"why aren't there more theorem provers with 30+ person-years of effort put into them\". That doesn't come cheap, and as a result you will see a variety of development-specific peculiarities in the ones that exist. Mizar is quite honestly the best contender in that space, it has had many years of effort put into it, but it started out in a completely different era and it has a lot of baggage from that time period. I will also of course shill my <a href=\"https://github.com/digama0/mm0\">MM0</a> system as a sort of hybrid of metamath with automation, although (like metamath) it is not explicitly set theory based so much as FOL based.</p>",
        "id": 321985530,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1674025945
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110049\">Mario Carneiro</span> <a href=\"#narrow/stream/113488-general/topic/Opaque.20junk.20values.20for.20partial.20functions/near/321985530\">said</a>:</p>\n<blockquote>\n<p>Just in case it wasn't obvious, this is basically asking \"why aren't there more theorem provers with 30+ person-years of effort put into them\". </p>\n</blockquote>\n<p>I'm not talking about math library, I'm talking about design choices of the verifier. Foundations, implementation decisions, term/tactic mode proofs, and similar concepts. Once conceptually designed, a single person can implemented it in a very short period of time and start building a math library.</p>",
        "id": 321988909,
        "sender_full_name": "Patrick Johnson",
        "timestamp": 1674027473
    },
    {
        "content": "<p>Last year I started designing and implementing a purely set-theoretic theorem prover. Two of my friends are working with me and we plan to finish the verifier near the end of this year. Then we will build a simple math library and prove basic things from number theory. I'm pretty sure this won't take 30+ person-years of effort.</p>",
        "id": 321989845,
        "sender_full_name": "Patrick Johnson",
        "timestamp": 1674027877
    },
    {
        "content": "<p>sure, but will it be \"good\"? That's a really load-bearing word. It takes years of effort for a theorem prover to become \"good\"</p>",
        "id": 321992415,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1674029030
    },
    {
        "content": "<p>There are plenty of theorem provers out there with every possible design decision if you don't put that word in</p>",
        "id": 321992506,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1674029059
    },
    {
        "content": "<p>Set theory based provers probably have different aesthetics, so what counts as junk value would be different. Judging from a type theoretic perspective returning the empty set definitely counts as junk values, but you could argue otherwise from the set theoretic view.</p>",
        "id": 321993037,
        "sender_full_name": "Trebor Huang",
        "timestamp": 1674029297
    },
    {
        "content": "<p>In any FOL system, function symbols are fundamentally required to denote something. It's no different from a type theory system in which there is only one or only a few types</p>",
        "id": 321993429,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1674029490
    },
    {
        "content": "<p>the best you can do is control what theorems are provable about that something</p>",
        "id": 321993447,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1674029507
    },
    {
        "content": "<p>Personally, I'm in the camp of embracing \"junk values\" and making them as useful as possible though, so I'm not really motivated to come up with even more tightly isolated junk values, because it never works and only causes pain in my experience</p>",
        "id": 321993720,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1674029607
    },
    {
        "content": "<p>So if I were making a theorem prover I would set <a href=\"https://github.com/digama0/mm0/blob/45e06c7f95293e974bebd66350c9c45ca304a9a3/examples/peano.mm0#L275\"><code>x / 0 = 0</code></a> like lean does</p>",
        "id": 321993956,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1674029708
    },
    {
        "content": "<p>In first order logic + set theory, the empty set looks very much like a global canonical junk, so I'm fine with that. Type theory doesn't give you that (at least not in Lean, I think some type theories not using the CH isomorphism introduce a global undefined value for every type).</p>",
        "id": 321994017,
        "sender_full_name": "Trebor Huang",
        "timestamp": 1674029729
    },
    {
        "content": "<p><code>Inhabited</code> basically gives you canonical junk</p>",
        "id": 321994041,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1674029745
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110049\">Mario Carneiro</span> <a href=\"#narrow/stream/113488-general/topic/Opaque.20junk.20values.20for.20partial.20functions/near/321993956\">said</a>:</p>\n<blockquote>\n<p>So if I were making a theorem prover I would set <a href=\"https://github.com/digama0/mm0/blob/45e06c7f95293e974bebd66350c9c45ca304a9a3/examples/peano.mm0#L275\"><code>x / 0 = 0</code></a> like lean does</p>\n</blockquote>\n<p>It highly depends on what the goal of a theorem prover is supposed to be. MM0 has an objective task it's trying to accomplish, so it makes sense to have <code>x / 0 = 0</code> as a theorem if it helps reach the final task. However, if we want to write a general-purpose theorem prover to formalize actual mathematics, I see the undefinedness of <code>x / 0</code> as a challenge for the theorem prover inventors, rather than a nuisance we want to avoid at all costs. Mathematicians can handle that on paper without any trouble, so a good theorem prover should have the ability to smoothly translate mathematician's intuition to a formal proof, not to artificially force mathematicians to change their intuition because of the implementational limitations.</p>",
        "id": 322119027,
        "sender_full_name": "Patrick Johnson",
        "timestamp": 1674065263
    },
    {
        "content": "<p>This is most likely an irreconcilable difference of opinion, but my angle as a logician and formalist is to find the optimal way to communicate mathematics to a computer, not just to do paper mathematics in the computer and faithfully represent all the designed-for-humans tricks used in paper presentations of mathematics. The latter is a goal for some people, and systems based on controlled natural language very clearly show it, but I am looking at the longer term, where we eventually realize we don't need to follow those old habits anymore. It is akin to the evolution of programming languages: many of the old programming languages were <em>very</em> CNL inspired, but modern programming languages have diverged somewhat from that into simpler grammars with a greater emphasis on symbols instead of words, making the most of a restricted lexicon to make things easy for both the human and the computer.</p>\n<p>As it relates to undefinedness specifically, I find that the best way to render the mathematical practice of having \"unmentionables\" is to use garbage values and then just... not talk about them. Or use them to reduce hypotheses in theorems because more hypotheses = more work.</p>",
        "id": 322125938,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1674067337
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"456794\">Patrick Johnson</span> <a href=\"#narrow/stream/113488-general/topic/Opaque.20junk.20values.20for.20partial.20functions/near/322119027\">said</a>:</p>\n<blockquote>\n<p>A good theorem prover should have the ability to smoothly translate mathematician's intuition to a formal proof, not to artificially force mathematicians to change their intuition because of the implementational limitations.</p>\n</blockquote>\n<p>Note that this might be alternatively phrased as</p>\n<blockquote>\n<p>A good theorem prover should never produce new mathematical viewpoints or ideas, and it should have the ability to transfer mathematician's old ideas as faithfully as possible.</p>\n</blockquote>",
        "id": 322136542,
        "sender_full_name": "Trebor Huang",
        "timestamp": 1674070476
    },
    {
        "content": "<p>I don't think I agree with this rephrasing. But in any case, I think that while there are cases where garbage values really are garbage, in many instances I think that appropriately chosen junk values can actually become \"not junk\". For instance, I consider the theorem</p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"kd\">example</span> <span class=\"o\">{</span><span class=\"n\">G</span> <span class=\"o\">:</span> <span class=\"kt\">Type</span><span class=\"bp\">*</span><span class=\"o\">}</span> <span class=\"o\">[</span><span class=\"n\">group_with_zero</span> <span class=\"n\">G</span><span class=\"o\">]</span> <span class=\"o\">(</span><span class=\"n\">x</span> <span class=\"o\">:</span> <span class=\"n\">G</span><span class=\"o\">)</span> <span class=\"o\">:</span> <span class=\"n\">x</span><span class=\"bp\">⁻¹⁻¹</span> <span class=\"bp\">=</span> <span class=\"n\">x</span> <span class=\"o\">:=</span> <span class=\"gr\">sorry</span>\n</code></pre></div>\n<p>a <em>feature</em>, not a bug or a misrepresentation of the mathematical content. Sure, it conflicts with the way mathematical content is currently presented, but I have pretty much decided that I prefer it this way and I would hope eventually the mathematical community could accept the more useful (i.e., ones that make a bunch of theorems have weaker hypotheses) \"junk values\".</p>\n<p>Oh, and if you don't want garbage values, there's always <a href=\"https://leanprover-community.github.io/mathlib_docs/find/pfun\">docs#pfun</a>.</p>",
        "id": 322138664,
        "sender_full_name": "Jireh Loreaux",
        "timestamp": 1674071226
    },
    {
        "content": "<p>I would say that mathematicians do <em>not</em> handle division by zero on paper without any trouble -- they simply <em>don't divide by zero</em>.</p>",
        "id": 322143672,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1674072867
    },
    {
        "content": "<p>Physicists, on the other hand…</p>",
        "id": 322156397,
        "sender_full_name": "Arien Malec",
        "timestamp": 1674077280
    },
    {
        "content": "<blockquote>\n<p>I would say that mathematicians do not handle division by zero on paper without any trouble -- they simply don't divide by zero.</p>\n</blockquote>\n<p>By \"Mathematicians can handle <strong>that</strong> on paper\" I mean handling of the additional assumptions of the form <code>x ≠ 0</code></p>",
        "id": 322160762,
        "sender_full_name": "Patrick Johnson",
        "timestamp": 1674078798
    },
    {
        "content": "<p>That is, they don't need to interrupt the proof to show that the division in some particular expression is well-defined. It is either obvious from the context, or in case it's not, they give a small comment explaining why the denominator can't be zero there.</p>",
        "id": 322161141,
        "sender_full_name": "Patrick Johnson",
        "timestamp": 1674078953
    },
    {
        "content": "<p>If one day mathematicians realize they want division by zero to be 0 and change the standard convention, we should accept that. My point is not whether that definition would be useful in practice or not, but that a good theorem prover should let the user easily work with truly undefined results if the user wants them in definitions for whatever reason.</p>",
        "id": 322162051,
        "sender_full_name": "Patrick Johnson",
        "timestamp": 1674079269
    },
    {
        "content": "<p>Yes, mathematicians are good at knowing that xy is obviously nonzero if x and y are nonzero, or that sqrt(x^2+1) is obviously non-zero etc (here x and y are reals). But this sounds like a hard problem for automation.</p>",
        "id": 322162567,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1674079460
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"456794\">Patrick Johnson</span> <a href=\"#narrow/stream/113488-general/topic/Opaque.20junk.20values.20for.20partial.20functions/near/322162051\">said</a>:</p>\n<blockquote>\n<p>If one day mathematicians realize they want division by zero to be 0 and change the standard convention, we should accept that. My point is not whether that definition would be useful in practice or not, but that a good theorem prover should let the user easily work with truly undefined results if the user wants them in definitions for whatever reason.</p>\n</blockquote>\n<p>These people are welcome to make their division with <code>pfun</code> but I'm happy to stick with what's easiest. I don't particularly believe in building scaffolding so that people can fall off from higher up</p>",
        "id": 322163512,
        "sender_full_name": "Eric Rodriguez",
        "timestamp": 1674079831
    },
    {
        "content": "<p>You can also use this as an argument against type systems.</p>",
        "id": 322164196,
        "sender_full_name": "Reid Barton",
        "timestamp": 1674080125
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110038\">Kevin Buzzard</span> <a href=\"#narrow/stream/113488-general/topic/Opaque.20junk.20values.20for.20partial.20functions/near/322162567\">said</a>:</p>\n<blockquote>\n<p>that xy is obviously nonzero if x and y are nonzero, or that sqrt(x^2+1) is obviously non-zero etc </p>\n</blockquote>\n<p>And it's not just this but also: the cardinality of a nonempty (and also finite, obviously) set is obviously non-zero, and the set is also nonempty for some obvious reason...</p>",
        "id": 322165674,
        "sender_full_name": "Reid Barton",
        "timestamp": 1674080795
    },
    {
        "content": "<p>If a mathematician wants to talk about division (as a partial function) in Lean, they can use <a href=\"https://leanprover-community.github.io/mathlib_docs/find/divp\">docs#divp</a> with <code>units.mk0</code> here and there.</p>",
        "id": 322184344,
        "sender_full_name": "Yury G. Kudryashov",
        "timestamp": 1674090955
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"404479\">Trebor Huang</span> <a href=\"#narrow/stream/113488-general/topic/Opaque.20junk.20values.20for.20partial.20functions/near/322136542\">said</a>:<br>\nNote that this might be alternatively phrased as</p>\n<blockquote>\n<p>A good theorem prover should never produce new mathematical viewpoints or ideas, and it should have the ability to transfer mathematician's old ideas as faithfully as possible.</p>\n</blockquote>\n<p>I don't really know if I agree with this rephrasing, because it is possible that at some point in the future, the problem of partial functions will be solved <em>by</em> an innovation in mathematics. I read somewhere that to formalize the many different types of limits in Lean we had to use filters, which in my opinion is an example of something difficult to formalize being formalized by coming up with new mathematics. You can call me overly optimistic, but in other words it's possible that at some point in the future we will encounter a way to express partial functions in a natural way consistent with pen-and-paper mathematics but friendly to formalization (kind of like how the Curry-Howard isomorphism is very unique and different from what mathematicians are used to but ultimately is consistent with mathematicians' basic rules). My point is not that this is particularly likely to happen, but rather that looking for ways to formalize difficult-to-formalize ideas in a natural way can actually be somewhat insightful, and not just clinging onto obsolete ideas from pen-and-paper mathematics.</p>\n<p>However, as far as Lean is concerned, I think <code>n / 0 = 0</code> is the best choice simply because it makes a lot of things easier to work with by reducing the number of hypotheses, and isn't as different from pen-and-paper mathematics as I had originally thought (and, as other people have mentioned, junk values can have a lot of desirable properties). The only place where I am a bit wary of this would be when programming, since I would normally expect division by zero to crash the program (which can potentially avoid many worse things such as data corruption or security vulnerabilities). Hopefully with the ability to do logical verification this won't be that big of a problem.</p>",
        "id": 322198065,
        "sender_full_name": "Niels Voss",
        "timestamp": 1674102461
    },
    {
        "content": "<p>What is the essential difference between introducing filters (for basic analysis) and introducing <code>x/0=0</code>? One is more aesthetically grounded than the other? Apart from that these two are both forcing something mathematicians don't conventionally use, because they make formalization easier.</p>",
        "id": 322198785,
        "sender_full_name": "Trebor Huang",
        "timestamp": 1674103223
    },
    {
        "content": "<p>Also, in Lean we have that <code>lst[n]!</code> crashes the program, but is definitionally equal to some junk value. Do we do that for division? (Not for real number, for the more computable stuff)</p>",
        "id": 322198860,
        "sender_full_name": "Trebor Huang",
        "timestamp": 1674103304
    },
    {
        "content": "<p>I can't really argue much about the filters because I actually don't know much about them, I just happened to briefly read about them somewhere. Division could be designed to crash when dividing by zero, but I think that actually might prevent you from being able to prove that your program doesn't crash. Right now, you pretty much know that if you don't use either panic or an operation ending with a <code>!</code> then your program probably won't crash. Maybe a separate <code>/!</code> operator that crashes could be introduced.<br>\nNow that I think about it more, I actually don't know a good way to resolve the programming aspect of division by zero, aside from using <code>divp</code>, which as was discussed earlier, would be more difficult to use.</p>",
        "id": 322199273,
        "sender_full_name": "Niels Voss",
        "timestamp": 1674103732
    },
    {
        "content": "<p>Now that I think about it, something like <code>divp</code> (or a <code>divp?</code> that returns an <code>option</code>) might not actually be that bad of an idea while programming, because it helps prevent certain types of errors when implementing algorithms. <code>n / 0 = 0</code> is still probably better for doing mathematics, though.</p>",
        "id": 322199658,
        "sender_full_name": "Niels Voss",
        "timestamp": 1674104110
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110038\">Kevin Buzzard</span> said in the blog post:</p>\n<blockquote>\n<p>Mathematicians don’t divide by 0 and hence in practice they never notice the difference between <code>real.div</code> and mathematical division (for which 1/0 is undefined).</p>\n</blockquote>\n<p>I've spent some time thinking about this. The purpose of an interactive theorem prover is not only to allow proving desirable results, but also to prevent proving undesirable results. Humans are prone to mistakes and the whole point of formalization is to be totally sure that our argument is correct. The quote from the blog post can be rephrased as: <em>\"Mathematicians never prove wrong theorems, so having <code>axiom foo : false</code> would not be a problem, because mathematicians don't use it.\"</em> (supposing there is no <code>print axioms</code> of course). If a theorem depends on <code>1 / 0 = 0</code>, it won't ever be considered a valid logical argument in any discussion.</p>\n<p><span class=\"user-mention silent\" data-user-id=\"110038\">Kevin Buzzard</span> <a href=\"#narrow/stream/116395-maths/topic/Why.20is.20.60eq.60.20more.20important.20than.20.60heq.60.3F/near/309628949\">said</a>:</p>\n<blockquote>\n<p>My instinct is that we formalise mathematics in type theory precisely so we can avoid nonsense like this. In other words, these hacks solve a problem in set theory which doesn't need to be solved in type theory.</p>\n</blockquote>\n<p>Type theory takes W-types for granted, but their existence had to be proved using set theory in order to convice mathematicians. Therefore, I won't call set-theoretic constructs a nonsense. Once you create an API, it doesn't matter what underlying foundation you're using.</p>",
        "id": 349109011,
        "sender_full_name": "Patrick Johnson",
        "timestamp": 1681392181
    },
    {
        "content": "<p><code>axiom foo : false</code> is very different to <code>lemma nat.one_div_zero : 1 / 0 = 0</code>; the first makes your whole world fall apart, the second just means that <code>/</code> means something subtly different to what you expect it to mean</p>",
        "id": 349110753,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1681392563
    },
    {
        "content": "<p>I guess the implied question is \"is there some natural-looking theorem that is true only when 1/0 = 0 and is actually false for normal mathematicians\" and I can't formulate an easy answer to that</p>",
        "id": 349113323,
        "sender_full_name": "Eric Rodriguez",
        "timestamp": 1681393127
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"310045\">Eric Wieser</span> <a href=\"#narrow/stream/113488-general/topic/Opaque.20junk.20values.20for.20partial.20functions/near/349110753\">said</a>:</p>\n<blockquote>\n<p><code>axiom foo : false</code> is very different to <code>lemma nat.one_div_zero : 1 / 0 = 0</code>; the first makes your whole world fall apart, the second just means that <code>/</code> means something subtly different to what you expect it to mean</p>\n</blockquote>\n<p>The example is just to show what proving an undesirable result means. The argument that mathematicians don't use <code>1 / 0</code> and we can define it to have any value, is a bad choice, because if a theorem on paper (using actual division) is true only under assumption <code>1 / 0 = 0</code>, it won't be convicing to other mathematicians (even if it may be very hard to come up with such example). If someone formalizes a big theorem in Lean, and the theorem statement uses division, I won't call that formalization convicing, because there is no way to check whether the proof relies on division by zero. Of course, it proved something, but possibly a subtly different statement to what mathematicians may think.</p>",
        "id": 349113620,
        "sender_full_name": "Patrick Johnson",
        "timestamp": 1681393196
    },
    {
        "content": "<p>If your problem is just convincing mathematicians, I can guarantee that <code>1/0 = 0</code> is not a problem (I've explained this to several colleagues, and nobody is bothered, since they're only interested in division when the denominator is not zero). Of course one can cheat and use this to write statements that look like a big theorem but are not, but this is totally unavoidable I think. In any case one should check that <code>ℝ</code> is defined as it should and similar things. You can have a look at Johan's talk about this (I don't have a link, but I am sure someone has).</p>",
        "id": 349115112,
        "sender_full_name": "Riccardo Brasca",
        "timestamp": 1681393553
    },
    {
        "content": "<p>The point is that division is characterized by <code>(a/b)*b=a</code> if <code>b ≠ 0</code>. This is true for Lean's division and it means that our division is the \"correct\" one.</p>",
        "id": 349115604,
        "sender_full_name": "Riccardo Brasca",
        "timestamp": 1681393670
    },
    {
        "content": "<p>Mathematicians don't divide by zero but there's no getting away from the fact that theorem statements and definitions need to be checked manually. It's not just that I can divide by 0, I can write something which looks like the Riemann hypothesis but which isn't, either because I made a slip or because I did something malicious with notation or unicode or whatever. In the liquid tensor experiment Adam Topaz made a <a href=\"https://leanprover-community.github.io/blog/posts/lte-examples/\">great effort</a> to convince skeptics that the team had indeed proved what they'd claimed they'd proved.</p>",
        "id": 349115896,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1681393729
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"456794\">Patrick Johnson</span> <a href=\"#narrow/stream/113488-general/topic/Opaque.20junk.20values.20for.20partial.20functions/near/349113620\">said</a>:</p>\n<blockquote>\n<p>If someone formalizes a big theorem in Lean, and the theorem statement uses division, I won't call that formalization convicing, because there is no way to check whether the proof relies on division by zero..</p>\n</blockquote>\n<p>Whether the <em>proof</em> relies on division by zero is irrelevant. All you care about is whether the <em>statement</em> divides by zero. Rationale: pretend the proof starts with \"let us define a new operator <code>lean_div</code> which we shall write <code>/</code> that satisfies <code>x / 0 = 0</code>\". Clearly the validity of a proof does not depend on which symbols we choose to notate it.</p>\n<p>In general, \"correctness\" of definitions that don't appear in the statement are irrelevant to trusting the proof.</p>",
        "id": 349122369,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1681395080
    },
    {
        "content": "<p>Patrick Johnson your claim that if someone formalises a theorem whose statement mentions division then you won't believe it indicates the error in your understanding. If you can very t that the <em>statement</em> doesn't involve division by zero then it doesn't matter if the proof uses division by zero, because instead of dividing by zero I can just define a new function <code>foo x y</code> which is division if y isn't zero and is 0 if y=0, and of course this doesn't give you a contradiction. My point is that this has nothing to do with division -- for <em>every</em> statement which is claimed to be proved by a theorem prover, you cannot be convinced by it until you have verified yourself that all the definitions involved are what you think they are. I will happily replace all occurrences of division in my statement by <code>foo</code> and openly claim that <code>foo</code> is division if the denominator isn't zero, and 0 otherwise, and this doesn't change anything. I can also define a function <code>bar</code> which takes two reals x and y and a proof that y isn't zero and returns x/y, and then claim a theorem involving bar and with additional <em>hypothesis</em> that all my denominators are nonzero, and from your objection this sounds like it will placate you, even though I'm just going to prove it by throwing away the hypotheses and using division anyway. I think you are failing to conflate the problem that lean division doesn't mean mathematical division with the problem that every single definition needs to be checked, whether it's division or not, if you want to be convinced of a lean proof.</p>",
        "id": 349127586,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1681396118
    },
    {
        "content": "<p>(sorry, I'm restating things Eric already said, my internet is not ideal right now)</p>",
        "id": 349127817,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1681396169
    },
    {
        "content": "<blockquote>\n<p>even though I'm just going to prove it by throwing away the hypotheses and using division anyway</p>\n</blockquote>\n<p>Throwing it away can change the meaning of your statement if the hypothesis appears in an existential quantifier.</p>",
        "id": 349128678,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1681396334
    },
    {
        "content": "<p>Maybe I was not precise enough. What I meant by <em>\"the proof relies on division by zero\"</em> is that if the statement contains division by a bound variable, the proof would be \"suspicious\" if it relies on <code>one_div_zero</code>, because the statement may not hold for mathematical division (I'm just clarifying up that sentence).</p>\n<p>In general, even though divison by zero is probably the most notable example, my point is that changing standard definitions to make proofs easier, and then pretending they're \"usual\" definitions when proving claims about them may be considered a wrong approach.</p>",
        "id": 349128921,
        "sender_full_name": "Patrick Johnson",
        "timestamp": 1681396390
    },
    {
        "content": "<p>Of course, if we're going to claim that division is confusing, <code>5 / 2 = 2</code> is surely far more upsetting to mathematicians than <code>5 / 0 = 0</code></p>",
        "id": 349128999,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1681396409
    },
    {
        "content": "<blockquote>\n<p>if the statement contains division by a bound variable</p>\n</blockquote>\n<p>Here's an example of the type of statement that is cause for concern:</p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"kn\">import</span> <span class=\"n\">data.rat.basic</span>\n<span class=\"kn\">import</span> <span class=\"n\">tactic.norm_num</span>\n\n<span class=\"c1\">-- this is probably rejected as false/meaninless by most mathematicians, but Lean says it is true</span>\n<span class=\"kd\">example</span> <span class=\"o\">:</span> <span class=\"bp\">∃</span> <span class=\"n\">x</span> <span class=\"o\">:</span> <span class=\"n\">ℚ</span><span class=\"o\">,</span> <span class=\"mi\">2</span> <span class=\"bp\">/</span> <span class=\"n\">x</span> <span class=\"bp\">=</span> <span class=\"mi\">3</span> <span class=\"bp\">/</span> <span class=\"n\">x</span> <span class=\"o\">:=</span> <span class=\"o\">⟨</span><span class=\"mi\">0</span><span class=\"o\">,</span> <span class=\"kd\">by</span> <span class=\"n\">simp</span><span class=\"o\">⟩</span>\n\n<span class=\"c1\">-- adding a `x ≠ 0` condition gives it the intended meaning</span>\n<span class=\"kd\">example</span> <span class=\"o\">:</span> <span class=\"bp\">¬</span> <span class=\"bp\">∃</span> <span class=\"o\">(</span><span class=\"n\">x</span> <span class=\"o\">:</span> <span class=\"n\">ℚ</span><span class=\"o\">)</span> <span class=\"o\">(</span><span class=\"n\">hx</span> <span class=\"o\">:</span> <span class=\"n\">x</span> <span class=\"bp\">≠</span> <span class=\"mi\">0</span><span class=\"o\">),</span> <span class=\"mi\">2</span> <span class=\"bp\">/</span> <span class=\"n\">x</span> <span class=\"bp\">=</span> <span class=\"mi\">3</span> <span class=\"bp\">/</span> <span class=\"n\">x</span> <span class=\"o\">:=</span>\n<span class=\"kd\">by</span> <span class=\"o\">{</span> <span class=\"n\">push_neg</span><span class=\"o\">,</span> <span class=\"n\">intros</span> <span class=\"n\">x</span> <span class=\"n\">hx</span><span class=\"o\">,</span> <span class=\"n\">norm_num</span> <span class=\"o\">[</span><span class=\"n\">div_eq_div_iff</span><span class=\"o\">,</span> <span class=\"n\">hx</span><span class=\"o\">]</span> <span class=\"o\">}</span>\n\n<span class=\"c1\">-- or as Kevin suggests, where `/ₚ` consumes the proof `hx` itself</span>\n<span class=\"kd\">example</span> <span class=\"o\">:</span> <span class=\"bp\">¬</span> <span class=\"bp\">∃</span> <span class=\"o\">(</span><span class=\"n\">x</span> <span class=\"o\">:</span> <span class=\"n\">ℚ</span><span class=\"o\">)</span> <span class=\"o\">(</span><span class=\"n\">hx</span> <span class=\"o\">:</span> <span class=\"n\">x</span> <span class=\"bp\">≠</span> <span class=\"mi\">0</span><span class=\"o\">),</span> <span class=\"mi\">2</span> <span class=\"bp\">/ₚ</span> <span class=\"o\">(</span><span class=\"n\">units.mk0</span> <span class=\"n\">x</span> <span class=\"n\">hx</span><span class=\"o\">)</span> <span class=\"bp\">=</span> <span class=\"mi\">3</span> <span class=\"bp\">/ₚ</span> <span class=\"o\">(</span><span class=\"n\">units.mk0</span> <span class=\"n\">x</span> <span class=\"n\">hx</span><span class=\"o\">)</span> <span class=\"o\">:=</span>\n<span class=\"kd\">by</span> <span class=\"o\">{</span> <span class=\"n\">push_neg</span><span class=\"o\">,</span> <span class=\"n\">intros</span> <span class=\"n\">x</span> <span class=\"n\">hx</span><span class=\"o\">,</span> <span class=\"n\">norm_num</span> <span class=\"o\">[</span><span class=\"n\">div_eq_div_iff</span><span class=\"o\">,</span> <span class=\"n\">hx</span><span class=\"o\">]</span> <span class=\"o\">}</span>\n</code></pre></div>\n<p>But note that this is only a problem because these are bound <em>by <code>∃</code></em>. The outermost <code>∀</code> binders are always safe, as you can pretend there was an unused assumption that the divisor was non-zero</p>",
        "id": 349130018,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1681396611
    },
    {
        "content": "<p>Patrick, weren't you meant to create your own proof assistant \"fixing\" all those \"issues\"? Why coming back again and again with always the same complaints?</p>",
        "id": 349130324,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1681396682
    },
    {
        "content": "<p>My two cents:</p>\n<p>I also used to struggle with understanding whether <code>1 / 0 = 0</code> could lead to unsound results. The blog post <a href=\"https://xenaproject.wordpress.com/2020/07/05/division-by-zero-in-type-theory-a-faq/\">https://xenaproject.wordpress.com/2020/07/05/division-by-zero-in-type-theory-a-faq/</a> helped me a lot, but I had to sort it out in my head a bit further to really convince myself.</p>\n<p>I agree that correctness of definitions (whatever it might possibly mean) is relevant only if it appears in a theorem <em>statement</em> or as an <em>axiom</em> that is reachable from the file. As for the axioms, it is easy; we don't add extra axioms. To make sure somebody really didn't add an inconsistent axiom, we can write <code>#print axioms the_unbelievable_theorem</code> and check that it contains only the standard axioms. So we are done with the axioms and we turn to the theorem statement. If someone adds an assumption (called a \"hypothesis\" in this community) inconsistent with <code>1 / 0 = 0</code> then the whole theorem is ruined, of course. However, I claim that such a mistake is easy to spot. How would such an assumption even look? The assumption cannot say \"the value <code>1 / 0</code> is undefined\" – this is not expressible in Lean. It would have to say something like <code>1 / 0 = 42</code> in order to allow us to prove <code>false</code> from it. However, such an assumption is immediately rejected by mathematicians, regardless of what they think about the division in Lean. Hence, probably the only assumption that might trick somebody into believing a deceitful theorem is <code>∀ x, 1 / x ≠ 0</code> or something like that. Again, why would the theorem statement even contain such a thing?</p>",
        "id": 349130568,
        "sender_full_name": "Martin Dvořák",
        "timestamp": 1681396733
    },
    {
        "content": "<p>Martin, I'm curious why you think division by zero is a bigger trap than unexpected rounding</p>",
        "id": 349131181,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1681396894
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"310045\">Eric Wieser</span> <a href=\"#narrow/stream/113488-general/topic/Opaque.20junk.20values.20for.20partial.20functions/near/349131181\">said</a>:</p>\n<blockquote>\n<p>Martin, I'm curious why you think division by zero is a bigger trap than unexpected rounding</p>\n</blockquote>\n<p>Rounding down is familiar from \"normal\" programming languages. Having a valid output for dividing by zero is \"unheard of\".</p>",
        "id": 349131593,
        "sender_full_name": "Martin Dvořák",
        "timestamp": 1681396985
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110031\">Patrick Massot</span> <a href=\"#narrow/stream/113488-general/topic/Opaque.20junk.20values.20for.20partial.20functions/near/349130324\">said</a>:</p>\n<blockquote>\n<p>Patrick, weren't you meant to create your own proof assistant \"fixing\" all those \"issues\"? Why coming back again and again with always the same complaints?</p>\n</blockquote>\n<p>They're not complaints. I'm currently busy with my final university semester (that's why the project is temporarily stalled), and just wanted to share my comment about the blog post. I'm happy that there are different theorem provers that handle those \"issues\" in different ways.</p>",
        "id": 349131890,
        "sender_full_name": "Patrick Johnson",
        "timestamp": 1681397053
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"417654\">Martin Dvořák</span> <a href=\"#narrow/stream/113488-general/topic/Opaque.20junk.20values.20for.20partial.20functions/near/349131593\">said</a>:</p>\n<blockquote>\n<p>Rounding down is familiar from \"normal\" programming languages. Having a valid output for dividing by zero is \"unheard of\".</p>\n</blockquote>\n<p>Note that Eric was talking about <em>mathematicians</em> in his claim. Most of them don't know/care about programming languages or the attitudes that PLs take towards dividing by zero.</p>",
        "id": 349134528,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1681397612
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"310045\">Eric Wieser</span> <a href=\"#narrow/stream/113488-general/topic/Opaque.20junk.20values.20for.20partial.20functions/near/349128678\">said</a>:</p>\n<blockquote>\n<p>Throwing it away can change the meaning of your statement if the hypothesis appears in an existential quantifier.</p>\n</blockquote>\n<p>Of course you can also use a universal quantifier: <code>∀ x, 2 / x ≠ 3 / x</code></p>",
        "id": 349135142,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1681397758
    },
    {
        "content": "<p>What I meant to exclude is top-level universal quantifiers. If you forget to add <code>x ≠ 0</code> there then your statement is just impossible to prove; If you forget in an existential, then your statement is true but looks like it should be false</p>",
        "id": 349136669,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1681398122
    },
    {
        "content": "<p>I imagine there's some better terminology that captures precisely which quantifiers it matters in, but hopefully it should be obvious on any given example</p>",
        "id": 349137058,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1681398210
    },
    {
        "content": "<p>I had what I thought was a decent reply to these sorts of questions in the condensed mathematics stream, but since probably most are not subscribed to that stream I'll link it here: <a href=\"#narrow/stream/267928-condensed-mathematics/topic/Real.20measures/near/295058844\">https://leanprover.zulipchat.com/#narrow/stream/267928-condensed-mathematics/topic/Real.20measures/near/295058844</a></p>\n<p>I guess I'll additionally argue the following. In general, mathematicians are not especially careful about how objects are defined (at least not at first blush), and yet they are comfortable switching between paradigms that arise often enough. For example, there are plenty of introductory algebra texts that say a ring has a 1, and a bunch more that don't have that requirement. Of course, mathematicians will be aware that rings in the former context satisfy the property that every proper ideal is contained in a maximal ideal, but this is false for rings in the latter context.</p>\n<p>This also happens in higher level theory where things are much more subtle. For example, an <em>absorbing</em> extension of C⋆-algebras often means something different when the underlying C⋆-algebra is unital versus non-unital, but the non-unital definition also makes sense for unital algebras, it just doesn't give the right theorems; this caused at least one major error in the literature that had to be later corrected.</p>\n<p>The point I'm trying to make is this: at least in Lean (or any formalization of mathematics) at least you can check (relatively easily?) that the definition corresponds with the one you intuited, or doesn't, as the case may be. Whereas in paper mathematics you have to check whether the author means <em>absorbing</em> in the unital sense or the non-unital sense, and then you have to trust that all the results they have based their work on also use the appropriate definition for the context. This is nigh on impossible to actually verify yourself.</p>",
        "id": 349147354,
        "sender_full_name": "Jireh Loreaux",
        "timestamp": 1681400557
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"310045\">Eric Wieser</span> <a href=\"#narrow/stream/113488-general/topic/Opaque.20junk.20values.20for.20partial.20functions/near/349137058\">said</a>:</p>\n<blockquote>\n<p>I imagine there's some better terminology that captures precisely which quantifiers it matters in, but hopefully it should be obvious on any given example</p>\n</blockquote>\n<p>I think the right pattern is that you should require that the expression would still typecheck if it used a partial division operator. So <code>∀ x, 2 / x ≠ 3 / x</code> is not good but <code>∀ x, x ≠ 0 -&gt; 2 / x ≠ 3 / x</code> is</p>",
        "id": 349148592,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1681400873
    },
    {
        "content": "<p>My claim is that something like the true statement <code>example : ∀ x, x / x * x = x</code> is harmless intuitively even though it doesn't mention <code>x ≠ 0</code>.</p>",
        "id": 349149464,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1681401098
    },
    {
        "content": "<p>Because  when reading you can imagine that it did say <code>x ≠ 0</code> and you just get a weaker statement than the one Lean had. The problems only arise when <code>x ≠ 0</code> would make make the statement stronger.</p>",
        "id": 349149620,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1681401129
    },
    {
        "content": "<p>Right, I think the point you are making is this: <code>(∀ x, Q x) → (∀ x, P x → Q x)</code> wheres <code>∃ x, Q x</code> does not imply <code>∃ x, P x ∧ Q x</code>. Here <code>P x</code> is the predicate for the subtype (e.g., <code>x ≠ 0</code>) which, if present, would make <code>Q x</code> type check with the partial division, per Mario's comment.</p>",
        "id": 349150311,
        "sender_full_name": "Jireh Loreaux",
        "timestamp": 1681401285
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"197836\">Jireh Loreaux</span> <a href=\"#narrow/stream/113488-general/topic/Opaque.20junk.20values.20for.20partial.20functions/near/349147354\">said</a>:</p>\n<blockquote>\n<p>an <em>absorbing</em> extension of C⋆-algebras often means something different when the underlying C⋆-algebra is unital versus non-unital, but the non-unital definition also makes sense for unital algebras, it just doesn't give the right theorems</p>\n</blockquote>\n<p>I encountered that in the Cambridge Part III Functional Analysis this term. I was absolutely confused how shamelessly we even made such a pair of overlapping definitions!</p>",
        "id": 349165838,
        "sender_full_name": "Yaël Dillies",
        "timestamp": 1681405305
    },
    {
        "content": "<p>It actually makes a bit of sense if you think about it from a categorical perspective, but admittedly that's a bit hard to see when first encountering it. That is, (non-unital) absorbing extensions behave correctly in the category C⋆Alg, whereas (strongly unital) absorbing extensions behave correctly in the category C⋆Alg₁, for a suitable interpretation of \"behave correctly\". (C⋆Alg is the category of not necessarily unital C⋆-algebras with ⋆-homomorphisms and C⋆Alg₁ is the category of unital C⋆-algebras with unital ⋆-homomorphisms.)</p>",
        "id": 349169145,
        "sender_full_name": "Jireh Loreaux",
        "timestamp": 1681406229
    }
]