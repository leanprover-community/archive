[
    {
        "content": "<p>For years, I have been saying that Lean has a small core and the soundness of proofs in Lean depends on the core only (assuming hardware is flawless, and so on). Lately, however, people have been asking me for a concrete number, which I don't know.</p>\n<p>How many lines of code is it that we really have to trust? Consider <code>native_decide</code> to be outside of the trusted codebase but the code that ensures <code>Lean.ofReduceBool</code> appears in <code>#print axioms</code> to be part of it. Consider the VS Code extension (and its backend support) to be outside of the trusted codebase, even though, had a dangerous bug been introduced into the VS Code extension, it might potentially be used to deceive people. Do we get to a reasonable number?</p>\n<p>As far as I know, the size of the core increased from Lean 3 to Lean 4, and the trust in it has decreased accordingly. I understand the role of external checkers; you can perhaps also inform me what their code size is.</p>",
        "id": 502042709,
        "sender_full_name": "Martin Dvořák",
        "timestamp": 1740575288
    },
    {
        "content": "<p>I am not a great authority here, but this is what I've gathered. Some things might be wrong here.<br>\nI believe the kernel in the Lean codebase has not been intentionally designed to be as small as possible, and the boundaries between what is the kernel and what isn't is not an entirely hard line. I believe in the Lean code base it's about 20k lines of code(?)<br>\nThere are external typecheckers (<a href=\"https://github.com/digama0/lean4lean/tree/master\">lean4lean</a>, <a href=\"https://github.com/ammkrn/nanoda_lib\">nanoda_lib</a>) that work well in practice (i.e. they have the required performance optimizations to be able to check Mathlib), and they're about 6k-8k lines of code. This also includes things like a pretty printer, so a minimal checker can be smaller.</p>",
        "id": 502047494,
        "sender_full_name": "Floris van Doorn",
        "timestamp": 1740576736
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"112857\">@Leonardo de Moura</span> answered the question in his talk today with the estimate of 8000 lines.</p>",
        "id": 568857334,
        "sender_full_name": "Martin Dvořák",
        "timestamp": 1768846171
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"111080\">Floris van Doorn</span> <a href=\"#narrow/channel/113488-general/topic/Trusted.20codebase.20size/near/502047494\">said</a>:</p>\n<blockquote>\n<p>the boundaries between what is the kernel and what isn't is not an entirely hard line.</p>\n</blockquote>\n<p>A good example of this is the fact that the kernel is written with the assumption that certain things are defined specifically as they are in Prelude (such as the hard-coded behavior of some operations on <code>Nat</code>).</p>",
        "id": 568866620,
        "sender_full_name": "James E Hanson",
        "timestamp": 1768849628
    },
    {
        "content": "<p>Could these things be easily checked with asserts?</p>",
        "id": 568870323,
        "sender_full_name": "Bbbbbbbbba",
        "timestamp": 1768850758
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"417654\">@Martin Dvořák</span>  by any chance, would the talk you're referring to be accessible somewhere?</p>",
        "id": 568871225,
        "sender_full_name": "Thomas C.",
        "timestamp": 1768851024
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"666160\">Thomas C.</span> <a href=\"#narrow/channel/113488-general/topic/Trusted.20codebase.20size/near/568871225\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"417654\">Martin Dvořák</span>  by any chance, would the talk you're referring to be accessible somewhere?</p>\n</blockquote>\n<p>It was recorded. I think it will soon appear here:<br>\n<a href=\"https://www.youtube.com/channel/UCWe5B7Ikr0AI9727doEUxPg\">https://www.youtube.com/channel/UCWe5B7Ikr0AI9727doEUxPg</a></p>",
        "id": 568872285,
        "sender_full_name": "Martin Dvořák",
        "timestamp": 1768851302
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"1010687\">Bbbbbbbbba</span> <a href=\"#narrow/channel/113488-general/topic/Trusted.20codebase.20size/near/568870323\">said</a>:</p>\n<blockquote>\n<p>Could these things be easily checked with asserts?</p>\n</blockquote>\n<p>It's not currently easy, no. I think there is a plan upstream to make forward progress on this at some point.</p>",
        "id": 568884267,
        "sender_full_name": "Chris Bailey",
        "timestamp": 1768854556
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"228466\">Chris Bailey</span> <a href=\"#narrow/channel/113488-general/topic/Trusted.20codebase.20size/near/568884267\">said</a>:</p>\n<blockquote>\n<p>It's not currently easy, no.</p>\n</blockquote>\n<p>Why is it not easy?</p>",
        "id": 568893677,
        "sender_full_name": "James E Hanson",
        "timestamp": 1768857012
    },
    {
        "content": "<p>Not all of the relevant items are declared (and therefore exported) simply. For some of them, you can just require e.g. <code>defEq (x + 0) x</code> and <code>defEq (x + y.succ) (succ (x + y))</code> and be done with addition. Those are easy enough to construct by hand in the checker, and they're robust against changes in lean.</p>\n<p>For things like div or mod, the compiled definition in lean is currently not so simple to construct, and changes in things like elaboration of recursive functions or auxiliary declarations might change what gets exported in ways that are equal to what was there before, but not definitionally equal. It would be a very annoying and unpredictable breakage in the checker, and this by hand construction is not very fun.</p>",
        "id": 568900391,
        "sender_full_name": "Chris Bailey",
        "timestamp": 1768858860
    },
    {
        "content": "<p>Would it suffice to check that these functions</p>\n<ul>\n<li>have the right propositional equations (by requiring such a theorem to be proven to the kernel) so that if they reduce literals to  a literal, it has to be the right one, and</li>\n<li>are defined without any axioms or opaques, so by some meta theory theorem, they do normalize to a ground value when applied to ground values? Or does no such theorem exist?</li>\n</ul>",
        "id": 568906226,
        "sender_full_name": "Joachim Breitner",
        "timestamp": 1768860615
    },
    {
        "content": "<p>I think option 1 would work, that was my guess for how to do it in our side discussion with Mario before he introduced the other option of changing the definitions so that the definitional equalities work. If it were possible to get the definitions to work out that would be nicer of course, but I don't know how practical it is. On the bright side I think the relevant lemmas for the alternative route are already there (e.g. <code>Nat.div_eq</code>, <code>Nat.mod_eq</code>) though with seemingly inconsistent names (see <code>Nat.pow_eq</code>).</p>",
        "id": 568915752,
        "sender_full_name": "Chris Bailey",
        "timestamp": 1768863092
    },
    {
        "content": "<p>Sorry, I meant checking both: the first to know that that the function can't go wrong, the second to know that the equalities on literals are actually definitionally</p>",
        "id": 568955024,
        "sender_full_name": "Joachim Breitner",
        "timestamp": 1768893627
    }
]