[
    {
        "content": "<p><a href=\"https://github.com/utensil/lean4_jupyter\">lean4_jupyter</a> is a Lean 4 Jupyter kernel via <a href=\"https://github.com/leanprover-community/repl\">repl</a>. It just released v0.0.1, an initial release that covers all basic features of <code>repl</code>.</p>\n<h2>What's already working</h2>\n<p><span aria-label=\"fire\" class=\"emoji emoji-1f525\" role=\"img\" title=\"fire\">:fire:</span> See it in action: <a href=\"https://nbviewer.org/github/utensil/lean4_jupyter/blob/18e8d701982d640aa443195f5ca287eec45313e3/examples/00_tutorial.ipynb?flush_cache=true\">Tutorial notebook</a>.</p>\n<p>The kernel can:</p>\n<ul>\n<li>execute Lean 4 commands (including definitions, theorems, etc.)</li>\n<li>execute Lean 4 tatics with magic like <code>%proof</code> immediately after a <code>sorry</code>ed theorem</li>\n<li>backtrack to earlier environment or proof states with magic like <code>%env 1</code> or <code>%prove 3</code></li>\n<li>support magics like <a href=\"https://nbviewer.org/github/utensil/lean4_jupyter/blob/v0.0.1/examples/01_cd.ipynb?flush_cache=true\"><code>%cd</code></a> or <a href=\"https://nbviewer.org/github/utensil/lean4_jupyter/blob/v0.0.1/examples/02_load.ipynb?flush_cache=true\"><code>%load</code></a> (loading a file)</li>\n<li>support for importing modules from projects and their dependencies, e.g. <code>Mathlib</code> ( <a href=\"https://nbviewer.org/github/utensil/lean4_jupyter/blob/v0.0.1/examples/03_import.ipynb?flush_cache=true\">demo</a> ).</li>\n</ul>\n<p>Output:</p>\n<ul>\n<li>In <code>jupyter notebook</code> and alike: echos the input annotated in <a href=\"https://github.com/cpitclaudel/alectryon?tab=readme-ov-file#as-a-library\">alectryon</a> style, at the corresponding line (not columns yet), with messages, proof states</li>\n<li>In <code>jupyter console</code> and alike: echos the input annotated in <a href=\"https://github.com/brendanzab/codespan\">codespan</a> style, at the corresponding <code>line:column</code>, with messages, proof states</li>\n<li>Raw <code>repl</code> input/output in JSON format can be inspected by click-to-expand in the WebUI.</li>\n</ul>\n<p>For what's next, check out <a href=\"https://github.com/utensil/lean4_jupyter?tab=readme-ov-file#whats-next\">TODOs in README</a>.</p>",
        "id": 439946692,
        "sender_full_name": "Utensil Song",
        "timestamp": 1716346398
    },
    {
        "content": "<h2>Rationale</h2>\n<p>I've always wanted to do literate programming with Lean 4 in Jupyter, but Lean LSP and Infoview in VS Code has provided an immersive experience with immediate feedback, so I could never imagine a better way to interact with Lean 4, until interacting with repl makes me believe that <em>limitless backtrack</em> is another feature that best accompanies the <em>reproducible interactivity</em> of alectryon style annotations.</p>\n<p>The idea came to me in an afternoon, and I thought it's technically trivial to implement overnight thanks to repl. It took me a bit longer to work out the logistics of UX and polish the code, but it's fun to see the potential.</p>",
        "id": 439946847,
        "sender_full_name": "Utensil Song",
        "timestamp": 1716346500
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"296911\">Utensil Song</span> <a href=\"#narrow/stream/113488-general/topic/lean4_jupyter.3A.20A.20Lean.204.20Jupyter.20kernel.20via.20repl/near/439946692\">said</a>:</p>\n<blockquote>\n<p><a href=\"https://github.com/utensil/lean4_jupyter\">lean4_jupyter</a> is a Lean 4 Jupyter kernel via <a href=\"https://github.com/leanprover-community/repl\">repl</a>. It just released v0.0.1, an initial release that covers all basic features of <code>repl</code>.</p>\n<h2>What's already working</h2>\n<p><span aria-label=\"fire\" class=\"emoji emoji-1f525\" role=\"img\" title=\"fire\">:fire:</span> See it in action: <a href=\"https://nbviewer.org/github/utensil/lean4_jupyter/blob/18e8d701982d640aa443195f5ca287eec45313e3/examples/00_tutorial.ipynb?flush_cache=true\">Tutorial notebook</a>.</p>\n<p>The kernel can:</p>\n<ul>\n<li>execute Lean 4 commands (including definitions, theorems, etc.)</li>\n<li>execute Lean 4 tatics with magic like <code>%proof</code> immediately after a <code>sorry</code>ed theorem</li>\n<li>backtrack to earlier environment or proof states with magic like <code>%env 1</code> or <code>%prove 3</code></li>\n<li>support magics like <a href=\"https://nbviewer.org/github/utensil/lean4_jupyter/blob/v0.0.1/examples/01_cd.ipynb?flush_cache=true\"><code>%cd</code></a> or <a href=\"https://nbviewer.org/github/utensil/lean4_jupyter/blob/v0.0.1/examples/02_load.ipynb?flush_cache=true\"><code>%load</code></a> (loading a file)</li>\n<li>support for importing modules from projects and their dependencies, e.g. <code>Mathlib</code> ( <a href=\"https://nbviewer.org/github/utensil/lean4_jupyter/blob/v0.0.1/examples/03_import.ipynb?flush_cache=true\">demo</a> ).</li>\n</ul>\n<p>Output:</p>\n<ul>\n<li>In <code>jupyter notebook</code> and alike: echos the input annotated in <a href=\"https://github.com/cpitclaudel/alectryon?tab=readme-ov-file#as-a-library\">alectryon</a> style, at the corresponding line (not columns yet), with messages, proof states</li>\n<li>In <code>jupyter console</code> and alike: echos the input annotated in <a href=\"https://github.com/brendanzab/codespan\">codespan</a> style, at the corresponding <code>line:column</code>, with messages, proof states</li>\n<li>Raw <code>repl</code> input/output in JSON format can be inspected by click-to-expand in the WebUI.</li>\n</ul>\n<p>For what's next, check out <a href=\"https://github.com/utensil/lean4_jupyter?tab=readme-ov-file#whats-next\">TODOs in README</a>.</p>\n</blockquote>\n<p>Hi great work. I wonder if you can help me. I'm trying to call repl from c#.</p>\n<p>I can make a process calling \"cmd\" with arguments \"lake exe repl\".</p>\n<p>Then I can send data to the stdin such as {\"cmd\":\"#eval 2+3\"}\\n</p>\n<p>Unfortunately it is only sending back the replies once the repl has exited out either by closing the shell window or forcing an error such as sending \\n\\n.  I am not sure if there is a way to force it to send a reply back to the stdout as soon as I've sent one command. It seems to be holding on to the replies until the end.</p>\n<p>Are you able to shed any light on this or point to the place in your code where you send the commands and get the replies?</p>\n<p>I am using this version of repl: <a href=\"https://github.com/leanprover-community/repl\">https://github.com/leanprover-community/repl</a></p>",
        "id": 443883965,
        "sender_full_name": "Mr Proof",
        "timestamp": 1718063235
    },
    {
        "content": "<p>Sounds like buffering problems in the way you are calling it. It certainly responds separately to each command.</p>",
        "id": 443885366,
        "sender_full_name": "Kim Morrison",
        "timestamp": 1718063923
    },
    {
        "content": "<p><a href=\"/user_uploads/3121/jkc7agOJy_iTFyKDii6LunLx/8B47A1CE-3A43-49F8-BC4B-F47643FA2ED1.jpg\">8B47A1CE-3A43-49F8-BC4B-F47643FA2ED1.jpg</a></p>\n<div class=\"message_inline_image\"><a href=\"/user_uploads/3121/jkc7agOJy_iTFyKDii6LunLx/8B47A1CE-3A43-49F8-BC4B-F47643FA2ED1.jpg\" title=\"8B47A1CE-3A43-49F8-BC4B-F47643FA2ED1.jpg\"><img src=\"/user_uploads/3121/jkc7agOJy_iTFyKDii6LunLx/8B47A1CE-3A43-49F8-BC4B-F47643FA2ED1.jpg\"></a></div><p><a href=\"https://github.com/leanprover-community/repl/pull/5#discussion_r1595010942\">https://github.com/leanprover-community/repl/pull/5#discussion_r1595010942</a></p>",
        "id": 443888096,
        "sender_full_name": "Utensil Song",
        "timestamp": 1718065215
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"725689\">@Mr Proof</span> To interact with repl, I was under the working assumption that it's a \\r\\n\\r\\n ending protocol, otherwise I can't make it respond reliably. This is a recurring theme that you always need a way to know when to stop receiving and start processing. I hope this would be explicitly stablized as the protocol, because the PRed Python implementation relies on the ending <code>env</code> which is not guaranteed to be there, and Eric's proposal of using one line ending as the request/response ending will also be fragile.</p>",
        "id": 443888574,
        "sender_full_name": "Utensil Song",
        "timestamp": 1718065583
    },
    {
        "content": "<p>Tried and still didn't work :( <br>\nI'm doing:</p>\n<div class=\"codehilite\" data-code-language=\"Lean4\"><pre><span></span><code><span class=\"w\">       </span><span class=\"n\">string</span><span class=\"w\"> </span><span class=\"n\">text</span><span class=\"bp\">=</span><span class=\"s2\">\"{</span><span class=\"se\">\\\"</span><span class=\"s2\">cmd</span><span class=\"se\">\\\"</span><span class=\"s2\">:</span><span class=\"se\">\\\"</span><span class=\"s2\">def x:Nat:=3</span><span class=\"se\">\\\"</span><span class=\"s2\">}</span><span class=\"err\">\\</span><span class=\"s2\">r</span><span class=\"se\">\\n</span><span class=\"err\">\\</span><span class=\"s2\">r</span><span class=\"se\">\\n</span><span class=\"s2\">\"</span><span class=\"bp\">;</span>\n<span class=\"w\">        </span><span class=\"n\">writer</span><span class=\"bp\">.</span><span class=\"n\">Write</span><span class=\"o\">(</span><span class=\"n\">text</span><span class=\"o\">)</span><span class=\"bp\">;</span>\n<span class=\"w\">        </span><span class=\"n\">writer</span><span class=\"bp\">.</span><span class=\"n\">Flush</span><span class=\"o\">()</span><span class=\"bp\">;</span>\n</code></pre></div>\n<p>So I must be doing something wrong. Only way so far I can get it to return a reply is to force an error for example doing three \\r\\n in a row or if I close the cmd window. Then it returns the error plus all the other replies.  Oh well. Back to the drawing board.</p>",
        "id": 443889435,
        "sender_full_name": "Mr Proof",
        "timestamp": 1718066154
    },
    {
        "content": "<p><a href=\"/user_uploads/3121/9QbHnR2cdyClLt7blT0Q-_5E/1CD45548-F78F-43AF-BC92-AD527F278AC6.jpg\">1CD45548-F78F-43AF-BC92-AD527F278AC6.jpg</a></p>\n<div class=\"message_inline_image\"><a href=\"/user_uploads/3121/9QbHnR2cdyClLt7blT0Q-_5E/1CD45548-F78F-43AF-BC92-AD527F278AC6.jpg\" title=\"1CD45548-F78F-43AF-BC92-AD527F278AC6.jpg\"><img src=\"/user_uploads/3121/9QbHnR2cdyClLt7blT0Q-_5E/1CD45548-F78F-43AF-BC92-AD527F278AC6.jpg\"></a></div><p><a href=\"/user_uploads/3121/dcsM2g2xzElLlP7KNIlYK11Y/310C37B1-81FB-40C3-94CB-414D2BCDFF45.jpg\">310C37B1-81FB-40C3-94CB-414D2BCDFF45.jpg</a></p>\n<div class=\"message_inline_image\"><a href=\"/user_uploads/3121/dcsM2g2xzElLlP7KNIlYK11Y/310C37B1-81FB-40C3-94CB-414D2BCDFF45.jpg\" title=\"310C37B1-81FB-40C3-94CB-414D2BCDFF45.jpg\"><img src=\"/user_uploads/3121/dcsM2g2xzElLlP7KNIlYK11Y/310C37B1-81FB-40C3-94CB-414D2BCDFF45.jpg\"></a></div><p>These simple code work in Python. I can't tell the difference between it and your code. I suspect that it's not that sending is not working, it's that receiving is not working, i.e. repl has responded but you didn't finish your receiving.</p>",
        "id": 443893569,
        "sender_full_name": "Utensil Song",
        "timestamp": 1718067973
    },
    {
        "content": "<p>Can you point me at the file which sends the replies? Maybe it's just missing a \"Flush\" command. <br>\nIt could be my code but I'd just like to check.</p>",
        "id": 443899143,
        "sender_full_name": "Mr Proof",
        "timestamp": 1718071374
    },
    {
        "content": "<p><a href=\"https://github.com/utensil/lean4_jupyter/blob/main/lean4_jupyter/repl.py\">https://github.com/utensil/lean4_jupyter/blob/main/lean4_jupyter/repl.py</a></p>",
        "id": 443904949,
        "sender_full_name": "Utensil Song",
        "timestamp": 1718075116
    },
    {
        "content": "<p><strong>UPDATE FIXED!!!!</strong> <span aria-label=\"grinning face with smiling eyes\" class=\"emoji emoji-1f601\" role=\"img\" title=\"grinning face with smiling eyes\">:grinning_face_with_smiling_eyes:</span> (with a little help from ChatGPT)<br>\nI manage to fix it! For anyone else having this problem here is the solution:</p>\n<p>In the Main.lean file in the REPL folder add:</p>\n<div class=\"codehilite\" data-code-language=\"Lean4\"><pre><span></span><code><span class=\"kn\">def</span><span class=\"w\"> </span><span class=\"n\">printFlush</span><span class=\"w\"> </span><span class=\"o\">[</span><span class=\"n\">ToString</span><span class=\"w\"> </span><span class=\"n\">α</span><span class=\"o\">]</span><span class=\"w\"> </span><span class=\"o\">(</span><span class=\"n\">s</span><span class=\"w\"> </span><span class=\"o\">:</span><span class=\"w\"> </span><span class=\"n\">α</span><span class=\"o\">)</span><span class=\"w\"> </span><span class=\"o\">:</span><span class=\"w\"> </span><span class=\"n\">IO</span><span class=\"w\"> </span><span class=\"n\">Unit</span><span class=\"w\"> </span><span class=\"o\">:=</span><span class=\"w\"> </span><span class=\"k\">do</span>\n<span class=\"w\">  </span><span class=\"k\">let</span><span class=\"w\"> </span><span class=\"n\">out</span><span class=\"w\"> </span><span class=\"bp\">←</span><span class=\"w\"> </span><span class=\"n\">IO</span><span class=\"bp\">.</span><span class=\"n\">getStdout</span>\n<span class=\"w\">  </span><span class=\"n\">out</span><span class=\"bp\">.</span><span class=\"n\">putStr</span><span class=\"w\"> </span><span class=\"o\">(</span><span class=\"n\">toString</span><span class=\"w\"> </span><span class=\"n\">s</span><span class=\"o\">)</span>\n<span class=\"w\">  </span><span class=\"n\">out</span><span class=\"bp\">.</span><span class=\"n\">flush</span><span class=\"w\"> </span><span class=\"c1\">-- Flush the output</span>\n</code></pre></div>\n<p>Then you can change the line which prints a newline after the output as:</p>\n<div class=\"codehilite\" data-code-language=\"Lean4\"><pre><span></span><code><span class=\"w\">  </span><span class=\"n\">printFlush</span><span class=\"w\"> </span><span class=\"s2\">\"\"</span><span class=\"w\"> </span><span class=\"c1\">-- easier to parse the output if there are blank lines</span>\n</code></pre></div>\n<p>Now it will flush the output appropriately. Now I just got to work out how to send multiline commands.</p>\n<p><strong>Next Tasks</strong><br>\nThe next thing on my list which I'm not sure how to do is to find a way to list all the available tactics. Ideally I would like to filter them by the ones that fit the current goals. Guess that's something I'll have to write in Lean</p>",
        "id": 444053505,
        "sender_full_name": "Mr Proof",
        "timestamp": 1718124968
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"725689\">@Mr Proof</span>, if you make a PR I'll merge it.</p>",
        "id": 444130285,
        "sender_full_name": "Kim Morrison",
        "timestamp": 1718156668
    },
    {
        "content": "<p>It seems <code>repl</code> replies immediately without buffering if its output is a terminal:</p>\n<div class=\"codehilite\" data-code-language=\"Bash\"><pre><span></span><code>$<span class=\"w\"> </span>~/gits/lean4-repl/.lake/build/bin/repl\n<span class=\"o\">{</span><span class=\"w\"> </span><span class=\"s2\">\"cmd\"</span><span class=\"w\"> </span>:<span class=\"w\"> </span><span class=\"s2\">\"import Mathlib.Logic.Lemmas\"</span><span class=\"w\"> </span><span class=\"o\">}</span><span class=\"w\"> </span><span class=\"c1\"># entered by me</span>\n\n<span class=\"o\">{</span><span class=\"s2\">\"env\"</span>:<span class=\"w\"> </span><span class=\"m\">0</span><span class=\"o\">}</span><span class=\"w\">  </span><span class=\"c1\"># appears immediately</span>\n\n<span class=\"o\">{</span><span class=\"w\"> </span><span class=\"s2\">\"cmd\"</span><span class=\"w\"> </span>:<span class=\"w\"> </span><span class=\"s2\">\"import Mathlib.Logic.Lemmas\"</span><span class=\"w\"> </span><span class=\"o\">}</span><span class=\"w\"> </span><span class=\"c1\"># entered by me</span>\n\n<span class=\"o\">{</span><span class=\"s2\">\"env\"</span>:<span class=\"w\"> </span><span class=\"m\">1</span><span class=\"o\">}</span>\n^C\n</code></pre></div>\n<p>But when the output is redirected to a file, there is buffering:</p>\n<div class=\"codehilite\" data-code-language=\"Bash\"><pre><span></span><code>$<span class=\"w\"> </span><span class=\"nb\">echo</span><span class=\"w\"> </span>&gt;<span class=\"w\"> </span>output.txt\n$<span class=\"w\"> </span>tail<span class=\"w\"> </span>-f<span class=\"w\"> </span>output.txt<span class=\"w\"> </span><span class=\"p\">&amp;</span><span class=\"w\"> </span><span class=\"o\">(</span>~/gits/lean4-repl/.lake/build/bin/repl<span class=\"w\"> </span>&gt;<span class=\"w\"> </span>output.txt<span class=\"o\">)</span>\n<span class=\"o\">[</span><span class=\"m\">1</span><span class=\"o\">]</span><span class=\"w\"> </span><span class=\"m\">12818</span>\n<span class=\"o\">{</span><span class=\"w\"> </span><span class=\"s2\">\"cmd\"</span><span class=\"w\"> </span>:<span class=\"w\"> </span><span class=\"s2\">\"import Mathlib.Logic.Lemmas\"</span><span class=\"w\"> </span><span class=\"o\">}</span><span class=\"w\"> </span><span class=\"c1\"># entered by me</span>\n\n<span class=\"o\">{</span><span class=\"w\"> </span><span class=\"s2\">\"cmd\"</span><span class=\"w\"> </span>:<span class=\"w\"> </span><span class=\"s2\">\"import Mathlib.Logic.Lemmas\"</span><span class=\"w\"> </span><span class=\"o\">}</span><span class=\"w\"> </span><span class=\"c1\"># entered by me</span>\n\n<span class=\"o\">{</span><span class=\"w\"> </span><span class=\"s2\">\"cmd\"</span><span class=\"w\"> </span>:<span class=\"w\"> </span><span class=\"s2\">\"import Mathlib.Logic.Lemmas\"</span><span class=\"w\"> </span><span class=\"o\">}</span><span class=\"w\"> </span><span class=\"c1\"># entered by me</span>\n\n<span class=\"c1\"># I pressed Ctrl+D here, then the remaining lines appear.</span>\n<span class=\"o\">{</span><span class=\"s2\">\"env\"</span>:<span class=\"w\"> </span><span class=\"m\">0</span><span class=\"o\">}</span>\n\n<span class=\"o\">{</span><span class=\"s2\">\"env\"</span>:<span class=\"w\"> </span><span class=\"m\">1</span><span class=\"o\">}</span>\n\n<span class=\"o\">{</span><span class=\"s2\">\"env\"</span>:<span class=\"w\"> </span><span class=\"m\">2</span><span class=\"o\">}</span>\n</code></pre></div>\n<p>Now I'll check if the fix from <span class=\"user-mention\" data-user-id=\"725689\">@Mr Proof</span> helps <span aria-label=\"fingers crossed\" class=\"emoji emoji-1f91e\" role=\"img\" title=\"fingers crossed\">:fingers_crossed:</span></p>",
        "id": 451150175,
        "sender_full_name": "Malvin Gattinger",
        "timestamp": 1720864112
    },
    {
        "content": "<p>Indeed it does <span aria-label=\"tada\" class=\"emoji emoji-1f389\" role=\"img\" title=\"tada\">:tada:</span> </p>\n<div class=\"codehilite\" data-code-language=\"Bash\"><pre><span></span><code>$<span class=\"w\"> </span>tail<span class=\"w\"> </span>-f<span class=\"w\"> </span>output.txt<span class=\"w\">  </span><span class=\"p\">&amp;</span><span class=\"w\"> </span><span class=\"o\">(</span>~/gits/lean4-repl/.lake/build/bin/repl<span class=\"w\"> </span>&gt;<span class=\"w\"> </span>output.txt<span class=\"o\">)</span>\n<span class=\"o\">[</span><span class=\"m\">1</span><span class=\"o\">]</span><span class=\"w\"> </span><span class=\"m\">13452</span>\n<span class=\"o\">{</span><span class=\"w\"> </span><span class=\"s2\">\"cmd\"</span><span class=\"w\"> </span>:<span class=\"w\"> </span><span class=\"s2\">\"import Mathlib.Logic.Lemmas\"</span><span class=\"w\"> </span><span class=\"o\">}</span>\n\n<span class=\"o\">{</span><span class=\"s2\">\"env\"</span>:<span class=\"w\"> </span><span class=\"m\">0</span><span class=\"o\">}</span>\n<span class=\"o\">{</span><span class=\"w\"> </span><span class=\"s2\">\"cmd\"</span><span class=\"w\"> </span>:<span class=\"w\"> </span><span class=\"s2\">\"import Mathlib.Logic.Lemmas\"</span><span class=\"w\"> </span><span class=\"o\">}</span>\n\n<span class=\"o\">{</span><span class=\"s2\">\"env\"</span>:<span class=\"w\"> </span><span class=\"m\">1</span><span class=\"o\">}</span>\n<span class=\"o\">{</span><span class=\"w\"> </span><span class=\"s2\">\"cmd\"</span><span class=\"w\"> </span>:<span class=\"w\"> </span><span class=\"s2\">\"import Mathlib.Logic.Lemmas\"</span><span class=\"w\"> </span><span class=\"o\">}</span>\n\n<span class=\"o\">{</span><span class=\"s2\">\"env\"</span>:<span class=\"w\"> </span><span class=\"m\">2</span><span class=\"o\">}</span>\n^C\n$<span class=\"w\"> </span><span class=\"nb\">fg</span>\ntail<span class=\"w\"> </span>-f<span class=\"w\"> </span>output.txt\n^C\n</code></pre></div>",
        "id": 451150342,
        "sender_full_name": "Malvin Gattinger",
        "timestamp": 1720864293
    },
    {
        "content": "<p><a href=\"https://github.com/leanprover-community/repl/pull/49\">Here</a> is a PR with the code from <span class=\"user-mention\" data-user-id=\"725689\">@Mr Proof</span>  above. I am still wondering how to write an automated test for this - the current tests only are for total input/output pairs, right? So they cannot check whether some output appears already before certain other input is given <span aria-label=\"thinking\" class=\"emoji emoji-1f914\" role=\"img\" title=\"thinking\">:thinking:</span></p>",
        "id": 451151385,
        "sender_full_name": "Malvin Gattinger",
        "timestamp": 1720864925
    },
    {
        "content": "<p>With that fix on top of 4.9.0 I was able to build this monster of bash, latex and lean: <a href=\"https://github.com/m4lvin/RepLeanTeX\">https://github.com/m4lvin/RepLeanTeX</a> <span aria-label=\"smirk cat\" class=\"emoji emoji-1f63c\" role=\"img\" title=\"smirk cat\">:smirk_cat:</span></p>",
        "id": 451173145,
        "sender_full_name": "Malvin Gattinger",
        "timestamp": 1720877824
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"422703\">Malvin Gattinger</span> <a href=\"#narrow/stream/113488-general/topic/lean4_jupyter.3A.20A.20Lean.204.20Jupyter.20kernel.20via.20repl/near/451151385\">said</a>:</p>\n<blockquote>\n<p><a href=\"https://github.com/leanprover-community/repl/pull/49\">Here</a> is a PR with the code from <span class=\"user-mention silent\" data-user-id=\"725689\">Mr Proof</span>  above. I am still wondering how to write an automated test for this - the current tests only are for total input/output pairs, right? So they cannot check whether some output appears already before certain other input is given <span aria-label=\"thinking\" class=\"emoji emoji-1f914\" role=\"img\" title=\"thinking\">:thinking:</span></p>\n</blockquote>\n<p>The PR is failing the test suite. Can you take a look, <span class=\"user-mention\" data-user-id=\"422703\">@Malvin Gattinger</span>?</p>",
        "id": 451791289,
        "sender_full_name": "Kim Morrison",
        "timestamp": 1721144673
    },
    {
        "content": "<p>The problem was <code>printFlush \"\"</code> vs <code>printFlush \"\\n\"</code> <span aria-label=\"man facepalming\" class=\"emoji emoji-1f926-200d-2642\" role=\"img\" title=\"man facepalming\">:man_facepalming:</span> and it's fixed now. Now more tests pass when I run them locally but the test case called <code>pickle_open</code> fails with <code>failed to open file 'test/e.olean'</code> and indeed I do not have any such file. Does that test need some special preparation? See <a href=\"https://github.com/leanprover-community/repl/actions/runs/10031272673\">CI run waiting here</a></p>",
        "id": 453038802,
        "sender_full_name": "Malvin Gattinger",
        "timestamp": 1721595523
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"110087\">@Kim Morrison</span> can you let the CI run for the PR to repl?</p>",
        "id": 454251249,
        "sender_full_name": "Malvin Gattinger",
        "timestamp": 1721984754
    },
    {
        "content": "<p>Related (but probably better another topic?), I have just found out that locally on my syste the <code>./test.sh</code> fails because the order in which<code>for infile in $IN_DIR/*.in; do</code> goes through the test files is <a href=\"https://unix.stackexchange.com/questions/368318/does-the-bash-star-wildcard-always-produce-an-ascending-sorted-list\">locale dependent</a>, but the <code>pickle_open_2</code> test only works when <code>pickle_open</code> has been before it to create the <code>e.olean</code> and similarly for the <code>pickle_open_scoped_2</code> test and the <code>H20231215_2.in</code> Mathlib test.</p>\n<p><a href=\"https://github.com/leanprover-community/repl/pull/50\">Here is another PR</a> to fix the order in which tests are run.</p>",
        "id": 454251327,
        "sender_full_name": "Malvin Gattinger",
        "timestamp": 1721984782
    },
    {
        "content": "<p>I've just started CI for both.</p>",
        "id": 454297326,
        "sender_full_name": "Kim Morrison",
        "timestamp": 1721999977
    },
    {
        "content": "<p>and <img alt=\":merge:\" class=\"emoji\" src=\"https://avatars.zulip.com/3121/emoji/images/37577b95.png\" title=\"merge\">'d both!</p>",
        "id": 454297833,
        "sender_full_name": "Kim Morrison",
        "timestamp": 1722000151
    },
    {
        "content": "<p>One long missing feature of <a href=\"https://github.com/utensil/lean4_jupyter\">lean4_jupyter</a> is syntax highlighting for code cells, now it's implemented. It looks like this:</p>\n<p><a href=\"/user_uploads/3121/CieuHWYFGu9kxE_SnE-vQDqz/image.png\">image.png</a></p>\n<div class=\"message_inline_image\"><a href=\"/user_uploads/3121/CieuHWYFGu9kxE_SnE-vQDqz/image.png\" title=\"image.png\"><img data-original-dimensions=\"2440x1506\" src=\"/user_uploads/thumbnail/3121/CieuHWYFGu9kxE_SnE-vQDqz/image.png/840x560.webp\"></a></div><p>I have also polished the installation process (for installing from git main branch), which should be streamlined by the one-liner installation (also used in CI), with some minor side effects (see \"note:\"). If anyone is interested to try it out and encounters issues, please report here or file an issue.</p>",
        "id": 483222749,
        "sender_full_name": "Utensil Song",
        "timestamp": 1732010154
    },
    {
        "content": "<p>Side note: It wasn't trivial for me as it involves creating a frontend JupyterLab extension to add a Lean 4 mode to CodeMirror, and initial survey showed there are quite some breaking changes from JupyterLab and CodeMirror since similar extensions. Thanks to <span class=\"user-mention\" data-user-id=\"310045\">@Eric Wieser</span> 's previous work on <a href=\"https://github.com/pygments/pygments/blob/master/pygments/lexers/lean.py\">Pygments lexer for Lean 4</a>, <a href=\"https://aider.chat/\">aider</a>, and help from JupyterLab forum, I managed to translate the Pygments lexer into a CodeMirror Lean 4 mode, only spending ~$5 on  <code>claude-3-5-sonnet-20241022</code>(48 out of 61 commits in <a href=\"https://github.com/utensil/lean4_jupyter/pull/2\">the PR</a> are by aider).</p>",
        "id": 483222809,
        "sender_full_name": "Utensil Song",
        "timestamp": 1732010163
    },
    {
        "content": "<p>If you have a CodeMirror lexer, I think there is a way to contribute it to github so that the \"edit\" button on github uses it</p>",
        "id": 483224174,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1732010561
    },
    {
        "content": "<p>For now the installation etc. are still on Lean 4.11, I haven't bumped it to 4.13 since repl doesn't maintain tags for stable Lean releases, and repl has recently bumped for v4.14.0-rc1 with quite some fixes, so later I'll bump to stable 4.14. <a href=\"https://github.com/utensil/lean4_jupyter?tab=readme-ov-file#support-matrix\">Support matrix</a> will maintain information about Lean and Python versions etc., I'm trying to roll both Lean and Python support to a relative recent version from time to time, as both are evolving rapidly.</p>",
        "id": 483224186,
        "sender_full_name": "Utensil Song",
        "timestamp": 1732010565
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"310045\">Eric Wieser</span> <a href=\"#narrow/channel/113488-general/topic/lean4_jupyter.3A.20A.20Lean.204.20Jupyter.20kernel.20via.20repl/near/483224174\">said</a>:</p>\n<blockquote>\n<p>If you have a CodeMirror lexer, I think there is a way to contribute it to github so that the \"edit\" button on github uses it</p>\n</blockquote>\n<p>That's an interesting thought. I haven't even tried to edit Lean 4 code using the edit button, TIL it's not syntax highlighted <span aria-label=\"joy\" class=\"emoji emoji-1f602\" role=\"img\" title=\"joy\">:joy:</span> </p>\n<p>It's not a fun to find out every piece of the ecosystem that we are used to are using drastically different mechanisms to highlight. Along the way I've seen you contributed to Pygments for minted in LaTeX, Linguist for Github to recognize it, and there are the TextMate-like one for the VSCode extension, Tree-sitter based one for Neovim, highlightjs-based one for e.g. Alectryon.</p>\n<p>The CodeMirror mode code can be separated from the code for the JupyterLab extension, so it's feasible with no duplication. Since the current translation is written in the legacy mode, it could be contributed to <a href=\"https://github.com/codemirror/legacy-modes\">https://github.com/codemirror/legacy-modes</a> . Or if I could figure out how to further port it to <a href=\"https://codemirror.net/examples/lang-package/\">CodeMirror 6</a>, then it would be <code>@codemirror/lang-lean</code>.</p>",
        "id": 483227777,
        "sender_full_name": "Utensil Song",
        "timestamp": 1732011720
    },
    {
        "content": "<p><a href=\"https://github.com/github-linguist/linguist/blob/f164d13fa618023ecf2d8f2ed9a6ce5fae731346/lib/linguist/languages.yml#L13C54-L13C75\">These lines</a> suggest that github is using codemirror 5, but you might want to do more searching to confirm</p>",
        "id": 483232734,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1732013209
    },
    {
        "content": "<p>It seems that linguist has no issues/PRs discussing adopting CodeMirror 6, so it will still require the mode exists at <a href=\"https://github.com/codemirror/codemirror5/tree/master/mode\">https://github.com/codemirror/codemirror5/tree/master/mode</a> ,  but CodeMirror 5 <a href=\"https://github.com/codemirror/codemirror5/pull/7041#issuecomment-1581950375\">no longer accepts new language PRs</a>. Recent PRs to linguist use <code>ace_mode: text</code> like you did. It seems that we might need to wait for the maintenance cycle to shift after all.</p>",
        "id": 483239701,
        "sender_full_name": "Utensil Song",
        "timestamp": 1732015289
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"296911\">Utensil Song</span> <a href=\"#narrow/channel/113488-general/topic/lean4_jupyter.3A.20A.20Lean.204.20Jupyter.20kernel.20via.20repl/near/483227777\">said</a>:</p>\n<blockquote>\n<p>Tree-sitter based one for Neovim</p>\n</blockquote>\n<p>I don’t think this is accurate.</p>",
        "id": 483246613,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1732017689
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110031\">Patrick Massot</span> <a href=\"#narrow/channel/113488-general/topic/lean4_jupyter.3A.20A.20Lean.204.20Jupyter.20kernel.20via.20repl/near/483246613\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"296911\">Utensil Song</span> <a href=\"#narrow/channel/113488-general/topic/lean4_jupyter.3A.20A.20Lean.204.20Jupyter.20kernel.20via.20repl/near/483227777\">said</a>:</p>\n<blockquote>\n<p>Tree-sitter based one for Neovim</p>\n</blockquote>\n<p>I don’t think this is accurate.</p>\n</blockquote>\n<p>It seems to <a href=\"https://github.com/Julian/lean.nvim/tree/main/queries/lean\">use tree-sitter as first pass</a>, then use information from LSP to be semantic.</p>",
        "id": 483246955,
        "sender_full_name": "Utensil Song",
        "timestamp": 1732017793
    },
    {
        "content": "<p>Very interesting, I had no idea! The tree-sitter approach looks so primitive compared to what Lean allows, but I guess it makes sense as a first pass.</p>",
        "id": 483247993,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1732018141
    },
    {
        "content": "<p>Yes, for the same reason vscode-lean maintains a Textmate-like lexer, but it's missing some new features because the user usually sees the LSP highlight very soon.</p>\n<p>Also, the link above is for tree-sitter queries, and the full parser is at <a href=\"https://github.com/Julian/tree-sitter-lean\">https://github.com/Julian/tree-sitter-lean</a> which is a bit more sophisticated.</p>",
        "id": 483248910,
        "sender_full_name": "Utensil Song",
        "timestamp": 1732018449
    }
]