[
    {
        "content": "<p>I was thinking of ways to outsource more of my work to my computer.<br>\nMaybe there is a way how to make progress on my proofs overnight (other than me having a revelation in a dream).<br>\nWhat if I could configure some tactics (perhaps <code>aesop</code> or <code>simp</code> variants) to be able to succeed even after minutes of no result.<br>\nAny tips?<br>\nI know there will be severely-diminishing results, but I want to try anyway.</p>",
        "id": 411344624,
        "sender_full_name": "Martin Dvo≈ô√°k",
        "timestamp": 1704450705
    },
    {
        "content": "<p>I imagine a hammer would fall into this category, but I think all current hammers for Lean (lean auto, lean-smt, duper,‚Ä¶) have very short timeout times.<br>\nThe existence of such an overnight tool would be really cool though!</p>",
        "id": 411419980,
        "sender_full_name": "Max Nowak üêâ",
        "timestamp": 1704482390
    },
    {
        "content": "<p>I'd also be very in favour of something like this, seems really cool:)</p>",
        "id": 411420392,
        "sender_full_name": "Eric Rodriguez",
        "timestamp": 1704482584
    },
    {
        "content": "<p>is there a way to set the timeout on individual invocations?</p>",
        "id": 411526939,
        "sender_full_name": "Alok Singh",
        "timestamp": 1704565451
    },
    {
        "content": "<p><code>set_option maxHeartbeats 0 in ...</code>?</p>",
        "id": 411545900,
        "sender_full_name": "Kim Morrison",
        "timestamp": 1704582699
    },
    {
        "content": "<p>I'm trying to pull from a couple recent deep learning architecture papers to hopefully make a true model-free policy-gradient reinforcement learning approach work, exposing the search tree/graph of attempted tactics and resulting (sub-) goal (-tuples) to let the model choose where to apply a tactic, and ofc also what tactic to apply.</p>\n<p>I'd love some decent information/statistics for the broadly-usable tactics about also critically how long they run/take.<br>\nAnd quite good would be some way to decently predict how long a tactic would run for in a specific situation to let the RL model exploit it when choosing whether it thinks a tactic in a place is (currently) worth it or not.</p>",
        "id": 411551905,
        "sender_full_name": "namibj",
        "timestamp": 1704587651
    },
    {
        "content": "<p>@namibj, check the output of the <code>tactic-benchmark</code> script in the <code>lean-training-data</code> repository for a proof of concept.</p>",
        "id": 411567426,
        "sender_full_name": "Kim Morrison",
        "timestamp": 1704601035
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110087\">Scott Morrison</span> <a href=\"#narrow/stream/113488-general/topic/Tactic.20worth.20running.20my.20PC.20overnight.3F/near/411567426\">said</a>:</p>\n<blockquote>\n<p>@namibj, check the output of the <code>tactic-benchmark</code> script in the <code>lean-training-data</code> repository for a proof of concept.</p>\n</blockquote>\n<p>Thanks for the pointer; somehow wasn't aware of that repo before. (I've now tried it a little, though the benchmarking itself should wait until I'm better at writing  Lean so the necessary modifications won't unnecessarily risk frustration in comparatively \"boring\" code.)<br>\n(Getting that benchmarking working will be more of a chore than a fun exercise, at least relative to much of the other Lean code I expect to write in the next weeks.)</p>",
        "id": 411646847,
        "sender_full_name": "namibj",
        "timestamp": 1704673775
    },
    {
        "content": "<p>It hasn't quite bubbled to the top of my list, but I would like to make many further improvements to <code>tactic-benchmark</code>. Really I want to build something much more general, so that is it possible to ask questions like \"For all occurrences of tactic X in the library, try running tactic Y (possibly aware of the context and the proof following X), and tell me about how things went.\"</p>\n<p>If you have particular requests let me know!</p>",
        "id": 411655259,
        "sender_full_name": "Kim Morrison",
        "timestamp": 1704679320
    },
    {
        "content": "<p>How much potential to prove more lemmas does <code>aesop</code> have if allowed an enormous number of heartbeats?<br>\nDo you <span class=\"user-mention\" data-user-id=\"256311\">@Jannis Limperg</span> have examples where <code>aesop</code> succeeds iff given more than the standard number of heartbeats?</p>",
        "id": 411906447,
        "sender_full_name": "Martin Dvo≈ô√°k",
        "timestamp": 1704796439
    },
    {
        "content": "<p>This would probably be a good application for neural approaches, which typically scale better for longer times.  Check out LLMStep and <a href=\"https://github.com/lean-dojo/LeanCopilot\">Lean Copilot</a>. (The later at least is just a tactic, so if you can can get it your vision to work with <code>aesop </code>, I think you could get it to work with Lean copilot.). And I agree RL is good for this setting, especially if there was a large number of sorries you were trying to fill in overnight.  Then it could learn from the ones it solved.  The has been lots of research in this direction (see <a class=\"stream\" data-stream-id=\"219941\" href=\"/#narrow/stream/219941-Machine-Learning-for-Theorem-Proving\">#Machine Learning for Theorem Proving</a> ) but less so practical tools (especially ones intended to be run overnight in batch), but that is just an engineering problem.</p>",
        "id": 411911989,
        "sender_full_name": "Jason Rute",
        "timestamp": 1704798204
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"584504\">@Kaiyu Yang</span> is giving a talk on Lean Copilot at Lean Together.</p>",
        "id": 411912461,
        "sender_full_name": "Jason Rute",
        "timestamp": 1704798336
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"115715\">Jason Rute</span> <a href=\"#narrow/stream/113488-general/topic/Tactic.20worth.20running.20my.20PC.20overnight.3F/near/411911989\">said</a>:</p>\n<blockquote>\n<p>(see <a class=\"stream\" data-stream-id=\"219941\" href=\"/#narrow/stream/219941-Machine-Learning-for-Theorem-Proving\">#Machine Learning for Theorem Proving</a> )</p>\n</blockquote>\n<p>I was unable to follow that stream as there was a lot going on, so I created a thread<br>\n<a href=\"#narrow/stream/219941-Machine-Learning-for-Theorem-Proving/topic/Testimonials\">https://leanprover.zulipchat.com/#narrow/stream/219941-Machine-Learning-for-Theorem-Proving/topic/Testimonials</a><br>\nhoping to learn about the fruits of ML for Lean, but nobody posted a testimonial there.</p>\n<p>I am looking forward to the talk on Lean Copilot as I need an overview for Lean users who don't actively watch the ML stuff, which I hope to get from the Lean Together lecture.</p>",
        "id": 411913753,
        "sender_full_name": "Martin Dvo≈ô√°k",
        "timestamp": 1704798770
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"115715\">Jason Rute</span> <a href=\"#narrow/stream/113488-general/topic/Tactic.20worth.20running.20my.20PC.20overnight.3F/near/411911989\">said</a>:</p>\n<blockquote>\n<p>(...) just an engineering problem.</p>\n</blockquote>\n<p>If the research part has been quite successful and some engineering problems are the current bottleneck for deploying AI assistants for Lean, then it is great news I guess?</p>",
        "id": 411915290,
        "sender_full_name": "Martin Dvo≈ô√°k",
        "timestamp": 1704799330
    },
    {
        "content": "<p>Maybe I oversold it slightly.  The current approaches are okay but not great.  Nonetheless, the research is certainly ahead of the practical tools.</p>",
        "id": 411921135,
        "sender_full_name": "Jason Rute",
        "timestamp": 1704801675
    },
    {
        "content": "<p>As for your testimonial page I think there are only 2 usable machine learning tools for all of ITPs, Lean Copilot and Coq Tactician.  There are also some hammers, Isabelle Sledgehammer and CoqHammer.  So the lack of testimonials is partly due to a lack of usable tools.</p>",
        "id": 411921622,
        "sender_full_name": "Jason Rute",
        "timestamp": 1704801867
    },
    {
        "content": "<p>And there are also some general purpose tools like GitHub Copilot and ChatGPT that some people find valuable.</p>",
        "id": 411921865,
        "sender_full_name": "Jason Rute",
        "timestamp": 1704801963
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"417654\">Martin Dvo≈ô√°k</span> <a href=\"#narrow/stream/113488-general/topic/Tactic.20worth.20running.20my.20PC.20overnight.3F/near/411915290\">said</a>:</p>\n<blockquote>\n<p>If the research part has been quite successful and some engineering problems are the current bottleneck for deploying AI assistants for Lean, then it is great news I guess?</p>\n</blockquote>\n<p>The major problems with RL as of what I'm aware of published in ATP that'd apply to Lean are:</p>\n<ol>\n<li>parametrization makes there be far too many allowed tactics in any given moment to use techniques that at some point brute-force over these in their reasoning.</li>\n<li>RL has a severe habit of being computationally extremely expensive</li>\n<li>humans look at the previous steps and attempted-but-rejected branches of the tree(-ish) search for a proof. ATP being technically a \"purely simulated environment\" planning task means that the constraints of \"no (free) rollback\" of most well-researched RL settings (simulated robots, real robots, chess, Atari games, etc.) don't apply. So no need for e.g. AlphaGo's monte-carlo tree search, or similar ones that try to build a world model to limit their interaction with the environment and still train their policy (and/or value) functions.</li>\n<li>Lean ATP as a task has an extremely unusually hard to predict task topology. No real use in predicting the results of a tactic, better to just hone one's intuition and try them out to observe the results.</li>\n<li>Lean4's AST is fairly complex, and side-stepping that by using language models massively increases the machine learning compute costs.</li>\n</ol>\n<p>I'm trying to cobble together a model architecture that ought to cope with 1-3 (2. should be treatable by using recent analytical result/developments that use higher-order differentiation to speed up convergence, akin to how Newton's method (applied to the gradient of the loss function) converges faster than plain gradient descent).</p>\n<p>The particular points that are not just an engineering problem AFAIK are how to isolate the model from human-originated identifiers/have the model view the symbols as the abstract entities they are, and how to squeeze out lean actions from an RL policy model that got to think about the proof state to make up it's mind on how to proceed (a diffusion model might work, but my attempts at finding prior art on doing conditioned generative diffusion on ASTs didn't yield anything more relevant than some nice results in generating molecule graphs (bio chemical/pharma industry (-adjacent) research)).</p>\n<p>In general I'd love to collaborate, especially with some help on the Lean parts as I'm sadly fairly new to Lean itself.</p>",
        "id": 412049000,
        "sender_full_name": "namibj",
        "timestamp": 1704852961
    },
    {
        "content": "<p>What is \"task topology\" please?</p>",
        "id": 412109046,
        "sender_full_name": "Martin Dvo≈ô√°k",
        "timestamp": 1704882343
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"417654\">Martin Dvo≈ô√°k</span> <a href=\"#narrow/stream/113488-general/topic/Tactic.20worth.20running.20my.20PC.20overnight.3F/near/411906447\">said</a>:</p>\n<blockquote>\n<p>How much potential to prove more lemmas does <code>aesop</code> have if allowed an enormous number of heartbeats?<br>\nDo you <span class=\"user-mention silent\" data-user-id=\"256311\">Jannis Limperg</span> have examples where <code>aesop</code> succeeds iff given more than the standard number of heartbeats?</p>\n</blockquote>\n<p>I don't have any examples like this, no. Ironically, I'm not a very heavy user of Aesop myself. I imagine that Aesop is going to struggle with heartbeat limits deep into Mathlib because it runs <code>simp</code> at lot, so there more heartbeats might help. But we're hopefully talking minutes of runtime here, not hours.</p>\n<p>Generally speaking, Aesop is not designed to be \"complete given infinite time\", like e.g. superposition provers are (in theory). You could try to add very general rules (unfold everything, add all recursors, etc.) but I don't think you'd get anything useful out of this.</p>",
        "id": 412109662,
        "sender_full_name": "Jannis Limperg",
        "timestamp": 1704882520
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"417654\">Martin Dvo≈ô√°k</span> <a href=\"#narrow/stream/113488-general/topic/Tactic.20worth.20running.20my.20PC.20overnight.3F/near/412109046\">said</a>:</p>\n<blockquote>\n<p>What is \"task topology\" please?</p>\n</blockquote>\n<p>The topological behavior/properties of the task itself. I had trouble pinning it down compactly; here's the log of my trying with a decent summary at the very end: <a href=\"https://chat.openai.com/share/2e8e0b7f-62cb-427d-8484-e2961a9db0b8\">https://chat.openai.com/share/2e8e0b7f-62cb-427d-8484-e2961a9db0b8</a></p>",
        "id": 412130984,
        "sender_full_name": "namibj",
        "timestamp": 1704889950
    },
    {
        "content": "<p>Note, when AI people use words like ‚Äútopology‚Äù and  ‚Äúmanifold‚Äù they use the words more casually than a mathematician means them.</p>",
        "id": 412152622,
        "sender_full_name": "Jason Rute",
        "timestamp": 1704897579
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"115715\">Jason Rute</span> <a href=\"#narrow/stream/113488-general/topic/Tactic.20worth.20running.20my.20PC.20overnight.3F/near/412152622\">said</a>:</p>\n<blockquote>\n<p>Not [...]</p>\n</blockquote>\n<p>I'll assume that was supposed to be \"Note\".<br>\nAnd yeah, I'd probably abused \"manifold\" somewhat. I don't expect to have done that nearly as much to \"topology\", though.<br>\nI did very much mean the e.g. connectivity of the time-history sweep/extension of the (observation, action) space, which is embedded in what's _roughly_ just the e.g. (finite-dimensional) rank-3 tensor representation of the raw video sequence (plus the action representation if not implied from the observation history).<br>\nBecause  on a graph search/path-discovery task like ITP, you're dealing with the structure of a hidden graph with tactics as edges and goals as nodes. You can apply a tactic to a goal and if it doesn't fail, the edge exists, and the resulting goal (might be <code>True</code>) is added if not yet part of your visible part of the graph and connected with the edge. If you include tactics with multiple subgoals, you'd get hyperedges, but that doesn't really change much.</p>\n<p>The point being, you're trying to find a path from your theorem initial goal node to a <code>True</code> to finish your proof. That graph's structure is fairly resistant to predicting without just trying. Also the try-able out-degree of a node is, if you're lucky, countably finite: you can't brute-force because tactics are parametric so you'd run into the heat death of the universe before you're done brute-forcing a single node's out-edges.<br>\nThus you have to train a \"gut feeling\"/policy to have a habit of choosing effective tactics. And you need some way to choose where to next apply a tactic.<br>\nRetrieval-less LeanCopilot today for example gives you such a \"gut feeling\", and aesop has some strategies (best/depth/breath first) using a normalized rating of how promising the suggested tactics for a particular goal are, and treating them as success probabilities with a probability tree/nesting calculation.</p>\n<p>Many RL tasks in research are far more predictable: e.g. 3D physics-based game engine simulated robots, or some industrial controller tasks where the structure is often so regular that until recently people have just relied on analytical (near-) optimal solutions with sometimes proven bounds to their in-optimality.</p>",
        "id": 412188097,
        "sender_full_name": "namibj",
        "timestamp": 1704907462
    },
    {
        "content": "<p>Is <code>rw_search</code> from <code>Mathlib.Tactic.RewriteSearch</code> worth running overnight?<br>\nDoes anybody have an experience with <code>rw_search</code> running for more than 5 minutes and eventually finding a proof?</p>",
        "id": 424630691,
        "sender_full_name": "Martin Dvo≈ô√°k",
        "timestamp": 1709551077
    },
    {
        "content": "<p>No.</p>",
        "id": 424645808,
        "sender_full_name": "Kim Morrison",
        "timestamp": 1709556536
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"417654\">Martin Dvo≈ô√°k</span> <a href=\"#narrow/stream/113488-general/topic/Tactic.20worth.20running.20my.20PC.20overnight.3F/near/411906447\">said</a>:</p>\n<blockquote>\n<p>How much potential to prove more lemmas does <code>aesop</code> have if allowed an enormous number of heartbeats?<br>\nDo you <span class=\"user-mention silent\" data-user-id=\"256311\">Jannis Limperg</span> have examples where <code>aesop</code> succeeds iff given more than the standard number of heartbeats?</p>\n</blockquote>\n<p><a href=\"https://github.com/leanprover-community/mathlib4/pull/6176\"><code>aided_by</code></a> <a href=\"#narrow/stream/270676-lean4/topic/Aesop.20etc.20in.20the.20background/near/378792005\"> :thread: </a> seems to be related, and partially answers this question.</p>\n<p>It's not actually for running overnight, instead it's running when the human is thinking, but since it's in the background, it naturally allows more heartbeats (such relaxation is not in the PR yet). Personally, I guess <code>aesop</code>/<code>duper</code> etc. has quite some potential for running for minutes, but not so much for hours.</p>",
        "id": 426276559,
        "sender_full_name": "Utensil Song",
        "timestamp": 1710316022
    },
    {
        "content": "<p>It has been a year.<br>\nHas any general-purpose tactic worth running overnight appeared in the meantime?<br>\nI made a suggestion for overnight aesop <a href=\"https://github.com/leanprover-community/aesop/issues/202\">https://github.com/leanprover-community/aesop/issues/202</a> but <span class=\"user-mention\" data-user-id=\"256311\">@Jannis Limperg</span> will not have time for developing it.</p>",
        "id": 505607158,
        "sender_full_name": "Martin Dvo≈ô√°k",
        "timestamp": 1741938855
    },
    {
        "content": "<p>From previous conversations, it seems like you are looking for a tactic which is easy to install, runs on windows without wsl, and is worth running overnight‚Äîwhich is a much larger ask.</p>",
        "id": 505633183,
        "sender_full_name": "Jason Rute",
        "timestamp": 1741946975
    },
    {
        "content": "<p>Not really \"runs on windows without wsl\" ‚Äî I got a new PC with Ubuntu a few weeks ago. Nevertheless, I would like to have something that runs out of the box.</p>",
        "id": 505634805,
        "sender_full_name": "Martin Dvo≈ô√°k",
        "timestamp": 1741947385
    },
    {
        "content": "<p>I think this is a reasonable feature, in terms of UX. But let me try to enhance it a little bit</p>\n<ul>\n<li>Such a tactic would need some mechanism for not losing track of the solution, if/when it is found. It needs to cache the solution locally (just in case the user accidentally messes up) and provide the proof as a \"try this\" hint for easy replacement. If the user replaces the tactic invocation with the \"try this\" hint, the cache can be thrown away</li>\n<li>The tactic can also cache previous attempts, if that helps to avoid trying the same fruitless path over and over. Again, once the \"try this\" hint is accepted by the user, this cache can be thrown away</li>\n</ul>",
        "id": 505664681,
        "sender_full_name": "Arthur Paulino",
        "timestamp": 1741956025
    },
    {
        "content": "<p>Such a tactic would also need to checkpoint its proof term generation, to recover from abrupt process termination.</p>",
        "id": 505665425,
        "sender_full_name": "Shreyas Srinivas",
        "timestamp": 1741956240
    },
    {
        "content": "<p>It would need to run asynchronously somehow.</p>",
        "id": 505665492,
        "sender_full_name": "Shreyas Srinivas",
        "timestamp": 1741956248
    },
    {
        "content": "<p>Even a try this would be printed if run from the command line.  I‚Äôve used this to benchmark Aesop and LeanCopilot in the past.</p>",
        "id": 505671898,
        "sender_full_name": "Jason Rute",
        "timestamp": 1741958124
    },
    {
        "content": "<p>I have never seen aesop take more than a few seconds. Has anyone actually ever set up some version of mathlib where some call to aesop with some lemmas suitable tagged actually takes e.g. 8 hours on a modern machine? Without that, this question is a bit nebulous.</p>",
        "id": 505675485,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1741959010
    },
    {
        "content": "<p>So in discord we discussed this and it was pointed out that Aesop is meant to be used interactively. But we were hoping that lean-auto + duper might benefit from multi hour runs if it were upstreamed and maintained</p>",
        "id": 505676462,
        "sender_full_name": "Shreyas Srinivas",
        "timestamp": 1741959261
    },
    {
        "content": "<p>Same for bv_decide</p>",
        "id": 505676491,
        "sender_full_name": "Shreyas Srinivas",
        "timestamp": 1741959270
    },
    {
        "content": "<p>I thought the idea was \"prove theorems in my WIP work while I'm sleeping\". I can imagine that we can find some goals which <code>bv_decide</code> would solve but it take 8 hours, however I cannot really imagine that they are goals which would show up in reality (at least in my own work!). I can imagine that AI tools could take hours though (and also cost a fair bit of money!).</p>",
        "id": 505679831,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1741960128
    },
    {
        "content": "<p>Small combinatorial problems</p>",
        "id": 505679965,
        "sender_full_name": "Shreyas Srinivas",
        "timestamp": 1741960166
    },
    {
        "content": "<p>One of the profs at my department was hacking on a certain allocation problem (assigning discrete goods to agents) satisfying some fairness criterion. He got a sat solver to say that a certain allocation exists for a small number of agents (that was previously a wide open question) by running a sat solver for 32 hours</p>",
        "id": 505680289,
        "sender_full_name": "Shreyas Srinivas",
        "timestamp": 1741960248
    },
    {
        "content": "<p>Unfortunately the sat solver he used doesn‚Äôt plug into a proof assistant easily so we don‚Äôt technically have a ‚Äúproof‚Äù yet.</p>",
        "id": 505680404,
        "sender_full_name": "Shreyas Srinivas",
        "timestamp": 1741960277
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"466334\">Shreyas Srinivas</span> <a href=\"#narrow/channel/113488-general/topic/Tactic.20worth.20running.20my.20PC.20overnight.3F/near/505676462\">said</a>:</p>\n<blockquote>\n<p>So in discord we discussed this and it was pointed out that Aesop is meant to be used interactively. But we were hoping that lean-auto + duper might benefit from multi hour runs if it were upstreamed and maintained</p>\n</blockquote>\n<p>The difference is that aesop is a general-purpose automation that works out of the box.<br>\nI don't think <code>lean-auto</code> or <code>duper</code> will satisfy it anytime soon.</p>",
        "id": 505686684,
        "sender_full_name": "Martin Dvo≈ô√°k",
        "timestamp": 1741961827
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110038\">Kevin Buzzard</span> <a href=\"#narrow/channel/113488-general/topic/Tactic.20worth.20running.20my.20PC.20overnight.3F/near/505675485\">said</a>:</p>\n<blockquote>\n<p>I have never seen aesop take more than a few seconds. Has anyone actually ever set up some version of mathlib where some call to aesop with some lemmas suitable tagged actually takes e.g. 8 hours on a modern machine? Without that, this question is a bit nebulous.</p>\n</blockquote>\n<p>I once had <code>aesop</code> call that took over 20 minutes and then succeeded. Never hours.</p>",
        "id": 505687437,
        "sender_full_name": "Martin Dvo≈ô√°k",
        "timestamp": 1741962028
    },
    {
        "content": "<p>My impression is that this is getting nowhere because people who have the skills to develop tactics are too focused on efficiency. At this point, I'd like to have anything slightly more complete than <code>aesop</code> ‚Äî no matter how inefficient; I won't mind if searching the proof space with slightly more breadth increases the runtime from 10 seconds to 10 hours.</p>",
        "id": 507461097,
        "sender_full_name": "Martin Dvo≈ô√°k",
        "timestamp": 1742657084
    },
    {
        "content": "<blockquote>\n<p>My impression is that this is getting nowhere because people who have the skills to develop tactics are too focused on efficiency.</p>\n</blockquote>\n<p>I wouldn't say they are too focused, as a simple matter of fact the vast majority of users use Lean interactively and thus getting as much as possible solved in a time that can be considered interactive is the most important metric for the majority of tactic developers. Furthermore many tools that we have like <code>aesop</code> or <code>simp</code> do not have completeness so they will very likely have diminishing returns very quickly (unless you are say, working on gigantic proof states in which case they might just take a while to consume the entire proof state). As mentioned previously tools that do have completeness (for their respective domains) and thus it is reasonable to let them run for very long is for example <code>bv_decide</code> or <code>duper</code>.</p>",
        "id": 507462600,
        "sender_full_name": "Henrik B√∂ving",
        "timestamp": 1742658168
    },
    {
        "content": "<blockquote>\n<p>no matter how inefficient</p>\n</blockquote>\n<p>IMHO, I would suggest caution there... For problems like proof search with a pretty \"strongly exponential\" blowup, a 'modest' efficiency improvement in the search strategy can make the difference between 10 minutes and 10 days, easily. Okay, maybe 10 days is \"fine\" for you, but what if it's a month? A year?</p>\n<p>As an example...</p>\n<p>Something like GodelProver <a href=\"https://arxiv.org/abs/2502.07640\">https://arxiv.org/abs/2502.07640</a> you could just run as many times as you'd like, getting independent samples. Their paper shows steady improvements in success on MiniF2F rate as number of attempts goes up, exponentially, as one would expect. It's not slowing down by 100k samples, so one can reasonably expect to still benefit up to 1M samples, at least. But producing 1M samples at 1sec/attempt (which would be kind of beefy!) would still mean 11 days.</p>\n<p>Bottom line: with a fairly new LLM-based approach, on MiniF2F problems, you would definitely continue to see benefit waiting up to 11 days per problem you want solved.</p>\n<p>At that kind of time scale, I definitely care about efficiency, not just 'can it maybe close my goal in theory'.</p>",
        "id": 507467974,
        "sender_full_name": "Alex Meiburg",
        "timestamp": 1742661984
    },
    {
        "content": "<p>A good method will solve log(t) theorems, from a set of theorems to solve, in time t.  If you have a sizable test set and enough compute to test it, you can see this plainly.  For example look at the plots in Graph2Tac.  (Yes, this won‚Äôt hold forever, but it will for a sizable range of time.)  But it is good to test this, because it may not be true of current methods.</p>",
        "id": 507514578,
        "sender_full_name": "Jason Rute",
        "timestamp": 1742695840
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"417654\">@Martin Dvo≈ô√°k</span> honestly as the person who requests this feature the most, you might be the perfect person to work on it, say testing various methods, tweaking Aesop and others to have this property, and  making something that works in practice.  I don‚Äôt know your background, but I imagine you are more capable than you may realize, especially with the support of the Lean community.</p>",
        "id": 507514801,
        "sender_full_name": "Jason Rute",
        "timestamp": 1742696023
    },
    {
        "content": "<p>I can look into it after I finish my Ph.D., but now I need to focus on finishing things towards my thesis. Learning metaprogramming would take too much time for me, while my contract is running out soon.</p>",
        "id": 507549611,
        "sender_full_name": "Martin Dvo≈ô√°k",
        "timestamp": 1742724022
    },
    {
        "content": "<p>One thought is that instead of looking for tactics which work on a single goal state for hours, which is something that probably has exponential blowup and quickly causes diminishing returns, but instead doing operations that scan all of Mathlib looking for ways to optimize or analyze proofs. Maybe things like</p>\n<ul>\n<li>Trying <code>aesop</code> after every single tactic state in Mathlib (iirc, there's a tool to do this now?)</li>\n<li>Trying various proof changes across Mathlib to try to speed them up</li>\n<li>Creating an sqlite database with every single local hypothesis and goal state that have ever been reached in Mathlib, and their corresponding proofs. Then filling in a new sorry could involve doing a scan to see if a similar situation has ever occurred in Mathlib, and informing the user if so.</li>\n</ul>",
        "id": 507586373,
        "sender_full_name": "Niels Voss",
        "timestamp": 1742751573
    },
    {
        "content": "<p>TryAtEachStep is the tool BTW</p>",
        "id": 507588457,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1742752905
    },
    {
        "content": "<p>That's an interesting thing to do, but doesn't help with proving things that you don't have a formalized proof for yet</p>",
        "id": 507591521,
        "sender_full_name": "Ruben Van de Velde",
        "timestamp": 1742754932
    },
    {
        "content": "<p>That's fair. I just can't imagine that goals which require between 1 hour and 10 days to solve are very common; I'd imagine most goals take either a couple of seconds at most or longer than the heat death of the universe. I think there would probably need to be an entirely new approach for this to be feasible.</p>",
        "id": 507595148,
        "sender_full_name": "Niels Voss",
        "timestamp": 1742757196
    },
    {
        "content": "<p>You are probably right, but in my case, the entire area between 2 minutes and 2 days is almost untested but viable to be tested. Something brute-force-able should be there.</p>",
        "id": 507595802,
        "sender_full_name": "Martin Dvo≈ô√°k",
        "timestamp": 1742757559
    },
    {
        "content": "<p>I guess the reason why I bring up scanning all of mathlib is because stuff that involves a full mathlib is expensive but not that expensive. This is the only task I can think of that is expensive for reasons other than exponential blowup. So maybe if <code>exact?</code> takes a few seconds to run, something that is like a depth-2 <code>exact?</code> will take on the order of hours to run? Of course, since you can't expect this to close every goal, this would make the most sense if you had like 15 or 20 sorries and left it running overnight to see if any of those sorries could be filled in, rather than focusing on a particular one.</p>\n<p>Of course, I'm just throwing around ideas, but it would be really cool if we had a way to let people dedicate compute power to solving math problems, so I hope this succeeds.</p>",
        "id": 507597571,
        "sender_full_name": "Niels Voss",
        "timestamp": 1742758599
    },
    {
        "content": "<p>Has depth-2¬†<code>exact?</code> been implemented?</p>",
        "id": 507598999,
        "sender_full_name": "Martin Dvo≈ô√°k",
        "timestamp": 1742759518
    },
    {
        "content": "<p>Not that I know of</p>",
        "id": 507604595,
        "sender_full_name": "Niels Voss",
        "timestamp": 1742763163
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"417654\">@Martin Dvo≈ô√°k</span> A depth-2 <code>exact?</code> in some form would be super cool. This topic was discussed briefly last week in <a href=\"#narrow/channel/113489-new-members/topic/Feasibility.20of.20an.20.60exact.3F.60.20tactic.20exploring.20two.20lemmas.20deep.3F\">#new members &gt; Feasibility of an &#96;exact?&#96; tactic exploring two lemmas deep?</a>, but as far as I can tell, the interesting feasibility question was never fully addressed.</p>",
        "id": 507865736,
        "sender_full_name": "Isak Colboubrani",
        "timestamp": 1742846496
    },
    {
        "content": "<p>I think more interesting would be to generalize the discharger for exact?. Currently it solves subgoals just via solve_by_elim. What happens if that in turn is allowed to call simp or grind? What if we use grind instead of solve_by_elim, etc.</p>",
        "id": 507894232,
        "sender_full_name": "Kim Morrison",
        "timestamp": 1742858722
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"448405\">Alex Meiburg</span> <a href=\"#narrow/channel/113488-general/topic/Tactic.20worth.20running.20my.20PC.20overnight.3F/near/507467974\">said</a>:</p>\n<blockquote>\n<p>Something like GodelProver <a href=\"https://arxiv.org/abs/2502.07640\">https://arxiv.org/abs/2502.07640</a></p>\n</blockquote>\n<p>Does anybody know if GodelProver works on goals that involve custom types?</p>",
        "id": 508327723,
        "sender_full_name": "Martin Dvo≈ô√°k",
        "timestamp": 1743006550
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110038\">Kevin Buzzard</span> <a href=\"#narrow/channel/113488-general/topic/Tactic.20worth.20running.20my.20PC.20overnight.3F/near/505675485\">said</a>:</p>\n<blockquote>\n<p>I have never seen aesop take more than a few seconds. Has anyone actually ever set up some version of mathlib where some call to aesop with some lemmas suitable tagged actually takes e.g. 8 hours on a modern machine? Without that, this question is a bit nebulous.</p>\n</blockquote>\n<p>FYI, I just finished a very difficult proof with <code>aesop</code> where increasing heartbeats from 5 million to 15 million make it succeed.</p>\n<p>Kudos to <span class=\"user-mention\" data-user-id=\"256311\">@Jannis Limperg</span> for providing such a powerful tool!</p>",
        "id": 527276617,
        "sender_full_name": "Martin Dvo≈ô√°k",
        "timestamp": 1751718588
    },
    {
        "content": "<p>What was the wall clock time? I'm guessing minutes and not overnight?</p>",
        "id": 527278246,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1751720526
    },
    {
        "content": "<p>Yeah, minutes on my new machine; would be over an hour on my old machine.</p>",
        "id": 527278323,
        "sender_full_name": "Martin Dvo≈ô√°k",
        "timestamp": 1751720637
    },
    {
        "content": "<p>The take-home message is that you can delegate hard work to your computer, already with the current technology, and it would be really cool to be able to delegate more.</p>",
        "id": 527278488,
        "sender_full_name": "Martin Dvo≈ô√°k",
        "timestamp": 1751720827
    },
    {
        "content": "<p>There is nothing novel about my last message, I know.</p>",
        "id": 527278638,
        "sender_full_name": "Martin Dvo≈ô√°k",
        "timestamp": 1751721014
    }
]