[
    {
        "content": "<p>djb (A <em>very</em> popular crypto, as in encryption, not as in crypto currency person) seems to be working towards formally verifying McEliece (a quantum computer resistant asymmetrical encryption scheme) in Lean 4!: <a href=\"https://mastodon.cr.yp.to/@djb/110780690497105946\">https://mastodon.cr.yp.to/@djb/110780690497105946</a></p>",
        "id": 378812371,
        "sender_full_name": "Henrik Böving",
        "timestamp": 1690379870
    },
    {
        "content": "<p>I'm fairly sure he's in the zulip :]</p>",
        "id": 378813682,
        "sender_full_name": "Eric Rodriguez",
        "timestamp": 1690380074
    },
    {
        "content": "<blockquote>\n<p>Beware that Lean is a general-purpose programming language. Malicious code anywhere inside the Lean software or inside leangoppa can spoil verification, destroy files, etc. In other words, the proof verification relies on a large TCB.</p>\n</blockquote>",
        "id": 378813786,
        "sender_full_name": "Matthew Ballard",
        "timestamp": 1690380093
    },
    {
        "content": "<p>Is there an independent verifier for lean4 yet?</p>",
        "id": 378814119,
        "sender_full_name": "Ruben Van de Velde",
        "timestamp": 1690380154
    },
    {
        "content": "<p>I don't think djb is alluding to the kernel  (aka the verifier) here, I'm rather certain he would agree that that is a very small TCB. I would guess the comment is directed more towards the fact that in the end you have to also trust that the compiler makes a faithful translation of your statement and proofs for the kernel to look at. And having an independent second Lean compiler is kind of pointless because the meta programming relies heavily on knowing precise internal things about the compiler</p>",
        "id": 378814708,
        "sender_full_name": "Henrik Böving",
        "timestamp": 1690380247
    },
    {
        "content": "<p>Now if you listen to e.g. Leo's talks you will notice that he says only the kernel is TCB and the compiler does not need to be trusted which is a fair statement to make in the sense that it is unlikely that the compiler will wrongly translate your statement and then still allow the proof that you wrote for the actual statement to go through. But <em>technically</em> speaking you still trust.</p>",
        "id": 378815269,
        "sender_full_name": "Henrik Böving",
        "timestamp": 1690380331
    },
    {
        "content": "<p>Yes Dan was at Leiden two weeks ago and has been active in discussions about this work in the private stream associated to the workshop</p>",
        "id": 378844718,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1690384754
    },
    {
        "content": "<p>I'm pretty sure \"trusted\" here mainly means \"trusted not to install a keylogger on your machine\".</p>",
        "id": 378854242,
        "sender_full_name": "Frédéric Dupuis",
        "timestamp": 1690386335
    },
    {
        "content": "<p>I would have thought \"trusted\" meant something more like Ken Thompson's \"Reflections on trusting trust\".</p>",
        "id": 378886282,
        "sender_full_name": "Jireh Loreaux",
        "timestamp": 1690392106
    },
    {
        "content": "<p>Oh, hey, <span class=\"user-mention\" data-user-id=\"110994\">@Joe Hendrix</span> and I did some work on McEliece as well :) On a cursory look, djb's repo seems to be aiming at verifying the mathematics of Goppa codes and eventually McEliece. In <a href=\"https://github.com/joehendrix/lean-crypto\">lean-crypto</a>, we were looking at the mostly orthogonal target of showing a concrete C implementation equivalent to a reference implementation in Lean 4.</p>",
        "id": 378888593,
        "sender_full_name": "Wojciech Nawrocki",
        "timestamp": 1690392574
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"630204\">@D. J. Bernstein</span> You might be interested in chiming in on this thread <span aria-label=\"this\" class=\"emoji emoji-1f446\" role=\"img\" title=\"this\">:this:</span></p>",
        "id": 378894727,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1690393918
    },
    {
        "content": "<p>Just so it is clear, it is entirely possible (and not too hard) to make a Lean file which when opened in the VS Code Lean plugin, starts to send information via the internet and run shell commands.  What it is capable of getting away with is probably largely up to the security on your computer.  (In Lean 3, just write a tactic using <a href=\"https://leanprover-community.github.io/mathlib_docs/find/tactic.unsafe_run_io\">docs3#tactic.unsafe_run_io</a> .  I assume you can still do this in Lean 4, but I don't know the secret.)</p>",
        "id": 378905705,
        "sender_full_name": "Jason Rute",
        "timestamp": 1690396044
    },
    {
        "content": "<p>Unlike a lot of programming languages, Lean's tactics can run when the language server is active, not just when you run the code.  So it is in some ways more of a security issue than say a python program, which can't do any harm (I think) by just opening it with the python vs code plugin.</p>",
        "id": 378906240,
        "sender_full_name": "Jason Rute",
        "timestamp": 1690396144
    },
    {
        "content": "<p>(But on the other hand, unsafe_run_io is really useful for some projects.  It lets you, for example, write tactics like lean-gptf and sagredo which interact with an external process or API.)</p>",
        "id": 378907435,
        "sender_full_name": "Jason Rute",
        "timestamp": 1690396395
    },
    {
        "content": "<p>You dont need unsafe_run_io in Lean 4 that tactics can execute IO is a built in intended feature. The TacticM monad stack is on top of IO</p>",
        "id": 378909964,
        "sender_full_name": "Henrik Böving",
        "timestamp": 1690396893
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"128280\">Wojciech Nawrocki</span> <a href=\"#narrow/stream/113488-general/topic/djb's.20formalization.20of.20McEliece/near/378888593\">said</a>:</p>\n<blockquote>\n<p>Oh, hey, <span class=\"user-mention silent\" data-user-id=\"110994\">Joe Hendrix</span> and I did some work on McEliece as well :) On a cursory look, djb's repo seems to be aiming at verifying the mathematics of Goppa codes and eventually McEliece. In <a href=\"https://github.com/joehendrix/lean-crypto\">lean-crypto</a>, we were looking at the mostly orthogonal target of showing a concrete C implementation equivalent to a reference implementation in Lean 4.</p>\n</blockquote>\n<p>Ultimately one wants end-to-end verification that the software is computing the specified cryptographic functions correctly on all inputs. It's clear which software matters: the machine code that the user is running. For the cryptographic functions, the optimal choice of formalization language is less obvious; we want to limit the risk of mismatches between the specification and the target of security analysis.</p>\n<p>Whatever choice is made there, stating the end-to-end theorem requires connecting definitions of (1) instruction semantics (which maybe doesn't match real CPU behavior; see, e.g., <a href=\"https://lock.cmpxchg8b.com/zenbleed.html\">https://lock.cmpxchg8b.com/zenbleed.html</a>), (2) the software, and (3) the mathematical objects inside the specified cryptosystem. The proofs I posted are covering pretty much everything one needs to know about <a href=\"https://github.com/leanprover-community/mathlib4/pull/3\">#3</a>, but obviously they aren't saying anything about <a href=\"https://github.com/leanprover-community/mathlib4/pull/2\">#2</a>. Certified compilation, translation validation, etc. can connect various (<a href=\"https://github.com/leanprover-community/mathlib4/pull/1\">#1</a>,<a href=\"https://github.com/leanprover-community/mathlib4/pull/2\">#2</a>) pairs, but that still leaves a gap between <a href=\"https://github.com/leanprover-community/mathlib4/pull/2\">#2</a> and <a href=\"https://github.com/leanprover-community/mathlib4/pull/3\">#3</a>.</p>\n<p>In short, the software proofs and the math proofs are both needed---preferably in a single framework that can hook them together rather than leaving risks of gaps between a software-verification system and a math-verification system.</p>\n<p>I know how to get everything done in HOL Light. I don't know how to get everything done in Lean, but I also know that I'm too new to Lean to  know.</p>",
        "id": 378923658,
        "sender_full_name": "D. J. Bernstein",
        "timestamp": 1690399711
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"630204\">@D. J. Bernstein</span> Have you also looked at Metamath Zero? The author of MM0 is <span class=\"user-mention\" data-user-id=\"110049\">@Mario Carneiro</span>, who is an expert on both MM0 and Lean.</p>",
        "id": 378930381,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1690401542
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"112680\">Johan Commelin</span> <a href=\"#narrow/stream/113488-general/topic/djb's.20formalization.20of.20McEliece/near/378930381\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"630204\">D. J. Bernstein</span> Have you also looked at Metamath Zero? The author of MM0 is <span class=\"user-mention silent\" data-user-id=\"110049\">Mario Carneiro</span>, who is an expert on both MM0 and Lean.</p>\n</blockquote>\n<p>I looked a bit. My initial feeling, which probably says more about the documentation I found than about the actual situation, was that (1) the level of verifiability of the proofs is attractive, (2) pretty-printing modules are critical for a broad audience to tolerate reading theorem statements, and (3) the libraries are impressive in Metamath but more impressive in HOL Light, perhaps because John Harrison is very fast but perhaps because HOL Light has better tools to support efficient proof development.</p>",
        "id": 379054600,
        "sender_full_name": "D. J. Bernstein",
        "timestamp": 1690446569
    },
    {
        "content": "<p>I think one needs to be careful not to mix MM0 and Metamath.  If I understand correctly, MM0, while it can be used as a Metamath checker, can also be used to check other logics like HOL.  I’m not entirely sure why <span class=\"user-mention\" data-user-id=\"112680\">@Johan Commelin</span> mentioned MM0, but I think it is because of MM0’s stated goal to prove the correctness of the MM0 verifier x86 code in MM0 (using PA as the logic for verifying the verifier), but I could be mistaken.</p>",
        "id": 379143224,
        "sender_full_name": "Jason Rute",
        "timestamp": 1690461801
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"630204\">D. J. Bernstein</span> <a href=\"#narrow/stream/113488-general/topic/djb's.20formalization.20of.20McEliece/near/378923658\">said</a>:</p>\n<blockquote>\n<p>I know how to get everything done in HOL Light. I don't know how to get everything done in Lean, but I also know that I'm too new to Lean to  know.</p>\n</blockquote>\n<p>Would you be willing to elaborate?  By “get everything done”, do you mean generate a proof that an actual working implementation of a piece of software (written in a real programming language like C++ or OCaml) is verified down to machine instructions (of the programming language? of the compiled code?) to behave as desired?  I'd be surprised this is possible in any current system, including HOL-Light, but is there a way to do it in HOL-Light?  (I haven't kept up to date on projects like CakeML and the such.  Is there some abstract programming language in HOL Light, which can be extracted to provably correct code?)</p>",
        "id": 379156517,
        "sender_full_name": "Jason Rute",
        "timestamp": 1690464048
    },
    {
        "content": "<p>I guess the big problem with Lean is that while you could prove the correctness of your Lean code, and even compile it to a binary (through C++), you couldn't be sure the binary (or generated C++ code) is faithful to the mathematical Lean code for a number of reasons:</p>\n<ul>\n<li>You can't verify the wrapping IO code (I think, maybe I'm wrong).</li>\n<li>The Lean compiler isn't near as likely to be bug free as the Lean kernel, and certainly isn't verified to be so.</li>\n<li>The full Lean compilation pipeline also relies on the correctness of a C++ compiler.</li>\n<li>Many low level Lean data types like <code>Nat</code>, <code>Array</code>, etc are modeled with simple mathematical definitions, but replaced with native data types.</li>\n<li>Many low level functions are also replaced with faster C++ versions which aren't formally verified to be equivalent.</li>\n</ul>",
        "id": 379156543,
        "sender_full_name": "Jason Rute",
        "timestamp": 1690464051
    },
    {
        "content": "<p>I also don't think Lean has any form of code extraction like Coq does.</p>",
        "id": 379157359,
        "sender_full_name": "Jason Rute",
        "timestamp": 1690464188
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"115715\">Jason Rute</span> <a href=\"#narrow/stream/113488-general/topic/djb's.20formalization.20of.20McEliece/near/379156517\">said</a>:</p>\n<blockquote>\n<p>I'd be surprised this is possible in any current system, including HOL-Light, but is there a way to do it in HOL-Light?  (I haven't kept up to date on projects like CakeML and the such.  Is there some abstract programming language in HOL Light, which can be extracted to provably correct code?)</p>\n</blockquote>\n<p><a href=\"https://drops.dagstuhl.de/opus/volltexte/2023/18379/pdf/LIPIcs-ITP-2023-4.pdf\">Candle</a> is probably what you are looking for.</p>",
        "id": 379168016,
        "sender_full_name": "Wenda Li",
        "timestamp": 1690465914
    },
    {
        "content": "<p>See <code>CURVE25519_X25519_BYTE_SUBROUTINE_CORRECT</code> in <a href=\"https://github.com/awslabs/s2n-bignum/blob/main/x86/proofs/curve25519_x25519.ml\">https://github.com/awslabs/s2n-bignum/blob/main/x86/proofs/curve25519_x25519.ml</a> for an example of an end-to-end proof in HOL Light that some fast x86 software correctly computes a (much more simply) specified mathematical function.</p>",
        "id": 379190225,
        "sender_full_name": "D. J. Bernstein",
        "timestamp": 1690469265
    },
    {
        "content": "<p>I agree having a framework is important.  One approach I took at Galois was building equivalence checking tools for checking software matches it's specification using SAW.  One tool we built in Lean was a <a href=\"https://github.com/GaloisInc/reopt-vcg\">VCG</a> that could prove decompiled LLVM matched the semantics of x86.  That tool itself is in Lean, but hasn't been formally verified itself.</p>",
        "id": 379581470,
        "sender_full_name": "Joe Hendrix",
        "timestamp": 1690564756
    },
    {
        "content": "<p>Update: The HOL Light version (<a href=\"https://cr.yp.to/2023/lightgoppa-20230811-verify.html\">https://cr.yp.to/2023/lightgoppa-20230811-verify.html</a>) is a 56997-byte gz, where the parts I'd classify as non-background are 26197 bytes. For comparison, the Lean version (<a href=\"https://cr.yp.to/2023/leangoppa-20230726-verify.html\">https://cr.yp.to/2023/leangoppa-20230726-verify.html</a>) is a 34067-byte gz, where non-background is 21595 bytes.</p>\n<p>The difference between 56997 bytes and 34067 bytes is easy to explain from specific topics in basic algebra that matter for these proofs and that lightgoppa develops where leangoppa calls mathlib: e.g., deg fg = deg f + deg g for polynomials f,g in one variable over a domain. Also, in non-compressed form, lightgoppa is much more verbose than leangoppa overall, again for easy-to-explain reasons (e.g., <code>ring_add(x_ring k) (ring_mul(x_ring k) a B) (ring_mul(x_ring k) b A)</code> instead of <code>a*B-b*A</code>, and frequent this-is-an-element-of-this-ring proof steps), although this isn't a pure win for Lean (e.g., lightgoppa rarely attaches labels to hypotheses inside and outside proofs, whereas leangoppa continually does).</p>\n<p>What' less obvious is why lightgoppa had lower elapsed time (started 31 July, so 12 days) than leangoppa (started 12 July, so 15 days), despite covering more background. Is this because I have more experience with HOL Light? Because the HOL Light proof was done second? More time was saved from HOL Light's proof automation than from Lean's proof automation? The UI was more responsive? The elapsed time doesn't reflect the actual work time?</p>",
        "id": 384284158,
        "sender_full_name": "D. J. Bernstein",
        "timestamp": 1691851533
    },
    {
        "content": "<blockquote>\n<p>Is this because I have more experience with HOL Light? Because the HOL Light proof was done second?</p>\n</blockquote>\n<p>These both seem very plausible answers. Second formalizations are always easier</p>",
        "id": 384295432,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1691854004
    },
    {
        "content": "<p>generally speaking I would put pretty big error bars on \"human time spent on project\" as a metric, because it is affected by things like what you were doing at the time (e.g. traveling) or your personal motivation. It is very difficult to get unbiased measurements of this, and although I don't know all the details of your month of work I would be inclined to consider this as a statistically insignificant deviation</p>",
        "id": 384297321,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1691854431
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110049\">Mario Carneiro</span> <a href=\"#narrow/stream/113488-general/topic/djb's.20formalization.20of.20McEliece/near/384295432\">said</a>:</p>\n<blockquote>\n<blockquote>\n<p>Is this because I have more experience with HOL Light? Because the HOL Light proof was done second?</p>\n</blockquote>\n<p>These both seem very plausible answers. Second formalizations are always easier</p>\n</blockquote>\n<p>I think all five answers (and perhaps more) are plausible, but the interesting quantitative question is how they explain the speed gap in this case, 4749 gz bytes/day for lightgoppa vs. 2271 gz bytes/day for leangoppa. If you consider the numbers I provided regarding background material then you'll see that \"second formalization\" has to be under half of the answer---a large part of lightgoppa is formalizing things that I hadn't formalized before, including in leangoppa!</p>",
        "id": 384299775,
        "sender_full_name": "D. J. Bernstein",
        "timestamp": 1691855084
    },
    {
        "content": "<p>I'm absolutely sure you are more proficient in HOL light than Lean. I very much doubt you could get most of the readers of this chat to produce that HOL light  code in 12 days</p>",
        "id": 384300068,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1691855158
    },
    {
        "content": "<p>how much HOL light code (est. lines of code) have you written prior to this project? Ditto for lean</p>",
        "id": 384300619,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1691855319
    },
    {
        "content": "<p>What is the compile time of the projects? Your overview page lists a time for the HOL light version (although it's not clear if this time also includes supporting material not in the project) but not the lean version</p>",
        "id": 384301200,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1691855506
    },
    {
        "content": "<p>I'm new to Lean, as mentioned above. But I'm not sure how to reconcile the following hypotheses: (1) formalization in Lean is so different from formalization in HOL Light that someone with experience in HOL Light will be much slower starting out in Lean; (2) formalization in Lean is so similar to formalization in HOL Light that formalizing something in Lean will give a big speed boost to formalizing the same thing in HOL Light.</p>",
        "id": 384301833,
        "sender_full_name": "D. J. Bernstein",
        "timestamp": 1691855694
    },
    {
        "content": "<p>Mathematically, there are a lot of similarities of course. It's the same mathematics in two languages</p>",
        "id": 384302129,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1691855765
    },
    {
        "content": "<p>But I would say that the formalization experience is very different, modulo the fundamental similarity of being mathematical formalizations</p>",
        "id": 384302290,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1691855817
    },
    {
        "content": "<p>Are there comparative writeups somewhere?</p>",
        "id": 384302382,
        "sender_full_name": "D. J. Bernstein",
        "timestamp": 1691855853
    },
    {
        "content": "<p>you just made one</p>",
        "id": 384302421,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1691855860
    },
    {
        "content": "<p>there aren't too many people with experience in both systems (I am one of them but I have not tried a comparative study, nor have I tried to do this kind of mathematics in HOL light so I'm sure there would be some more learning there)</p>",
        "id": 384302806,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1691855970
    },
    {
        "content": "<p>I think it is pretty good that you were able to go from ~no lean experience (I assume) to being able to formalize a complex mathematics statement with only a 2x slowdown</p>",
        "id": 384302896,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1691855991
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110049\">Mario Carneiro</span> <a href=\"#narrow/stream/113488-general/topic/djb's.20formalization.20of.20McEliece/near/384302421\">said</a>:</p>\n<blockquote>\n<p>you just made one</p>\n</blockquote>\n<p>Well, sort of. :-) The *.ml and *.lean files don't directly say anything about formalization processes: as an extreme example, they obviously don't say anything about UI responsiveness.</p>",
        "id": 384303143,
        "sender_full_name": "D. J. Bernstein",
        "timestamp": 1691856040
    },
    {
        "content": "<p>(reminded of <a href=\"https://danluu.com/productivity-velocity/\">https://danluu.com/productivity-velocity/</a>)</p>",
        "id": 384303297,
        "sender_full_name": "D. J. Bernstein",
        "timestamp": 1691856071
    },
    {
        "content": "<p>The UI experience is pretty fundamentally different, I'm not sure numerical comparisons would even be helpful</p>",
        "id": 384303404,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1691856098
    },
    {
        "content": "<p>although the overall compile time number is probably useful (hence my question above)</p>",
        "id": 384303543,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1691856126
    },
    {
        "content": "<p>I thought I put the compile-time numbers into both postings.</p>",
        "id": 384303772,
        "sender_full_name": "D. J. Bernstein",
        "timestamp": 1691856183
    },
    {
        "content": "<p><a href=\"https://cr.yp.to/2023/leangoppa-20230726-verify.html\">https://cr.yp.to/2023/leangoppa-20230726-verify.html</a> lacks a compile time number</p>",
        "id": 384303864,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1691856200
    },
    {
        "content": "<p>oh, it says \"takes a few minutes\"</p>",
        "id": 384303988,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1691856222
    },
    {
        "content": "<p>I would be interested in a more precise number to compare with the 1165 seconds number</p>",
        "id": 384304176,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1691856249
    },
    {
        "content": "<p>and also a clarification on whether that number includes the massive HOL startup cost</p>",
        "id": 384304414,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1691856308
    },
    {
        "content": "<p>Lean is definitely much faster running through the verification: it verifies a few independent *.lean files in parallel, and doesn't run through re-verifying the standard library.</p>",
        "id": 384304438,
        "sender_full_name": "D. J. Bernstein",
        "timestamp": 1691856312
    },
    {
        "content": "<p>do you know how to profile a HOL light project while excluding the startup cost?</p>",
        "id": 384304779,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1691856371
    },
    {
        "content": "<p>1165 is for the full <code>time ocaml ...</code> command, as stated.</p>",
        "id": 384304809,
        "sender_full_name": "D. J. Bernstein",
        "timestamp": 1691856377
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110049\">Mario Carneiro</span> <a href=\"#narrow/stream/113488-general/topic/djb's.20formalization.20of.20McEliece/near/384304779\">said</a>:</p>\n<blockquote>\n<p>do you know how to profile a HOL light project while excluding the startup cost?</p>\n</blockquote>\n<p><code>Sys.time();;</code></p>",
        "id": 384305456,
        "sender_full_name": "D. J. Bernstein",
        "timestamp": 1691856519
    },
    {
        "content": "<p>(I was hoping you would do it for me <span aria-label=\"smile\" class=\"emoji emoji-1f642\" role=\"img\" title=\"smile\">:smile:</span> )</p>",
        "id": 384305563,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1691856544
    },
    {
        "content": "<p>actually, could you say more about your impressions re: \"UI responsiveness\"? My own impression is that the feedback loop in lean is worlds better than HOL light, one of the key differentiators IMO, but it's possible that you mean something more specific</p>",
        "id": 384306014,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1691856621
    },
    {
        "content": "<p>80% of the theorems for this one are from the standard library (defaults plus ringtheory plus products). Probably less of the run time since the standard library puts effort into constructing proofs efficiently whereas I'm casually using model elimination at almost every step.</p>",
        "id": 384306293,
        "sender_full_name": "D. J. Bernstein",
        "timestamp": 1691856681
    },
    {
        "content": "<p>I'm just thinking about the cost to run the code that you wrote (those 56997 bytes)</p>",
        "id": 384306478,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1691856723
    },
    {
        "content": "<p>I was basically never waiting for HOL Light during proof development for this project---just a bit at the end to run through checking everything. I had much more waiting for Lean (via nvim), especially the pernicious type of waiting where there isn't an instantaneous answer and you're not sure how long you're supposed to wait.</p>",
        "id": 384306774,
        "sender_full_name": "D. J. Bernstein",
        "timestamp": 1691856780
    },
    {
        "content": "<p>I see, so you never went backward and revised theorems?</p>",
        "id": 384306992,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1691856843
    },
    {
        "content": "<p>Maybe vscode would have been better.</p>",
        "id": 384307039,
        "sender_full_name": "D. J. Bernstein",
        "timestamp": 1691856850
    },
    {
        "content": "<p>Oh, that's an interesting point, I don't know whether there is a significant difference there as I don't use nvim</p>",
        "id": 384307139,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1691856877
    },
    {
        "content": "<p>Note that there are some tricks to reduce the amount of waiting, like putting <code>#exit</code> after the current theorem or using <code>sorry</code> for subproofs</p>",
        "id": 384307358,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1691856937
    },
    {
        "content": "<p>How long of a wait are we talking?</p>",
        "id": 384307539,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1691856965
    },
    {
        "content": "<p>\"responsive lean\" seems to be in the ballpark of 500 ms, although I know it can get much worse as you use heavier tactics</p>",
        "id": 384307894,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1691857064
    },
    {
        "content": "<p>This may be obvious, but lean is still under active development and people are trying to fix these kind of issues if you can isolate them and/or suggest improvements</p>",
        "id": 384308182,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1691857152
    },
    {
        "content": "<p>I often ran into the default heartbeat limit. Much more often had delays of a few seconds. If I had to list the top three performance-related problems that I encountered with Lean then it'd be (1) no obvious line-by-line feedback regarding performance, (2) the search tools such as <code>apply?</code> apparently prioritizing some sort of completeness rather than aiming for the best quick answers, (3) any change to a proof triggering a recompilation of the proof from the top, at least with nvim. Splitting off lots of lemmas reduced the issues with <a href=\"https://github.com/leanprover-community/mathlib4/pull/2\">#2</a> and <a href=\"https://github.com/leanprover-community/mathlib4/pull/3\">#3</a> but of course has its own costs: some proofs are highly connected.</p>",
        "id": 384309519,
        "sender_full_name": "D. J. Bernstein",
        "timestamp": 1691857560
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110049\">Mario Carneiro</span> <a href=\"#narrow/stream/113488-general/topic/djb's.20formalization.20of.20McEliece/near/384303404\">said</a>:</p>\n<blockquote>\n<p>The UI experience is pretty fundamentally different, I'm not sure numerical comparisons would even be helpful</p>\n</blockquote>\n<p>What do you see as the big differences?</p>",
        "id": 384309931,
        "sender_full_name": "D. J. Bernstein",
        "timestamp": 1691857673
    },
    {
        "content": "<p>Lean uses a document-style interaction mode, you can edit earlier theorems and see the effect on later ones immediately. In HOL light this means either redefining stuff and then replaying an ad hoc set of later theorems, possibly ending up in an inconsistent state, or restarting HOL light and waiting for that massive startup cost again</p>",
        "id": 384310556,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1691857833
    },
    {
        "content": "<p>on the flip side because HOL light is basically a REPL you get immediate feedback on the line you are currently typing</p>",
        "id": 384310705,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1691857873
    },
    {
        "content": "<p>(I also generally hate REPLs for the shitty text editing experience they provide by dint of being an elaborate command line interface)</p>",
        "id": 384310811,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1691857908
    },
    {
        "content": "<p>You can also just put your cursor anywhere and see information about proof steps, or hover and go-to-def on things, and get autocomplete. This is huge for me, and the REPL has only a poor approximation of it in that you can recall specific theorems by name</p>",
        "id": 384311568,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1691858143
    },
    {
        "content": "<p>Hmmm. The HOL Light tutorial says \"In fact, when I’m developing a proof in HOL I usually construct this kind of tactic script explicitly in an editor, and copy parts into the goalstack as I proceed to make sure I’m on the right track.\" I recently switched to the vi plugin from <span class=\"user-mention\" data-user-id=\"217807\">@Freek Wiedijk</span>, which nicely speeds up the copy-and-paste steps.</p>",
        "id": 384311709,
        "sender_full_name": "D. J. Bernstein",
        "timestamp": 1691858194
    },
    {
        "content": "<p>Yeah, I recall HOL4 also has some fancy things to make the copy paste part less terrible</p>",
        "id": 384311780,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1691858229
    },
    {
        "content": "<p>still, I think it would be a lot easier to draft such a proof if you could just see all of the intermediate steps without prompting and with live updating</p>",
        "id": 384311959,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1691858304
    },
    {
        "content": "<p>Realistically, the UI ends up looking fairly similar: editor window with a proof script under development, separate window showing the goal stack (most recent assumptions at the bottom in case of overflow).</p>",
        "id": 384311990,
        "sender_full_name": "D. J. Bernstein",
        "timestamp": 1691858315
    },
    {
        "content": "<p>that's just a technical limitation of HOL light as currently implemented, not something I consider good proof assistant design</p>",
        "id": 384312076,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1691858339
    },
    {
        "content": "<p>?</p>",
        "id": 384312101,
        "sender_full_name": "D. J. Bernstein",
        "timestamp": 1691858360
    },
    {
        "content": "<p>that was continuing my previous line</p>",
        "id": 384312141,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1691858378
    },
    {
        "content": "<p>That is to say, you could in principle have a more document-editor style interface even for HOL light and I think you would be able to get a faster feedback loop that way</p>",
        "id": 384312350,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1691858454
    },
    {
        "content": "<p>Hmmm. My direct recent experience with the comparative UI speed seems to be the opposite of what you're saying.</p>",
        "id": 384312473,
        "sender_full_name": "D. J. Bernstein",
        "timestamp": 1691858491
    },
    {
        "content": "<p>To slightly oversimplify: Instantaneous feedback from HOL Light, continual random slowdowns with Lean.</p>",
        "id": 384312805,
        "sender_full_name": "D. J. Bernstein",
        "timestamp": 1691858596
    },
    {
        "content": "<p>The other key to this being effective is that proofs have to be broken up into small self-contained units (proof steps) which are individually valid. HOL light has this (its proof mode encourages you to not write <code>proof(...</code> and just write top to bottom, but rather to split out each tactic into <code>e(...)</code> steps) but lean doesn't (you write directly into atomic <code>theorem</code> command blocks, and lean can only give you feedback when the whole command block is processed)</p>",
        "id": 384313032,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1691858660
    },
    {
        "content": "<p>In part this is a technical issue in lean, it should be able to give you feedback about the result of a tactic as soon as that tactic is complete, and it should not need to rerun tactics that have not changed since the last edit</p>",
        "id": 384313200,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1691858740
    },
    {
        "content": "<p>But if lean had a proof mode like HOL light's <code>e(...)</code> steps broken out as separate lean commands then you would certainly get back the speed benefits you are seeing in HOL Light</p>",
        "id": 384313356,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1691858788
    },
    {
        "content": "<p>because it's just a lot simpler to process a linear sequence of things than a complicated AST</p>",
        "id": 384313427,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1691858814
    },
    {
        "content": "<p>now I think I want to try to demo something like that in lean</p>",
        "id": 384313940,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1691858983
    },
    {
        "content": "<p>In, e.g., <code>goppa_closer.lean</code>, I ended up with 20 lemmas simply trying to avoid Lean slowdowns, whereas for HOL Light I split out 4 for the same theorem.</p>",
        "id": 384314377,
        "sender_full_name": "D. J. Bernstein",
        "timestamp": 1691859137
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110049\">Mario Carneiro</span> <a href=\"#narrow/stream/113488-general/topic/djb's.20formalization.20of.20McEliece/near/384304176\">said</a>:</p>\n<blockquote>\n<p>I would be interested in a more precise number to compare with the 1165 seconds number</p>\n</blockquote>\n<p>On the same machine, 29 seconds for getting the cache, 165 seconds for building the project.</p>",
        "id": 384315098,
        "sender_full_name": "D. J. Bernstein",
        "timestamp": 1691859423
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110049\">Mario Carneiro</span> <a href=\"#narrow/stream/113488-general/topic/djb's.20formalization.20of.20McEliece/near/384307358\">said</a>:</p>\n<blockquote>\n<p>Note that there are some tricks to reduce the amount of waiting, like putting <code>#exit</code> after the current theorem or using <code>sorry</code> for subproofs</p>\n</blockquote>\n<p>For both HOL Light and Lean, I'm usually editing the last theorem in the file. (In general, I'm writing proofs bottom-up, which is always a safe way to be sure what's true, even when proof development follows other paths.) If I think a theorem really belongs somewhere else, I'll just put a <code>move</code> comment to handle later. For Lean, to avoid nvim crashing every few minutes, I would most often edit a theorem as a comment, and uncomment it when I wanted feedback. For HOL Light, the plugin has explicit keystrokes to request feedback.</p>",
        "id": 384316542,
        "sender_full_name": "D. J. Bernstein",
        "timestamp": 1691859834
    },
    {
        "content": "<p>Apparently there's progress on the nvim plugin for Lean so I might be able to skip the commenting-uncommenting part.</p>",
        "id": 384316744,
        "sender_full_name": "D. J. Bernstein",
        "timestamp": 1691859925
    },
    {
        "content": "<p>Meanwhile the HOL Light plugin was crashing ocaml, but that was triggered on the scale of hours and was easy to fix (fd leak). One deduces from this that I'm typically doing a goal-stack update every second or so on average.</p>",
        "id": 384317401,
        "sender_full_name": "D. J. Bernstein",
        "timestamp": 1691860151
    },
    {
        "content": "<p>I think this is a combination of multiple modes: often I'll type, say, 10 lines without asking for feedback; often I'll be flipping back and forth between lines while studying the list of assumptions.</p>",
        "id": 384318240,
        "sender_full_name": "D. J. Bernstein",
        "timestamp": 1691860451
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110049\">Mario Carneiro</span> <a href=\"#narrow/stream/113488-general/topic/djb's.20formalization.20of.20McEliece/near/384311568\">said</a>:</p>\n<blockquote>\n<p>You can also just put your cursor anywhere and see information about proof steps, or hover and go-to-def on things, and get autocomplete. This is huge for me, and the REPL has only a poor approximation of it in that you can recall specific theorems by name</p>\n</blockquote>\n<p>Just to advertise <span class=\"user-mention\" data-user-id=\"217807\">@Freek Wiedijk</span>'s plugin a bit more: If you put your cursor somewhere in the proof and type Ctrl-H then the separate goal-stack window shows the proof state at that point. Ctrl-P and Ctrl-N move to the previous state and the next state, while automatically moving the cursor to a logical spot.</p>",
        "id": 384320302,
        "sender_full_name": "D. J. Bernstein",
        "timestamp": 1691861222
    },
    {
        "content": "<p>(The first part of that should be easily doable in <code>nvim</code> FWIW -- the second part we thought of I believe and want(ed) to do but I don't know if there's a more efficient way to do so in Lean than literally iterating over positions in the document and pulling the goal state, I think for something nicer there would need to be server-side support. Also in general please do feel free to file feature requests or complaints if they're <code>nvim</code>-specific,  even though in the past year I have not gotten much time to work on things, but I very much don't mind / need some active user nagging to get to things and guilt me away from other commitments)</p>",
        "id": 384321888,
        "sender_full_name": "Julian Berman",
        "timestamp": 1691861776
    },
    {
        "content": "<p>To be more specific on the first bit, I'll have to try Freek's plugin, but let me know if <code>vim.keymap.set('n', '&lt;C-H&gt;', require'lean.commands'.show_goal)</code> is what you mean, or equivalently typing the command <code>:LeanGoal</code> (see also <code>:LeanTermGoal</code>)</p>",
        "id": 384323083,
        "sender_full_name": "Julian Berman",
        "timestamp": 1691862193
    },
    {
        "content": "<p>Which I think Gabriel added.</p>",
        "id": 384323104,
        "sender_full_name": "Julian Berman",
        "timestamp": 1691862198
    },
    {
        "content": "<p>To mention some points where I found Lean faster than HOL Light: The Lean documentation for beginners definitely points to better discovery tools than anything I've found for HOL Light. I found autocomplete and <code>exact?</code> and so on helpful for learning what was available. Also, <code>simp?</code> serves both as a teaching tool and as a proof-speedup tool, although I'm not sure I like the way it discards the input line. <span class=\"user-mention\" data-user-id=\"321696\">@Julian Berman</span> Thanks for fixing the <code>?</code> handling, btw.</p>",
        "id": 384323371,
        "sender_full_name": "D. J. Bernstein",
        "timestamp": 1691862293
    },
    {
        "content": "<p>My pleasure -- yeah feel free to complain more certainly if you notice specific things. I am myself quite bad at Lean, so I have plenty of blindspots I'm sure on what needs work -- luckily there have been others (Gabriel and Rish) who contributed and are much much much better at Lean and therefore knew what to contribute, but yeah complaints are very welcome because when I play with things I'm tinkering with simple nonsense, so it's helpful to hear when someone is doing more interesting things what needs work.</p>",
        "id": 384323939,
        "sender_full_name": "Julian Berman",
        "timestamp": 1691862494
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"630204\">@D. J. Bernstein</span> In the near future, we'll have a tactic combinator called <code>says</code> (I think there is a PR to mathlib underway). It will allow you to write <code>tac1 says tac2</code>, where <code>tac1</code> can be slow, and <code>tac2</code> can be fast. That way, the input line <code>simp?</code> will no longer need to be discarded.</p>\n<p>An option to Lean will indicate whether <code>says</code> should only execute <code>tac2</code> (fast mode) or whether it should execute <code>tac1</code> and check that it spits out <code>tac2</code> as \"Try this\" comment (CI mode).</p>",
        "id": 384325018,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1691862913
    },
    {
        "content": "<p>Sounds perfect.</p>",
        "id": 384328975,
        "sender_full_name": "D. J. Bernstein",
        "timestamp": 1691864278
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"321696\">Julian Berman</span> <a href=\"#narrow/stream/113488-general/topic/djb's.20formalization.20of.20McEliece/near/384323083\">said</a>:</p>\n<blockquote>\n<p>To be more specific on the first bit, I'll have to try Freek's plugin, but let me know if <code>vim.keymap.set('n', '&lt;C-H&gt;', require'lean.commands'.show_goal)</code> is what you mean, or equivalently typing the command <code>:LeanGoal</code> (see also <code>:LeanTermGoal</code>)</p>\n</blockquote>\n<p>Here's a small example of what the plugin looks like: <a href=\"https://cr.yp.to/2023/20230812/step-hol-light-example.html\">https://cr.yp.to/2023/20230812/step-hol-light-example.html</a></p>",
        "id": 384329655,
        "sender_full_name": "D. J. Bernstein",
        "timestamp": 1691864549
    },
    {
        "content": "<p>For the nvim Lean plugin, the equivalent of Ctrl-H (showing the goals at the current position) is always happening as the cursor moves, and is fast enough that I'm fine with this being automatic. What's slower is editing and then waiting for Lean to recompile the proof from the top, which I gather is a general Lean limitation at the moment rather than something nvim-specific; this turns quadratic costs into cubic costs for something that I'd hope is linear cost.</p>",
        "id": 384332394,
        "sender_full_name": "D. J. Bernstein",
        "timestamp": 1691865462
    },
    {
        "content": "<p>I'm reminded of another Lean slowdown I encountered for some proofs: long formulas seemed to be a big speed problem. I figured that this was from Lean trying to decide what type to use for additions etc., so I inserted a bunch of type declarations, which seemed to help.</p>",
        "id": 384332652,
        "sender_full_name": "D. J. Bernstein",
        "timestamp": 1691865601
    },
    {
        "content": "<p>To be clear, when I say \"long\", I mean things like <code>(((X:k[X])^t21*(X:k[X])*R-Q:k[X])*bar (h*q:k[X]) - ((X:k[X])^(t21)*D*bar (h*b:k[X]):k[X]) - ((X:k[X])^(t21)*(X:k[X]) * (R-bar B) * bar (h*q):k[X]):k[X]).degree</code>, which is nowhere near the length frequently appearing in some areas of math.</p>",
        "id": 384333179,
        "sender_full_name": "D. J. Bernstein",
        "timestamp": 1691865826
    },
    {
        "content": "<p>(But I hear <code>bar B</code> is popular these days.)</p>",
        "id": 384333293,
        "sender_full_name": "D. J. Bernstein",
        "timestamp": 1691865860
    },
    {
        "content": "<p>As far as I know there isn't anything particularly sensitive to length in the elaboration algorithm, other than basically linear costs (possibly high depending on the complexity of the typeclass problems)</p>",
        "id": 384335578,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1691866859
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110049\">Mario Carneiro</span> <a href=\"#narrow/stream/113488-general/topic/djb's.20formalization.20of.20McEliece/near/384310556\">said</a>:</p>\n<blockquote>\n<p>Lean uses a document-style interaction mode, you can edit earlier theorems and see the effect on later ones immediately. In HOL light this means either redefining stuff and then replaying an ad hoc set of later theorems, possibly ending up in an inconsistent state, or restarting HOL light and waiting for that massive startup cost again</p>\n</blockquote>\n<p>This is something where I can quantify costs: once or twice a day I would start a separate HOL Light session to run through the whole file, and sometimes this would show that I had accidentally moved a theorem before a theorem that it depended on, so I had to move it down. But I wasn't _waiting_ for the separate HOL Light session; I was continuing to type new proofs.</p>\n<p>Every now and then I realized that I wanted to replace an existing lemma with a generalization (this happened more often for HOL Light than for Lean since I was developing more background lemmas), and of course it's logically necessary to check all the theorems using the lemma, but this never ended up breaking anything. For Lean, any change to the hypotheses of a lemma tends to break callers using <code>exact</code> etc. Anyway, this wasn't a big issue overall for these proofs: the target proofs had already been written down carefully before any of the formalization, and the background was things like polynomial derivatives where everybody knows the usual proofs.</p>",
        "id": 384337277,
        "sender_full_name": "D. J. Bernstein",
        "timestamp": 1691867637
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110049\">Mario Carneiro</span> <a href=\"#narrow/stream/113488-general/topic/djb's.20formalization.20of.20McEliece/near/384305563\">said</a>:</p>\n<blockquote>\n<p>(I was hoping you would do it for me <span aria-label=\"smile\" class=\"emoji emoji-1f642\" role=\"img\" title=\"smile\">:smile:</span> )</p>\n</blockquote>\n<p>On a 3GHz Skylake core, loading the default libraries took 97 seconds, loading further libraries took 228 seconds, and running the new proofs took 423 seconds.</p>",
        "id": 384344202,
        "sender_full_name": "D. J. Bernstein",
        "timestamp": 1691871056
    },
    {
        "content": "<p>that doesn't seem to add up to 1165 seconds, where is the rest of the time going?</p>",
        "id": 384347102,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1691872677
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110049\">Mario Carneiro</span> <a href=\"#narrow/stream/113488-general/topic/djb's.20formalization.20of.20McEliece/near/384335578\">said</a>:</p>\n<blockquote>\n<p>As far as I know there isn't anything particularly sensitive to length in the elaboration algorithm, other than basically linear costs (possibly high depending on the complexity of the typeclass problems)</p>\n</blockquote>\n<p>Does the heterogenous nature of <code>+</code> add to the cost here? Is lean trying to guess the final outparam from outside in after each inner expression is elaborated?</p>",
        "id": 384355569,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1691877922
    },
    {
        "content": "<p><code>binop%</code> is supposed to fix that issue, although it's possible that there are still issues. I think this would require a contrived stress test example to determine the actual asymptotic complexity</p>",
        "id": 384357247,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1691879075
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"112680\">Johan Commelin</span> <a href=\"#narrow/stream/113488-general/topic/djb's.20formalization.20of.20McEliece/near/384325018\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"630204\">D. J. Bernstein</span> In the near future, we'll have a tactic combinator called <code>says</code> (I think there is a PR to mathlib underway). It will allow you to write <code>tac1 says tac2</code>, where <code>tac1</code> can be slow, and <code>tac2</code> can be fast. That way, the input line <code>simp?</code> will no longer need to be discarded.</p>\n<p>An option to Lean will indicate whether <code>says</code> should only execute <code>tac2</code> (fast mode) or whether it should execute <code>tac1</code> and check that it spits out <code>tac2</code> as \"Try this\" comment (CI mode).</p>\n</blockquote>\n<p>Here \"near future\" is actually 2 weeks ago. :-)</p>",
        "id": 384386970,
        "sender_full_name": "Scott Morrison",
        "timestamp": 1691896242
    },
    {
        "content": "<p><a href=\"https://cr.yp.to/2023/leangoppa-20230813-slower.tar.gz\">https://cr.yp.to/2023/leangoppa-20230813-slower.tar.gz</a> takes 229 seconds for <code>lake build</code> specifically for <code>goppa_closer.lean</code> (after everything else is built), where the original takes 75 seconds for that file, on a dual EPYC 7742 (128 cores, apparently using just 1 for this) running at 2.245GHz.</p>\n<p>Compared to leangoppa-20230726, leangoppa-20230813-slower undoes various explicit <code>:k[X]</code> annotations and sets a much higher heartbeat limit. There are no other differences. Both builds succeed.</p>\n<p>To be clear, this is not a contrived example: it's simply reconstructing and benchmarking one of the Lean performance problems that I encountered in formalizing the (not particularly complicated) proofs in this paper. At that point I worked around this problem rather than benchmarking it. (\"I figured that this was from Lean trying to decide what type to use for additions etc., so I inserted a bunch of type declarations, which seemed to help.\")</p>\n<p>With my performance-measurement hat on, let me again emphasize the HOL Light advantage of obvious feedback on the cost of each line (specifically for model elimination, the Swiss army knife that all my <code>have</code> and <code>qed</code> lines are using). At the UI level, I'm automatically getting that feedback in a separate window (beyond the main editing window and the goal-stack window) and rapidly deal with any noticeable slowdowns (by inserting an extra <code>have</code> step, or adding <code>xyzzylemma</code> into the model elimination where I neglected to include <code>xyzzylemma</code> earlier). The feedback doesn't cover parsing time, but HOL Light doesn't have let's-think-hard-about-which-addition-you-really-mean built into the parser; if it did then I think I'd want that timed too. I gather that Lean has profiling tools, but nothing is on by default except for the heartbeat limit. Simply reporting the number of heartbeats used for parsing+tactics on each line should help a lot.</p>",
        "id": 384395363,
        "sender_full_name": "D. J. Bernstein",
        "timestamp": 1691901201
    },
    {
        "content": "<blockquote>\n<p>let me again emphasize the HOL Light advantage of obvious feedback on the cost of each line</p>\n</blockquote>\n<p>what are you referring to here?</p>",
        "id": 384396790,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1691902039
    },
    {
        "content": "<p>You can turn on profiling of course, if you care to see numbers; most of the time it's patently obvious what parts are slow because you have to wait for the slow parts</p>",
        "id": 384396952,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1691902119
    },
    {
        "content": "<p>if you put <code>set_option profiling true</code> lean will report on how long things take if they are above a certain threshold, which seems near to what you are describing for HOL light</p>",
        "id": 384397240,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1691902224
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110049\">Mario Carneiro</span> <a href=\"#narrow/stream/113488-general/topic/djb's.20formalization.20of.20McEliece/near/384347102\">said</a>:</p>\n<blockquote>\n<p>that doesn't seem to add up to 1165 seconds, where is the rest of the time going?</p>\n</blockquote>\n<p>Different machine, as I said. On the EPYC, some <code>Sys.time()</code> outputs from a fresh run are <code>151.221226 505.213478 510.140727 608.500798 808.137747000000104 1170.793694</code> for, respectively, end of default library inclusion, end of ring-theory inclusion, end of products inclusion, start of linear-dependence proof, end of linear-dependence proof, end of all proofs.</p>\n<p>The linear-dependence proof says (with a proof designed to be subsequently adapted into a proof of algorithm correctness) that if you're given n homogeneous linear equations in more than n variables over a domain then you can find a nonzero solution (I guess I should say \"strictly more\" for readers from France). This proof isn't in leangoppa since leangoppa simply puts together Lean's <code>linearIndependent_iff_card_eq_finrank_span</code> and <code>finrank_le</code> to get the field case of the same statement, and the Goppa-decoding proofs need only the field case. (_Using_ the statement was much more of a hassle, since the linear-dependence statements in Lean want finite index and coindex types while the proof in question wants degree-related polynomial exponents as index and coindex types, as we discussed in a separate thread.) What I found in the HOL Light library before writing lightgoppa was just the real case, which isn't of much use for algebraic coding theory.</p>",
        "id": 384398973,
        "sender_full_name": "D. J. Bernstein",
        "timestamp": 1691903128
    },
    {
        "content": "<p>looks like most of the slowdown in leangoppa-slower example is caused by <code>goppa_checking_2_lemma_hbsum6</code>, which has its heartbeat count (as measured by <code>count_heartbeats in</code>) go from 1535277 (well over the default 200000) to 85821. Most of the other theorems are not in the same order of magnitude</p>",
        "id": 384399717,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1691903524
    },
    {
        "content": "<p>I will see if I can extract a MWE</p>",
        "id": 384399758,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1691903543
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110049\">Mario Carneiro</span> <a href=\"#narrow/stream/113488-general/topic/djb's.20formalization.20of.20McEliece/near/384397240\">said</a>:</p>\n<blockquote>\n<p>if you put <code>set_option profiling true</code> lean will report on how long things take if they are above a certain threshold, which seems near to what you are describing for HOL light</p>\n</blockquote>\n<p>The level of information provided is very different. With HOL Light, what's scrolling by in the third window, by default, zero extra effort, is line-by-line model-elimination performance numbers:</p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code>  <span class=\"bp\">#</span> <span class=\"k\">have</span> <span class=\"bp\">`</span><span class=\"n\">ring_homomorphism</span><span class=\"o\">(</span><span class=\"n\">x_ring</span> <span class=\"n\">r</span><span class=\"o\">,</span><span class=\"n\">x_ring</span> <span class=\"n\">r</span><span class=\"o\">)</span> <span class=\"o\">(</span><span class=\"n\">poly_shift</span> <span class=\"n\">r</span> <span class=\"o\">(</span><span class=\"n\">c</span><span class=\"o\">:</span><span class=\"n\">R</span><span class=\"o\">))</span><span class=\"bp\">`</span> <span class=\"o\">[</span><span class=\"n\">poly_shift_morphism</span><span class=\"o\">]</span>\n<span class=\"mi\">0</span><span class=\"bp\">..</span><span class=\"mi\">0</span><span class=\"bp\">..</span><span class=\"mi\">1</span><span class=\"bp\">..</span><span class=\"n\">solved</span> <span class=\"n\">at</span> <span class=\"mi\">4</span>\n  <span class=\"bp\">#</span> <span class=\"n\">qed</span><span class=\"o\">[</span><span class=\"n\">RING_HOMOMORPHISM_PRODUCT</span><span class=\"o\">]</span>\n<span class=\"mi\">0</span><span class=\"bp\">..</span><span class=\"mi\">0</span><span class=\"bp\">..</span><span class=\"mi\">1</span><span class=\"bp\">..</span><span class=\"mi\">2</span><span class=\"bp\">..</span><span class=\"mi\">5</span><span class=\"bp\">..</span><span class=\"mi\">15</span><span class=\"bp\">..</span><span class=\"mi\">31</span><span class=\"bp\">..</span><span class=\"mi\">48</span><span class=\"bp\">..</span><span class=\"mi\">75</span><span class=\"bp\">..</span><span class=\"n\">solved</span> <span class=\"n\">at</span> <span class=\"mi\">90</span>\n</code></pre></div>\n<p>With <code>set_option profiler true</code> in Lean, I get various total timings for each theorem, but not line-by-line timings.</p>",
        "id": 384401322,
        "sender_full_name": "D. J. Bernstein",
        "timestamp": 1691904521
    },
    {
        "content": "<p>here's a goppa-free MWE, still not mathlib-minimized:</p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"kn\">import</span> <span class=\"n\">Mathlib.RingTheory.Polynomial.Basic</span>\n<span class=\"kn\">open</span> <span class=\"n\">Polynomial</span> <span class=\"n\">BigOperators</span> <span class=\"n\">Finset</span>\n\n<span class=\"kd\">variable</span> <span class=\"o\">{</span><span class=\"n\">U</span><span class=\"o\">:</span> <span class=\"kt\">Type</span> <span class=\"n\">u</span><span class=\"o\">}</span> <span class=\"o\">[</span><span class=\"n\">DecidableEq</span> <span class=\"n\">U</span><span class=\"o\">]</span> <span class=\"o\">{</span><span class=\"n\">k</span><span class=\"o\">:</span> <span class=\"kt\">Type</span> <span class=\"n\">v</span><span class=\"o\">}</span> <span class=\"o\">[</span><span class=\"n\">Field</span> <span class=\"n\">k</span><span class=\"o\">]</span>\n<span class=\"kd\">variable</span> <span class=\"o\">{</span><span class=\"n\">α</span> <span class=\"n\">r</span> <span class=\"n\">d</span><span class=\"o\">:</span> <span class=\"n\">U</span> <span class=\"bp\">→</span> <span class=\"n\">k</span><span class=\"o\">}</span> <span class=\"o\">{</span><span class=\"n\">S</span><span class=\"o\">:</span> <span class=\"n\">Finset</span> <span class=\"n\">U</span><span class=\"o\">}</span> <span class=\"o\">{</span><span class=\"n\">g</span><span class=\"o\">:</span> <span class=\"n\">k</span><span class=\"o\">[</span><span class=\"n\">X</span><span class=\"o\">]}</span> <span class=\"o\">{</span><span class=\"n\">t</span><span class=\"o\">:</span> <span class=\"n\">ℕ</span><span class=\"o\">}</span>\n\n<span class=\"n\">count_heartbeats</span> <span class=\"k\">in</span> <span class=\"c1\">-- Used 7057 heartbeats</span>\n<span class=\"kd\">theorem</span> <span class=\"n\">goppa_checking_2_lemma_hbsum6_fast</span> <span class=\"o\">:</span> <span class=\"n\">True</span> <span class=\"o\">:=</span> <span class=\"kd\">by</span>\n  <span class=\"k\">have</span> <span class=\"o\">:</span>\n    <span class=\"o\">(</span><span class=\"bp\">∑</span> <span class=\"n\">s</span> <span class=\"k\">in</span> <span class=\"n\">S</span><span class=\"o\">,</span> <span class=\"bp\">∑</span> <span class=\"n\">j</span> <span class=\"k\">in</span> <span class=\"n\">range</span> <span class=\"o\">(</span><span class=\"mi\">2</span><span class=\"bp\">*</span><span class=\"n\">t</span><span class=\"o\">),</span> <span class=\"n\">C</span> <span class=\"o\">((</span><span class=\"n\">r</span> <span class=\"n\">s</span> <span class=\"bp\">/</span> <span class=\"o\">(</span><span class=\"n\">g</span><span class=\"bp\">^</span><span class=\"mi\">2</span><span class=\"o\">:</span><span class=\"n\">k</span><span class=\"o\">[</span><span class=\"n\">X</span><span class=\"o\">])</span><span class=\"bp\">.</span><span class=\"n\">eval</span> <span class=\"o\">(</span><span class=\"n\">α</span> <span class=\"n\">s</span><span class=\"o\">))</span> <span class=\"bp\">*</span> <span class=\"o\">(</span><span class=\"n\">d</span> <span class=\"n\">s</span><span class=\"o\">)</span><span class=\"bp\">^</span><span class=\"n\">j</span><span class=\"o\">)</span> <span class=\"bp\">*</span> <span class=\"o\">(</span><span class=\"n\">X</span><span class=\"o\">:</span><span class=\"n\">k</span><span class=\"o\">[</span><span class=\"n\">X</span><span class=\"o\">])</span><span class=\"bp\">^</span><span class=\"o\">(</span><span class=\"mi\">2</span><span class=\"bp\">*</span><span class=\"n\">t</span><span class=\"bp\">-</span><span class=\"mi\">1</span><span class=\"bp\">-</span><span class=\"n\">j</span><span class=\"o\">:</span><span class=\"n\">ℕ</span><span class=\"o\">))</span> <span class=\"bp\">=</span>\n    <span class=\"o\">(</span><span class=\"bp\">∑</span> <span class=\"n\">s</span> <span class=\"k\">in</span> <span class=\"n\">S</span><span class=\"o\">,</span> <span class=\"bp\">∑</span> <span class=\"n\">j</span> <span class=\"k\">in</span> <span class=\"n\">range</span> <span class=\"o\">(</span><span class=\"mi\">2</span><span class=\"bp\">*</span><span class=\"n\">t</span><span class=\"o\">),</span> <span class=\"n\">C</span> <span class=\"o\">((</span><span class=\"n\">r</span> <span class=\"n\">s</span> <span class=\"bp\">/</span> <span class=\"o\">(</span><span class=\"n\">g</span><span class=\"bp\">^</span><span class=\"mi\">2</span><span class=\"o\">:</span><span class=\"n\">k</span><span class=\"o\">[</span><span class=\"n\">X</span><span class=\"o\">])</span><span class=\"bp\">.</span><span class=\"n\">eval</span> <span class=\"o\">(</span><span class=\"n\">α</span> <span class=\"n\">s</span><span class=\"o\">))</span> <span class=\"bp\">*</span> <span class=\"o\">(</span><span class=\"n\">d</span> <span class=\"n\">s</span><span class=\"o\">)</span><span class=\"bp\">^</span><span class=\"n\">j</span><span class=\"o\">)</span> <span class=\"bp\">*</span> <span class=\"o\">(</span><span class=\"n\">X</span><span class=\"o\">:</span><span class=\"n\">k</span><span class=\"o\">[</span><span class=\"n\">X</span><span class=\"o\">])</span><span class=\"bp\">^</span><span class=\"o\">(</span><span class=\"mi\">2</span><span class=\"bp\">*</span><span class=\"n\">t</span><span class=\"bp\">-</span><span class=\"mi\">1</span><span class=\"bp\">-</span><span class=\"n\">j</span><span class=\"o\">:</span><span class=\"n\">ℕ</span><span class=\"o\">))</span> <span class=\"o\">:=</span> <span class=\"n\">rfl</span>\n  <span class=\"n\">trivial</span>\n\n<span class=\"kd\">set_option</span> <span class=\"n\">maxHeartbeats</span> <span class=\"mi\">10000000</span>\n<span class=\"n\">count_heartbeats</span> <span class=\"k\">in</span> <span class=\"c1\">-- Used 1606622 heartbeats</span>\n<span class=\"kd\">theorem</span> <span class=\"n\">goppa_checking_2_lemma_hbsum6_slow</span> <span class=\"o\">:</span> <span class=\"n\">True</span> <span class=\"o\">:=</span> <span class=\"kd\">by</span>\n  <span class=\"k\">have</span> <span class=\"o\">:</span>\n    <span class=\"o\">(</span><span class=\"bp\">∑</span> <span class=\"n\">s</span> <span class=\"k\">in</span> <span class=\"n\">S</span><span class=\"o\">,</span> <span class=\"bp\">∑</span> <span class=\"n\">j</span> <span class=\"k\">in</span> <span class=\"n\">range</span> <span class=\"o\">(</span><span class=\"mi\">2</span><span class=\"bp\">*</span><span class=\"n\">t</span><span class=\"o\">),</span> <span class=\"n\">C</span> <span class=\"o\">((</span><span class=\"n\">r</span> <span class=\"n\">s</span> <span class=\"bp\">/</span> <span class=\"o\">(</span><span class=\"n\">g</span><span class=\"bp\">^</span><span class=\"mi\">2</span><span class=\"o\">)</span><span class=\"bp\">.</span><span class=\"n\">eval</span> <span class=\"o\">(</span><span class=\"n\">α</span> <span class=\"n\">s</span><span class=\"o\">))</span> <span class=\"bp\">*</span> <span class=\"o\">(</span><span class=\"n\">d</span> <span class=\"n\">s</span><span class=\"o\">)</span><span class=\"bp\">^</span><span class=\"n\">j</span><span class=\"o\">)</span> <span class=\"bp\">*</span> <span class=\"o\">(</span><span class=\"n\">X</span><span class=\"o\">:</span><span class=\"n\">k</span><span class=\"o\">[</span><span class=\"n\">X</span><span class=\"o\">])</span><span class=\"bp\">^</span><span class=\"o\">(</span><span class=\"mi\">2</span><span class=\"bp\">*</span><span class=\"n\">t</span><span class=\"bp\">-</span><span class=\"mi\">1</span><span class=\"bp\">-</span><span class=\"n\">j</span><span class=\"o\">:</span><span class=\"n\">ℕ</span><span class=\"o\">))</span> <span class=\"bp\">=</span>\n    <span class=\"o\">(</span><span class=\"bp\">∑</span> <span class=\"n\">s</span> <span class=\"k\">in</span> <span class=\"n\">S</span><span class=\"o\">,</span> <span class=\"bp\">∑</span> <span class=\"n\">j</span> <span class=\"k\">in</span> <span class=\"n\">range</span> <span class=\"o\">(</span><span class=\"mi\">2</span><span class=\"bp\">*</span><span class=\"n\">t</span><span class=\"o\">),</span> <span class=\"n\">C</span> <span class=\"o\">((</span><span class=\"n\">r</span> <span class=\"n\">s</span> <span class=\"bp\">/</span> <span class=\"o\">(</span><span class=\"n\">g</span><span class=\"bp\">^</span><span class=\"mi\">2</span><span class=\"o\">)</span><span class=\"bp\">.</span><span class=\"n\">eval</span> <span class=\"o\">(</span><span class=\"n\">α</span> <span class=\"n\">s</span><span class=\"o\">))</span> <span class=\"bp\">*</span> <span class=\"o\">(</span><span class=\"n\">d</span> <span class=\"n\">s</span><span class=\"o\">)</span><span class=\"bp\">^</span><span class=\"n\">j</span><span class=\"o\">)</span> <span class=\"bp\">*</span> <span class=\"o\">(</span><span class=\"n\">X</span><span class=\"o\">:</span><span class=\"n\">k</span><span class=\"o\">[</span><span class=\"n\">X</span><span class=\"o\">])</span><span class=\"bp\">^</span><span class=\"o\">(</span><span class=\"mi\">2</span><span class=\"bp\">*</span><span class=\"n\">t</span><span class=\"bp\">-</span><span class=\"mi\">1</span><span class=\"bp\">-</span><span class=\"n\">j</span><span class=\"o\">:</span><span class=\"n\">ℕ</span><span class=\"o\">))</span> <span class=\"o\">:=</span> <span class=\"n\">rfl</span>\n  <span class=\"n\">trivial</span>\n</code></pre></div>\n<p>I know that our polynomial library has some known / recurring performance issues - <span class=\"user-mention\" data-user-id=\"110038\">@Kevin Buzzard</span> does this look familiar?</p>",
        "id": 384401336,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1691904529
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"630204\">@D. J. Bernstein</span> Heavy tactics do have this kind of logging as well, and they will show up in the profiler. It's just that we have fewer of them; the lack of a <code>METIS_TAC</code>/ <code>qed</code> equivalent is a long standing open problem for mathlib</p>",
        "id": 384401605,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1691904721
    },
    {
        "content": "<p>minimized some more:</p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"kn\">import</span> <span class=\"n\">Mathlib.RingTheory.Polynomial.Basic</span>\n<span class=\"kn\">open</span> <span class=\"n\">Polynomial</span> <span class=\"n\">BigOperators</span> <span class=\"n\">Finset</span>\n\n<span class=\"kd\">variable</span> <span class=\"o\">{</span><span class=\"n\">k</span><span class=\"o\">:</span> <span class=\"kt\">Type</span> <span class=\"n\">v</span><span class=\"o\">}</span> <span class=\"o\">[</span><span class=\"n\">Field</span> <span class=\"n\">k</span><span class=\"o\">]</span> <span class=\"o\">{</span><span class=\"n\">α</span><span class=\"o\">:</span> <span class=\"n\">k</span><span class=\"o\">}</span> <span class=\"o\">{</span><span class=\"n\">S</span><span class=\"o\">:</span> <span class=\"n\">Finset</span> <span class=\"n\">ℕ</span><span class=\"o\">}</span> <span class=\"o\">{</span><span class=\"n\">g</span><span class=\"o\">:</span> <span class=\"n\">k</span><span class=\"o\">[</span><span class=\"n\">X</span><span class=\"o\">]}</span>\n\n<span class=\"n\">count_heartbeats</span> <span class=\"k\">in</span> <span class=\"c1\">-- Used 6637 heartbeats</span>\n<span class=\"kd\">theorem</span> <span class=\"n\">goppa_checking_2_lemma_hbsum6_fast</span> <span class=\"o\">:</span> <span class=\"n\">True</span> <span class=\"o\">:=</span> <span class=\"kd\">by</span>\n  <span class=\"k\">have</span> <span class=\"o\">:</span>\n    <span class=\"o\">(</span><span class=\"bp\">∑</span> <span class=\"n\">_s</span> <span class=\"k\">in</span> <span class=\"n\">S</span><span class=\"o\">,</span> <span class=\"bp\">∑</span> <span class=\"n\">_s</span> <span class=\"k\">in</span> <span class=\"n\">S</span><span class=\"o\">,</span> <span class=\"n\">C</span> <span class=\"o\">(</span><span class=\"mi\">1</span> <span class=\"bp\">*</span> <span class=\"o\">(</span><span class=\"n\">g</span><span class=\"bp\">^</span><span class=\"mi\">2</span><span class=\"o\">:</span><span class=\"n\">k</span><span class=\"o\">[</span><span class=\"n\">X</span><span class=\"o\">])</span><span class=\"bp\">.</span><span class=\"n\">eval</span> <span class=\"n\">α</span> <span class=\"bp\">*</span> <span class=\"mi\">1</span><span class=\"o\">))</span> <span class=\"bp\">=</span>\n    <span class=\"o\">(</span><span class=\"bp\">∑</span> <span class=\"n\">_s</span> <span class=\"k\">in</span> <span class=\"n\">S</span><span class=\"o\">,</span> <span class=\"bp\">∑</span> <span class=\"n\">_s</span> <span class=\"k\">in</span> <span class=\"n\">S</span><span class=\"o\">,</span> <span class=\"n\">C</span> <span class=\"o\">(</span><span class=\"mi\">1</span> <span class=\"bp\">*</span> <span class=\"o\">(</span><span class=\"n\">g</span><span class=\"bp\">^</span><span class=\"mi\">2</span><span class=\"o\">:</span><span class=\"n\">k</span><span class=\"o\">[</span><span class=\"n\">X</span><span class=\"o\">])</span><span class=\"bp\">.</span><span class=\"n\">eval</span> <span class=\"n\">α</span> <span class=\"bp\">*</span> <span class=\"mi\">1</span><span class=\"o\">))</span> <span class=\"o\">:=</span> <span class=\"n\">rfl</span>\n  <span class=\"n\">trivial</span>\n\n<span class=\"kd\">set_option</span> <span class=\"n\">maxHeartbeats</span> <span class=\"mi\">2000000</span>\n<span class=\"n\">count_heartbeats</span> <span class=\"k\">in</span> <span class=\"c1\">-- Used 1076105 heartbeats</span>\n<span class=\"kd\">theorem</span> <span class=\"n\">goppa_checking_2_lemma_hbsum6_slow</span> <span class=\"o\">:</span> <span class=\"n\">True</span> <span class=\"o\">:=</span> <span class=\"kd\">by</span>\n  <span class=\"k\">have</span> <span class=\"o\">:</span>\n    <span class=\"o\">(</span><span class=\"bp\">∑</span> <span class=\"n\">_s</span> <span class=\"k\">in</span> <span class=\"n\">S</span><span class=\"o\">,</span> <span class=\"bp\">∑</span> <span class=\"n\">_s</span> <span class=\"k\">in</span> <span class=\"n\">S</span><span class=\"o\">,</span> <span class=\"n\">C</span> <span class=\"o\">(</span><span class=\"mi\">1</span> <span class=\"bp\">*</span> <span class=\"o\">(</span><span class=\"n\">g</span><span class=\"bp\">^</span><span class=\"mi\">2</span><span class=\"o\">)</span><span class=\"bp\">.</span><span class=\"n\">eval</span> <span class=\"n\">α</span> <span class=\"bp\">*</span> <span class=\"mi\">1</span><span class=\"o\">))</span> <span class=\"bp\">=</span>\n    <span class=\"o\">(</span><span class=\"bp\">∑</span> <span class=\"n\">_s</span> <span class=\"k\">in</span> <span class=\"n\">S</span><span class=\"o\">,</span> <span class=\"bp\">∑</span> <span class=\"n\">_s</span> <span class=\"k\">in</span> <span class=\"n\">S</span><span class=\"o\">,</span> <span class=\"n\">C</span> <span class=\"o\">(</span><span class=\"mi\">1</span> <span class=\"bp\">*</span> <span class=\"o\">(</span><span class=\"n\">g</span><span class=\"bp\">^</span><span class=\"mi\">2</span><span class=\"o\">)</span><span class=\"bp\">.</span><span class=\"n\">eval</span> <span class=\"n\">α</span> <span class=\"bp\">*</span> <span class=\"mi\">1</span><span class=\"o\">))</span> <span class=\"o\">:=</span> <span class=\"n\">rfl</span>\n  <span class=\"n\">trivial</span>\n</code></pre></div>",
        "id": 384403314,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1691905851
    },
    {
        "content": "<p>Hm, using <code>g*2</code> instead of <code>g^2</code> is fast, as is <code>HPow.hPow g 2</code> instead of <code>g^2</code>. So I think this is pointing a finger at the erroneous usage of <code>binop%</code> for the power function, cc: <span class=\"user-mention\" data-user-id=\"306601\">@Kyle Miller</span></p>",
        "id": 384403564,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1691906010
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110049\">Mario Carneiro</span> <a href=\"#narrow/stream/113488-general/topic/djb's.20formalization.20of.20McEliece/near/384401605\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"630204\">D. J. Bernstein</span> Heavy tactics do have this kind of logging as well, and they will show up in the profiler. It's just that we have fewer of them; the lack of a <code>METIS_TAC</code>/ <code>qed</code> equivalent is a long standing open problem for mathlib</p>\n</blockquote>\n<p>I'm actually using MESON rather than METIS. Either way, from a user perspective it's super-convenient to be able to just list all the relevant lemmas and have the computer figure out the logic of putting them together. The computation is very fast in most of the cases where simpler tactics would work. Of course there are also situations better handled by <code>rw</code> or <code>simp</code> or Lean's <code>aesop</code>, but most of the lightgoppa proof steps are model elimination.</p>",
        "id": 384403740,
        "sender_full_name": "D. J. Bernstein",
        "timestamp": 1691906121
    },
    {
        "content": "<p>The WIP tactic for this in lean is <a href=\"https://github.com/leanprover-community/duper\"><code>duper</code></a>, but in a recent discussion with <span class=\"user-mention\" data-user-id=\"110865\">@Jeremy Avigad</span> it came up that we don't have too many example uses and the authors are having difficulty determining what sort of things need to be supported, so if you could give some examples that would be very helpful.</p>",
        "id": 384404002,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1691906283
    },
    {
        "content": "<p>Again, every <code>have</code> step in the lightgoppa proofs is model elimination!</p>",
        "id": 384404118,
        "sender_full_name": "D. J. Bernstein",
        "timestamp": 1691906363
    },
    {
        "content": "<p>yes, but HOL light uses a different proof style which is more statement-centric. Maybe you could mock up what you would want to write in the lean proof such that model elimination plays a bigger role?</p>",
        "id": 384404245,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1691906408
    },
    {
        "content": "<p>Actually, I'm not sure I know what you mean by \"model elimination\". This is an SMT solver, is it not?</p>",
        "id": 384404498,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1691906531
    },
    {
        "content": "<p><a href=\"https://www.cl.cam.ac.uk/~jrh13/atp/OCaml/meson.ml\">https://www.cl.cam.ac.uk/~jrh13/atp/OCaml/meson.ml</a> is a MESON introduction.</p>",
        "id": 384404677,
        "sender_full_name": "D. J. Bernstein",
        "timestamp": 1691906648
    },
    {
        "content": "<p>I'm not sure what you mean by \"statement-centric\". Pretty much every <code>exact</code> and <code>apply</code> step in leangoppa is something that I would rather have expressed with model elimination.</p>",
        "id": 384404801,
        "sender_full_name": "D. J. Bernstein",
        "timestamp": 1691906720
    },
    {
        "content": "<p>I see very few <code>exact</code> and <code>apply</code> in e.g. <code>goppa_closer</code>, you seem to like calc proofs a lot</p>",
        "id": 384404924,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1691906784
    },
    {
        "content": "<p>Obviously <code>by exact</code> is eliminated so you need to do more than <code>grep</code> to see what's going on. Beyond the <code>exact</code> and <code>apply</code> steps, many of the sequences of rewriting tactics would have been handled just as easily by model elimination. Yes, I tend to use declarative proofs, and <code>calc</code> is a win for that.</p>",
        "id": 384406006,
        "sender_full_name": "D. J. Bernstein",
        "timestamp": 1691907395
    },
    {
        "content": "<p>On second thought, <code>grep</code> used as follows gives some idea of what's going on, namely 361 lines of output: <code>grep ':= .' Goppadecoding/*.lean | grep -v ':= by'</code></p>\n<p>The fact that <code>exact?</code> can find these is also what makes model elimination work instantly for them. The big advantage of model elimination is that it can handle multiple steps at once. The model-elimination user supplies the list of lemmas but doesn't have to bother spelling out the connecting logic or which hypotheses to plug in.</p>",
        "id": 384408369,
        "sender_full_name": "D. J. Bernstein",
        "timestamp": 1691908540
    },
    {
        "content": "<p>Mathlib's closest approximation to this is <code>solve_by_elim</code>. <code>exact?</code> is just trying out every relevant library lemma, and then calling <code>solve_by_elim</code> to discharge the subgoals. You can call <code>solve_by_elim [X, Y, Z]</code> manually to give it extra lemmas, or <code>have := X</code> ahead of an an <code>exact?</code> to allow the library search step to use <code>X</code> in tackling subgoals.</p>",
        "id": 384409281,
        "sender_full_name": "Scott Morrison",
        "timestamp": 1691909043
    },
    {
        "content": "<p>I'll give that a try, thanks.</p>",
        "id": 384411057,
        "sender_full_name": "D. J. Bernstein",
        "timestamp": 1691909980
    },
    {
        "content": "<p>Passing along some comments from John Harrison on MESON:</p>\n<blockquote>\n<p>I originally implemented it precisely to act in the way you are<br>\nusing it, plugging together other theorems in straightforward<br>\nbut mildly fiddly ways in support of a more declarative style of<br>\nproof. See the little paragraph \"a model elimination prover\" on<br>\np13 here:</p>\n<p><a href=\"https://www.cl.cam.ac.uk/~jrh13/papers/mizar_times.pdf\">https://www.cl.cam.ac.uk/~jrh13/papers/mizar_times.pdf</a></p>\n<p>The underlying model elimination idea was invented by Loveland in<br>\nthe context of linear resolution, and recast by Stickel, Plaisted<br>\nand others into a form that is a fairly small tweak to Prolog-type<br>\nbackchaining while still being complete for first-order logic<br>\n(which Prolog is not, even if you do complete search instead of<br>\ndepth-first). Of course, my associated book \"Handbook of Practical<br>\nLogic and Automated Reasoning\" explains the code you pointed to in<br>\nmore detail, while this is the sub-reference [18] from that paragraph<br>\nabove talks about the implementation details:</p>\n<p><a href=\"https://www.cl.cam.ac.uk/~jrh13/papers/me.pdf\">https://www.cl.cam.ac.uk/~jrh13/papers/me.pdf</a></p>\n<p>It doesn't discuss proof generation in HOL Light, but as usual<br>\nwith these search-dominated procedures that's fairly trivial/obvious.<br>\nI'm sure Mario could produce a Lean version in a long weekend ;-)</p>\n</blockquote>",
        "id": 384732498,
        "sender_full_name": "D. J. Bernstein",
        "timestamp": 1692010562
    },
    {
        "content": "<blockquote>\n<p>I'm sure Mario could produce a Lean version in a long weekend ;-)</p>\n</blockquote>\n<p>heh, I've already started</p>",
        "id": 384915948,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1692049603
    },
    {
        "content": "<p><a href=\"https://cr.yp.to/papers.html#goppadecoding\">https://cr.yp.to/papers.html#goppadecoding</a> now compares its informal theorem statements to formalizations in Lean (and in HOL Light), and includes a partial review of the underlying definitions. This isn't about the formalization process beyond the outputs; I'm planning a separate writeup of observations regarding the process.</p>",
        "id": 385968454,
        "sender_full_name": "D. J. Bernstein",
        "timestamp": 1692383728
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"630204\">D. J. Bernstein</span> <a href=\"#narrow/stream/113488-general/topic/djb's.20formalization.20of.20McEliece/near/385968454\">said</a>:</p>\n<blockquote>\n<p>now compares its informal theorem statements to formalizations in Lean (and in HOL Light)</p>\n</blockquote>\n<p>The format for this is really excellent, left and right columns with corresponding code and math! Very helpful!</p>",
        "id": 385985660,
        "sender_full_name": "Oisin McGuinness",
        "timestamp": 1692391057
    },
    {
        "content": "<p>I had a quick look at the paper and I have one important remark: it seems you systematically use the word Lean when you want to write Mathlib. A typical sentence doing that is \"Lean defines an equivalent function under the name <code>monomial</code>\". In fact it seems the word Mathlib does not appear in the paper. I only read very superficially so I cannot say whether this is crucial anywhere. But it could be, especially since you write for computer scientists that could be interested in constructive math or computability (which are almost totally ignored by Mathlib but fully supported by the Lean kernel).</p>",
        "id": 386166421,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1692494094
    },
    {
        "content": "<p>You also have strange sentences about what polynomials are in mathematics such as \"Mathematically, multivariate polynomials over a ring r are functions from exponent vectors to r satisfying certain finiteness conditions.\" and \"Presumably what will be best in the long run is a formalized version of what appears in the mathematical literature: a simple definition of univariate polynomial rings, a more complicated definition of multivariate polynomial rings, and theorems regarding the relationship between the definitions.\". This may match the way you were taught polynomials, but this is far from being universal. You would have a hard time matching these sentences to how Bourbaki defines polynomials for instance.</p>",
        "id": 386167042,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1692494308
    },
    {
        "content": "<p>Note these are comments and improvement suggestions that may sound like criticisms but this isn't my goal. And overall this paper looks very interesting to me (although I don't see why you would care about this information).</p>",
        "id": 386167331,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1692494424
    },
    {
        "content": "<p>From page 47:</p>\n<blockquote>\n<p>Lean also provides natDegree producing results in N, in particular mapping<br>\n0 to 0.</p>\n</blockquote>\n<p>I assume this should read \"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mo>−</mo><mi mathvariant=\"normal\">∞</mi></mrow><annotation encoding=\"application/x-tex\">-\\infty</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6667em;vertical-align:-0.0833em;\"></span><span class=\"mord\">−</span><span class=\"mord\">∞</span></span></span></span> to 0\"</p>",
        "id": 386200191,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1692520658
    },
    {
        "content": "<p>no, I think it means mapping the zero polynomial to natDegree 0</p>",
        "id": 386203010,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1692522877
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110031\">Patrick Massot</span> <a href=\"#narrow/stream/113488-general/topic/djb's.20formalization.20of.20McEliece/near/386166421\">said</a>:</p>\n<blockquote>\n<p>I had a quick look at the paper and I have one important remark: it seems you systematically use the word Lean when you want to write Mathlib. A typical sentence doing that is \"Lean defines an equivalent function under the name <code>monomial</code>\". In fact it seems the word Mathlib does not appear in the paper. I only read very superficially so I cannot say whether this is crucial anywhere. But it could be, especially since you write for computer scientists that could be interested in constructive math or computability (which are almost totally ignored by Mathlib but fully supported by the Lean kernel).</p>\n</blockquote>\n<p>Thanks for the comment. Given that <a href=\"https://leanprover-community.github.io/\">https://leanprover-community.github.io/</a> describes mathlib as \"the Lean mathematical library\", I think it's appropriate to attribute mathlib's definitions to Lean. There are a few cases where the internal structure of proof assistants is relevant to the text, and for those cases I'm using assistant-independent terminology such as \"kernel\"; I'm trying to avoid flooding the reader with assistant-specific terminology.</p>",
        "id": 386204892,
        "sender_full_name": "D. J. Bernstein",
        "timestamp": 1692524429
    },
    {
        "content": "<p>I agree with Patrick that this is wrong. Lean is a programming language that happens to be excellent for doing formalised mathematics. Mathlib is by a large margin the largest mathematical library written in Lean, and hence may be called \"the Lean mathematical library\". Moreover Lean the language is both informed by the needs of Mathlib, and wants to support it.</p>\n<p>But Mathlib is not Lean, nor a part of Lean, and I think just basic academic standards of attribution argue against \"it is appropriate to attribute mathlib's definitions to Lean\".</p>",
        "id": 386207548,
        "sender_full_name": "Scott Morrison",
        "timestamp": 1692526345
    },
    {
        "content": "<p>Note that the group of people that develop Lean 4 and the group of people that develop Mathlib 4 does only have a very small intersection so most things that are done in Mathlib 4 happen without influence by the Lean 4 developers.</p>",
        "id": 386208005,
        "sender_full_name": "Henrik Böving",
        "timestamp": 1692526738
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"630204\">@D. J. Bernstein</span> the reason that it was feasible to do your project in lean is because of mathlib. Note that the lean 4 repo is owned by GitHub user <code>leanprover</code>which is AFAIK Leo or Microsoft or whatever, but the mathlib is owned by <code>leanprover-community</code>, which is a community-led project consisting of the people you see here who answer your questions for free and are building an amazing product.</p>",
        "id": 386209464,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1692527989
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110031\">Patrick Massot</span> <a href=\"#narrow/stream/113488-general/topic/djb's.20formalization.20of.20McEliece/near/386167042\">said</a>:</p>\n<blockquote>\n<p>You also have strange sentences about what polynomials are in mathematics such as \"Mathematically, multivariate polynomials over a ring r are functions from exponent vectors to r satisfying certain finiteness conditions.\" and \"Presumably what will be best in the long run is a formalized version of what appears in the mathematical literature: a simple definition of univariate polynomial rings, a more complicated definition of multivariate polynomial rings, and theorems regarding the relationship between the definitions.\". This may match the way you were taught polynomials, but this is far from being universal. You would have a hard time matching these sentences to how Bourbaki defines polynomials for instance.</p>\n</blockquote>\n<p>Um, have you actually read Bourbaki's definition?</p>\n<p>The polynomial A-algebra on I is defined at the beginning of Algebra 4 as the free commutative A-algebra on I. That's defined on page 448 of (the English translation of) Algebra 1-3 as the A-algebra of the free commutative monoid on I. The free commutative monoid on I is defined on page 92 as finitely supported vectors indexed by I with entries in \\N. The A-algebra of S is defined on page 446 as the finitely supported vectors indexed by S with entries in A.</p>\n<p>So, with the terminology unfolded, that's the finitely supported A-vectors indexed by finitely supported vectors indexed by I with entries in \\N. How exactly do you believe this isn't consistent with \"multivariate polynomials over a ring r are functions from exponent vectors to r satisfying certain finiteness conditions\"?</p>",
        "id": 386220438,
        "sender_full_name": "D. J. Bernstein",
        "timestamp": 1692536156
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110031\">Patrick Massot</span> <a href=\"#narrow/stream/113488-general/topic/djb's.20formalization.20of.20McEliece/near/386167331\">said</a>:</p>\n<blockquote>\n<p>Note these are comments and improvement suggestions that may sound like criticisms but this isn't my goal. And overall this paper looks very interesting to me (although I don't see why you would care about this information).</p>\n</blockquote>\n<p>Sorry, can you clarify which information you're referring to?</p>",
        "id": 386220542,
        "sender_full_name": "D. J. Bernstein",
        "timestamp": 1692536198
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110087\">Scott Morrison</span> <a href=\"#narrow/stream/113488-general/topic/djb's.20formalization.20of.20McEliece/near/386207548\">said</a>:</p>\n<blockquote>\n<p>But Mathlib is not Lean, nor a part of Lean</p>\n</blockquote>\n<p>Please clarify. It's okay to talk about mathlib as Lean's mathematics library and to talk about \"Lean's mathlib\", but the possession concept here isn't transitive---mathlib is Lean's mathlib, and mathlib's X is Lean's mathlib's X, but isn't Lean's X?</p>",
        "id": 386222041,
        "sender_full_name": "D. J. Bernstein",
        "timestamp": 1692537157
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110038\">Kevin Buzzard</span> <a href=\"#narrow/stream/113488-general/topic/djb's.20formalization.20of.20McEliece/near/386209464\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"630204\">D. J. Bernstein</span> the reason that it was feasible to do your project in lean is because of mathlib. Note that the lean 4 repo is owned by GitHub user <code>leanprover</code>which is AFAIK Leo or Microsoft or whatever, but the mathlib is owned by <code>leanprover-community</code>, which is a community-led project consisting of the people you see here who answer your questions for free and are building an amazing product.</p>\n</blockquote>\n<p>Poking around, I find DBLP:conf/cpp/X20, which of course I'm happy to cite.</p>",
        "id": 386223112,
        "sender_full_name": "D. J. Bernstein",
        "timestamp": 1692537900
    },
    {
        "content": "<p>Current draft: <code>See \\cite{1996/harrison} for an introduction to HOL Light, \\cite{2021/moura} for an introduction to Lean 4, and \\cite{2020/mathlib} for an introduction to the Lean math library. This appendix says ``HOL Light'' and ``Lean'' to refer to the full proof assistants available when these formalizations began, including the math libraries.</code></p>\n<p>When I'm pointing out that, e.g., Lean automatically understands <code>(0:K)^{-1} = 0</code> to have the second <code>0</code> meaning <code>0:K</code>, I think it's an active disservice to the reader to try to explain my current understanding of how this feature is decomposed between language structures and library structures. If saying \"Lean\" here triggers offense because of some sort of credit battle between the language and the library, then I would suggest adding documentation on the preferred terminology for referring to the full package.</p>",
        "id": 386224805,
        "sender_full_name": "D. J. Bernstein",
        "timestamp": 1692539092
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"630204\">D. J. Bernstein</span> <a href=\"#narrow/stream/113488-general/topic/djb's.20formalization.20of.20McEliece/near/386222041\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"110087\">Scott Morrison</span> <a href=\"#narrow/stream/113488-general/topic/djb's.20formalization.20of.20McEliece/near/386207548\">said</a>:</p>\n<blockquote>\n<p>But Mathlib is not Lean, nor a part of Lean</p>\n</blockquote>\n<p>Please clarify. It's okay to talk about mathlib as Lean's mathematics library and to talk about \"Lean's mathlib\", but the possession concept here isn't transitive---mathlib is Lean's mathlib, and mathlib's X is Lean's mathlib's X, but isn't Lean's X?</p>\n</blockquote>\n<p>Just use \"Mathlib\" where you have used \"Lean\". Mathlib can be (and should be) used as a proper noun to describe \"Lean's mathematical library\" (where \"mathematical library\" is not a proper noun); \"Lean's mathlib\" sounds a bit odd. Elsewhere, when describing properties of the library, attribute them to \"mathlib\", not \"lean\".</p>",
        "id": 386246735,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1692554792
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"630204\">D. J. Bernstein</span> <a href=\"#narrow/stream/113488-general/topic/djb's.20formalization.20of.20McEliece/near/386224805\">said</a>:</p>\n<blockquote>\n<p>When I'm pointing out that, e.g., Lean automatically understands <code>(0:K)^{-1} = 0</code> to have the second <code>0</code> meaning <code>0:K</code>, I think it's an active disservice to the reader to try to explain my current understanding of how this feature is decomposed between language structures and library structures. If saying \"Lean\" here triggers offense because of some sort of credit battle between the language and the library, then I would suggest adding documentation on the preferred terminology for referring to the full package.</p>\n</blockquote>\n<p>The preferred terminology is \"mathlib\". A natural way to rephrase your sentence is: \"Mathlib automatically understands <code>(0:K)^{-1} = 0</code> to have the second <code>0</code> meaning <code>0:K</code>\". Lean has very little to do with almost anything in this sentence, that's entirely library choices you are talking about.</p>",
        "id": 386247257,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1692555355
    },
    {
        "content": "<p>Although, you could also try personifying these systems less so that you don't need to use active voice and cause this issue</p>",
        "id": 386247345,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1692555435
    },
    {
        "content": "<p>\"In lean, the second <code>0</code> of <code>(0:K)^{-1} = 0</code> is interpreted as meaning <code>0:K</code>\" seems fine to me, but not \"Lean defines multivariate polynomials as ....\" because mathlib is the one doing the defining, not lean</p>",
        "id": 386247532,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1692555609
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110049\">Mario Carneiro</span> <a href=\"#narrow/stream/113488-general/topic/djb's.20formalization.20of.20McEliece/near/386246735\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"630204\">D. J. Bernstein</span> <a href=\"#narrow/stream/113488-general/topic/djb's.20formalization.20of.20McEliece/near/386222041\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"110087\">Scott Morrison</span> <a href=\"#narrow/stream/113488-general/topic/djb's.20formalization.20of.20McEliece/near/386207548\">said</a>:</p>\n<blockquote>\n<p>But Mathlib is not Lean, nor a part of Lean</p>\n</blockquote>\n<p>Please clarify. It's okay to talk about mathlib as Lean's mathematics library and to talk about \"Lean's mathlib\", but the possession concept here isn't transitive---mathlib is Lean's mathlib, and mathlib's X is Lean's mathlib's X, but isn't Lean's X?</p>\n</blockquote>\n<p>Just use \"Mathlib\" where you have used \"Lean\". Mathlib can be (and should be) used as a proper noun to describe \"Lean's mathematical library\" (where \"mathematical library\" is not a proper noun); \"Lean's mathlib\" sounds a bit odd. Elsewhere, when describing properties of the library, attribute them to \"mathlib\", not \"lean\".</p>\n</blockquote>\n<p>I appreciate the suggestions, but I'm also really confused at this point, given, e.g., that <a href=\"https://arxiv.org/abs/2108.10700\">https://arxiv.org/abs/2108.10700</a> says \"Lean's mathlib\" in its title, and that <a href=\"https://xenaproject.wordpress.com\">https://xenaproject.wordpress.com</a> is continually saying things like \"Lean for the curious mathematician\" with no evident backlash.</p>\n<p>If it's wrong for me to attribute definitions of (say) polynomials to Lean, then why is it okay for <a href=\"https://xenaproject.wordpress.com/what-maths-is-in-lean/\">https://xenaproject.wordpress.com/what-maths-is-in-lean/</a> to list polynomials as an answer to the question \"What maths is in Lean?\"? Sure, that was in 2019, but \"What maths is in Lean?\" is listed as one of the featured tabs on top of the page, and there doesn't seem to be an erratum anywhere saying that the terminology was wrong.</p>\n<p>Regarding the idea of just saying \"mathlib\" everywhere, I'm more than a bit skeptical that this is accurate in, e.g., <code>Here is how to run {\\tt leangoppa} in Lean.</code>; <code>In both HOL Light and Lean, the universe is partitioned into disjoint ``types''.</code>; <code>the Lean syntax often allows the map from $\\N$ to $\\Z$ to be left implicit</code>; <code>Lean automatically using the desired function</code>; etc.</p>\n<p>More generally, the text is describing user-visible features of the language-plus-library bundle that I was using. I'm going to use one name for that bundle, and I'm not going to allow the text to be sidetracked into irrelevant internal details (even on the occasions where I'm pretty sure I know those details). If \"Lean\" causes confusion as a name for the bundle then it's hard to imagine that the opposite extreme of \"mathlib\" fixes the problem. How about \"LUM\", for \"Lean union mathlib\"?</p>",
        "id": 386251159,
        "sender_full_name": "D. J. Bernstein",
        "timestamp": 1692558933
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110087\">Scott Morrison</span> <a href=\"#narrow/stream/113488-general/topic/djb's.20formalization.20of.20McEliece/near/386207548\">said</a>:</p>\n<blockquote>\n<p>I think just basic academic standards of attribution argue against \"it is appropriate to attribute mathlib's definitions to Lean\".</p>\n</blockquote>\n<p>To make sure I understand, you're saying the title \"What maths is in Lean?\" of <a href=\"https://xenaproject.wordpress.com/what-maths-is-in-lean/\">https://xenaproject.wordpress.com/what-maths-is-in-lean/</a> is violating \"basic academic standards of attribution\" by saying that algebra etc. are \"in Lean\"?</p>",
        "id": 386251832,
        "sender_full_name": "D. J. Bernstein",
        "timestamp": 1692559537
    },
    {
        "content": "<p>I think that title should be read as \"what maths has been written in Lean\", not \"what maths does Lean provide\"</p>",
        "id": 386252122,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1692559852
    },
    {
        "content": "<p>\"Lean for the curious mathematician\" is also a \"brand name\" of a sort, it is the title of a conference that has been held for several years.</p>",
        "id": 386253450,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1692561100
    },
    {
        "content": "<blockquote>\n<p>Regarding the idea of just saying \"mathlib\" everywhere, I'm more than a bit skeptical that this is accurate in, e.g., <br>\n* Here is how to run {\\tt leangoppa} in Lean</p>\n</blockquote>\n<p>This is just a weird sentence to say, you can't run it in anything else, can you? You aren't running it \"in mathlib\" in any case.</p>\n<blockquote>\n<ul>\n<li>In both HOL Light and Lean, the universe is partitioned into disjoint \"types\"</li>\n</ul>\n</blockquote>\n<p>Agreed, this is a property of Lean, not mathlib.</p>\n<blockquote>\n<ul>\n<li>the Lean syntax often allows the map from $\\N$ to $\\Z$ to be left implicit</li>\n</ul>\n</blockquote>\n<p>This is also a property of lean. Certainly \"Lean syntax\" is more correct than \"mathlib syntax\" as mathlib doesn't define syntax (well it kind of does, but I would generally describe that as \"notation\" rather than \"syntax\")</p>\n<blockquote>\n<ul>\n<li>Lean automatically using the desired function</li>\n</ul>\n</blockquote>\n<p>This one is borderline, but I would probably prefer to use \"lean\" here.</p>\n<p>The fact is that there are things that lean does and things that mathlib does, and you should try to attribute things correctly because they are different entities. I realize this might be challenging, but similar situations do exist in most other theorem provers as well. HOL light bundles its library with the language, but if for example you were writing about a project that depends on the Flyspeck formalization, you should differentiate between definitions that came from the Flyspeck part and things that came from the base library. Same thing with AFP vs Isabelle/HOL vs Isabelle/Pure, or metamath vs <a href=\"http://set.mm\">set.mm</a>, or Mizar vs MML, or the Coq standard library vs mathcomp.</p>",
        "id": 386254668,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1692561855
    },
    {
        "content": "<p>It's true that you shouldn't attribute everything to mathlib, nor everything to lean. If you can't be bothered to differentiate you could use Lean/mathlib, but generally that seems like lazy writing and in each individual instance you should use the right one. It's mostly not too hard since when talking about language behaviors it's lean and when talking about definitions and library objects (especially when commenting on the form of definitions and how easy/difficult they are to work with) it's mathlib you are talking about.</p>",
        "id": 386255604,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1692562475
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110049\">Mario Carneiro</span> <a href=\"#narrow/stream/113488-general/topic/djb's.20formalization.20of.20McEliece/near/386254668\">said</a>:</p>\n<blockquote>\n<p>The fact is that there are things that lean does and things that mathlib does, and you should try to attribute things correctly because they are different entities.</p>\n</blockquote>\n<p>There are also things that various compiler layers do, things that the OS does, things that the CPU does, things that the RAM does, etc. Those are different entities. Ergo, anyone writing about Lean should separately attribute those things? Does one mention of AMD and zero mentions of the RAM manufacturer really do justice to their critical contributions here?</p>\n<p>I also don't understand why you think it's incorrect to attribute behavior to the unified system, when the observed and easily reproducible and relevant facts are that the unified system is behaving as described. Referring to verifiability as laziness doesn't help your case.</p>\n<p>Regarding terminology for the unified system, I've now reviewed enough material to be sure that I made the correct choice for this paper. If I see consistent, stable, documented renaming of \"Lean for the curious mathematician\", \"What maths is in Lean\", \"Learning Lean\", etc., I'll be happy to adjust my future use of terminology to match. To answer your question, I've run leangoppa in some ad-hoc tools that I wrote that of course test vastly less than Lean does, whereas obviously what matters at this point in the paper is the level of assurance obtained by running it in Lean.</p>",
        "id": 386262100,
        "sender_full_name": "D. J. Bernstein",
        "timestamp": 1692567893
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"630204\">D. J. Bernstein</span> <a href=\"#narrow/stream/113488-general/topic/djb's.20formalization.20of.20McEliece/near/386220438\">said</a>:</p>\n<blockquote>\n<p>Um, have you actually read Bourbaki's definition?</p>\n<p>The polynomial A-algebra on I is defined at the beginning of Algebra 4 as the free commutative A-algebra on I. That's defined on page 448 of (the English translation of) Algebra 1-3 as the A-algebra of the free commutative monoid on I. The free commutative monoid on I is defined on page 92 as finitely supported vectors indexed by I with entries in \\N. The A-algebra of S is defined on page 446 as the finitely supported vectors indexed by S with entries in A.</p>\n<p>So, with the terminology unfolded, that's the finitely supported A-vectors indexed by finitely supported vectors indexed by I with entries in \\N. How exactly do you believe this isn't consistent with \"multivariate polynomials over a ring r are functions from exponent vectors to r satisfying certain finiteness conditions\"?</p>\n</blockquote>\n<p>Yes, I am very familiar with Bourbaki's definition. And if you unfold all constructions then you indeed get there. This is exactly why I always teach this as an example of how meaning is lost if you unfold too many definitions in math. Note I wrote that writing \"polynomials <em>are</em> ...\" is strange (rather than <em>wrong</em>). You are really insisting on implementation details here. And even unfolding definitions, I don't see \"a simple definition of univariate polynomial rings, a more complicated definition of multivariate polynomial rings, and theorems regarding the relationship between the definitions\" in there. </p>\n<p>But I don't think there is much point in continuing this specific discussion. I clearly failed to convey the tone I intended for this remark (despite my attempt in the following message). I don't want you to feel attacked, especially since this is a really very minor point. I probably shouldn't have raised it.</p>",
        "id": 386262127,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1692567932
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"630204\">D. J. Bernstein</span> <a href=\"#narrow/stream/113488-general/topic/djb's.20formalization.20of.20McEliece/near/386220542\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"110031\">Patrick Massot</span> <a href=\"#narrow/stream/113488-general/topic/djb's.20formalization.20of.20McEliece/near/386167331\">said</a>:</p>\n<blockquote>\n<p>Note these are comments and improvement suggestions that may sound like criticisms but this isn't my goal. And overall this paper looks very interesting to me (although I don't see why you would care about this information).</p>\n</blockquote>\n<p>Sorry, can you clarify which information you're referring to?</p>\n</blockquote>\n<p>The information that I think your paper looks very interesting. Probably I shouldn't have tried to write all this in English while being so tired.</p>",
        "id": 386262205,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1692568023
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"630204\">D. J. Bernstein</span> <a href=\"#narrow/stream/113488-general/topic/djb's.20formalization.20of.20McEliece/near/386251832\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"110087\">Scott Morrison</span> <a href=\"#narrow/stream/113488-general/topic/djb's.20formalization.20of.20McEliece/near/386207548\">said</a>:</p>\n<blockquote>\n<p>I think just basic academic standards of attribution argue against \"it is appropriate to attribute mathlib's definitions to Lean\".</p>\n</blockquote>\n<p>To make sure I understand, you're saying the title \"What maths is in Lean?\" of <a href=\"https://xenaproject.wordpress.com/what-maths-is-in-lean/\">https://xenaproject.wordpress.com/what-maths-is-in-lean/</a> is violating \"basic academic standards of attribution\" by saying that algebra etc. are \"in Lean\"?</p>\n</blockquote>\n<p>A post from 2019, whose first line is \"NB: A more up to date list of what is in mathlib is here on the leanprover-community website.\" seems pretty funny as evidence that everyone conflates Lean and Mathlib, and that it is a good thing to continue doing so, in my mind. <span aria-label=\"woman shrugging\" class=\"emoji emoji-1f937-200d-2640\" role=\"img\" title=\"woman shrugging\">:woman_shrugging:</span></p>",
        "id": 386265832,
        "sender_full_name": "Scott Morrison",
        "timestamp": 1692572133
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110031\">Patrick Massot</span> <a href=\"#narrow/stream/113488-general/topic/djb's.20formalization.20of.20McEliece/near/386262127\">said</a>:</p>\n<blockquote>\n<p>And even unfolding definitions, I don't see \"a simple definition of univariate polynomial rings, a more complicated definition of multivariate polynomial rings, and theorems regarding the relationship between the definitions\" in there.</p>\n</blockquote>\n<p>The text at hand correctly states that this is \"what appears in the mathematical literature\". It doesn't make absurd claims about arbitrary nonempty subsets of the literature.</p>\n<p>As for the multivariate definition, I've provided pinpoint citations trivially matching up Bourbaki's definition to the description I gave, so please withdraw the claim that \"You would have a hard time matching these sentences to how Bourbaki defines polynomials\".</p>\n<p>Given your background and your comment about \"implementation details\", I presume that what you were actually thinking of from the beginning was initial pointed rings---which, sure, _can_ be converted from a predicate into a construction via the generic universal-algebra construction of free objects, but that's _not_ how polynomial rings are defined in Bourbaki or in mainstream commutative algebra.</p>\n<p>I remember having fun teaching a commutative-algebra course 25 years ago. I started by proving that the usual finite axiomatization of a (commutative) ring implies that rings satisfy all (0,1,-,+,*) identities satisfied by \\Z, the latter statement being defined via the usual concrete definition of multivariate polynomials and proven via freeness (along with some facts about \\Z). This also shows en passant that the concrete objects are isomorphic _as pointed rings_ to the generic universal-algebra free objects. But this doesn't mean these are defining the same objects!</p>\n<p>The big advantage of the concrete definition, beyond its accessibility, is that it's directly equipped with helpful structure beyond the ring structure. Proofs in the literature are continually taking advantage of this structure, even when the objective is purely to prove a general ring statement that makes no reference to this structure. Every proof mentioning a power-series coefficient, or in particular a polynomial coefficient, is directly referring to this structure. So I would question the competence of anyone objecting to the concrete definition.</p>",
        "id": 386265994,
        "sender_full_name": "D. J. Bernstein",
        "timestamp": 1692572303
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110087\">Scott Morrison</span> <a href=\"#narrow/stream/113488-general/topic/djb's.20formalization.20of.20McEliece/near/386265832\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"630204\">D. J. Bernstein</span> <a href=\"#narrow/stream/113488-general/topic/djb's.20formalization.20of.20McEliece/near/386251832\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"110087\">Scott Morrison</span> <a href=\"#narrow/stream/113488-general/topic/djb's.20formalization.20of.20McEliece/near/386207548\">said</a>:</p>\n<blockquote>\n<p>I think just basic academic standards of attribution argue against \"it is appropriate to attribute mathlib's definitions to Lean\".</p>\n</blockquote>\n<p>To make sure I understand, you're saying the title \"What maths is in Lean?\" of <a href=\"https://xenaproject.wordpress.com/what-maths-is-in-lean/\">https://xenaproject.wordpress.com/what-maths-is-in-lean/</a> is violating \"basic academic standards of attribution\" by saying that algebra etc. are \"in Lean\"?</p>\n</blockquote>\n<p>A post from 2019, whose first line is \"NB: A more up to date list of what is in mathlib is here on the leanprover-community website.\" seems pretty funny as evidence that everyone conflates Lean and Mathlib, and that it is a good thing to continue doing so, in my mind. <span aria-label=\"woman shrugging\" class=\"emoji emoji-1f937-200d-2640\" role=\"img\" title=\"woman shrugging\">:woman_shrugging:</span></p>\n</blockquote>\n<p>Please clarify. If attributing mathlib's definitions to Lean violates \"basic academic standards of attribution\", should I conclude that the \"What maths is in Lean?\" title of this 2019 posting was violating \"basic academic standards of attribution\"? If not, why not? How about the continued highlighting of that title as a tab on the same site, as mentioned above? Needless to say, proper attribution is an ethics requirement, and claims of improper attribution should be resolved.</p>",
        "id": 386267572,
        "sender_full_name": "D. J. Bernstein",
        "timestamp": 1692573880
    },
    {
        "content": "<p>It is indeed imprecise wording at best, and would definitely be more accurately written as \"What maths is in mathlib?\". Whether this rises to the level of misconduct is questionable, but it is not an academic paper and it is also only a title, targeted at people who may not yet know the difference. There is still plenty of space to be more precise in the body text, and indeed the very first line when I click through says \"what is in mathlib\".</p>",
        "id": 386291934,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1692586163
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"630204\">D. J. Bernstein</span> <a href=\"#narrow/stream/113488-general/topic/djb's.20formalization.20of.20McEliece/near/386262100\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"110049\">Mario Carneiro</span> <a href=\"#narrow/stream/113488-general/topic/djb's.20formalization.20of.20McEliece/near/386254668\">said</a>:</p>\n<blockquote>\n<p>The fact is that there are things that lean does and things that mathlib does, and you should try to attribute things correctly because they are different entities.</p>\n</blockquote>\n<p>There are also things that various compiler layers do, things that the OS does, things that the CPU does, things that the RAM does, etc. Those are different entities. Ergo, anyone writing about Lean should separately attribute those things? Does one mention of AMD and zero mentions of the RAM manufacturer really do justice to their critical contributions here?</p>\n</blockquote>\n<p>Yes of course they should be attributed if their behavior is relevant. If a proof verifies on AMD and not on Intel then of course you should say these things. If the CPU is not relevant or you are not talking about it, then you should not.</p>\n<p>Same thing applies here. If you are talking about lean, you should use \"lean\" as the subject of the sentence, and if you are talking about mathlib then you should use \"mathlib\" as the subject of the sentence. If you are talking about the CPU then say that. This is not about acknowledging their \"critical contributions\", that's what citations are for and you've done that well enough already. This is just about using the correct subjects for sentences to identify distinct entities correctly.</p>\n<blockquote>\n<p>I also don't understand why you think it's incorrect to attribute behavior to the unified system, when the observed and easily reproducible and relevant facts are that the unified system is behaving as described. Referring to verifiability as laziness doesn't help your case.</p>\n</blockquote>\n<p>It would be incorrect to attribute the definition of multivariate polynomials to Intel too. They had no hand in the matter. Saying \"the computer\" or \"Intel/AMD/Lean/Mathlib\" doesn't help anything, there is exactly one party involved in the definition of multivariate polynomials relevant to the discussion and not looking up which one it is and saying all of them is lazy writing. And saying \"Lean\" is misattribution, as you have omitted the relevant party. In some places and times you might be able to get away with such misattribution, but an academic paper is not one of them and if I was a reviewer of your paper this would be a blocking concern.</p>",
        "id": 386293744,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1692587237
    },
    {
        "content": "<p>I don't think that some random blog post I wrote years ago when I was just finding my feet should be used as evidence for anything</p>",
        "id": 386342295,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1692609319
    },
    {
        "content": "<p>I suspected you would say that, but didn't want to put words in your mouth <span aria-label=\"smile\" class=\"emoji emoji-1f642\" role=\"img\" title=\"smile\">:smile:</span></p>",
        "id": 386342805,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1692609467
    },
    {
        "content": "<p>Sorry, I've only had very limited internet access for the last week</p>",
        "id": 386342964,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1692609511
    },
    {
        "content": "<p>FWIW <span class=\"user-mention\" data-user-id=\"630204\">@D. J. Bernstein</span> your post has triggered a bit of an audit of our teaching materials to make sure we haven't made this slip-up elsewhere. You might be able to dig up some examples but that doesn't mean they are recommended practice. (The other examples you gave, LFTCM and \"learning lean\", seem to be using the word \"lean\" correctly, even if lean isn't the only thing on the agenda.)</p>",
        "id": 386344018,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1692609825
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"630204\">D. J. Bernstein</span> <a href=\"#narrow/stream/113488-general/topic/djb's.20formalization.20of.20McEliece/near/386251159\">said</a>:</p>\n<blockquote>\n<p>but I'm also really confused at this point, given, e.g., that <a href=\"https://arxiv.org/abs/2108.10700\">https://arxiv.org/abs/2108.10700</a> says \"Lean's mathlib\" in its title</p>\n</blockquote>\n<p>My intention in this phrasing was to convey \"Mathlib, the library for lean\", in the same way as I might say \"Python's numpy\" or \"C++'s Eigen\"; the phrasing is certainly ambiguous, but a fully unambiguous title would have been too long for my taste. The main text clarifies the relationship in the first sentence, just as Kevin's blog post does.</p>",
        "id": 386345543,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1692610295
    },
    {
        "content": "<p>it is a bit of an unfortunate truth that \"mathlib\" without additional context is somewhat unclear to the uninitiated - it looks like an abbreviation of \"math library\" (and it is), but a math library for what? In practice, it is used more as a proper noun, and it isn't really correct to unpack it as \"math library\" any more than one would unpack \"microsoft\" as \"microcomputer software\"</p>",
        "id": 386346157,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1692610477
    },
    {
        "content": "<p>hence one will generally have to specify with qualifiers like \"lean's mathlib\" or \"the lean mathematical library\" when giving titles and other zero-context introductions</p>",
        "id": 386346535,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1692610578
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110049\">Mario Carneiro</span> <a href=\"#narrow/stream/113488-general/topic/djb's.20formalization.20of.20McEliece/near/386344018\">said</a>:</p>\n<blockquote>\n<p>The other examples you gave, LFTCM and \"learning lean\", seem to be using the word \"lean\" correctly, even if lean isn't the only thing on the agenda.</p>\n</blockquote>\n<p>I find it crystal clear that these sources are using \"Lean\" to refer to the core-language-plus-library bundle. If a reader is, despite the available documentation, somehow coming to a \"Lean\" course with the idea that \"Lean\" refers only to the Lean core language and not also to Lean's math library, and is then told a little bit about the core language and much more about the library, then the reader is forced to conclude that either (1) the idea was wrong or (2) the course was mislabeled.</p>\n<p>Saying something like \"No, look, you also learned something about the core language\" is like claiming that an \"Introduction to Python\" book actually means \"Python\" as just the core language and not also the libraries, despite most of the book being about library features.</p>",
        "id": 386364114,
        "sender_full_name": "D. J. Bernstein",
        "timestamp": 1692616036
    },
    {
        "content": "<p>Okay, but again this is just branding. It does not justify incorrect usage of terms in an academic paper</p>",
        "id": 386368334,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1692617643
    },
    {
        "content": "<p>Sure, the course is mislabeled. Does this help clarify the situation?</p>",
        "id": 386368476,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1692617702
    },
    {
        "content": "<p>FWIW, the <a href=\"https://www.oreilly.com/library/view/learning-python-5th/9781449355722/\">first \"intro to python book\" I found a contents page for</a> is genuinely only about the core language and standard library. I think it's important to note that mathlib is <em>not</em> the standard library in the same sense as <code>subprocess</code> or <code>json</code> are in python.</p>",
        "id": 386368549,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1692617731
    },
    {
        "content": "<p>\"This is a online interactive tutorial to Lean focused on proving properties of the elementary operations on natural numbers\"</p>",
        "id": 386378983,
        "sender_full_name": "D. J. Bernstein",
        "timestamp": 1692621375
    },
    {
        "content": "<p>\"the standard mathematics oriented reference is Mathematics in Lean\"</p>",
        "id": 386379005,
        "sender_full_name": "D. J. Bernstein",
        "timestamp": 1692621384
    },
    {
        "content": "<p>\"This repository is an introduction to theorem proving in Lean for the impatient\"</p>",
        "id": 386379139,
        "sender_full_name": "D. J. Bernstein",
        "timestamp": 1692621437
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"630204\">D. J. Bernstein</span> <a href=\"#narrow/stream/113488-general/topic/djb's.20formalization.20of.20McEliece/near/386378983\">said</a>:</p>\n<blockquote>\n<p>\"This is a online interactive tutorial to Lean focused on proving properties of the elementary operations on natural numbers\"</p>\n</blockquote>\n<p>I think this is mostly correct, the natural number game uses approximately no mathlib</p>",
        "id": 386379174,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1692621450
    },
    {
        "content": "<p>\"Approximately no\" sounds like nonzero to me.</p>",
        "id": 386379265,
        "sender_full_name": "D. J. Bernstein",
        "timestamp": 1692621481
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"630204\">D. J. Bernstein</span> <a href=\"#narrow/stream/113488-general/topic/djb's.20formalization.20of.20McEliece/near/386379005\">said</a>:</p>\n<blockquote>\n<p>\"the standard mathematics oriented reference is Mathematics in Lean\"</p>\n</blockquote>\n<p>This is accurate; the second paragraph of the intro says \"This tutorial is based on Lean’s large and ever-growing library, Mathlib.\". This is akin to titling a book \"data science in python\", and then proceeding to use numpy througout even though you didn't feature it in the title.</p>",
        "id": 386380658,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1692621918
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"630204\">@D. J. Bernstein</span> I've been in a field for the best part of a week and I'm now just catching up and am very surprised to see this conversation still continuing. A bunch of people have told you that you're not citing mathlib correctly and my impression is that all you're doing is spending days and days clutching at straws and attempting to find examples which do things like you (often written by me <strong>in 2018</strong> when the lean community was a completely different place) without ever mentioning the far larger body of literature which is citing mathlib correctly. If you really don't want to give credit to the library you used despite having this spelt out to you then I guess that's fine, although it is also a bit unprofessional. If you want to continually search the internet for evidence that your view is correct despite the community continually explaining to you that it is not then I'm not sure you're going to get anywhere.</p>",
        "id": 386380686,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1692621927
    },
    {
        "content": "<p>Um, there hasn't been any evident change since 2018. There's pervasive, continuing use of \"Lean\" to refer to the whole bundle. Finding a massive pile of examples takes no effort.</p>",
        "id": 386381169,
        "sender_full_name": "D. J. Bernstein",
        "timestamp": 1692622085
    },
    {
        "content": "<p>\"Induction in Lean isn’t just something which you do on natural numbers\"</p>",
        "id": 386381411,
        "sender_full_name": "D. J. Bernstein",
        "timestamp": 1692622171
    },
    {
        "content": "<p>That one is genuinely about Lean, <code>induction</code> is a builtin tactic, as are the natural numbers</p>",
        "id": 386381664,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1692622216
    },
    {
        "content": "<p>\"A year and a half after the challenge was posed by Peter Scholze we have finally formally verified the main theorem of liquid vector spaces using the Lean proof assistant\"---gee, why not \"using mathlib\"?</p>",
        "id": 386381801,
        "sender_full_name": "D. J. Bernstein",
        "timestamp": 1692622233
    },
    {
        "content": "<p>\"The corresponding statement in Lean is the following\"---why no credit here to mathlib?</p>",
        "id": 386381957,
        "sender_full_name": "D. J. Bernstein",
        "timestamp": 1692622273
    },
    {
        "content": "<p>\"The success of the project is the result of the hard work of many people in the Lean community\"---why not also \"the mathlib community\"?</p>",
        "id": 386382031,
        "sender_full_name": "D. J. Bernstein",
        "timestamp": 1692622292
    },
    {
        "content": "<p>I'd say the mathlib community is a subset of the Lean community.</p>",
        "id": 386382664,
        "sender_full_name": "Kyle Miller",
        "timestamp": 1692622415
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"630204\">D. J. Bernstein</span> <a href=\"#narrow/stream/113488-general/topic/djb's.20formalization.20of.20McEliece/near/386381801\">said</a>:</p>\n<blockquote>\n<p>\"A year and a half after the challenge was posed by Peter Scholze we have finally formally verified the main theorem of liquid vector spaces using the Lean proof assistant\"---gee, why not \"using mathlib\"?</p>\n</blockquote>\n<p>This is like saying \"we wrote a program in Javascript\" even though you're surely pulling in any number of libraries.</p>",
        "id": 386382912,
        "sender_full_name": "Kyle Miller",
        "timestamp": 1692622462
    },
    {
        "content": "<p>\"the status of algebraic geometry in Lean\"---why not \"in mathlib\"?</p>",
        "id": 386382958,
        "sender_full_name": "D. J. Bernstein",
        "timestamp": 1692622470
    },
    {
        "content": "<p>\"They also created evidence for Lean’s Ext groups, profinite spaces, condensed abelian groups and so on\"---why not mathlib's Ext groups?</p>",
        "id": 386383303,
        "sender_full_name": "D. J. Bernstein",
        "timestamp": 1692622558
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"630204\">D. J. Bernstein</span> <a href=\"#narrow/stream/113488-general/topic/djb's.20formalization.20of.20McEliece/near/386382958\">said</a>:</p>\n<blockquote>\n<p>\"the status of algebraic geometry in Lean\"---why not \"in mathlib\"?</p>\n</blockquote>\n<p>The mathlib project is part of the greater Lean project in terms of the community's attention. If mathlib has something formalized, then \"Lean\" in a very informal sense has it formalized. It would be more accurate to say that mathlib has algebraic geometry certainly.</p>",
        "id": 386383629,
        "sender_full_name": "Kyle Miller",
        "timestamp": 1692622637
    },
    {
        "content": "<p>A paper saying \"Lean defines ...\" is being accused of inaccuracy and academic misconduct, but meanwhile it's okay to say \"Lean's Ext groups\"? Seriously?</p>",
        "id": 386385116,
        "sender_full_name": "D. J. Bernstein",
        "timestamp": 1692623020
    },
    {
        "content": "<p>The Ext group in question here resides <a href=\"https://github.com/leanprover-community/lean-liquid/blob/92f188bd17f34dbfefc92a83069577f708851aec/src/for_mathlib/derived/derived_cat.lean#L524\">in LTE itself</a> (which the blog post is about), not in mathlib</p>",
        "id": 386386331,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1692623356
    },
    {
        "content": "<p>Sorry, at what point was there an accusation of misconduct?</p>",
        "id": 386386598,
        "sender_full_name": "Kyle Miller",
        "timestamp": 1692623405
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"310045\">Eric Wieser</span> <a href=\"#narrow/stream/113488-general/topic/djb's.20formalization.20of.20McEliece/near/386386331\">said</a>:</p>\n<blockquote>\n<p>The Ext group in question here resided in LTE itself (which the blog post is about), not in mathlib</p>\n</blockquote>\n<p>So attributing LTE's definitions to Lean is okay, while attributing mathlib's definitions to Lean isn't?</p>",
        "id": 386386817,
        "sender_full_name": "D. J. Bernstein",
        "timestamp": 1692623479
    },
    {
        "content": "<p>I don't think \"Lean's Ext groups\" is a good description. Note that this is again Kevin's blog, where he has an explicit disclaimer: \"I am not speaking for all the authors or the Lean community or the mathlib community or any other organization\"</p>",
        "id": 386387165,
        "sender_full_name": "Kyle Miller",
        "timestamp": 1692623576
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"306601\">Kyle Miller</span> <a href=\"#narrow/stream/113488-general/topic/djb's.20formalization.20of.20McEliece/near/386386598\">said</a>:</p>\n<blockquote>\n<p>Sorry, at what point was there an accusation of misconduct?</p>\n</blockquote>\n<p>\"I think just basic academic standards of attribution argue against \"it is appropriate to attribute mathlib's definitions to Lean\".\"; \"you should try to attribute things correctly\"; \"If you really don't want to give credit to the library you used ... a bit unprofessional\"</p>",
        "id": 386387267,
        "sender_full_name": "D. J. Bernstein",
        "timestamp": 1692623606
    },
    {
        "content": "<p>Oh, sure. I see people have also given you examples in other languages and systems.</p>\n<p>I wouldn't bat an eye at a course called \"Numerical linear algebra in Python\" and then it being all about how to use numpy. I <em>would</em> be surprised if someone used numpy in a paper and insisted on saying things like \"Python defines <code>numpy.array</code>.\" That seems like it would be confusing, and I'd imagine it might rub the numpy developers the wrong way.</p>\n<p>Just in case you're not aware, the people objecting to attributing mathlib definitions to Lean itself are all mathlib contributors. We might not be consistent with it, but despite all the mistakes you've found that are out there, I think we all generally want to distinguish Lean and mathlib.</p>",
        "id": 386393287,
        "sender_full_name": "Kyle Miller",
        "timestamp": 1692625117
    },
    {
        "content": "<p>At least this mathlib contributor would be happy with \"Lean defines an equivalent function under the name <code>monomial</code>\" -&gt; \"The Lean mathematical library <code>mathlib</code> defines an equivalent function under the name <code>monomial</code>\".</p>",
        "id": 386393834,
        "sender_full_name": "Kyle Miller",
        "timestamp": 1692625271
    },
    {
        "content": "<blockquote>\n<p>I'd imagine it might rub the numpy developers the wrong way.</p>\n</blockquote>\n<p>With my numpy maintainer hat on, I agree</p>",
        "id": 386393874,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1692625287
    },
    {
        "content": "<p>Let me also risk saying this: my impression is that the distinction between Lean and Mathlib became clearer with time, especially with the advance of Lean 4. Back in the days, <code>leanprover-community</code> had to maintain its own fork of Lean 3 in order to keep Mathlib evolving. Not that it <em>causes</em> confusion, but it can contribute to historical blurriness since the ones developing Lean 3 in practice were, for a while, Mathlib maintainers. The scenario is very different now with Lean 4, which is pretty new to the community. And your publication can be a force that pushes future writers towards more precise writing.</p>\n<p>And I also want to say this: I don't think you're indulging in any form of misconduct. To me, it's just that the community is adapting/evolving, very much like Lean and Mathlib themselves.</p>",
        "id": 386396913,
        "sender_full_name": "Arthur Paulino",
        "timestamp": 1692626133
    },
    {
        "content": "<p>Two cents from an outsider: I do understand that people want proper attribution and that's great, but the GItHub organization is called <code>leanprover-community</code>, the community Zulip is called <code>leanprover.zulipchat.com</code>, and the project is called \"Lean mathematical library\". I honestly thought it was a deliberate attempt at creating a unified identity, even after following the project for a couple of years and knowing that the two parts are developed by an almost disjoint set of people.</p>",
        "id": 386396943,
        "sender_full_name": "Mauricio Collares",
        "timestamp": 1692626145
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"306601\">Kyle Miller</span> <a href=\"#narrow/stream/113488-general/topic/djb's.20formalization.20of.20McEliece/near/386382664\">said</a>:</p>\n<blockquote>\n<p>I'd say the mathlib community is a subset of the Lean community.</p>\n</blockquote>\n<p>We might have Lean libraries for subjects other than mathematics in the future. At least, I hope so.</p>",
        "id": 386400065,
        "sender_full_name": "Bulhwi Cha",
        "timestamp": 1692626891
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"306601\">Kyle Miller</span> <a href=\"#narrow/stream/113488-general/topic/djb's.20formalization.20of.20McEliece/near/386387165\">said</a>:</p>\n<blockquote>\n<p>I don't think \"Lean's Ext groups\" is a good description. Note that this is again Kevin's blog, where he has an explicit disclaimer: \"I am not speaking for all the authors or the Lean community or the mathlib community or any other organization\"</p>\n</blockquote>\n<p>I'm not sure why this disclaimer is relevant here. Is there a URL somewhere where I can see some of those other people stating that \"Lean's Ext groups\" was inappropriate attribution and incorrect attribution and unprofessional?</p>\n<p>There's this mountain of examples of the word \"Lean\" obviously being used to include not just the core language but also the math library. This provides a perfectly straightforward explanation for mathlib-oriented courses and workshops being labeled as \"Lean\" courses and workshops, for wording such as \"Lean's Ext groups\" (the distinction between mathlib and prototypes isn't relevant here), for wording going out of its way to refer specifically to the core language when that's relevant (such as \"If you are interested in Lean as a programming language\"), etc. There's nothing wrong with using this definition.</p>\n<p>Meanwhile there's an alternate universe in a particular Zulip chat where \"Lean\" means specifically the core language and definitely not mathlib, and where there's a remarkable pile of ad-hoc excuses for the mountain of public exceptions and the lack of errata (it's not a mountain, these are isolated mistakes that are really hard to find, it's just an occasional slip from Kevin, okay it's not just Kevin but there's nothing from l’Académie française, this one was way back in 2019, that one was way back in 2022, the course really does teach people something about the language, etc.), and where a new paper writing \"Lean's definition of fields\" is engaging in academic misconduct.</p>\n<p>Sorry, no, this doesn't survive Occam's razor. If you'd like to change terminology, start by clearly documenting the change and comprehensively updating other documentation to match; skip the fiction that people using the existing terminology are doing something wrong.</p>",
        "id": 386407119,
        "sender_full_name": "D. J. Bernstein",
        "timestamp": 1692628578
    },
    {
        "content": "<p>The existence of inconsistencies or imprecisions should not be an excuse to continue indulging in them, though.</p>",
        "id": 386410535,
        "sender_full_name": "Damiano Testa",
        "timestamp": 1692629483
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"310045\">Eric Wieser</span> <a href=\"#narrow/stream/113488-general/topic/djb's.20formalization.20of.20McEliece/near/386381664\">said</a>:</p>\n<blockquote>\n<p>That one is genuinely about Lean, <code>induction</code> is a builtin tactic, as are the natural numbers</p>\n</blockquote>\n<p>For me this is further confirmation of the value of a name for the unified system (such as the established name, \"Lean\"). When I'm reporting properties that I observe from the system as a whole, I'm reporting what I know. I often don't know how these properties come from properties of the components---in this case, the core language versus mathlib---and I also don't want to pester the reader with irrelevant internal details.</p>",
        "id": 386410886,
        "sender_full_name": "D. J. Bernstein",
        "timestamp": 1692629563
    },
    {
        "content": "<p>Maybe this is all a call to action. Apparently the <code>leanprover-community</code> needs some kind of official manifest clarifying all this from now on.</p>\n<p>This is another personal impression of mine, which is aligned with a few other comments made on this thread: the structure of the Zulip server <em>can</em> strengthen such kinds of confusion. There exist Lean 4 and Mathlib. This is Zulip server is for Lean as a whole. And yet, threads about Mathlib are spread everywhere. In the <a class=\"stream\" data-stream-id=\"113488\" href=\"/#narrow/stream/113488-general\">#general</a> stream, people talk about Mathlib and it's taken for granted that the thread is properly contextualized when, in fact, Mathlib is one (the major) Lean 4 library/use case.</p>\n<p>Again, there's definitely history to explain the current scenario. But we need to acknowledge that this is very hard on newcomers and can backfire if we expect people to get the distinctions right.</p>",
        "id": 386417882,
        "sender_full_name": "Arthur Paulino",
        "timestamp": 1692631249
    },
    {
        "content": "<p>I'm sorry this thread has gotten heated and I'd like to try to defuse some tension here. First of all,  there should be no accusation of academic misconduct here. Lean and mathlib are different entities, with different contributors, maintained by different organizations. Historically these lines have been very blurred, and this is reflected in a lot of the material on the web. It's not reasonable to expect someone new to the community to immediately grasp the current distinctions.</p>\n<p><span class=\"user-mention\" data-user-id=\"630204\">@D. J. Bernstein</span>: I think most of the pushback in this thread is reactions to mathlib not being mentioned at all in your paper. Most of the people who have written the million lines of Lean code in mathlib see themselves as mathlib contributors, not Lean contributors. There are very few Lean contributors in comparison. Even though it clearly wasn't intentional, this reads as a mistaken attribution. Work that uses mathlib should mention that it is based on mathlib and cite the CPP 2020 paper by The Mathlib Community (and I mean \"should\" in the peer review suggestion sense, not as an accusation). Would you mind adding these to your paper? </p>\n<p>I agree with the opinions here that I personally would refer to \"mathlib\" instead of \"Lean\" at various points in your paper. I also think that, <em>with a mention and reference to mathlib at the start</em>, it's entirely clear what's meant and not a point worth arguing about. The semantics of Lean vs mathlib matter for development and could definitely stand to be clarified in places like the community website. (We're happy to take PRs from anyone updating unclear phrasing.) As a shorthand for \"the context of your formalization\" in your paper, write what you want.</p>",
        "id": 386427096,
        "sender_full_name": "Rob Lewis",
        "timestamp": 1692633368
    },
    {
        "content": "<p>Thanks for the comments.</p>\n<p>Regarding your question, this was already answered much earlier, but I'll collect the quotes here for your convenience. Specifically, after a literature allusion appeared (with, I should note, wording that was neither clear nor temperate), I promptly wrote <code>Poking around, I find DBLP:conf/cpp/X20, which of course I'm happy to cite</code> and posted the following draft text: <code>See \\cite{1996/harrison} for an introduction to HOL Light, \\cite{2021/moura} for an introduction to Lean 4, and \\cite{2020/mathlib} for an introduction to the Lean math library. This appendix says ``HOL Light'' and ``Lean'' to refer to the full proof assistants available when these formalizations began, including the math libraries.</code></p>\n<p>Regarding terminology for the unified system presented to users, at this point I've seen overwhelming evidence that \"Lean\" is the established name. This should be centrally documented in a way that's very easy to find (to be able to rapidly and conclusively terminate anything that's even remotely like the discussion that occurred above), and if different terminology is desired for whatever reason then that should be prominently documented as a change of terminology.</p>",
        "id": 386445691,
        "sender_full_name": "D. J. Bernstein",
        "timestamp": 1692640323
    },
    {
        "content": "<p>Hi, <span class=\"user-mention\" data-user-id=\"630204\">@D. J. Bernstein</span>. I know you and I have talked about this kind of thing before (and I spent some time trying to get that very paper formalised in Lean/Mathlib 3 last year, to some mixed success). Can I help at all? This is pretty much my direct area of interest.</p>",
        "id": 386449758,
        "sender_full_name": "Wrenna Robson",
        "timestamp": 1692641981
    },
    {
        "content": "<p>As it happens, in fact, in recent days I've been adapting your own control bits formalisation to Lean 4, using a partrial Lean 3 adapation I did a couple of years ago as a base, to good success. I don't think I'm that far from having a full proof of the construction, though I'm really at the technical point of it.</p>",
        "id": 386449921,
        "sender_full_name": "Wrenna Robson",
        "timestamp": 1692642046
    },
    {
        "content": "<p>Indeed, I think you may even be using my Hamming weight portion of the library that I wrote for this very purpose!</p>",
        "id": 386450139,
        "sender_full_name": "Wrenna Robson",
        "timestamp": 1692642144
    },
    {
        "content": "<p>Ah, perhaps not, I see you have your own definition of it. Just so you know, this exists. <a href=\"https://leanprover-community.github.io/mathlib4_docs/Mathlib/InformationTheory/Hamming.html\">https://leanprover-community.github.io/mathlib4_docs/Mathlib/InformationTheory/Hamming.html</a></p>",
        "id": 386450589,
        "sender_full_name": "Wrenna Robson",
        "timestamp": 1692642362
    },
    {
        "content": "<p>Third paragraph of my appendix is citing Section 4 of your paper \"for a report of previous progress towards formalizing this paper's theorems in Lean\"; I figured it was better for the reader to look at your description than to have me try to give more details. Regarding further work, what I want to see in the end is theorems saying things like \"this x86 code computes CM.Decap\", and obviously many things still need to be done to put that together.</p>",
        "id": 386451335,
        "sender_full_name": "D. J. Bernstein",
        "timestamp": 1692642648
    },
    {
        "content": "<p>Oh, nice!</p>",
        "id": 386451529,
        "sender_full_name": "Wrenna Robson",
        "timestamp": 1692642736
    },
    {
        "content": "<p>Yes - there's a big big road ahead for that kind of thing. I am coming to the end of my funding now (and so am trying to drag together a thesis out of all the things I've done and thought, as one does), but suffice it to say I have a <em>lot</em> of thoughts about it and I'm really excited to see serious senior cryptographers like yourself getting involved in the Lean/mathlib world.</p>",
        "id": 386451682,
        "sender_full_name": "Wrenna Robson",
        "timestamp": 1692642813
    },
    {
        "content": "<p>For various reasons I've been out of the lean world for a bit. Good to be back in just to see you be here!</p>",
        "id": 386452659,
        "sender_full_name": "Wrenna Robson",
        "timestamp": 1692643136
    },
    {
        "content": "<p>This was the archive of much of what I did last year. A lot of what I ended up doing ended up back-ported into mathlib, though, I think: I tended towards a more \"finding the right way to state and fit things together\" approach, which is much (much) slower. <a href=\"https://github.com/linesthatinterlace/goppadecoding\">https://github.com/linesthatinterlace/goppadecoding</a></p>",
        "id": 386452857,
        "sender_full_name": "Wrenna Robson",
        "timestamp": 1692643205
    },
    {
        "content": "<p>In particular, I think most of <a href=\"https://leanprover-community.github.io/mathlib_docs/linear_algebra/lagrange.html\">https://leanprover-community.github.io/mathlib_docs/linear_algebra/lagrange.html</a> was rewritten as a result of that work.</p>",
        "id": 386453289,
        "sender_full_name": "Wrenna Robson",
        "timestamp": 1692643369
    },
    {
        "content": "<p>Sorry, let me link to the mathlib4 docs. In particular, Lagrange.interpolate (<a href=\"https://leanprover-community.github.io/mathlib4_docs/Mathlib/LinearAlgebra/Lagrange.html#Lagrange.interpolate\">https://leanprover-community.github.io/mathlib4_docs/Mathlib/LinearAlgebra/Lagrange.html#Lagrange.interpolate</a>) is essentially your \"interpolator\" (<a href=\"https://cr.yp.to/2023/leangoppa-20230726/Goppadecoding/vanishing.lean.html\">https://cr.yp.to/2023/leangoppa-20230726/Goppadecoding/vanishing.lean.html</a>), but with the advantage that by construction it has the linearity between the values at the nodes and the polynomial. (Also, the Mathlib definition is computable.)</p>",
        "id": 386455746,
        "sender_full_name": "Wrenna Robson",
        "timestamp": 1692644401
    },
    {
        "content": "<p>Beyond Goppa decoding and control bits, I'm planning to formalize the necessary sorting-network proofs soon. There are then all sorts of smaller pieces needed such as Fangcheng-style row reduction. I've heard about two echelon-form projects for Lean, and maybe one or both of those has done algorithmic proofs. I wrote a row-reduction proof of linear dependence for lightgoppa with an eye towards proving algorithms later. For stating and proving theorems about software, HOL Light has models of x86 and ARM, including enough instructions to be useful; I don't know whether Lean does.</p>\n<p>It can certainly be time-consuming to organize things for integration into a central library. Given the urgency of rolling out post-quantum software and the damage that can be done by bugs, I've been prioritizing getting things proven and deferring cleanup thoughts.</p>",
        "id": 386455972,
        "sender_full_name": "D. J. Bernstein",
        "timestamp": 1692644477
    },
    {
        "content": "<p>I want to share one lesson I've learned (painfully), as someone who, while much less of a cryptographer than you, was at a similar point myself in the past: in general, when working with Mathlib in particular, it is always so much better to <em>use the library</em> rather than making new definitions from scratch. This is because of the understanding of definitions as a cost, for which the price must be paid in the API to use them (lemmas). Using preconstructed objects about which theorems exist mean we get the API for free.</p>",
        "id": 386456053,
        "sender_full_name": "Wrenna Robson",
        "timestamp": 1692644513
    },
    {
        "content": "<p>I don't see anything wrong with your prioritisation, to be clear - it is just a thought.</p>",
        "id": 386456144,
        "sender_full_name": "Wrenna Robson",
        "timestamp": 1692644543
    },
    {
        "content": "<p>A mistake I see a lot of formalisation stuff make in our neck of the woods (that is, by cryptographers, not really yourself) is to treat \"having a list of formalised statements and definitions\" as a good thing. But I think over time I've come to believe that it isn't - it is a mortgage on the future whose price must be paid in LoC.</p>",
        "id": 386456287,
        "sender_full_name": "Wrenna Robson",
        "timestamp": 1692644607
    },
    {
        "content": "<p>Incidentally, thanks to comments made by our own <span class=\"user-mention\" data-user-id=\"310045\">@Eric Wieser</span> recently, I've re-interpreted the control bits algorithm as operating on binary bits of the numbers (in that each layer of the control bits network corresponds to conditional flipping of a progressively more sigificant bit, where the control bits are indexed by the residuum left when you remove that bit).</p>",
        "id": 386456575,
        "sender_full_name": "Wrenna Robson",
        "timestamp": 1692644725
    },
    {
        "content": "<p>It turns out to be a really nice and very functional interpretation which made things \"click\" in this context.</p>",
        "id": 386456686,
        "sender_full_name": "Wrenna Robson",
        "timestamp": 1692644764
    },
    {
        "content": "<p>I don't think Lean has much stating and proving theorems about software. I believe it to be possible (I have never done this), especially in lean 4, to compile Lean code itself to efficient C or assembly, I think possibly in a way that is provably correct or which at least only relies on the trusted core. So one approach would be to implement CMcE totally in Lean, in both an \"efficient\" way and a way which preserves the algebraic abstractions, prove the bridge between them, prove the algebraic things about the latter you want and compile the efficient code which has these functional and mathematical guarantees along with it.</p>",
        "id": 386456995,
        "sender_full_name": "Wrenna Robson",
        "timestamp": 1692644906
    },
    {
        "content": "<p>My appendix notes that Lean already had theorems on direct interpolation (which predates Lagrange, btw). But the conventional statement isn't really the right statement! Goppa decoding is one way to see this: applying the statement to Goppa decoding means taking the usual denominators and multiplying to cancel them. Humans tend to be familiar with the conventional statement and in any case do the cancellation very quickly, but the right statement doesn't have any divisions in the statement and the proof, and doesn't require a field.</p>",
        "id": 386457817,
        "sender_full_name": "D. J. Bernstein",
        "timestamp": 1692645273
    },
    {
        "content": "<p>The conventional statement of Lagrange? I think I know what you mean.</p>",
        "id": 386457914,
        "sender_full_name": "Wrenna Robson",
        "timestamp": 1692645315
    },
    {
        "content": "<p>Over time I've grown more and more pessimistic about the role of this kind of verification in effectively reducing bugs. I think the messy state of the start of the NIST PQ signatures process has shown that, uh, cryptographers are not immune to obvious bugs which break their schemes. Your own work in that regard has shown that, as you continue to bat away and drill down on the... less robust entries. What I used to be more optimistic about, and am now more pessimistic about, is the role of verification and formal methods in that process. As you say, there is a tension between a desire to produce verified code in a timely manner, and making it lie flat with other work. But one thing I'm trying to do at the moment is reason and think through what exactly any of this actually <em>means</em> for what ought to matter - the security that the cryptography produces.</p>",
        "id": 386457955,
        "sender_full_name": "Wrenna Robson",
        "timestamp": 1692645341
    },
    {
        "content": "<p>Right, yes, I've reminded myself now - yes I agree completely, in a sense that interpolation isn't what one really wants because you multiply it up. I have a feeling that the \"thing multiplied up\" is precisely Lagrange.nodal (<a href=\"https://leanprover-community.github.io/mathlib4_docs/Mathlib/LinearAlgebra/Lagrange.html#Lagrange.nodal\">https://leanprover-community.github.io/mathlib4_docs/Mathlib/LinearAlgebra/Lagrange.html#Lagrange.nodal</a>), which I define here as needing a field but I think iirc that is almost certainly incorrect/a product of not having quite enough time.</p>",
        "id": 386458659,
        "sender_full_name": "Wrenna Robson",
        "timestamp": 1692645651
    },
    {
        "content": "<p>It might be because outside of a field one has to worry about uniqueness? But I'm fairly sure field is far too strong. Anyway, yes, Lean had most of this stuff before - the previous formulations were just less useful for the stuff we'd need to do.</p>",
        "id": 386458785,
        "sender_full_name": "Wrenna Robson",
        "timestamp": 1692645720
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"330967\">@Wrenna Robson</span>, instead of copying and pasting, you can use the linkifier, like so: <a href=\"https://leanprover-community.github.io/mathlib4_docs/find/?pattern=Lagrange.nodal#doc\">docs#Lagrange.nodal</a></p>",
        "id": 386463790,
        "sender_full_name": "Jireh Loreaux",
        "timestamp": 1692648011
    },
    {
        "content": "<p>Oh, thank you - sorry.</p>",
        "id": 386463882,
        "sender_full_name": "Wrenna Robson",
        "timestamp": 1692648049
    },
    {
        "content": "<p>(no need to be sorry, I just wanted to remind you of that convenience <span aria-label=\"smiley\" class=\"emoji emoji-1f603\" role=\"img\" title=\"smiley\">:smiley:</span>)</p>",
        "id": 386464111,
        "sender_full_name": "Jireh Loreaux",
        "timestamp": 1692648149
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"330967\">Wrenna Robson</span> <a href=\"#narrow/stream/113488-general/topic/djb's.20formalization.20of.20McEliece/near/386456995\">said</a>:</p>\n<blockquote>\n<p>I don't think Lean has much stating and proving theorems about software. I believe it to be possible (I have never done this), especially in lean 4, to compile Lean code itself to efficient C or assembly, I think possibly in a way that is provably correct or which at least only relies on the trusted core. So one approach would be to implement CMcE totally in Lean, in both an \"efficient\" way and a way which preserves the algebraic abstractions, prove the bridge between them, prove the algebraic things about the latter you want and compile the efficient code which has these functional and mathematical guarantees along with it.</p>\n</blockquote>\n<p>To the extent that users are asking for really fast cryptographic code, the code is produced by humans with a mix of assembly and vector instructions rather than by \"optimizing\" compilers; <a href=\"https://cr.yp.to/talks.html#2015.04.16\">https://cr.yp.to/talks.html#2015.04.16</a> explains the basic reasons for this. That's true even without the constraint of \"certifying\" (proving) the compiler (or the weaker but sufficient constraint of \"translation validation\", meaning proving that _this_ code was correctly compiled). So people are instead working on directly verifying machine language (or, in some cases, assembly via Jasmin). Theorems in any case need an instruction-set definition, which is more than a little bit painful to write and validate for modern instruction sets.</p>",
        "id": 386474070,
        "sender_full_name": "D. J. Bernstein",
        "timestamp": 1692651282
    },
    {
        "content": "<p>Somewhat less painful, for the important case of unrollable code, is to use symbolic-execution tools (SAW, angr, Manticore) to convert low-level code into a simpler language without vectors, jumps, memory, etc. This relies on the tools to have been adequately validated but makes subsequent proofs easier---if the proof tools can handle sequences of (say) 100000 instructions.</p>",
        "id": 386474687,
        "sender_full_name": "D. J. Bernstein",
        "timestamp": 1692651575
    },
    {
        "content": "<p>Those tools don't magically escape the instruction-set difficulty; angr still doesn't support AVX-512, for example.</p>",
        "id": 386474964,
        "sender_full_name": "D. J. Bernstein",
        "timestamp": 1692651700
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"330967\">Wrenna Robson</span> <a href=\"#narrow/stream/113488-general/topic/djb's.20formalization.20of.20McEliece/near/386457955\">said</a>:</p>\n<blockquote>\n<p>Over time I've grown more and more pessimistic about the role of this kind of verification in effectively reducing bugs. I think the messy state of the start of the NIST PQ signatures process has shown that, uh, cryptographers are not immune to obvious bugs which break their schemes. Your own work in that regard has shown that, as you continue to bat away and drill down on the... less robust entries. What I used to be more optimistic about, and am now more pessimistic about, is the role of verification and formal methods in that process. As you say, there is a tension between a desire to produce verified code in a timely manner, and making it lie flat with other work. But one thing I'm trying to do at the moment is reason and think through what exactly any of this actually <em>means</em> for what ought to matter - the security that the cryptography produces.</p>\n</blockquote>\n<p>Given that McEliece's system has maintained the same security exponent despite a long string of focused attack papers over 45 years, we _hope_ that the exponent is optimal (and, more importantly, that concrete parameters take about as long to break as we think). It'd then be terrible to have security lost because of algorithm bugs or software bugs, and certainly proof tools can help eliminate those bugs.</p>\n<p>But, indeed, we don't have proofs of the security levels. I very much doubt that the asymptotic security levels are provable. A concrete security claim such as 2^256 (in a carefully defined model) is, if correct, also trivially \"provable\", but there's no reason to think that anyone will ever know a proof.</p>\n<p>We don't even have something that sounds much wimpier, namely proofs of the performance of the _known_ attacks that we think are fastest among known attacks. See also <a href=\"https://cat.cr.yp.to/cryptattacktester-20230614.pdf#appendix.B\">https://cat.cr.yp.to/cryptattacktester-20230614.pdf#appendix.B</a> for a survey of many years of similar proof gaps for factorization, discrete logs, and lattices. We don't even have proofs of the performance of something as easy as a sensibly optimized brute-force search against AES-128!</p>\n<p>It's certainly conceivable that in the end we'll end up with verified software for a cryptosystem whose security level is much lower than we think it is. I gave a short talk at last month's Lean event (<a href=\"https://cr.yp.to/talks.html#2023.07.11\">https://cr.yp.to/talks.html#2023.07.11</a>) covering some ways that proofs help in applied cryptography and some ways that they don't.</p>",
        "id": 386479908,
        "sender_full_name": "D. J. Bernstein",
        "timestamp": 1692654363
    },
    {
        "content": "<p>Sounds great, I'll try and check it out soon.</p>",
        "id": 386482736,
        "sender_full_name": "Wrenna Robson",
        "timestamp": 1692656018
    },
    {
        "content": "<p>I am aware - I can't remember the name, is it FiatCrypto - that there is some really nice \"we assemble the assembly in verified ways so you don't have to\" fast implementations out there. And there's been some work recently - some using Jasmin, yeah - that gives me some hope that fast cryptography can also mean verified cryptography.</p>\n<p>It seems to me that what is missing is true will from applied cryptographers (other than people like yourself and a few others - but what I might call the average practitioner of street cryptography) in using these tools for the things that they are good for. I've attended HACS for the last two years and that's been really good but I'm always a bit like... OK but how can we get this usable by not-We.</p>\n<p>One thing I will say about Lean and in particular the mathlib project: it has an amazing, active and helpful user community. It's really impossible to undersell how important that is I think. I've wrestled with quite a few tools that nominally ought to be the exact correct tool for the job - but they're a nightmare to use and if you hit a block you're sunk.</p>",
        "id": 386483304,
        "sender_full_name": "Wrenna Robson",
        "timestamp": 1692656372
    },
    {
        "content": "<p>And yes... security levels in cryptography are, let's be real, something of a dark art. At the very least I think one ought to be honest about how many assumptions one makes...</p>",
        "id": 386483416,
        "sender_full_name": "Wrenna Robson",
        "timestamp": 1692656437
    },
    {
        "content": "<p>I don't know if you ever get the thing where you read some provable security proof and you're like - OK but where's the beef, what's the moment you do the Clever Thing that isn't just symbol-manipulation or \"well I'm going to assume this is hard\".</p>",
        "id": 386483503,
        "sender_full_name": "Wrenna Robson",
        "timestamp": 1692656502
    },
    {
        "content": "<p>FYI <span class=\"user-mention\" data-user-id=\"630204\">@D. J. Bernstein</span>, I have acted on your comment that of course the \"multiplied up\" polynomials of Lagrange interpolation do not need to be a field, and refactored the file accordingly. <a href=\"https://github.com/leanprover-community/mathlib4/pull/6714\">#6714</a>.</p>\n<p>If you have further comments or thoughts they would be welcome. I think I am probably going to submit a future patch to move these definitions and proofs into the Polynomial namespace, so there's certainly more refactoring to be done.</p>",
        "id": 386492446,
        "sender_full_name": "Wrenna Robson",
        "timestamp": 1692661934
    },
    {
        "content": "<p>If you have any theorems or definitions that have come from your goppa decoding work above that you think belong into Mathlib, I'm happy to help with that, as I'm a bit more familiar with the process and shaking off the rust.</p>",
        "id": 386492497,
        "sender_full_name": "Wrenna Robson",
        "timestamp": 1692661987
    },
    {
        "content": "<p>One thing we do not have in Mathlib currently is a satisfactory definition of a (linear) code. Obviously there's lots of concrete definitions one could choose, but choosing the \"right\" definition in Lean was frustrating past the point of usefulness. Please let me know if you have thoughts. Getting some coding theory into Mathlib would be a great future goal, and one that is compatible with some of the cryptographic aims. You might also want to join up with some of those people looking at more computational aspects and proofs, but I'm not best placed to talk about that.</p>",
        "id": 386492727,
        "sender_full_name": "Wrenna Robson",
        "timestamp": 1692662163
    },
    {
        "content": "<p>Yes, linear codes would be good to have. I started a PR in mathlib3 <a href=\"https://github.com/leanprover-community/mathlib/pull/16774\">!3#16774</a>, but did not finish it (perhaps it could be ported at some point). I thought it would be useful for my own crypto goals, but I think I got sidetracked, and in any case, I felt my inexperience in writing code that isn't necessarily tailored to a particular goal, but was meant to be more of a general purpose API.</p>",
        "id": 386500604,
        "sender_full_name": "Bolton Bailey",
        "timestamp": 1692666321
    },
    {
        "content": "<p>I seem to recall I spent a while trying to define a construction to give a nice API around finding minimum distances. Trying to remember what it was called.</p>",
        "id": 386544733,
        "sender_full_name": "Wrenna Robson",
        "timestamp": 1692688366
    },
    {
        "content": "<p><a href=\"https://leanprover-community.github.io/mathlib4_docs/find/?pattern=Set.infSep#doc\">docs#Set.infSep</a> ?</p>",
        "id": 386544814,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1692688415
    },
    {
        "content": "<p>It was <a href=\"https://leanprover-community.github.io/mathlib4_docs/find/?pattern=Set.infsep#doc\">docs#Set.infsep</a></p>",
        "id": 386544937,
        "sender_full_name": "Wrenna Robson",
        "timestamp": 1692688463
    },
    {
        "content": "<p>That name is wrong, it should be InfSep or infSep, yeah.</p>",
        "id": 386545016,
        "sender_full_name": "Wrenna Robson",
        "timestamp": 1692688511
    },
    {
        "content": "<p>As I recall there's also some things that are true for when the distance is specifically integer-valued that I never quite got round to writing down (and then life happened, as it does).</p>",
        "id": 386545312,
        "sender_full_name": "Wrenna Robson",
        "timestamp": 1692688678
    },
    {
        "content": "<p>I eliminated all coding-theory terminology from this paper's theorem statements, so maybe I'm not the best person to ask for advice on an API for general linear codes. :-) Most of the literature is about k-linear codes defined as k-subspaces of k^n, normally with k required to be finite. Often the literature is doing arithmetic on indices so it's helpful to pick an index set, and then {1,...,n} is traditional but {0,...,n-1} is a bit smoother because the indices are often polynomial exponents. Some of the literature is on non-linear codes, codes over more general rings, infinite-length codes, and metrics other than the Hamming metric. Sometimes definitions are general enough to include lattices.</p>",
        "id": 386657298,
        "sender_full_name": "D. J. Bernstein",
        "timestamp": 1692723976
    },
    {
        "content": "<p>The natural thing in mathlib is 0 to n-1 because tuples of k are Fin n -&gt; k, and Fin n is the subtype of Nat from 0 to n-1 with the modular arithmetic.</p>",
        "id": 386677919,
        "sender_full_name": "Wrenna Robson",
        "timestamp": 1692731871
    },
    {
        "content": "<p>And yes the annoyance has been that in a sense to incorporate all possible things one might mean by \"a code\" is an almost uselessly wide definition.</p>",
        "id": 386678132,
        "sender_full_name": "Wrenna Robson",
        "timestamp": 1692731968
    },
    {
        "content": "<p>I have a feeling that actually the thing that makes codes interesting is often the fact that their metrics are integer valued as much as anything... something about that gives a discreteness that gives rise to interesting properties. But I'm not a coding theorist!</p>",
        "id": 386678297,
        "sender_full_name": "Wrenna Robson",
        "timestamp": 1692732037
    },
    {
        "content": "<p>Why did you decide to eliminate coding theory references in the statements? Not that I think it was the wrong decision, I can see why you might, but I'm interested in your own thinking.</p>",
        "id": 386678381,
        "sender_full_name": "Wrenna Robson",
        "timestamp": 1692732083
    },
    {
        "content": "<p>The theorems in the paper are aimed at readers who simply want to understand Goppa decoding and don't want to take a full coding-theory course. The main metrics are the time to read theorems (including the necessary definitions) and the time to read proofs. Being in a Goppa code has such a simple formula that defining and using a name for it, either as a predicate or as a set, ends up as a loss in both metrics; this is obvious for the proofs (which are continually working with the formula) but also true for the theorem statements. Code length and designed distance already have short formulas in this context. Minimum distance is mathematically more interesting but doesn't show up in any of the theorems.</p>",
        "id": 386721584,
        "sender_full_name": "D. J. Bernstein",
        "timestamp": 1692751967
    },
    {
        "content": "<p>Designed distance?</p>",
        "id": 386787681,
        "sender_full_name": "Wrenna Robson",
        "timestamp": 1692778309
    },
    {
        "content": "<p>That's 2t+1 in this paper. When there's a construction that outputs a code and a decoding algorithm that's guaranteed to decode any t errors, people talk about 2t+1 as the \"designed distance\" or \"design distance\" of the construction---or, sloppily, of the code. Obviously the minimum distance of the code is at least as large.</p>",
        "id": 386811490,
        "sender_full_name": "D. J. Bernstein",
        "timestamp": 1692786641
    },
    {
        "content": "<p>Oh, that makes sense. I'm not sure I've seen the term but I see why you'd have it.</p>",
        "id": 386816054,
        "sender_full_name": "Wrenna Robson",
        "timestamp": 1692788230
    },
    {
        "content": "<p>There is a new preprint on <span class=\"user-mention\" data-user-id=\"630204\">@D. J. Bernstein</span> 's site, <a href=\"https://cr.yp.to/papers.html#pwccp\">https://cr.yp.to/papers.html#pwccp</a>, titled \"Papers with computer-checked proofs\" It is an extremely interesting detailed and candid account of his recent formalizations, in both HOL Light  and  Lean (with mathlib) of various results (including the Goppa code article discussed upstream). </p>\n<p>I don't want to spoil it, but it is a paper that deserves to have a large audience. (Possibly too long for the rumored special issue(s) of the Bulletin of the AMS coming up?)</p>\n<p>Here is the Abstract: \"This report gives case studies supporting the hypothesis that it is often affordable for a paper presenting theorems to also include proofs that have been checked with today’s proof-checking software.\"</p>\n<p>And a fun intro to one section: \"I heard about proof-checking software last century, but my first project...\"</p>\n<p>If you don't have time to read the whole paper, the introduction (pages 1--6) is recommended to all.</p>",
        "id": 390341244,
        "sender_full_name": "Oisin McGuinness",
        "timestamp": 1694447382
    },
    {
        "content": "<p>Thanks for the kind words! I think what most mathematicians have heard about formalization amounts to \"It's really painful\" and so they don't even consider it, even when they're in what I think is a very common situation, namely that they could rapidly get their N pages of proofs formalized along with adding &lt;2N pages of background material to proof-assistant libraries. I'm hoping that more papers quantifying formalization time can give further authors a better idea of what's possible.</p>",
        "id": 390389895,
        "sender_full_name": "D. J. Bernstein",
        "timestamp": 1694467342
    },
    {
        "content": "<p>Yes I think you're publically displaying data which there is a dearth of.</p>",
        "id": 390390443,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1694467659
    },
    {
        "content": "<p>Just one comment on: </p>\n<p>\"in the words of 1991 de Bruijn [28], referees “need not bother about correctness and can concentrate on whether the paper is interesting and new”\"</p>\n<p>This was <em>not</em> my experience editing the Exp Math special issue; referees discovered a mistake in the way a key concept was formalized, and the formalization had to be redone!... See: <a href=\"https://www.tandfonline.com/doi/full/10.1080/10586458.2022.2088982\">https://www.tandfonline.com/doi/full/10.1080/10586458.2022.2088982</a></p>\n<p>(Of course I agree that, once the definitions and statements have been carefully checked, the rest of the refereeing load is significantly reduced. But sometimes the definitions are <em>the</em> key new idea, and can be extremely complicated...)</p>",
        "id": 390494736,
        "sender_full_name": "Alex Kontorovich",
        "timestamp": 1694516516
    },
    {
        "content": "<p>Section 4.2 of my report focuses on risks of misformalizations. Countermeasures are previewed in Section 2.1, in various examples in Section 3, and in Section 4.1. Of course, even without computers, people often get definitions terribly wrong, whether the complications come from the depth of (some) pure mathematics or from the intrinsic complexity of (some) applications: for example, [72] surveys proof failures in cryptography, and many of the failures are convincingly attributed to bad definitions.</p>",
        "id": 390506286,
        "sender_full_name": "D. J. Bernstein",
        "timestamp": 1694520830
    },
    {
        "content": "<p>My reading of de Bruijn's article is that his concept of a referee evaluating whether the paper is \"interesting\" started with referees being given the formalized version of the paper, and his \"lighten the burden\" came from the referee not having to worry about whether the proofs are correct. I wouldn't interpret \"lighten\" as \"eliminate\".</p>",
        "id": 390508793,
        "sender_full_name": "D. J. Bernstein",
        "timestamp": 1694521611
    }
]