[
    {
        "content": "<p>I have a few ideal membership problem that I'd like to verify in Lean, but it seems that they are too large for <code>grind</code>/<code>grobner</code>, or any tactic that I know to handle. I opened <a href=\"https://github.com/leanprover/lean4/issues/11861\">https://github.com/leanprover/lean4/issues/11861</a> for this, which understandably is low priority as a performance enhancement request, but I am still seeking for a solution to my own problem.</p>\n<p>One of the lemma I'd like to prove is <a href=\"https://live.lean-lang.org/#project=lean-nightly&amp;codez=FAFwFgpg9gThC2ACAZlKxGIBQFdE0QGtEAPRAT0QC9EBDRAI0QGNEAuRAJVpAEoNsYKO2xkAtIjwAqar0QA9RACZEAagoLliCQUUqZNPYgC8iAAz9MWMAEsR9I+qZGJrI6YsDrABwCOIshl6dUoZJgkaGVYPS0FiDmIXbDx1GDlHRABGE3M5Ni8CKQFMEtLsLGIZMnUsXDV8dK0JTLkZclaWTRVVYrK+rH1JRBlKui766XKUhvGJJQ76MLVevtWyrELk+rTtZQ7Rxc6etZOSgd261I7LrRk0jqYo7RXTksnRtz3hl9OqOWOTptatMdkFdsxrjdQYx6h8OpFJOkfogACzfPqUFy9XS3LRGEbjAyEl4bYmvcoVYakerA7aNFTNDrtKmfbrI07nGTvKkOLTqSa0q6zL5gpYA8nk0kyKFyOb7Hks5YS17nCQyqk3Qb3KmPTpidkS7lPPStA2/JHKzAAZnREqlUzpCtckJBD1hLPhvH+Bqw2QkeCSOPmto5tVG1QdQqSLSpzONfLNq05QwJYIyAvVSWDoph4sta3t6rlVIOirz+dKqq2Qul0y1Xp1iv1FbKRs6JpDFb+CkTpX0vewQPVYOdGuHuaIHqp3Y75beZJVlKqNMzTSyTI6rKVdsGbd53RTkZmWYWjbn+cLrt22cnOdY553Fyvtfq9bdT2bFbbrNN+e7RQ5IdnzGUdpXHJh1DhadGitOQPHYUwGHIAQAHMYCgBgADsIBgYAgA\">this one</a> (the same one attached in the issue). I have tried the following</p>\n<ul>\n<li><code>grind</code></li>\n<li>Ask sage to verify it, and generate the cofactors for each ideal generator as certificates. However these coefficients are several hundreds of KB long, and it overflows the stack when checking in Lean, even if I raise the stack limit</li>\n<li>Break down the computation into multiple stage and ask sage to reduce the polynomial at intermediate result: the intermediate result is still too long to even <em>state</em> in Lean. Lean hits recursion limit in instance synthesize</li>\n</ul>\n<p>So the only way left I can think of is to somehow implement a better grobner basis implementation in Lean for my specialized problem. I know that my polynomials all have integer coefficients, and I can delegate the initial calculation of grobner basis to sage, so I only need to implement the reduction part. How feasible is it to do better, given that I think <code>grind</code> is already very advanced?</p>\n<p>The rough implementation idea I have is</p>\n<ul>\n<li>implement an adhoc computable polynomial, possibly just as a list of monomials?</li>\n<li>map arithmetic to polynomial arithmetic </li>\n<li>define the reduction procedure as a program, and prove a theorem that this program doesn't change the ideal membership</li>\n<li><code>decide</code> (or, <code>native_decide</code> if I have to, which I accept for my own challenging problem) that the polynomial reduces to 0</li>\n</ul>\n<p>Does this sound good enough?</p>",
        "id": 566656875,
        "sender_full_name": "Weiyi Wang",
        "timestamp": 1767757450
    },
    {
        "content": "<p>Without using <code>native_decide</code> it is going to be a very challenging problem.</p>\n<p>In your linked example, I tried with</p>\n<div class=\"codehilite\" data-code-language=\"Lean4\"><pre><span></span><code><span class=\"kn\">set_option</span><span class=\"w\"> </span><span class=\"n\">maxHeartbeats</span><span class=\"w\"> </span><span class=\"mi\">0</span><span class=\"w\"> </span><span class=\"k\">in</span>\n<span class=\"kn\">set_option</span><span class=\"w\"> </span><span class=\"n\">maxRecDepth</span><span class=\"w\"> </span><span class=\"mi\">10</span><span class=\"bp\">_</span><span class=\"mi\">000</span><span class=\"w\"> </span><span class=\"k\">in</span>\n</code></pre></div>\n<p>and </p>\n<div class=\"codehilite\" data-code-language=\"Lean4\"><pre><span></span><code><span class=\"w\">  </span><span class=\"n\">grobner</span><span class=\"w\"> </span><span class=\"o\">(</span><span class=\"n\">ringSteps</span><span class=\"w\"> </span><span class=\"o\">:=</span><span class=\"w\"> </span><span class=\"mi\">1</span><span class=\"bp\">_</span><span class=\"mi\">000</span><span class=\"bp\">_</span><span class=\"mi\">000</span><span class=\"o\">)</span>\n</code></pre></div>\n<p>after a few cycles of reading <code>grind</code>'s diagnostics (in the \"Issues\" and \"Thresholds\" sections it tells you which limits to raise), but this still results in a server crash eventually, after consuming more than 128gb of RAM.</p>",
        "id": 566844076,
        "sender_full_name": "Kim Morrison",
        "timestamp": 1767829735
    },
    {
        "content": "<p>Got it. I am ok to have <code>native_decide</code> for now. This is just formalizing an old math problem for fun without intention to contribute it to mathlib anyway, and having a solution is better than having a <code>sorry</code> there for personal satisfaction.</p>",
        "id": 566844454,
        "sender_full_name": "Weiyi Wang",
        "timestamp": 1767830014
    },
    {
        "content": "<p>There might be a way for me to avoid <code>native_decide</code> by verbosely write down the reduction steps. This was what I wanted to do with the third bullet point in my previous attempts. It didn't work because the plan expression in the statements is too long for type class system to handle. I hope that if I encode it into an opaque list it won't invoke the system bypass the limits</p>",
        "id": 566845250,
        "sender_full_name": "Weiyi Wang",
        "timestamp": 1767830548
    },
    {
        "content": "<p><del>I already hit the first wall quickly... I'd like to use <a href=\"https://leanprover-community.github.io/mathlib4_docs/find/?pattern=MonomialOrder#doc\">docs#MonomialOrder</a> to avoid re-inventing the wheel, but it uses Finsupp, which seems ... very noncomputable? I just wanted to convert to my <code>Fin n → ℕ</code> to <code>Fin n →₀ ℕ</code>, using <a href=\"https://leanprover-community.github.io/mathlib4_docs/find/?pattern=Finsupp.equivFunOnFinite#doc\">docs#Finsupp.equivFunOnFinite</a>, but that immediately gives me noncomputable error</del> alright that's easy enough to resolve with a one liner <code>Finsupp.mk (Finset.univ.filter (m.exp · ≠ 0)) m.exp (by simp)</code></p>",
        "id": 566846612,
        "sender_full_name": "Weiyi Wang",
        "timestamp": 1767831611
    },
    {
        "content": "<p>I guess it is because it uses <code>Finite</code> but not <code>Fintype</code>...</p>",
        "id": 566846700,
        "sender_full_name": "Weiyi Wang",
        "timestamp": 1767831676
    },
    {
        "content": "<p>Is the proof too large for the kernel to handle or too large for the elaborator (e.g. tactics, typeclasses, type inference)? If the former, there's not much you can do except to restructure the proof; if the latter, you might be able to just bypass the elaborator completely and only have the kernel check it.</p>",
        "id": 566854686,
        "sender_full_name": "Niels Voss",
        "timestamp": 1767838002
    },
    {
        "content": "<p>For the three attempts I had, I know the third one is in elaborator. The second one might be in elaborator as well (something under the <code>linear_combination</code> tactic). For the first one, <code>grind</code> is too blackboxy for me to think</p>",
        "id": 566854922,
        "sender_full_name": "Weiyi Wang",
        "timestamp": 1767838149
    },
    {
        "content": "<p>Although I said I accept native_decide, I still want to see how far I can get with kernel. Now I am learning the hard way that it is not easy to make something reducible by kernel, let alone efficiently lol</p>",
        "id": 567060606,
        "sender_full_name": "Weiyi Wang",
        "timestamp": 1767923396
    },
    {
        "content": "<blockquote>\n<p>Is the proof too large for the kernel to handle or too large for the elaborator (e.g. tactics, typeclasses, type inference)?</p>\n</blockquote>\n<p>So I think the real answer to this is that it is too large for the kernel. I now have a bare bone computable polynomial implementation, and I let the kernel compute an expression around the same size of my problem. Eventually it hit stack overflow after I raise all the soft limits. I know it is not elaborator problem because I can send the same expression to <code>#eval</code> and compute without problem</p>",
        "id": 567062471,
        "sender_full_name": "Weiyi Wang",
        "timestamp": 1767924819
    },
    {
        "content": "<p>Does stack overflow just mean you need to adjust your <code>ulimit -s</code>? I am not familiar with if you're talking about stack memory or some internal stack</p>",
        "id": 567092524,
        "sender_full_name": "Vlad Tsyrklevich",
        "timestamp": 1767947869
    },
    {
        "content": "<p>I hit the same kind of stack overflow message with previous attemp 2 as well. There I tried both setting ulimit and Leans's --tstack option but it didn't help</p>",
        "id": 567131900,
        "sender_full_name": "Weiyi Wang",
        "timestamp": 1767961987
    },
    {
        "content": "<p>Alright I finally proved my lemma... with <code>native_decide</code> and 3 minutes build time <span aria-label=\"face with peeking eye\" class=\"emoji emoji-1fae3\" role=\"img\" title=\"face with peeking eye\">:face_with_peeking_eye:</span></p>",
        "id": 567291506,
        "sender_full_name": "Weiyi Wang",
        "timestamp": 1768018288
    },
    {
        "content": "<p>Nice! Are there reusable components? It would be great to have an example recorded somewhere for people who need to do large Grobner reductions.</p>",
        "id": 567303839,
        "sender_full_name": "Kim Morrison",
        "timestamp": 1768034507
    },
    {
        "content": "<p>I have it uploaded to my current project repo but it's still a mess at the moment. Going tk have some fun optimizing and cleaning up in the following days</p>",
        "id": 567316586,
        "sender_full_name": "Weiyi Wang",
        "timestamp": 1768048317
    },
    {
        "content": "<p>For whoever searched for this thread, I recorded my first proof of the lemma in the OP <a href=\"https://github.com/wwylele/Poncelet/blob/6dcb9d1eaeed0d44e69d9bde923e382fba310ea6/Poncelet/Heavy/Inverse1.lean#L48\">here</a>. I am going to learn writing tactics and wrap the scaffolding in a nicer way</p>",
        "id": 567333913,
        "sender_full_name": "Weiyi Wang",
        "timestamp": 1768064935
    }
]