[
    {
        "content": "<p>Hi, I'm looking to formalize backpropagation (<a href=\"http://neuralnetworksanddeeplearning.com/chap2.html\">http://neuralnetworksanddeeplearning.com/chap2.html</a>) in Lean as a learning exercise.  1) Is this too difficult for a beginner in Lean 2) If not, could somebody familiar with Lean and Backprop possibly point me in the right direction.</p>\n<p>Thanks!</p>",
        "id": 527380453,
        "sender_full_name": "Tony Johnson",
        "timestamp": 1751845035
    },
    {
        "content": "<p>Caveat: I last looked at this area over 10 years ago and am somewhat new to Lean. I don't know what you mean by formalise here. Do you mean a Lean version of what has been done in Haskell: <a href=\"https://hackage.haskell.org/package/backprop\">https://hackage.haskell.org/package/backprop</a>? I haven't looked but I haven't seen anything about AD on zulip or stochastic gradient descent for that matter.</p>",
        "id": 527615793,
        "sender_full_name": "Dominic Steinitz",
        "timestamp": 1751957936
    },
    {
        "content": "<p>And although I have programmed in Haskell for over 30 years, I found proving things in Lean a steep learning curve.</p>",
        "id": 527616009,
        "sender_full_name": "Dominic Steinitz",
        "timestamp": 1751958034
    }
]