[
    {
        "content": "<p>This might be a very stupid question. But I want to see how to cache intermediate results in tactics.</p>\n<p>For example, I might have a big first \"first | t1 | ... | tn\" with n very large, in the first run of lean compiler, it finds that tk just works. How to directly cache this so that next time it directly just tries tk?</p>\n<p>I ask this because otherwise one has to manually reduce the big first to tk for compilation efficiency. Having a cached version completely nukes the problem. There will be no scaling problem with using big tactics.</p>",
        "id": 486695321,
        "sender_full_name": "Xiyu Zhai",
        "timestamp": 1733597804
    },
    {
        "content": "<p>There is a <a href=\"https://leanprover-community.github.io/mathlib4_docs/find/?pattern=Lean.Parser.Tactic.save#doc\">docs#Lean.Parser.Tactic.save</a> tactic that caches the tactic state. It helps when you're working on a heavy proof and don't want to wait for the entire proof above the cursor to be processed again every time you change something.</p>",
        "id": 486719550,
        "sender_full_name": "Vasilii Nesterov",
        "timestamp": 1733619000
    },
    {
        "content": "<p>But this tactic is for proof development, and has nothing to do with compilation efficiency. During compilation, each theorem is compiled only once, so no cache is needed.</p>",
        "id": 486720758,
        "sender_full_name": "Vasilii Nesterov",
        "timestamp": 1733620058
    },
    {
        "content": "<p>Thanks a lot! That's very interesting!</p>\n<p>I'm tailored to believe the design of a tactic system has a lot to with specific use cases. I came across the thought on cached tactics in thinking about AI completing lean proofs.</p>",
        "id": 486728116,
        "sender_full_name": "Xiyu Zhai",
        "timestamp": 1733627246
    }
]