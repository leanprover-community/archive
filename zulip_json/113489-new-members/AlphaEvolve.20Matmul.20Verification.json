[
    {
        "content": "<p>I tried verifying the correctness of the matrix multiplication formula in AlphaEvolve by DeepMind. I'm currently stuck on the last step, but I still want to share my code.</p>\n<p>As far as I know, the AlphaEvolve team discovered a formula that computes the product of two 4×4 matrices using only 48 complex number multiplications. This surpasses previous algorithms. (The Strassen algorithm, proposed in 1969, requires 49 multiplications. A straightforward implementation by definition needs 64 multiplications.)</p>\n<p><a href=\"https://github.com/google-deepmind/alphaevolve_results\">https://github.com/google-deepmind/alphaevolve_results</a><br>\nThe official Python verification code was published here, but it seems to involve concepts about tensors rather than directly implementing the matrix multiplication formula.</p>\n<p><a href=\"https://github.com/PhialsBasement/AlphaEvolve-MatrixMul-Verification\">https://github.com/PhialsBasement/AlphaEvolve-MatrixMul-Verification</a><br>\nThis person simplified the code and explicitly implemented the formula.</p>\n<hr>\n<p><a href=\"https://github.com/dx2102/AlphaEvolve-Matmul-Verification/blob/main/check.py\">https://github.com/dx2102/AlphaEvolve-Matmul-Verification/blob/main/check.py</a><br>\nBased on their code, I can verify the formula’s correctness with <code>sympy</code>: the result matrix computed by the new formula matches the matrix product defined by standard multiplication, after polynomial simplification. (Unfortunately the code seems to exceed Zulip's 10,000 character limit so I posted the github link)</p>\n<p><a href=\"https://github.com/dx2102/AlphaEvolve-Matmul-Verification/blob/main/check.lean\">https://github.com/dx2102/AlphaEvolve-Matmul-Verification/blob/main/check.lean</a><br>\nI also attempted to represent and prove the correctness in Lean. I managed to expand the definition of matrix multiplication. The next step is to verify that 16 huge polynomials simplify to zero. However, the problem is that <code>ring</code> doesn't seem to recognize that <code>Complex.I ^ 2 = -1</code>. The results after running <code>simp</code> and <code>ring</code> are both a bit strange.</p>\n<p>Given that even <code>sympy</code> takes a few seconds to simplify these polynomials, the process might be even slower in Lean. If anyone can still manage to complete this proof, I’d find it really interesting!</p>",
        "id": 519501658,
        "sender_full_name": "David Xu",
        "timestamp": 1747791157
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"476523\">@Sidharth Hariharan</span> I know you have exams right now but don't you have some beefed up<code>norm-num</code> which eats this for breakfast?</p>",
        "id": 519531003,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1747808238
    },
    {
        "content": "<p>Yes, our slight modification to <code>norm_num</code> handles expressions like <code>I ^ 2 = -1</code> (and more complicated expressions). However, it is limited to 'numerical' expressions, that is, expressions where the real and imaginary parts consist solely of numbers. I tried testing it on <span class=\"user-mention\" data-user-id=\"740877\">@Deming Xu</span>'s code, but the expressions there aren't numerical (they involve variables, namely, matrix entries), so our <code>norm_num</code> unfortunately doesn't seem to be able to handle them—at least, not on its own. Some combination of it with <code>ring</code> or <code>field_simp</code> might yield better results, but I'm not too sure. I'll send an update if I manage to get it working.</p>\n<p>That being said, I do remember there being a discussion about creating some kind of <code>ring</code> extension that'd be able to handle ring extensions with <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>i</mi></mrow><annotation encoding=\"application/x-tex\">i</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6595em;\"></span><span class=\"mord mathnormal\">i</span></span></span></span> (pun intended)...</p>",
        "id": 519844123,
        "sender_full_name": "Sidharth Hariharan",
        "timestamp": 1747922577
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"740877\">Deming Xu</span> <a href=\"#narrow/stream/113489-new-members/topic/AlphaEvolve.20Matmul.20Verification/near/519501658\">said</a>:</p>\n<blockquote>\n<p>I tried verifying the correctness of the matrix multiplication formula in AlphaEvolve by DeepMind. I'm currently stuck on the last step, but I still want to share my code.</p>\n<p>As far as I know, the AlphaEvolve team discovered a formula that computes the product of two 4×4 matrices using only 48 complex number multiplications. This surpasses previous algorithms. (The Strassen algorithm, proposed in 1969, requires 49 multiplications. A straightforward implementation by definition needs 64 multiplications.)</p>\n<p><a href=\"https://github.com/google-deepmind/alphaevolve_results\">https://github.com/google-deepmind/alphaevolve_results</a><br>\nThe official Python verification code was published here, but it seems to involve concepts about tensors rather than directly implementing the matrix multiplication formula.</p>\n<p><a href=\"https://github.com/PhialsBasement/AlphaEvolve-MatrixMul-Verification\">https://github.com/PhialsBasement/AlphaEvolve-MatrixMul-Verification</a><br>\nThis person simplified the code and explicitly implemented the formula.</p>\n<hr>\n<p><a href=\"https://github.com/dx2102/AlphaEvolve-Matmul-Verification/blob/main/check.py\">https://github.com/dx2102/AlphaEvolve-Matmul-Verification/blob/main/check.py</a><br>\nBased on their code, I can verify the formula’s correctness with <code>sympy</code>: the result matrix computed by the new formula matches the matrix product defined by standard multiplication, after polynomial simplification. (Unfortunately the code seems to exceed Zulip's 10,000 character limit so I posted the github link)</p>\n<p><a href=\"https://github.com/dx2102/AlphaEvolve-Matmul-Verification/blob/main/check.lean\">https://github.com/dx2102/AlphaEvolve-Matmul-Verification/blob/main/check.lean</a><br>\nI also attempted to represent and prove the correctness in Lean. I managed to expand the definition of matrix multiplication. The next step is to verify that 16 huge polynomials simplify to zero. However, the problem is that <code>ring</code> doesn't seem to recognize that <code>Complex.I ^ 2 = -1</code>. The results after running <code>simp</code> and <code>ring</code> are both a bit strange.</p>\n<p>Given that even <code>sympy</code> takes a few seconds to simplify these polynomials, the process might be even slower in Lean. If anyone can still manage to complete this proof, I’d find it really interesting!</p>\n</blockquote>\n<p>That tensor stuff is standard in the literature on improving the matrix multiplication constant. The good news is that these are computer scientists’ tensors.</p>",
        "id": 519928144,
        "sender_full_name": "Shreyas Srinivas",
        "timestamp": 1747951598
    },
    {
        "content": "<p>Basically n dimensional arrays.</p>",
        "id": 519928241,
        "sender_full_name": "Shreyas Srinivas",
        "timestamp": 1747951665
    }
]