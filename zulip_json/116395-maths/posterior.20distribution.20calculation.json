[
    {
        "content": "<p>I am currently thinking about how to calculate the posterior distribution of the following problem: </p>\n<ol>\n<li>Let x1, . . . , xm be i.i.d. sample from a normal distribution with mean \\mu and variance \\sigma^2. Suppose for each x_i we observe y_i = |x_i| rather than x_i. How do I calculate the posterior distribution of p(x_i | y_i, \\mu, \\sigma^2) for this problem?</li>\n<li>In addition, can we directly derive the gradient of the parameters \\mu and \\sigma^2? Use the log-likelihood function l(\\mu, \\sigma^2; y) to derive the parameters. I found that this seems to be difficult to find because the distribution of y is more complicated.</li>\n</ol>",
        "id": 483682571,
        "sender_full_name": "leo Robert",
        "timestamp": 1732191672
    },
    {
        "content": "<p>Short answer: at the moment we don't have the tools that would allow an easy computation.</p>\n<p>Let's proceed with the longer answer.<br>\nYou can express the conditional distribution of x given y with <a href=\"https://leanprover-community.github.io/mathlib4_docs/Mathlib/Probability/Kernel/CondDistrib.html#ProbabilityTheory.condDistrib\">ProbabilityTheory.condDistrib</a>, which is formally a Markov kernel (<a href=\"https://leanprover-community.github.io/mathlib4_docs/Mathlib/Probability/Kernel/Defs.html#ProbabilityTheory.Kernel\">ProbabilityTheory.Kernel</a>).</p>\n<p>Alternatively, it might be easier to not work with random variables but with measures and Markov kernels. You have a Gaussian measure that you map by a measurable function (the absolute value). You can identify the function with its deterministic kernel and use the definition of a posterior kernel that I wrote here: <a href=\"https://github.com/RemyDegenne/testing-lower-bounds/blob/0f09ff100a06a5e4542181514bfff74213ae126b/TestingLowerBounds/Kernel/BayesInv.lean#L43\">https://github.com/RemyDegenne/testing-lower-bounds/blob/0f09ff100a06a5e4542181514bfff74213ae126b/TestingLowerBounds/Kernel/BayesInv.lean#L43</a> . What is called <code>bayesInv</code> there is a posterior (it's called Bayesian inverse in some parts of the literature). However note that this is not in Mathlib but in another project and the lemmas about it depend on other results from that project.</p>\n<p>That does not tell you much about how you can actually compute the posterior, and I am afraid that at the moment Mathlib will have very few lemmas to help you with that, but at least you can write that object in Lean.</p>",
        "id": 483685926,
        "sender_full_name": "Rémy Degenne",
        "timestamp": 1732192751
    },
    {
        "content": "<p>Sorry I just saw that this is in the <a class=\"stream\" data-stream-id=\"116395\" href=\"/#narrow/channel/116395-maths\">#maths</a>  channel, and not <a class=\"stream\" data-stream-id=\"217875\" href=\"/#narrow/channel/217875-Is-there-code-for-X.3F\">#Is there code for X?</a> . Are you asking about how to do it in Lean, or how to do it in paper maths?</p>",
        "id": 483687198,
        "sender_full_name": "Rémy Degenne",
        "timestamp": 1732193148
    },
    {
        "content": "<p>Yeah, I want to ask how to do it in paper math</p>",
        "id": 483688409,
        "sender_full_name": "leo Robert",
        "timestamp": 1732193497
    },
    {
        "content": "<p>Then why are you asking on the lean Zulip? :-)</p>",
        "id": 483843358,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1732255877
    }
]