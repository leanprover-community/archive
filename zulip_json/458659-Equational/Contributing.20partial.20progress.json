[
    {
        "content": "<p>It might be useful in this project to have some organized way to contribute \"partial progress\" towards some end goal in a way that's visible. Right now, for automatically generated proofs, it's hard for someone else to know what partial progress has been made in a particular direction because only the final Lean proofs are added to Generated/.</p>\n<p>For example, in a few different places I've mentioned that I've enumerated all 4^(4*4) magmas and can derive a bunch of refutations from this. But I don't have the Lean knowledge to actually formalize this yet (or the time right now), and so there's not a good way for me to add this to someone other people can see.</p>\n<p>This means other people have been duplicating work on this problem, when it would be better to continue from where I left it off. So it would be great if I could put these partial results somewhere so someone else could pick up on it and finish formalizing it, much like is being done in <a href=\"https://github.com/leanprover-community/mathlib4/pull/19\">#19</a> for the finite polynomials.</p>\n<p>I've noticed other people have made similar partial progress on generating candidate refutations using different approaches, too, but don't have anywhere to \"broadcast\" their partial progress.</p>\n<p>I don't have any great solutions, but off the top of my head I could imagine:</p>\n<ul>\n<li>Committing a PR with the partial solution to Generated/ (or a new location? WIP/)</li>\n<li>Submitting a PR to create a branch on your local fork of the project, and merging new changes into that fork until the work is complete.</li>\n<li>Track partial progress on an issue</li>\n</ul>\n<p>For generated solutions, it would also be great to have a way to share data. Enumerating over all 2^32 magmas takes some time, but after it's done, I can reduce it down to a set of just 500k \"unique\" magmas (in that: they partition the equations differently). So sharing this file would save others from the compute time of running the brute force search again.</p>",
        "id": 473467376,
        "sender_full_name": "Nicholas Carlini",
        "timestamp": 1727628126
    },
    {
        "content": "<p>I believe that's exactly what you should use <code>conjecture</code> for (maybe that's not a great name) --- statements we're fairly sure are true, but don't have a proof in Lean yet</p>",
        "id": 473467441,
        "sender_full_name": "Daniel Weber",
        "timestamp": 1727628206
    },
    {
        "content": "<p>Currently any issue for which a PR has been proposed is in the \"In progress\" column of the project dashboard taskview.</p>",
        "id": 473467455,
        "sender_full_name": "Shreyas Srinivas",
        "timestamp": 1727628231
    },
    {
        "content": "<p>So if you coordinate on this issue, and comment on it,  you can already avoid the redundant work part</p>",
        "id": 473467494,
        "sender_full_name": "Shreyas Srinivas",
        "timestamp": 1727628262
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"761294\">Nicholas Carlini</span> <a href=\"#narrow/stream/458659-Equational/topic/Contributing.20partial.20progress/near/473467376\">said</a>:</p>\n<blockquote>\n<p>For example, in a few different places I've mentioned that I've enumerated all 4^(4*4) magmas and can derive a bunch of refutations from this. But I don't have the Lean knowledge to actually formalize this yet (or the time right now),</p>\n</blockquote>\n<p>As long as you put them in a file similar for the polynoimals, the actual expression in Lean will be rather similar.</p>\n<p>(Not addressing the problem of how to efficiently avoid duplicate work, but that’ll get better as the initial rush ebbs down.)</p>",
        "id": 473467580,
        "sender_full_name": "Joachim Breitner",
        "timestamp": 1727628353
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"690858\">Daniel Weber</span> <a href=\"#narrow/stream/458659-Equational/topic/Contributing.20partial.20progress/near/473467441\">said</a>:</p>\n<blockquote>\n<p>I believe that's exactly what you should use <code>conjecture</code> for (maybe that's not a great name) --- statements we're fairly sure are true, but don't have a proof in Lean yet</p>\n</blockquote>\n<p>Ah that's great. The way to do this would be to submit the source to Generated/ like the other code, and then Conjectures to theorems/?</p>",
        "id": 473467695,
        "sender_full_name": "Nicholas Carlini",
        "timestamp": 1727628401
    },
    {
        "content": "<p>One thing you don't want to do is put everything in one PR</p>",
        "id": 473467702,
        "sender_full_name": "Shreyas Srinivas",
        "timestamp": 1727628407
    },
    {
        "content": "<p>If you can break the task into smaller chunk and post separate issues, one of the maintainers can look at it and make it a project task.</p>",
        "id": 473467737,
        "sender_full_name": "Shreyas Srinivas",
        "timestamp": 1727628454
    },
    {
        "content": "<p>And yeah you can use <code>conjecture</code> and <code>proof_wanted</code> to leave stubs</p>",
        "id": 473467823,
        "sender_full_name": "Shreyas Srinivas",
        "timestamp": 1727628533
    },
    {
        "content": "<p>As I understand it, GitHub projects also allows creating roadmaps. I am not on my machine so I can't explore it right away</p>",
        "id": 473467926,
        "sender_full_name": "Shreyas Srinivas",
        "timestamp": 1727628612
    },
    {
        "content": "<p>What's the best way to host data? 500k tables isn't enormous, but I don't think I want to be committing 66MB to the git repo. (Although in this case, it'll probably shrink considerably once I dedup against the ones already resolved in <a href=\"https://github.com/leanprover-community/mathlib4/pull/19\">#19</a>).</p>",
        "id": 473467931,
        "sender_full_name": "Nicholas Carlini",
        "timestamp": 1727628618
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"761294\">Nicholas Carlini</span> <a href=\"#narrow/stream/458659-Equational/topic/Contributing.20partial.20progress/near/473467695\">said</a>:</p>\n<blockquote>\n<p>Ah that's great. The way to do this would be to submit the source to Generated/ like the other code, and then Conjectures to theorems/?</p>\n</blockquote>\n<p>I thought you wanted to avoid the lean part :-). Just put a <code>.txt</code> file in a similar format somewhere, and I’ll pick it up from there</p>",
        "id": 473467966,
        "sender_full_name": "Joachim Breitner",
        "timestamp": 1727628648
    },
    {
        "content": "<p>If the file is still too large, then maybe not yet. Can you use the list of known implications to reduce it to list only interesting facts (in this case you have to list both equations satisfied and non-satisfied in your format)</p>",
        "id": 473468029,
        "sender_full_name": "Joachim Breitner",
        "timestamp": 1727628714
    },
    {
        "content": "<p>We could try integration with kaggle or zenodo</p>",
        "id": 473468258,
        "sender_full_name": "Shreyas Srinivas",
        "timestamp": 1727628926
    },
    {
        "content": "<p>Yes, the <code>conjecture</code> keyword is suitable for auto-generated claims whose statement is formalized in Lean, but the proof is not yet available (and some subsequent task would be to convert them to a <code>theorem</code>).  It is functionally similar to <code>proof_wanted</code> on the front-end, but at the back-end we would like you to use <code>conjecture</code> instead of <code>proof_wanted</code> because the former contains some metadata that will allow us to easily scoop up all the conjectures present in a given dependency tree of Lean files.  (We are also currently talking about similarly converting <code>theorem</code> to another functionally similar keyword that would carry similar metadata, see <a class=\"stream-topic\" data-stream-id=\"458659\" href=\"/#narrow/stream/458659-Equational/topic/Lean.20script.20for.20extracting.20current.20set.20of.20implications\">#Equational &gt; Lean script for extracting current set of implications</a> )</p>",
        "id": 473469580,
        "sender_full_name": "Terence Tao",
        "timestamp": 1727630001
    },
    {
        "content": "<blockquote>\n<p>We are also currently talking about similarly converting <code>theorem</code> to another functionally similar keyword that would carry similar metadata</p>\n</blockquote>\n<p>Current plan is to keep these using the <code>theorem</code> keyword and to add an attribute <code>@[equational_result]</code>. (Discussed in the linked thread.)</p>",
        "id": 473471187,
        "sender_full_name": "David Renshaw",
        "timestamp": 1727630523
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"470149\">Joachim Breitner</span> <a href=\"#narrow/stream/458659-Equational/topic/Contributing.20partial.20progress/near/473467966\">said</a>:</p>\n<blockquote>\n<p>I thought you wanted to avoid the lean part :-). Just put a <code>.txt</code> file in a similar format somewhere, and I’ll pick it up from there</p>\n</blockquote>\n<p>I've reduced the set of 500k tables down to just 500 \"covering tables\". This loses some interestingness data (about implications A=/&gt;B that we can only refute due to a very small number of tables) but we can recover that later. I'll submit a PR with this partial data shortly.</p>",
        "id": 473472871,
        "sender_full_name": "Nicholas Carlini",
        "timestamp": 1727631007
    },
    {
        "content": "<p>That's sensible, thanks.</p>",
        "id": 473473358,
        "sender_full_name": "Joachim Breitner",
        "timestamp": 1727631470
    },
    {
        "content": "<p>Is the data set with the polynomial based ones also reduced in the same way?</p>\n<p>And do any of the two subsume the other?</p>",
        "id": 473473758,
        "sender_full_name": "Joachim Breitner",
        "timestamp": 1727631816
    },
    {
        "content": "<p>It is \"mostly\" reduced. I did a bit more fancy reducing on this one</p>",
        "id": 473473814,
        "sender_full_name": "Nicholas Carlini",
        "timestamp": 1727631849
    },
    {
        "content": "<p>For the polynomials, I process them in order, and only add a new polynomial if it covers something not seen previously.</p>",
        "id": 473473828,
        "sender_full_name": "Nicholas Carlini",
        "timestamp": 1727631867
    },
    {
        "content": "<p>But this does not yet prune based on known implications, right?</p>",
        "id": 473473877,
        "sender_full_name": "Joachim Breitner",
        "timestamp": 1727631916
    },
    {
        "content": "<p>But it is possible that adding one polynomial then makes a previous one redundant. I didn't handle that case for these. I added that logic for this new set because it brings me from 500k -&gt; 1.5k for the initial prune, then down to just 500 after several rounds of pruning.</p>",
        "id": 473473883,
        "sender_full_name": "Nicholas Carlini",
        "timestamp": 1727631924
    },
    {
        "content": "<p>Sorry what do you mean?</p>",
        "id": 473473889,
        "sender_full_name": "Nicholas Carlini",
        "timestamp": 1727631929
    },
    {
        "content": "<p>We know Equation92 implies Equation91.<br>\nSo if a magma satisifies 92, we don't have to also include 91 in the list of satisfies equations.<br>\nLikewise, if another magma does not satisfies 91, then we don’t have to include 92 in the list of refuted equations.<br>\nI expect pruning the list of equations to prove for a given example magma this way will bring file size and processing time down significantly.</p>",
        "id": 473474071,
        "sender_full_name": "Joachim Breitner",
        "timestamp": 1727632076
    },
    {
        "content": "<p>Although we can do that pruning when converting from the data files to the lean files, if you’d rather keep the data files complete.</p>",
        "id": 473474146,
        "sender_full_name": "Joachim Breitner",
        "timestamp": 1727632131
    },
    {
        "content": "<p>I don't think trimming those out works . Suppose I have a magma with equations A, B. Suppose also A=&gt;B. I need to keep them both in, because this set tells me lots of A =/&gt; X and B =/&gt;X for many X. If I removed B, you lose all of these. Right?</p>",
        "id": 473474274,
        "sender_full_name": "Nicholas Carlini",
        "timestamp": 1727632221
    },
    {
        "content": "<p>There are already ruby scripts in the scripts folder for doing this</p>",
        "id": 473474297,
        "sender_full_name": "Shreyas Srinivas",
        "timestamp": 1727632243
    },
    {
        "content": "<p><a href=\"https://github.com/teorth/equational_theories/blob/main/scripts/transitive_reduction.rb\">https://github.com/teorth/equational_theories/blob/main/scripts/transitive_reduction.rb</a></p>",
        "id": 473474485,
        "sender_full_name": "Shreyas Srinivas",
        "timestamp": 1727632386
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"761294\">Nicholas Carlini</span> <a href=\"#narrow/stream/458659-Equational/topic/Contributing.20partial.20progress/near/473474274\">said</a>:</p>\n<blockquote>\n<p>If I removed B, you lose all of these. Right?</p>\n</blockquote>\n<p>No, why? Your data set says “M satisfies A and does not satsify X”. That suffices, doesn’t it? Downstream tools (those drawaing the graphs) will know that A → B, and thus also B /→ X – no need to waste CPU time on proving that M satisfies B.</p>",
        "id": 473474683,
        "sender_full_name": "Joachim Breitner",
        "timestamp": 1727632554
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"466334\">Shreyas Srinivas</span> <a href=\"#narrow/stream/458659-Equational/topic/Contributing.20partial.20progress/near/473474485\">said</a>:</p>\n<blockquote>\n<p><a href=\"https://github.com/teorth/equational_theories/blob/main/scripts/transitive_reduction.rb\">https://github.com/teorth/equational_theories/blob/main/scripts/transitive_reduction.rb</a></p>\n</blockquote>\n<p>That’s for implications, isn’t it? Not quite what we are looking for here – we want to reduce antiimplications given a set of known implications.</p>",
        "id": 473474769,
        "sender_full_name": "Joachim Breitner",
        "timestamp": 1727632577
    },
    {
        "content": "<p>I can write something in Lean once <a href=\"https://github.com/teorth/equational_theories/pull/93\">equational#93</a> is merged, what API should it have?</p>",
        "id": 473474898,
        "sender_full_name": "Daniel Weber",
        "timestamp": 1727632688
    },
    {
        "content": "<p>Okay you're probably right. I don't do this now yet. If you want to reduce it further and can derive the same results that seems worth doing</p>",
        "id": 473474899,
        "sender_full_name": "Nicholas Carlini",
        "timestamp": 1727632691
    },
    {
        "content": "<p>Right. But if your data files (reduced by you) are of reasonable size, then it makes sense to make that reduction when converting to lean.</p>",
        "id": 473474936,
        "sender_full_name": "Joachim Breitner",
        "timestamp": 1727632742
    },
    {
        "content": "<p>Yeah they are. Will have the PR up shortly</p>",
        "id": 473474955,
        "sender_full_name": "Nicholas Carlini",
        "timestamp": 1727632768
    },
    {
        "content": "<p>I’m running out of time for today.</p>\n<p>Once <a href=\"https://github.com/teorth/equational_theories/pull/110\">https://github.com/teorth/equational_theories/pull/110</a> is merged then <a href=\"https://github.com/teorth/equational_theories/pull/19\">https://github.com/teorth/equational_theories/pull/19</a> (which converts the polynials) is ready, I’d say. It doesn’t do this reduction yet, but maybe we can merge that already and iterate on <code>main</code>.</p>",
        "id": 473475040,
        "sender_full_name": "Joachim Breitner",
        "timestamp": 1727632812
    },
    {
        "content": "<p>Code is up at <a href=\"https://github.com/teorth/equational_theories/pull/111\">https://github.com/teorth/equational_theories/pull/111</a></p>",
        "id": 473475333,
        "sender_full_name": "Nicholas Carlini",
        "timestamp": 1727633019
    },
    {
        "content": "<p>Here is something that you maybe can do already, similar to your covering reduction.<br>\nSay you have one M1 satisfying <code>[1,2]</code> and refuting <code>[3,4]</code>. <br>\nAnd M2 satisfies <code>[1]</code> and refutes <code>[2,3,4]</code>. Then testing 3 and 4 doesn't really tell us anything new, And it would suffice to look at equation 1 and 2 here.</p>\n<p>I suspect that this will reduce the data set quite some more.</p>\n<p>Even without this it would be good to include in the data set both lists, satisfied and refutes, so that it's clear what it's saying even when the list of equations is extended (which I believe there are plans for). Or does that make them too long (even with the a above reduction)?</p>",
        "id": 473478158,
        "sender_full_name": "Joachim Breitner",
        "timestamp": 1727634763
    },
    {
        "content": "<p>Yeah that's a good optimization to apply. I don't think it would make them too long, I just didn't for now because right now the sets are guaranteed to be complement of each other.</p>",
        "id": 473478506,
        "sender_full_name": "Nicholas Carlini",
        "timestamp": 1727634894
    }
]