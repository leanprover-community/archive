[
    {
        "content": "<p>We are rapidly approaching the point where the trivial Lean file structure we have right now of putting everything in a single <code>Basic.lean</code> file is not going to be sustainable.  So I would like to open a discussion on how best to structure the Lean code in a way that can sustainably handle many submissions (both large and small) from various contributors working on different portions of the graph (as opposed to the situation until yesterday in which the human contributors were mostly focused on a small (~20 vertex) portion of the graph).</p>\n<p>Here is what I am thinking as a first pass of a file structure:</p>\n<ul>\n<li>A <code>Magma.lean</code> file to store the basic API for Magmas (which currently is extremely rudimentary, but perhaps will become more sophisticated as per <span class=\"user-mention\" data-user-id=\"243562\">@Adam Topaz</span> 's proposed refactoring)</li>\n<li>A <code>Equations.lean</code> file, importing <code>Magma.lean</code>, that contains definitions of all the 4694 equations, with optional docstrings.</li>\n<li>Various contributed lean files, importing <code>Equations.lean</code>, that contain some set of implications and anti-implications, which could be computer-generated, human-generated, or some mix of both.  For instance one could have a project to completely map out some designated portion of the implication graph, in which one imports some large computer-generated lean files to settle all the \"easy\" implications and then have the human participants fill out the remaining ones.  The human proofs thus generated could then serve as templates to create further automated files to locate all other implications that can be resolved the same techique.</li>\n</ul>\n<p>The point is that these latter lean files could be worked on almost independently, and we would not need to coordinate via a single \"Outstanding tasks\" thread (which is rapidly becoming unwieldy) but could instead split into smaller groups.</p>\n<p>One technical issue with this structure is that it is possible that the same implication might be proven by two different groups, so that we have the same theorem with the same name proven in two different files.  This creates a conflict when importing from both files.  Perhaps there is some workaround for this issue using namespaces?  I'd be open to suggestions on this.</p>",
        "id": 473132914,
        "sender_full_name": "Terence Tao",
        "timestamp": 1727449815
    },
    {
        "content": "<p>That's exactly the structure I am already assuming in <a href=\"https://github.com/teorth/equational_theories/pull/19\">https://github.com/teorth/equational_theories/pull/19</a>.<br>\nThe splitting is also very helpful if some files are slow to process, to process them in parallel.</p>\n<p>Refinement suggestions: Put all generated lean files in a subdirectory <code>Generated/</code></p>",
        "id": 473135747,
        "sender_full_name": "Joachim Breitner",
        "timestamp": 1727450657
    },
    {
        "content": "<p>The duplicate names is only a problem if you try import all files into one. Maybe in the first phase it suffices if the lemma statements follow a certain pattern that can be read using a python script, when producing graphs and other aggregate information?</p>",
        "id": 473135749,
        "sender_full_name": "Joachim Breitner",
        "timestamp": 1727450658
    },
    {
        "content": "<p>I recommend one additional layer: 1 or more files that import all the files with the implications and non-implications. These can</p>\n<ul>\n<li>check for duplicate lemmas</li>\n<li>automatically generate Hasse-diagrams, todo-list, ...</li>\n</ul>",
        "id": 473139732,
        "sender_full_name": "Floris van Doorn",
        "timestamp": 1727451585
    },
    {
        "content": "<p>I wonder if that should really be a lean file at this point. Processing the auto-generated lean files can be very slow, and you don't really need a lean import here - hence my suggestion to implement that part pragmatically with python. No need to actually check all the proofs if you just want to update the diagrams and todo-lists. Proof checking can be done on CI, and shouldn't slow down anyone else working with the data.</p>",
        "id": 473140280,
        "sender_full_name": "Joachim Breitner",
        "timestamp": 1727451672
    },
    {
        "content": "<p>One option is that this last layer just outputs a list of pairs of proven implications and a list of pairs of disproven implications, and then programs in other languages can use these lists for data analysis. That seems more robust than trying to parse Lean using Python... <br>\nWe can also have a CI step run Lean with the option <code>set_option debug.byAsSorry true</code>, which will not verify any proofs but still can generate this data.</p>",
        "id": 473142095,
        "sender_full_name": "Floris van Doorn",
        "timestamp": 1727451970
    },
    {
        "content": "<p>If you say so… I expect you don’t gain that much from gathering the information of what is proved where from lean over something simple textual, but will run into otherwise avoidable hurdles. Anyways, as usually, power to those who do actually do it :-)</p>",
        "id": 473144639,
        "sender_full_name": "Joachim Breitner",
        "timestamp": 1727452389
    },
    {
        "content": "<p>How would you envision the all-importing file to collect the proven and dispoven implications?</p>\n<p>Checking for the existence of theorems with an expected name for each implication/nonimplication probably won’t scale (because we probably do not want to explicit list all nonimplications) and will cause problems with duplicates.</p>\n<p>So maybe go through the environment (or through a list of explicitly tagged theorems) and look at their type, looking for certain shapes? e.g. those of the form</p>\n<div class=\"codehilite\" data-code-language=\"Lean4\"><pre><span></span><code><span class=\"bp\">∀</span><span class=\"w\"> </span><span class=\"o\">(</span><span class=\"n\">G</span><span class=\"o\">:</span><span class=\"w\"> </span><span class=\"kt\">Type</span><span class=\"bp\">*</span><span class=\"o\">)</span><span class=\"w\"> </span><span class=\"o\">[</span><span class=\"n\">Magma</span><span class=\"w\"> </span><span class=\"n\">G</span><span class=\"o\">],</span><span class=\"w\"> </span><span class=\"n\">Equation4513</span><span class=\"w\"> </span><span class=\"n\">G</span><span class=\"w\"> </span><span class=\"bp\">→</span><span class=\"w\"> </span><span class=\"n\">Equation4512</span><span class=\"w\"> </span><span class=\"n\">G</span>\n<span class=\"bp\">∃</span><span class=\"w\"> </span><span class=\"o\">(</span><span class=\"n\">G</span><span class=\"o\">:</span><span class=\"w\"> </span><span class=\"kt\">Type</span><span class=\"o\">)</span><span class=\"w\"> </span><span class=\"o\">(</span><span class=\"bp\">_</span><span class=\"o\">:</span><span class=\"w\"> </span><span class=\"n\">Magma</span><span class=\"w\"> </span><span class=\"n\">G</span><span class=\"o\">),</span><span class=\"w\"> </span><span class=\"n\">Equation387</span><span class=\"w\"> </span><span class=\"n\">G</span><span class=\"w\"> </span><span class=\"bp\">∧</span><span class=\"w\"> </span><span class=\"bp\">¬</span><span class=\"w\"> </span><span class=\"n\">Equation42</span><span class=\"w\"> </span><span class=\"n\">G</span>\n<span class=\"bp\">∃</span><span class=\"w\"> </span><span class=\"o\">(</span><span class=\"n\">G</span><span class=\"w\"> </span><span class=\"o\">:</span><span class=\"w\"> </span><span class=\"kt\">Type</span><span class=\"o\">)</span><span class=\"w\"> </span><span class=\"o\">(</span><span class=\"bp\">_</span><span class=\"w\"> </span><span class=\"o\">:</span><span class=\"w\"> </span><span class=\"n\">Magma</span><span class=\"w\"> </span><span class=\"n\">G</span><span class=\"o\">),</span><span class=\"w\"> </span><span class=\"n\">Facts</span><span class=\"w\"> </span><span class=\"n\">G</span><span class=\"w\"> </span><span class=\"o\">[</span><span class=\"mi\">1</span><span class=\"o\">,</span><span class=\"w\"> </span><span class=\"mi\">2</span><span class=\"o\">,</span><span class=\"w\"> </span><span class=\"bp\">…</span><span class=\"o\">]</span><span class=\"w\"> </span><span class=\"o\">[</span><span class=\"mi\">4</span><span class=\"o\">,</span><span class=\"w\"> </span><span class=\"mi\">5</span><span class=\"o\">,</span><span class=\"w\"> </span><span class=\"bp\">…</span><span class=\"o\">]</span>\n</code></pre></div>\n<p>(using an atttribute is probably better, as that attribute can complain if the theorem statement isn't understood)</p>\n<p>We can even introduce a<code>magma_theorem</code> command with a syntax like <code>example</code> so that the poor user doesn’t have to come up with a name for each of these theorems, when the type is enough really :)</p>",
        "id": 473148427,
        "sender_full_name": "Joachim Breitner",
        "timestamp": 1727453000
    },
    {
        "content": "<p>I would imagine putting all results in a namespace, and then analyze the types of all declarations in that namespace. <br>\nIf we go with the <code>magma_theorem</code> route, we could also let that command put the data in an environment extension.</p>",
        "id": 473158372,
        "sender_full_name": "Floris van Doorn",
        "timestamp": 1727455718
    },
    {
        "content": "<p>Namespace works as well indeed, guess that's a nice and cheap way to simulate an attribute.</p>",
        "id": 473158934,
        "sender_full_name": "Joachim Breitner",
        "timestamp": 1727455835
    },
    {
        "content": "<p>\"everything under a certain namespace that matches a certain shape\" makes a lot of sense to me</p>",
        "id": 473162931,
        "sender_full_name": "David Renshaw",
        "timestamp": 1727456623
    },
    {
        "content": "<p>i think having it in an environment extension might be useful too though, i think that allows you to find the data in the <code>.olean</code> files, which might be easier to parse?</p>",
        "id": 473164708,
        "sender_full_name": "Edward van de Meent",
        "timestamp": 1727457105
    },
    {
        "content": "<p>i'm not an expert regarding this though, i just went \"i read about this a few weeks ago, that might be useful\"</p>",
        "id": 473164926,
        "sender_full_name": "Edward van de Meent",
        "timestamp": 1727457157
    },
    {
        "content": "<p>i don't know if it is practical</p>",
        "id": 473164958,
        "sender_full_name": "Edward van de Meent",
        "timestamp": 1727457167
    },
    {
        "content": "<p>I like the namespace containment proposal, as well as the idea of a \"ground truth\" lean file that imports all the other files and somehow computes the raw list of implications that can be obtained from the other files, which can then be post-processed by both Lean and non-Lean tools.  I also like not having to rely on specific naming conventions for implications, but using Lean's internal processing to figure out what has and has not yet been proved.</p>\n<p>In the immediate term, perhaps we can refactor <code>Basic.lean</code> into <code>Magma.lean</code>, <code>Equations.lean</code>, and say <code>Subgraph.lean</code> (this is a proposed name for the subproject to explore a designated small subgraph of the entire dependency graph - other suggestions welcome), and place all the implications in <code>Subgraph.lean</code> in a namespace?  Then we can expand <code>Equations.lean</code> to contain all 4694 equations instead of just 20 or so.   The incoming large collections of automatically generated implications could then also have a similar structure to <code>Subgraph.lean</code>, and then one would have some other lean file (name TBD, e.g., <code>Implications.lean</code>) to import all of these and process them to create the ground truth of Lean implications.</p>",
        "id": 473165342,
        "sender_full_name": "Terence Tao",
        "timestamp": 1727457258
    },
    {
        "content": "<p>For automatically-generated proofs, I would suggest we also have somewhere organized to store the corresponding code that generated these proofs so that everything can be reproduced (and understood).</p>",
        "id": 473167308,
        "sender_full_name": "Nicholas Carlini",
        "timestamp": 1727457759
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"761294\">Nicholas Carlini</span> <a href=\"#narrow/stream/458659-Equational/topic/Refactoring.20the.20Lean.20file.20structure/near/473167308\">said</a>:</p>\n<blockquote>\n<p>For automatically-generated proofs, I would suggest we also have somewhere organized to store the corresponding code that generated these proofs so that everything can be reproduced (and understood).</p>\n</blockquote>\n<p>I would also add that every automatically generated proof file should come with a chapter of the blueprint that explains the automatic generation process.  This can largely be a LaTeX file with very few metadata links to lean code.</p>",
        "id": 473167630,
        "sender_full_name": "Terence Tao",
        "timestamp": 1727457841
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"761294\">Nicholas Carlini</span> <a href=\"#narrow/stream/458659-Equational/topic/Refactoring.20the.20Lean.20file.20structure/near/473167308\">said</a>:</p>\n<blockquote>\n<p>For automatically-generated proofs, I would suggest we also have somewhere organized to store the corresponding code that generated these proofs so that everything can be reproduced (and understood).</p>\n</blockquote>\n<p>Of course! And - at least if possible - CI should check that they are actually the expected output of these tools.</p>",
        "id": 473169148,
        "sender_full_name": "Joachim Breitner",
        "timestamp": 1727458303
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"470149\">Joachim Breitner</span> <a href=\"#narrow/stream/458659-Equational/topic/Refactoring.20the.20Lean.20file.20structure/near/473169148\">said</a>:</p>\n<blockquote>\n<p>Of course! And - at least if possible - CI should check that they are actually the expected output of these tools.</p>\n</blockquote>\n<p>This  should be possible in principle for most cases. In my case, I'd have to re-run my massive refutation set because it's randomized and I didn't set an initial seed. (It takes &lt;4 hours to run, so it wouldn't take that long to do.)</p>\n<p>Although I can imagine some cases where it might be hard to guarantee \"deterministic builds\" if there's anything that ever were to involve some larger systems that's not a simple python script.</p>",
        "id": 473169789,
        "sender_full_name": "Nicholas Carlini",
        "timestamp": 1727458542
    },
    {
        "content": "<p>I have gone ahead and refactored <code>Basic.lean</code> into <code>Magma.lean</code>, <code>Equations.lean</code>, and <code>Subgraph.lean</code>, but I have not had time to verify that it actually works (for some reason Lean wanted to recompile all of Mathlib, which I am trying now to talk it out of).  Hopefully the commit I just made passes CI, but if not someone may need to fix it.  I have kept <code>Basic.lean</code> for now but noted that it is deprecated, and will remove it later.</p>",
        "id": 473193297,
        "sender_full_name": "Terence Tao",
        "timestamp": 1727465385
    },
    {
        "content": "<blockquote>\n<p>Hopefully the commit I just made passes CI</p>\n</blockquote>\n<p>Nope, but this fixes it: <a href=\"https://github.com/teorth/equational_theories/pull/24\">https://github.com/teorth/equational_theories/pull/24</a></p>",
        "id": 473198829,
        "sender_full_name": "David Renshaw",
        "timestamp": 1727467027
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"243791\">David Renshaw</span> <a href=\"#narrow/stream/458659-Equational/topic/Refactoring.20the.20Lean.20file.20structure/near/473198829\">said</a>:</p>\n<blockquote>\n<blockquote>\n<p>Hopefully the commit I just made passes CI</p>\n</blockquote>\n<p>Nope, but this fixes it: <a href=\"https://github.com/teorth/equational_theories/pull/24\">https://github.com/teorth/equational_theories/pull/24</a></p>\n</blockquote>\n<p>CI running</p>",
        "id": 473199657,
        "sender_full_name": "Shreyas Srinivas",
        "timestamp": 1727467339
    },
    {
        "content": "<p>Do you want me to run it on the other PR as well?</p>",
        "id": 473199926,
        "sender_full_name": "Shreyas Srinivas",
        "timestamp": 1727467462
    },
    {
        "content": "<p>Oh wait it failed</p>",
        "id": 473199970,
        "sender_full_name": "Shreyas Srinivas",
        "timestamp": 1727467477
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"657719\">Terence Tao</span> <a href=\"#narrow/stream/458659-Equational/topic/Refactoring.20the.20Lean.20file.20structure/near/473193297\">said</a>:</p>\n<blockquote>\n<p>I have gone ahead and refactored <code>Basic.lean</code> into <code>Magma.lean</code>, <code>Equations.lean</code>, and <code>Subgraph.lean</code>, but I have not had time to verify that it actually works (for some reason Lean wanted to recompile all of Mathlib, which I am trying now to talk it out of).  Hopefully the commit I just made passes CI, but if not someone may need to fix it.  I have kept <code>Basic.lean</code> for now but noted that it is deprecated, and will remove it later.</p>\n</blockquote>\n<p>Do you want equations.lean to have all of the equations, and each set of theorems to just bulk load them all from? In my PR I tried splitting out only those equations necessary for each proof because it takes ~20 minutes for lean to prove a few easy theorems when you load all 4k equations, compared to ~30 seconds if you just load the ones you need. But it's ugly to have to re-define each equation in multiple places.</p>\n<p>An alternate to consider would be to have a EquationXYZ.lean file per equation so just the ones you need to import for your proofs could be loaded.</p>",
        "id": 473206535,
        "sender_full_name": "Nicholas Carlini",
        "timestamp": 1727469318
    },
    {
        "content": "<p>I'd be very surprised that simply loading the file with 4000 defs is causing a slow down. On my PR I have all of them in one file and it's fine. <br>\nJust because all equations are in one file doesn't mean you have to process all of them in one downstream file, if that's the bottleneck.</p>",
        "id": 473209603,
        "sender_full_name": "Joachim Breitner",
        "timestamp": 1727470103
    },
    {
        "content": "<p>I was surprised too. But I have two files that differ only in the that one has all the definitions and the other doesn't, and one takes 30 seconds and the other 20 minutes. Maybe I'm invoking lean wrong and there's a \"--go-fast\" argument? My first time downloading lean was 6 hours ago...</p>",
        "id": 473209958,
        "sender_full_name": "Nicholas Carlini",
        "timestamp": 1727470206
    },
    {
        "content": "<p>Not at the computer right now. If you point to a PR with your work I can have a look (tomorrow).</p>",
        "id": 473210328,
        "sender_full_name": "Joachim Breitner",
        "timestamp": 1727470331
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"761294\">Nicholas Carlini</span> <a href=\"#narrow/stream/458659-Equational/topic/Refactoring.20the.20Lean.20file.20structure/near/473209958\">said</a>:</p>\n<blockquote>\n<p>I was surprised too. But I have two files that differ only in the that one has all the definitions and the other doesn't, and one takes 30 seconds and the other 20 minutes. Maybe I'm invoking lean wrong and there's a \"--go-fast\" argument? My first time downloading lean was 6 hours ago...</p>\n</blockquote>\n<p>I just learned about this, you want to preprocess the defs by putting them in a separate file and using lean -c to generate an .olean file, then include that.</p>",
        "id": 473223632,
        "sender_full_name": "Vlad Tsyrklevich",
        "timestamp": 1727475573
    },
    {
        "content": "<p>Are you not using <code>lake</code>?</p>",
        "id": 473247345,
        "sender_full_name": "Joachim Breitner",
        "timestamp": 1727477349
    },
    {
        "content": "<p>Thanks both. I'm running with <code>time lake env lean -c equational_theories/rewrites2/rewrite_ux_vz_wz_zx.lean</code>. If it's cached, though, then I only ran it once and didn't require the definitions cross-file, I just added them to the top of the file on each timing test. I will use lake and/or -c and it sounds like that should fix things.</p>",
        "id": 473247522,
        "sender_full_name": "Nicholas Carlini",
        "timestamp": 1727477484
    },
    {
        "content": "<p>Hmm, so if we end up putting all 4694 equations in a single <code>Equations.lean</code> file, is there a way to compile the file into an .olean file once and have that available for all contributors to use without having to recompile it?  I presume we would not touch the <code>Equations.lean</code> file very often (and if we do, we could make an .olean again).  </p>\n<p>Without having a common <code>Equations.lean</code> file, it's going to be difficult to integrate together many independent contributed Lean files proving different sets of implications... as suggested above one could instead have 4694 separate Equation files, and create various further Equations files for various specific sets of Equations, including an <code>Equations_all.lean</code> that imports all of them, but this feels clunky to me.  What is the best approach here?</p>",
        "id": 473253407,
        "sender_full_name": "Terence Tao",
        "timestamp": 1727481337
    },
    {
        "content": "<p>A file with all equations should be fine? I have that on my branch and it works well. The first compilation take a bit (maybe a minute or two), but once it's built I can import and use it quickly without issues. 4000 defs isn't thst large, compared to mathlib which you also import regularly… I don't quite see the issue here (but maybe I'm missing something or there is a big difference in workflow)</p>",
        "id": 473299606,
        "sender_full_name": "Joachim Breitner",
        "timestamp": 1727506942
    },
    {
        "content": "<p>That said, for a nicer onboarding for contributers that open files before building it may make sense to have two files, one with a few equations (maybe those with comments, and those for which we have manual implication proofs) and one that imports that and adds all other equations, typically imported by automated files.</p>",
        "id": 473301224,
        "sender_full_name": "Joachim Breitner",
        "timestamp": 1727507628
    },
    {
        "content": "<p>I’ll just do that now :-)</p>\n<p><a href=\"https://github.com/teorth/equational_theories/pull/48\">https://github.com/teorth/equational_theories/pull/48</a>, and merged.</p>",
        "id": 473310211,
        "sender_full_name": "Joachim Breitner",
        "timestamp": 1727511644
    },
    {
        "content": "<p>2 messages were moved from this topic to <a class=\"stream-topic\" data-stream-id=\"458659\" href=\"/#narrow/stream/458659-Equational/topic/A.20lean.20list.20of.20all.20equations.3F\">#Equational &gt; A lean list of all equations?</a> by <span class=\"user-mention silent\" data-user-id=\"470149\">Joachim Breitner</span>.</p>",
        "id": 473313532,
        "sender_full_name": "Notification Bot",
        "timestamp": 1727513092
    }
]