[
    {
        "content": "<p>I recently came across the <a href=\"https://github.com/secure-foundations/human-eval-verus\">human-eval-verus project</a> which collects hand-written formally verified solutions to the HumanEval benchmark (which was originally intended as an AI benchmark, but for the purposes of this project it's just a collection of simple programming problems) using the Verus Rust verification system. I thought it might be fun to have something similar for Lean, so I created <a href=\"https://github.com/TwoFX/human-eval-lean\">human-eval-lean</a> which aims to collect verified Lean solutions to the problems.</p>\n<p>So far I have imported all of the <a href=\"https://github.com/TwoFX/human-eval-lean/tree/master/HumanEvalLean\">problem statements</a>, <a href=\"https://github.com/TwoFX/human-eval-lean/blob/master/HumanEvalLean/HumanEval3.lean\">solved one of the easiest problems</a> and created an <a href=\"https://github.com/TwoFX/human-eval-lean/issues\">issue for every problem</a> to make it easy to discuss and claim issues.</p>\n<p>I thought that some members of this stream might find it fun to poke at the problems, see how far we can get, and gradually converge to a set of good solutions in idiomatic Lean. Having multiple solutions for some problems showing the various styles that Lean allows would also be great. Even just documenting in the issues which parts of the problem are difficult to solve/verify using Lean could be very useful for improving Lean as a verification platform.</p>\n<p>If that sounds interesting or fun, I'm looking forward to PRs and discussions!</p>\n<p>(Just to be clear: this effort is not connected to the Lean FRO, this is just me in my free time :))</p>",
        "id": 515255033,
        "sender_full_name": "Markus Himmel",
        "timestamp": 1746006072
    },
    {
        "content": "<p>I can try if I find a bit of free time</p>",
        "id": 515255906,
        "sender_full_name": "Shreyas Srinivas",
        "timestamp": 1746006306
    },
    {
        "content": "<p>But where is the task list?  Is there a checklist of completed tasks in the repo?</p>",
        "id": 515256040,
        "sender_full_name": "Shreyas Srinivas",
        "timestamp": 1746006349
    },
    {
        "content": "<p>The idea is to close the corresponding issue once a problem is solved, so outstanding tasks are just open issues. I might add all of the issues to a GitHub project so that it's possible to view the list in a more compact way.</p>",
        "id": 515257247,
        "sender_full_name": "Markus Himmel",
        "timestamp": 1746006647
    },
    {
        "content": "<p>You could borrow the system we used for equational theories</p>",
        "id": 515278961,
        "sender_full_name": "Shreyas Srinivas",
        "timestamp": 1746013091
    },
    {
        "content": "<p>Cool! Related: a few months ago I wrote a few simple programming problems with verified Lean solutions at <a href=\"https://github.com/GasStationManager/CodeProofBenchmark\">CodeProofBenchmark</a>. The problems were all in the range of easy to trivial, but I thought some of the proofs were less trivial, as least to me.</p>\n<p>Question: would you consider AI-written solutions, as long as the specifications are created or verified by humans? I don't know how the current LLMs will do, but it'd be fun to try.</p>",
        "id": 515310167,
        "sender_full_name": "GasStationManager",
        "timestamp": 1746020937
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"776090\">GasStationManager</span> <a href=\"#narrow/channel/236449-Program-verification/topic/Collecting.20small.20program.20verification.20examples/near/515310167\">said</a>:</p>\n<blockquote>\n<p>Question: would you consider AI-written solutions, as long as the specifications are created or verified by humans? I don't know how the current LLMs will do, but it'd be fun to try.</p>\n</blockquote>\n<p>Sure, feel free to use whatever tools are useful to you when creating solutions.</p>",
        "id": 516224023,
        "sender_full_name": "Markus Himmel",
        "timestamp": 1746456990
    },
    {
        "content": "<p>There has been some criticism of humaneval as a target. <br>\nI'm not an expert, but quick googling gave me some alternatives. More knowledgeable experts will hopefully supplement me on this.<br>\n<a href=\"https://github.com/CoderEval/CoderEval\">https://github.com/CoderEval/CoderEval</a><br>\n<a href=\"https://github.com/evalplus/evalplus?tab=readme-ov-file\">https://github.com/evalplus/evalplus?tab=readme-ov-file</a></p>\n<p><a href=\"https://blog.continue.dev/an-introduction-to-code-llm-benchmarks-for-software-engineers/\">https://blog.continue.dev/an-introduction-to-code-llm-benchmarks-for-software-engineers/</a><br>\n<a href=\"https://huggingface.co/blog/leaderboard-bigcodebench\">https://huggingface.co/blog/leaderboard-bigcodebench</a></p>\n<p>Apparently, this one already provides unit tests for Lean (and Rocq and ocaml ...)<br>\n<a href=\"https://github.com/nuprl/MultiPL-E?tab=readme-ov-file\">https://github.com/nuprl/MultiPL-E?tab=readme-ov-file</a></p>",
        "id": 516448239,
        "sender_full_name": "Bas Spitters",
        "timestamp": 1746538817
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"259452\">Bas Spitters</span> <a href=\"#narrow/channel/236449-Program-verification/topic/Collecting.20small.20program.20verification.20examples/near/516448239\">said</a>:</p>\n<blockquote>\n<p>There has been some criticism of humaneval as a target</p>\n</blockquote>\n<p>As I understand it (correct me if I'm wrong), this criticism is aimed at HumanEval when used to evaluate LLMs. Since human-eval-lean isn't about that, and focuses on evaluating Lean as a programming language and verification platform instead, I think it's not a problem to use it for this project.</p>",
        "id": 516465326,
        "sender_full_name": "Markus Himmel",
        "timestamp": 1746543023
    }
]