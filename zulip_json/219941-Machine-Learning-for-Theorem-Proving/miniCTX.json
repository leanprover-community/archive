[
    {
        "content": "<p><a href=\"https://arxiv.org/pdf/2408.03350\">miniCTX</a> just came out. The central premise of this work is that the lemmas that directly precede the theorem currently being proved is crucial context knowledge for proving agents. If I understand correctly, their approach is to predict the next tactic not only based on the current proof state but also based on the entire file's source code up until the current position. They fine-tune a LLM based with such a dataset. This results in substantial improvements on theorems that have lots of dependencies.</p>\n<p>I can't help but shamelessly compare this work to <a href=\"https://arxiv.org/abs/2401.02949\">Graph2Tac</a>, and more generally the entire premise behind <a href=\"https://coq-tactician.github.io/\">Tactician</a> (work by me and my co-authors). There, the idea is to do online updates of models with information collected from recent lemmas and proofs. This is shown to be extremely effective to the point where super-simple ML techniques can significantly outperform all other techniques simply because they can include recent knowledge in their predictions.</p>\n<p>All evidence seems to be pointing towards online capabilities being extremely important for theorem proving. The only question is to find the cheapest and most effective method of incorporating this online information!</p>",
        "id": 457263738,
        "sender_full_name": "Lasse Blaauwbroek",
        "timestamp": 1723091504
    },
    {
        "content": "<p>Additional note: The miniCTX paper seems to be a bit short on recent relevant related work, not only my own but also others. CC <span class=\"user-mention\" data-user-id=\"409334\">@Sean Welleck</span></p>",
        "id": 457265962,
        "sender_full_name": "Lasse Blaauwbroek",
        "timestamp": 1723092225
    },
    {
        "content": "<p>Hi everyone,</p>\n<p><span class=\"user-mention\" data-user-id=\"631691\">@Thomas Zhu</span> , <span class=\"user-mention\" data-user-id=\"409334\">@Sean Welleck</span> , and I are excited to announce the release of the new version of miniCTX (<a href=\"https://cmu-l3.github.io/minictx/\">https://cmu-l3.github.io/minictx/</a>, <a href=\"https://www.arxiv.org/abs/2408.03350\">https://www.arxiv.org/abs/2408.03350</a>), a context-rich benchmark for evaluating neural theorem proving in realistic scenarios. miniCTX contains theorems sourced from real Lean projects and textbooks, each associated with infile context (preceding code in a file), as well as cross-file context represented by premises. Models are tasked with proving a theorem given access to code from the theorem's repository, which contains context that is needed for the proof.</p>\n<p>Along with miniCTX, we offer robust tools for data extraction, automated annotation, and interaction with Lean: <a href=\"https://github.com/cmu-l3/ntp-toolkit\">NTP-Toolkit</a> is an automated tool designed to extract training and evaluation data from Lean repositories with minimal manual effort. The toolkit transforms Lean 4 repositories into next-tactic or full proof examples, enabling seamless fine-tuning and evaluation of language models. </p>\n<p>Finally, we have an evaluation repo (<a href=\"https://github.com/cmu-l3/minictx-eval\">minictx-eval</a>) (based on the Lean REPL) that should make it easy to evaluate models for tactic-based proof search, full proof generation, or other strategies. </p>\n<p>We updated miniCTX based on feedback from the community, and in this new version we include both in-file context and cross-file premise context. The updated NTP-Toolkit now extracts imported modules with premises and tracks the number of both in-file and cross-file premises used. We’ve also expanded miniCTX with new splits beyond traditional math proofs, opening up new possibilities for formal verification and other domains.</p>\n<p>We believe that the current version of miniCTX captures the complete context of a problem in realistic scenarios, thus serving as a more comprehensive benchmark compared to traditional ones. We also pay significant attention to automation in the toolkit, so users can test new repositories easily, and we can update the benchmark with new problems to avoid potential data contamination.</p>",
        "id": 477292130,
        "sender_full_name": "Jiewen Hu",
        "timestamp": 1729109412
    },
    {
        "content": "<p>In detail, the miniCTX benchmark contains problems from real-world projects including PFR, PimeNumberTheorem+, HepLean, and SciLean, as well as textbook problems like HTPI. We found that there are simple methods that drastically improve performance in real-world problems (19.5% to 35.9%). Meanwhile, existing competition-style benchmarks cannot capture this performance boost (miniF2F 32.8% to 33.6%), suggesting there is a significant gap for current benchmarks in assessing real-world theorem proving.</p>",
        "id": 477298845,
        "sender_full_name": "Thomas Zhu",
        "timestamp": 1729112093
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"306713\">@Lasse Blaauwbroek</span> Also, thank you for the suggestions! We agree Graph2Tac is a very relevant work in online learning, and we incorporated it in the relevant work section.<br>\nOur ntp-toolkit is also based on Kim Morrison's lean-training-data, and we are also indebted to the authors of open-source Lean projects that are in our benchmark.</p>",
        "id": 477299128,
        "sender_full_name": "Thomas Zhu",
        "timestamp": 1729112202
    },
    {
        "content": "<p>We will present miniCTX as an Oral presentation at ICLR in Singapore tomorrow! Please come to Oral Session 1A, 4/24 11:06am if you are interested!</p>",
        "id": 513756795,
        "sender_full_name": "Thomas Zhu",
        "timestamp": 1745372838
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"631691\">Thomas Zhu</span> <a href=\"#narrow/stream/219941-Machine-Learning-for-Theorem-Proving/topic/miniCTX/near/513756795\">said</a>:</p>\n<blockquote>\n<p>We will present miniCTX as an Oral presentation at ICLR in Singapore tomorrow! Please come to Oral Session 1A, 4/24 11:06am if you are interested!</p>\n</blockquote>\n<p>Please record if possible<span aria-label=\"pleading face\" class=\"emoji emoji-1f97a\" role=\"img\" title=\"pleading face\">:pleading_face:</span></p>",
        "id": 513776926,
        "sender_full_name": "Alok Singh",
        "timestamp": 1745384829
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"337670\">Alok Singh</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/miniCTX/near/513776926\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"631691\">Thomas Zhu</span> <a href=\"#narrow/stream/219941-Machine-Learning-for-Theorem-Proving/topic/miniCTX/near/513756795\">said</a>:</p>\n<blockquote>\n<p>We will present miniCTX as an Oral presentation at ICLR in Singapore tomorrow! Please come to Oral Session 1A, 4/24 11:06am if you are interested!</p>\n</blockquote>\n<p>Please record if possible<span aria-label=\"pleading face\" class=\"emoji emoji-1f97a\" role=\"img\" title=\"pleading face\">:pleading_face:</span></p>\n</blockquote>\n<p>Unfortunately this is unlikely (perhaps unless you have the virtual pass for ICLR). We will share our slides later. But the content of the oral talk will be a strict subset of the content of our paper: <a href=\"https://www.arxiv.org/pdf/2408.03350\">https://www.arxiv.org/pdf/2408.03350</a></p>",
        "id": 513991370,
        "sender_full_name": "Thomas Zhu",
        "timestamp": 1745457988
    }
]