[
    {
        "content": "<p>I recently read some work on LLM Lean proof generation. Some works such as ReProver and DeepSeek-Prover-V1.5 generate one-step tactics and then combine them into a complete proof through search methods. But when I practiced, I found that there might be some problems when dealing with tactics such as cases and induction. For example:</p>\n<div class=\"codehilite\" data-code-language=\"Lean4\"><pre><span></span><code><span class=\"kn\">theorem</span><span class=\"w\"> </span><span class=\"n\">list_length_nonneg</span><span class=\"w\"> </span><span class=\"o\">{</span><span class=\"n\">α</span><span class=\"w\"> </span><span class=\"o\">:</span><span class=\"w\"> </span><span class=\"kt\">Type</span><span class=\"o\">}</span><span class=\"w\"> </span><span class=\"o\">(</span><span class=\"n\">xs</span><span class=\"w\"> </span><span class=\"o\">:</span><span class=\"w\"> </span><span class=\"n\">List</span><span class=\"w\"> </span><span class=\"n\">α</span><span class=\"o\">)</span><span class=\"w\"> </span><span class=\"o\">:</span><span class=\"w\"> </span><span class=\"mi\">0</span><span class=\"w\"> </span><span class=\"bp\">≤</span><span class=\"w\"> </span><span class=\"n\">xs</span><span class=\"bp\">.</span><span class=\"n\">length</span><span class=\"w\"> </span><span class=\"o\">:=</span><span class=\"w\"> </span><span class=\"k\">by</span>\n<span class=\"w\">  </span><span class=\"n\">induction</span><span class=\"w\"> </span><span class=\"n\">xs</span><span class=\"w\"> </span><span class=\"k\">with</span>\n<span class=\"w\">  </span><span class=\"bp\">|</span><span class=\"w\"> </span><span class=\"n\">nil</span><span class=\"w\"> </span><span class=\"bp\">=&gt;</span><span class=\"w\"> </span><span class=\"n\">simp</span>\n<span class=\"c1\">--  | cons head tail ih =&gt;</span>\n<span class=\"w\">    </span><span class=\"c1\">-- simp</span>\n<span class=\"w\">    </span><span class=\"c1\">-- exact Nat.zero_le _</span>\n</code></pre></div>\n<p>REPL reports error : <code>alternative 'cons' has not been provided</code><br>\nWhen only some cases are generated for a large model, the REPL verification will fail due to errors. In my opinion, these works will be verified by lean after generating tactics, and will be filtered when errors occur (but for cases/inductions, the proof can be completed if it continues). How do these works like ReProver handle the situation where LLM gradually generates cases and inductions and verify these tactics in detail?</p>",
        "id": 528333830,
        "sender_full_name": "sicheng tan",
        "timestamp": 1752238378
    },
    {
        "content": "<p>I think it shouldn't be filtered because of REPL errors.  Do I just need to specially handle this case's error like <code>alternative 'cons' has not been provided</code> to let LLM generate next tactic?<br>\nAdditional Notes：When I change code to:</p>\n<div class=\"codehilite\" data-code-language=\"Lean4\"><pre><span></span><code><span class=\"kn\">theorem</span><span class=\"w\"> </span><span class=\"n\">list_length_nonneg</span><span class=\"w\"> </span><span class=\"o\">{</span><span class=\"n\">α</span><span class=\"w\"> </span><span class=\"o\">:</span><span class=\"w\"> </span><span class=\"kt\">Type</span><span class=\"o\">}</span><span class=\"w\"> </span><span class=\"o\">(</span><span class=\"n\">xs</span><span class=\"w\"> </span><span class=\"o\">:</span><span class=\"w\"> </span><span class=\"n\">List</span><span class=\"w\"> </span><span class=\"n\">α</span><span class=\"o\">)</span><span class=\"w\"> </span><span class=\"o\">:</span><span class=\"w\"> </span><span class=\"mi\">0</span><span class=\"w\"> </span><span class=\"bp\">≤</span><span class=\"w\"> </span><span class=\"n\">xs</span><span class=\"bp\">.</span><span class=\"n\">length</span><span class=\"w\"> </span><span class=\"o\">:=</span><span class=\"w\"> </span><span class=\"k\">by</span>\n<span class=\"w\">  </span><span class=\"n\">induction</span><span class=\"w\"> </span><span class=\"n\">xs</span><span class=\"w\"> </span><span class=\"k\">with</span>\n<span class=\"w\">  </span><span class=\"bp\">|</span><span class=\"w\"> </span><span class=\"n\">nil</span><span class=\"w\"> </span><span class=\"bp\">=&gt;</span><span class=\"w\"> </span><span class=\"n\">simp</span>\n<span class=\"w\"> </span><span class=\"bp\">|</span><span class=\"w\"> </span><span class=\"n\">cons</span><span class=\"w\"> </span><span class=\"n\">head</span><span class=\"w\"> </span><span class=\"n\">tail</span><span class=\"w\"> </span><span class=\"n\">ih</span><span class=\"w\"> </span><span class=\"bp\">=&gt;</span>\n<span class=\"w\">    </span><span class=\"c1\">-- simp</span>\n<span class=\"w\">    </span><span class=\"c1\">-- exact Nat.zero_le _</span>\n</code></pre></div>\n<p>It only report <code>unsolved goals</code>. This will let LLM to generate tactic continuely until finish proof.</p>",
        "id": 528335236,
        "sender_full_name": "sicheng tan",
        "timestamp": 1752238824
    },
    {
        "content": "<p>I don't quite understand. You should run LLMs yourself to see how they deal with this issue.</p>",
        "id": 528518314,
        "sender_full_name": "(deleted)",
        "timestamp": 1752400271
    }
]