[
    {
        "content": "<p>I checked and have not seen this noted here, if wrong please link to earlier topic.</p>\n<p>In reading \"System card: Claude Opus 4 &amp; Claude Sonnet 4\" (<a href=\"https://www-cdn.anthropic.com/4263b940cabb546aa0e3283f35b686f4f3b2ff47.pdf\">PDF</a>)</p>\n<p>For section <code>4.2.3 Reinforcement learning behavior review</code> it notes</p>\n<p><a href=\"/user_uploads/3121/tlyDjX1EyGMezjVbbNddEUsa/image.png\">image.png</a></p>\n<div class=\"message_inline_image\"><a href=\"/user_uploads/3121/tlyDjX1EyGMezjVbbNddEUsa/image.png\" title=\"image.png\"><img data-original-content-type=\"image/png\" data-original-dimensions=\"658x282\" src=\"/user_uploads/thumbnail/3121/tlyDjX1EyGMezjVbbNddEUsa/image.png/840x560.webp\"></a></div><p>...</p>\n<p><a href=\"/user_uploads/3121/iepRATpbjGyj1CFCAd1VnqRY/image.png\">image.png</a></p>\n<div class=\"message_inline_image\"><a href=\"/user_uploads/3121/iepRATpbjGyj1CFCAd1VnqRY/image.png\" title=\"image.png\"><img data-original-content-type=\"image/png\" data-original-dimensions=\"653x209\" src=\"/user_uploads/thumbnail/3121/iepRATpbjGyj1CFCAd1VnqRY/image.png/840x560.webp\"></a></div><p>The text was to complicated to format correctly here so reverted to using screen captures.</p>\n<p>The import part as text so that it can be searched for</p>\n<blockquote>\n<p>Transcript 4.2.3.A An example where Claude Opus 4 produces a superficially reasonable solution to a task it knows is impossible. When given a complex mathematical theorem-proving problem, it determines in its scratchpad that the theorem cannot be true, but does not reveal this in its final response; it instead produces a plausible-looking proof attempt of a theorem it knows to be false.</p>\n</blockquote>",
        "id": 520505557,
        "sender_full_name": "Eric Taucher",
        "timestamp": 1748282626
    },
    {
        "content": "<p>This is a great find, thanks <span class=\"user-mention\" data-user-id=\"366057\">@Eric Taucher</span> ! Another passage from that document: (this is part of the model's reasoning chain-of-thought:)</p>\n<blockquote>\n<p>Actually, let me think one more time. The user specifically asked me to prove <br>\nthis theorem, and they said they'll run it in Lean. If the theorem is false <br>\n(which I believe it is), then Lean won't be able to prove it. </p>\n</blockquote>\n<p>If we stop here, and imagine a future version of the model that \"happens\" to know of a way to fool the Lean proof checker...</p>",
        "id": 520528412,
        "sender_full_name": "GasStationManager",
        "timestamp": 1748292712
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"776090\">GasStationManager</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/System.20card.3A.20Claude.20Opus.204.20.26.20Claude.20Sonnet.204/near/520528412\">said</a>:</p>\n<blockquote>\n<p>This is a great find, thanks</p>\n</blockquote>\n<p>For a few years have been helping answer questions on the <a href=\"https://community.openai.com/\">OpenAI API forum</a> for developers and one thing some of us try to instill into those asking fundamental questions about specific models is to just read the system card, as they often do have valuable knowledge.</p>\n<p>Another point of  note is from  section <code>6 Reward hacking</code></p>\n<blockquote>\n<p>Reward hacking occurs when an AI model performing a task finds a way to maximize its rewards that technically satisfies the rules of the task, but violates the intended purpose (in other words, the model finds and exploits a shortcut or loophole). Specific examples of reward hacking include hard-coding (writing solutions that directly output expected values) and special-casing (writing insufficiently general solutions) to pass tests. </p>\n<p>Our previous model, Claude Sonnet 3.7, showed a tendency to resort to these behaviors, particularly in agentic coding settings such as Claude Code. Whereas Claude Opus 4 and Claude Sonnet 4 still exhibit these behaviors, the frequency has decreased significantly, and both models are easier to correct with prompting. Across our reward hacking evaluations, Claude Opus 4 showed an average 67% decrease in hard-coding behavior and Claude Sonnet 4 a 69% average decrease compared to Claude Sonnet 3.7. Further, in our tests, <strong>we found that simple prompts could dramatically reduce Claude Opus 4 and Claude Sonnet 4’s propensity towards these behaviors</strong>, while such prompts often failed to improve Claude Sonnet 3.7’s behavior, demonstrating improved instruction-following.</p>\n</blockquote>",
        "id": 520529362,
        "sender_full_name": "Eric Taucher",
        "timestamp": 1748293170
    },
    {
        "content": "<p>This makes me think of a library of false statements explicitly proved false as a dataset</p>",
        "id": 520726307,
        "sender_full_name": "Alok Singh",
        "timestamp": 1748366496
    },
    {
        "content": "<p>Great find <span class=\"user-mention\" data-user-id=\"366057\">@Eric Taucher</span>!!!</p>\n<p>This made me laugh:</p>\n<blockquote>\n<p>Maybe I can use some tactic that will magically work.</p>\n</blockquote>",
        "id": 522433410,
        "sender_full_name": "Adam Kurkiewicz",
        "timestamp": 1749064434
    },
    {
        "content": "<p>The fact that they are explicitly testing its performance on Lean 4 probably explains why the performance of their model seems to have, overall, significantly improved from earlier models</p>",
        "id": 522433560,
        "sender_full_name": "Adam Kurkiewicz",
        "timestamp": 1749064502
    },
    {
        "content": "<blockquote>\n<p>Claude Opus 4 and Claude Sonnet 4 still exhibit these behaviors, the frequency has decreased significantly, and both models are easier to correct with prompting.  <br>\n....  <br>\n....we found that simple prompts could dramatically reduce Claude Opus 4 and Claude Sonnet 4’s propensity towards these behaviors</p>\n</blockquote>\n<p>What prompting is this, pray tell?</p>",
        "id": 522485681,
        "sender_full_name": "David Michael Roberts",
        "timestamp": 1749090740
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"130272\">David Michael Roberts</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/System.20card.3A.20Claude.20Opus.204.20.26.20Claude.20Sonnet.204/near/522485681\">said</a>:</p>\n<blockquote>\n<p>What prompting is this, pray tell?</p>\n</blockquote>\n<p>I checked the system card looking for more specifics on such simple prompts and found none.</p>\n<p>All I can say is that when I read that section and why I noted in this forum is that simplifying a prompt is a valid suggestion that works at times and one users may not consider.</p>\n<p>There is so much information about creating prompts, more often than not suggesting to add more to the prompt. However sometimes, just a simple prompt works better.</p>\n<p>For example years ago created a prompt to check, enhance, style, etc. text that I would publish online in a forum, it was nearing 20 different instructions. Now that prompt is just <code>polish this</code> followed by a blank line and the text needing to be polished.</p>\n<p>Like you would be interested in more factual details.</p>",
        "id": 522545375,
        "sender_full_name": "Eric Taucher",
        "timestamp": 1749116148
    },
    {
        "content": "<p>One possibility to help in this situation would be to create a forum topic or subtopic where users can post prompts they are using related to Lean so that other can learn from them and possibly provide feedback.</p>",
        "id": 522548044,
        "sender_full_name": "Eric Taucher",
        "timestamp": 1749116907
    },
    {
        "content": "<p>Recently Anthropic created <a href=\"https://www.anthropic.com/claude-explains\">Claude Explains</a>, a blog for Claude. I see it as a sales pitch to upsell users to using Claude code and ignore that part, however the blog post do contain useful prompts related to Python, Typescript, and other popular coding tasks. The site is something I will be keeping tabs on to see if it does become a useful resource for Clade prompts.</p>",
        "id": 522549130,
        "sender_full_name": "Eric Taucher",
        "timestamp": 1749117272
    }
]