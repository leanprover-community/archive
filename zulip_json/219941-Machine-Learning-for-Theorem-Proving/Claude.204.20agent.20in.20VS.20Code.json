[
    {
        "content": "<p>I have been trying to find the best setup in VS Code for agent mode. It seems to me that Claude 4 is one of the better models. It seems to be able to reason better about Lean and fix errors. However, often it stops before all problems have been solved and declares everything fixed.</p>\n<p>Am I forgetting something? A configuration or settings that prevents Claude 4 from seeing the Lean output and proof state?</p>",
        "id": 526140973,
        "sender_full_name": "Willem vanhulle",
        "timestamp": 1751051917
    },
    {
        "content": "<p>The VS Code agent has only limited access to your project, such as file contents, history and some diagnostic messages. A lot of the information (e.g. most of the Lean InfoView) is not available as it is a custom VS Code extension.</p>\n<p><a href=\"https://github.com/oOo0oOo/lean-lsp-mcp\">lean-lsp-mcp</a> is an <a href=\"https://modelcontextprotocol.io/introduction\">MCP</a> that provides additional tools to the agent, such as</p>\n<ul>\n<li>Obtaining proof state at any position in a Lean file.</li>\n<li>Reading all diagnostic messages (including errors, warnings, and infos).</li>\n<li>Querying external search tools such as <a href=\"http://leansearch.net\">leansearch.net</a>.</li>\n</ul>",
        "id": 526192821,
        "sender_full_name": "Oliver Dressler",
        "timestamp": 1751104163
    },
    {
        "content": "<p>Hey Willem, </p>\n<p>I have been using ClaudeCode to auto-formalize some things and have found many concerning behaviors, including the one you mentioned. </p>\n<p>To work around it, at the beginning of every working session I instruct Claude (among many other things) to use the command <code>Bash(lake build &lt;module_name&gt; 2&gt;&amp;1 | tee build_output.txt)</code> This writes the entire output of the build to a text file in /root which the LLM has access to.</p>",
        "id": 526202216,
        "sender_full_name": "Eric Vergo",
        "timestamp": 1751115182
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"624658\">Eric Vergo</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Claude.204.20agent.20in.20VS.20Code/near/526202216\">zei</a>:</p>\n<blockquote>\n<p>To work around it, at the beginning of every working session I instruct Claude (among many other things) to use the command <code>Bash(lake build &lt;module_name&gt; 2&gt;&amp;1 | tee build_output.txt)</code> This writes the entire output of the build to a text file in /root which the LLM has access to.</p>\n</blockquote>\n<p>This sounds like a good solution, but I think it is still best to install the MCP server as mentioned by <span class=\"user-mention\" data-user-id=\"802311\">@Oliver Dressler</span>. Once I got it set-up I could stop copy-pasting a lot of context. I have just made a nix definition for it you need it: <a href=\"https://github.com/wvhulle/riddle-proofs\">https://github.com/wvhulle/riddle-proofs</a>.</p>",
        "id": 526202375,
        "sender_full_name": "Willem vanhulle",
        "timestamp": 1751115350
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"928352\">Willem vanhulle</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Claude.204.20agent.20in.20VS.20Code/near/526202375\">said</a>:</p>\n<blockquote>\n<p>I have just made a nix definition for it you need it: <a href=\"https://github.com/wvhulle/riddle-proofs\">https://github.com/wvhulle/riddle-proofs</a>.</p>\n</blockquote>\n<p>Thanks; I will check this out. </p>\n<p>I'm still spending time getting my hands dirty to find all the rough edges when working with these systems. For the time being, I don't feel like I have a good enough understanding of what can go wrong with Claude Code by itself to incorporate new tools. I'm preparing a longer post, but I have seen 'reward hacking' behaviors such as: deleting theorems it couldn't prove to reduce sorry counts, introducing new axioms when explicitly told not to, among many others. While the MCP tools look like they will help prevent these behaviors, it's worth noting that 'the motivation' to do so is still there.</p>\n<p>Based on what I have seen while working with Claude Code, I believe that documenting, studying, and understanding this behavior while an LLM works with Lean will be of broad interest. Here is why: If the LLM is essentially trying to cheat when writing formally verified code that it knows is going to be reviewed by mathematicians/computer scientists, what on earth is it doing when it's in an environment where it's much harder to catch cheating and it's not being scrutinized properly?</p>",
        "id": 526203672,
        "sender_full_name": "Eric Vergo",
        "timestamp": 1751117022
    },
    {
        "content": "<p>Maybe it is just not trained yet on the right large Lean corpus. I think that’s more likely, since it’s very arcane.</p>",
        "id": 526203880,
        "sender_full_name": "Willem vanhulle",
        "timestamp": 1751117252
    }
]