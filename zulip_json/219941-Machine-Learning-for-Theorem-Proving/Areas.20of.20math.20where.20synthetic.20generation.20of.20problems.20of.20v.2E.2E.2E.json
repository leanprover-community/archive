[
    {
        "content": "<p>After watching David Silver's talk, where he discusses running RL based proof search on a diverse set of problems of arbitrary difficulty, it seems to me that it would be interesting to compile a list of areas where it is possible to generate infinite synthetic data easily which crosses the human math frontier in the sense that it contains both many easy question, many hard but solvable questions and many hard and unsolved. Maybe if you have access to huge amounts of compute you could also think about actually running RL on one of these (idk if it's feasible today but could be in the near future)</p>\n<p>Here are a few that came to my mind</p>\n<p>1) Diophantine/rational solutions to integer polynomials (a lot of human math progress has come from this)</p>\n<p>2) Decision problems in algebraic geometry with no easy algorithm to decide (is a variety birational to P^n? How bad are its singularities? Etc)</p>\n<p>3) Infinitude of Prime n-tuples with certain characteristics so that heuristically we expect infinitely many.</p>\n<p>Some other examples that came to mind include (ir)rationality of integrals of algebraic functions, existence and uniqueness of randomly generated pdes but I'm less sure about those. Would be interested in other people's ideas/feedback on this.</p>\n<p>Should say that I don't work in any of the above areas so caveat lector</p>",
        "id": 476869802,
        "sender_full_name": "Andy Jiang",
        "timestamp": 1728952320
    },
    {
        "content": "<p>Random 3-SAT at the phase transition threshold tho I'm not sure if it has much relevance to improving proof search</p>",
        "id": 476916959,
        "sender_full_name": "Sid",
        "timestamp": 1728976014
    },
    {
        "content": "<p>Thinking about how Diophantine equations behave under changes of parameters reminds me a bit of the current Equational project. In the 80s there was a push to find all integer solutions to <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msup><mi>Y</mi><mn>2</mn></msup><mo>=</mo><msup><mi>X</mi><mn>3</mn></msup><mo>+</mo><mi>n</mi></mrow><annotation encoding=\"application/x-tex\">Y^2=X^3+n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8141em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.22222em;\">Y</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.8974em;vertical-align:-0.0833em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.07847em;\">X</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">3</span></span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.4306em;\"></span><span class=\"mord mathnormal\">n</span></span></span></span> for <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>n</mi></mrow><annotation encoding=\"application/x-tex\">n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.4306em;\"></span><span class=\"mord mathnormal\">n</span></span></span></span> an integer with <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi mathvariant=\"normal\">∣</mi><mi>n</mi><mi mathvariant=\"normal\">∣</mi><mo>≤</mo><mn>1000.</mn></mrow><annotation encoding=\"application/x-tex\">|n|\\leq1000.</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\">∣</span><span class=\"mord mathnormal\">n</span><span class=\"mord\">∣</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">≤</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6444em;\"></span><span class=\"mord\">1000.</span></span></span></span> This is an interesting set of equations because for a fixed <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>n</mi></mrow><annotation encoding=\"application/x-tex\">n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.4306em;\"></span><span class=\"mord mathnormal\">n</span></span></span></span> there are only finitely many solutions in <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>X</mi><mo separator=\"true\">,</mo><mi>Y</mi></mrow><annotation encoding=\"application/x-tex\">X,Y</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8778em;vertical-align:-0.1944em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07847em;\">X</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.22222em;\">Y</span></span></span></span> but there can be random large solutions eg already with <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>n</mi><mo>=</mo><mn>17</mn></mrow><annotation encoding=\"application/x-tex\">n=17</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.4306em;\"></span><span class=\"mord mathnormal\">n</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6444em;\"></span><span class=\"mord\">17</span></span></span></span> there is a solution with <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>Y</mi></mrow><annotation encoding=\"application/x-tex\">Y</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.22222em;\">Y</span></span></span></span> a six digit number. There were a number of techniques known but each only applied to a subset of <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>n</mi></mrow><annotation encoding=\"application/x-tex\">n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.4306em;\"></span><span class=\"mord mathnormal\">n</span></span></span></span> s (and solving Diophantine equations is already an undecidable domain so this is expected).</p>",
        "id": 476918853,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1728976502
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"246665\">Sid</span> <a href=\"#narrow/stream/219941-Machine-Learning-for-Theorem-Proving/topic/Areas.20of.20math.20where.20synthetic.20generation.20of.20problems.20of.20v.2E.2E.2E/near/476916959\">said</a>:</p>\n<blockquote>\n<p>Random 3-SAT at the phase transition threshold tho I'm not sure if it has much relevance to improving proof search</p>\n</blockquote>\n<p>Sounds interesting! I feel like maybe in this case the RL should learn something about proving certain 3SAT problems. Though it's very outside of what I think about so I personally won't be able to understand the things it will have learned.</p>",
        "id": 476980920,
        "sender_full_name": "Andy Jiang",
        "timestamp": 1728996294
    },
    {
        "content": "<p>Just come across this paper: <a href=\"https://arxiv.org/abs/2410.09988\">https://arxiv.org/abs/2410.09988</a>. They seem to claim the <code>asymptotic methods</code> graduate course problems can be generated algorithmically. That also reminds me of the <code>symbolic integration</code> area as well.</p>",
        "id": 477777426,
        "sender_full_name": "fzyzcjy",
        "timestamp": 1729317970
    },
    {
        "content": "<p>A couple of other examples (I believe any area has these):</p>\n<ul>\n<li>Given a random knot, what is its <a href=\"https://en.wikipedia.org/wiki/Slice_genus\">slice genus</a>.</li>\n<li>Given a random presentation of a group, is it trivial? finite? torsion free? residually finite?</li>\n</ul>",
        "id": 477795740,
        "sender_full_name": "Siddhartha Gadgil",
        "timestamp": 1729335078
    },
    {
        "content": "<p>One has to be careful.  Unless you are particularly interested in a particular distribution of “random” knots/groups/matrices/etc, you could draw the wrong mathematical conclusions from your data.   For example almost all finite groups are 2-groups.  Some poor ML for math papers make really weird conclusions that are overfit to their sampling distribution.   It is best to work with many distributions, including pathological cases.  The knot theory DeepMind Nature paper had a good discussion on this.</p>",
        "id": 477796510,
        "sender_full_name": "Jason Rute",
        "timestamp": 1729335802
    },
    {
        "content": "<p>There is an ongoing seminar at Harvard CMSA about ML for Math, and I think generation of math data is one of there main topics.  You could check out their Zulip at <a href=\"https://mml2024.zulipchat.com/\">https://mml2024.zulipchat.com/</a>.</p>",
        "id": 477796882,
        "sender_full_name": "Jason Rute",
        "timestamp": 1729336151
    },
    {
        "content": "<p>Certainly with the equational theories project we are finding that 0.01% of the implications are holding the vast majority of the mathematically interesting features!  So \"randomly generated\" should definitely only be one component of a diverse data set, not the only component. (Of course, the other components are far harder to find in bulk, more or less by definition...)</p>\n<p>In a somewhat parallel note: we exhaustively iterated over all magmas of size up to 4 to generate counterexamples, which worked pretty well, but still left a fair chunk of unresolved implications.  Iterating over all magmas of size 5 was computationally prohibitive, and using randomly sampled magmas of this size produced almost no new counterexamples.  However, using randomly sampled <em>cancellative</em> magmas of size 5 ended up being more productive, as this extra constraint significantly changed the distributions of what laws the magma obeyed.</p>",
        "id": 477907377,
        "sender_full_name": "Terence Tao",
        "timestamp": 1729440610
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"657719\">Terence Tao</span> <a href=\"#narrow/stream/219941-Machine-Learning-for-Theorem-Proving/topic/Areas.20of.20math.20where.20synthetic.20generation.20of.20problems.20of.20v.2E.2E.2E/near/477907377\">said</a>:</p>\n<blockquote>\n<p>Certainly with the equational theories project we are finding that 0.01% of the implications are holding the vast majority of the mathematically interesting features!  So \"randomly generated\" should definitely only be one component of a diverse data set, not the only component. (Of course, the other components are far harder to find in bulk, more or less by definition...)<br>\n</p>\n</blockquote>\n<p>Thanks for the comment! I don't know if this is unrealistic but I was hoping running reinforcement learning on a similar dataset as this one you guys are working on will similarly first dispatch of the \"easy\" 99.99% of problems and spend the rest of the time trying to learn on the rest. Of course I don't know if in practice it does with this way or also whether if the increase in difficulty is too steep at the end whether the reinforcement learning will just get stuck after the easy problems.</p>\n<p>Btw this project looks really cool, congrats on getting the number of unsolved questions down to just a handful!</p>",
        "id": 478172441,
        "sender_full_name": "Andy Jiang",
        "timestamp": 1729554681
    }
]