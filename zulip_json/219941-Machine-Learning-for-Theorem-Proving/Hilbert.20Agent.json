[
    {
        "content": "<p><a href=\"https://arxiv.org/abs/2509.22819\">https://arxiv.org/abs/2509.22819</a> -- they have an agentic framework which with Gemini + Goedel Prover gets 70% on PutnamBench</p>",
        "id": 542422893,
        "sender_full_name": "Opt",
        "timestamp": 1759302824
    },
    {
        "content": "<p>How is this different from Lego Prover?</p>",
        "id": 542423526,
        "sender_full_name": "Simon Sorg",
        "timestamp": 1759303108
    },
    {
        "content": "<p>Lego prover looks entirely different to me</p>",
        "id": 542435766,
        "sender_full_name": "(deleted)",
        "timestamp": 1759307261
    },
    {
        "content": "<p>Anyway it's clear AI can prove theorems. Now the next step is building faster AIs</p>",
        "id": 542441970,
        "sender_full_name": "(deleted)",
        "timestamp": 1759309074
    },
    {
        "content": "<p>Here's a goal. Prove nontrivial theorems under 1 second.</p>",
        "id": 542442923,
        "sender_full_name": "(deleted)",
        "timestamp": 1759309334
    },
    {
        "content": "<p>but how is it different from everything else? also when can we use it?</p>",
        "id": 542525426,
        "sender_full_name": "Jared green",
        "timestamp": 1759332641
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"766274\">Simon Sorg</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Hilbert.20Agent/near/542423526\">schrieb</a>:</p>\n<blockquote>\n<p>How is this different from Lego Prover?</p>\n</blockquote>\n<p>Lego - growing skill library, with \"neural\" / AI-autonomous focus.<br>\nHilbert - informal reasoning-focused, with orchestration (4 components: \"an informal LLM that excels at mathematical reasoning, a specialized prover LLM optimized for Lean 4 tactics, a formal verifier, and a semantic theorem retriever\")</p>\n<p>The future systems will most likely combine both \"neural\" and \"natural\". Modularity and growing libraries make sense, but also the ability to have autonomous NNs marking things green in the blueprint makes sense too.</p>",
        "id": 542549278,
        "sender_full_name": "Michael Bucko",
        "timestamp": 1759340003
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"394803\">Jared green</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Hilbert.20Agent/near/542525426\">said</a>:</p>\n<blockquote>\n<p>but how is it different from everything else? also when can we use it?</p>\n</blockquote>\n<p>The components used in the paper are all publicly available. Both Goedel Prover v2 and Gemini 2.5 Pro are publicly available, and the prompts are in the paper. Replication takes some effort but isn't impossible, as every important detail is in the paper.</p>",
        "id": 542554023,
        "sender_full_name": "(deleted)",
        "timestamp": 1759341612
    },
    {
        "content": "<p>I'm just getting a chance to start reading the Hilbert paper this morning. It's quite similar to something I'm working on. </p>\n<p>Hopefully I can write up a quick article on what I've done over the weekend and open source my code next week. It's built to be built upon, e.g. swapping in new formal provers and decomposition agents. So it should be a framework of general use in future.</p>",
        "id": 545228955,
        "sender_full_name": "Kelly Davis",
        "timestamp": 1760605464
    },
    {
        "content": "<p>Here's the initial version <a href=\"https://github.com/KellyJDavis/goedels-poetry\">Gödels Poetry</a>.</p>\n<p>I'd appreciate any feedback, with enough eyeballs all bugs are shallow.</p>",
        "id": 545833612,
        "sender_full_name": "Kelly Davis",
        "timestamp": 1760884321
    },
    {
        "content": "<p>Hilbert paper's results are quite interesting. I tried to reproduce the same: <a href=\"https://github.com/ayush1801/HilbertProverX\">https://github.com/ayush1801/HilbertProverX</a></p>\n<h3>Results and Observations:</h3>\n<ul>\n<li>On <code>MiniF2F-test</code> set, we achieve <code>74.5%</code> (<code>182/244</code>) using the above parameters. <code>39</code> of these proofs cannot be proved directly and are proved recursively. With the similar reasoner calls as above, the paper achieves the performance of <code>80-85%</code>. </li>\n<li>All the successful proofs are provided at <code>./datasets/MINIF2F_TEST.zip</code></li>\n<li>Some interesting observations:<br>\n    - We find that proofs are generally unnecessarily long with a lot of unused tactics. <br>\n    - There are a lot of major trivial lemmas that are generated and the current prover models often struggle to prove these: <br>\n        - <code>theorem one_is_integer : (1 : ℚ).isInt := sorry</code><br>\n        - <code>theorem a4_val (a : ℕ → ℕ) (h₄ : a 4 ^ 3 = 125) : a 4 = 5 := sorry</code><br>\n        - <code>theorem unknown_terms_final_value : ((212 : ℤ) + (414 : ℤ)) = (626 : ℤ) := sorry</code>      <br>\n        - <code>theorem six_div_ten_eq_three_div_five : (6 : ℚ) / (10 : ℚ) = (3 : ℚ) / (5 : ℚ) := sorry</code><br>\n        - Ideally, the provers should not waste compute on proving such trivial goals. These goals should be offloaded to tactics developed in latest versions such as <code>grind</code> and <a href=\"https://github.com/JOSHCLUNE/LeanHammer\"><code>hammers</code></a> and should be made more powerful as these don't handle all the trivial goals.<br>\n    - Without strict theorem check, models tend to transform the original theorem statements/lemmas being proved.</li>\n</ul>\n<h3>Upcoming Plan</h3>\n<ul>\n<li>Measuring performance on other benchmarks and using other reasoners.</li>\n<li>Parallelising the pipeline.</li>\n<li>Analysing the same to get better understanding of the above observations.</li>\n<li>Exploring ideas to make the pipeline more efficient and better in terms of performance.</li>\n<li>Collaborations are welcome! Please reach out to me!!</li>\n</ul>\n<p>Please try it out <span aria-label=\"slight smile\" class=\"emoji emoji-1f642\" role=\"img\" title=\"slight smile\">:slight_smile:</span></p>",
        "id": 553852601,
        "sender_full_name": "Ayush Agrawal",
        "timestamp": 1762348860
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"439607\">@Ayush Agrawal</span> </p>\n<p>I don't know if the repo's settings are the ones you used for benchmarking, but a quick (and maybe incorrect) glance at the code finds the repo's</p>\n<ul>\n<li>Subgoal solving seems to use fewer attempts , 1 vs 4, than Hilbert</li>\n<li>Shallow solve has stricter line limits, 5 vs 30, than Hilbert</li>\n<li>Error correction uses fewer iterations, 4 vs 6, than Hilbert</li>\n<li>Search users fewer queries, 1 vs 5, than Hilbert</li>\n</ul>\n<p>these likely go quite away to explaining the differences?</p>",
        "id": 553870797,
        "sender_full_name": "Kelly Davis",
        "timestamp": 1762352861
    },
    {
        "content": "<p>Subgoal solving does use 4 attempts (see the batch size). Yes, shallow solve proof length and error correction has fewer iterations. Search queries are also 5, check the prompts and the extraction part. If anything still feels off, let me know!</p>",
        "id": 553871568,
        "sender_full_name": "Ayush Agrawal",
        "timestamp": 1762353059
    },
    {
        "content": "<p>I think differences could be pertained to prompt formatting, thinking budget of the reasoner models as well as some hyperparameter difference in terms of overall compute budget (2 of those you pointed out!). We do plan to carry out the evaluations on other benchmarks.</p>",
        "id": 553872600,
        "sender_full_name": "Ayush Agrawal",
        "timestamp": 1762353301
    }
]