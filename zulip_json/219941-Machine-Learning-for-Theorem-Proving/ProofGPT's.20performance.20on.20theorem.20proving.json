[
    {
        "content": "<p>Hello everyone,</p>\n<p>I'm new to this forum. I have been working on code generation and am now interested in theorem proving (particularly in Lean). I'm now looking for a backbone transformer to use or fine-tune.</p>\n<p>I was wondering if ProofGPT has been evaluated on proving Lean theorems. The authors of the ProofNet paper mentioned that they \"leave an investigation of formal theorem proving and proof autoformalization to future work.\" But ProofGPT seems to be the only open-sourced model that can be used for theorem proving?</p>\n<p>So I have the following questions.</p>\n<ul>\n<li>Is ProofGPT the most appropriate open-sourced model for Lean theorem proving? I still want to play with a model or possibly fine-tune it, so I do not want to use GPT-3.5/GPT-4 at this stage.</li>\n<li>Would minif2f (or other datasets?) be a suitable evaluation set, that is, would it be too difficult or too easy? I'd like to run some evaluation experiments, but I just wanted to make sure it's meaningful.</li>\n</ul>\n<p>Thanks!</p>",
        "id": 361181235,
        "sender_full_name": "Shun Zhang",
        "timestamp": 1685055759
    },
    {
        "content": "<p>Hi Shun, like you, I'm also new to this forum and to the task of theorem proving. It seems we're encountering some similar issues. I'd like to share my current understanding and experience, but please bear in mind that I'm still learning. Corrections or additional insights from more seasoned members would be very welcome.</p>\n<blockquote>\n<ul>\n<li>Is ProofGPT the most appropriate open-sourced model for Lean theorem proving? I still want to play with a model or possibly fine-tune it, so I do not want to use GPT-3.5/GPT-4 at this stage.</li>\n</ul>\n</blockquote>\n<p>Although I'm not extensively familiar with ProofGPT, I've been working on replicating the results from the <a href=\"https://arxiv.org/abs/2102.06203\">PACT</a> paper using LLAMA as the backbone. If you're interested, you might find additional details <a href=\"#narrow/stream/217875-Is-there-code-for-X.3F/topic/Code.20for.20GPT-F.20or.20other.20LLM.20used.20for.20ATP\">here</a>.</p>\n<blockquote>\n<ul>\n<li>Would minif2f (or other datasets?) be a suitable evaluation set, that is, would it be too difficult or too easy? I'd like to run some evaluation experiments, but I just wanted to make sure it's meaningful.</li>\n</ul>\n</blockquote>\n<p>I'm also having this question. The current SOTA result on miniF2F is not high (&lt;50% for Pass@64). But after reviewing some of the human-written proofs for miniF2F, I found a wide range of difficulty levels. Some proofs are surprisingly straightforward, involving just <a href=\"https://github.com/openai/miniF2F/blob/main/lean/src/test.lean#L82\">one line of tactics</a> or <a href=\"https://github.com/openai/miniF2F/blob/main/lean/src/test.lean#L164\">simple calculations</a> rather than complex proofs (more examples can be found <a href=\"https://github.com/openai/miniF2F/blob/main/lean/src/test.lean#L70\">here</a> and <a href=\"https://github.com/openai/miniF2F/blob/main/lean/src/test.lean#L139\">here</a>). Conversely, others are quite <a href=\"https://github.com/openai/miniF2F/blob/main/lean/src/test.lean#L26\">complex</a> or <a href=\"https://github.com/openai/miniF2F/blob/main/lean/src/test.lean#L623\">lengthy</a>, which potentially raises the chance for an LLM to make a mistake. I'm interested in understanding which questions current Large Language Models struggle to answer correctly.</p>\n<p>On a separate note, I believe I've read your impactful <a href=\"https://arxiv.org/abs/2303.05510\">paper</a> on program synthesis that uses pass rates on test cases as a heuristic for forward-checking with MCTS. If you're open to discussing it, I'd be curious to understand why you shifted your interest from program synthesis to theorem proving. I'm still in the process of understanding the role theorem proving can play in enhancing LLM's general abilities (reasoning and planning).</p>",
        "id": 361319395,
        "sender_full_name": "Dongwei Jiang",
        "timestamp": 1685105872
    },
    {
        "content": "<p>Hi Dongwei, Thanks for your reply. It's very helpful!<br>\nI'm actually considering theorem proving as a new test domain, as it appears to be more challenging than code generation. We may have to come up with new algorithms that can reason to better solve theorem proving problems.</p>",
        "id": 361459476,
        "sender_full_name": "Shun Zhang",
        "timestamp": 1685146236
    },
    {
        "content": "<p>Hi Shun, glad to hear you're interested in the proofGPT model. </p>\n<p>As far as I'm aware, proofGPT is the only open-source model fine-tuned on math, so it is a natural candidate for work on theorem proving. I'd expect proofGPT to be better than the pre-trained models used in the openai and meta papers, due to the former having a larger parameter count and more pre-training. </p>\n<p>Minif2f is a challenging benchmark, and I can't think of an obvious way in which the test data could've contaminated the proofGPT training set.</p>",
        "id": 361462197,
        "sender_full_name": "Zhangir Azerbayev",
        "timestamp": 1685148443
    },
    {
        "content": "<p>(deleted)</p>",
        "id": 361481811,
        "sender_full_name": "Alex Sweeney",
        "timestamp": 1685165239
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"284997\">@Zhangir Azerbayev</span> Thanks for confirming that I'm on the right track! It's also good to know that minif2f is not in ProofGPT's training set.</p>",
        "id": 361491817,
        "sender_full_name": "Shun Zhang",
        "timestamp": 1685171308
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"284997\">@Zhangir Azerbayev</span> is ProofGPTâ€™s training data, both pre training and math training publicly available?  So that one could just grep for the names of the minif2f problems?</p>",
        "id": 361536718,
        "sender_full_name": "Jason Rute",
        "timestamp": 1685184146
    },
    {
        "content": "<p>Note most of the data leakage in the PACT paper came from the general purpose pretraining (common crawl) and not from the math specific pretraining (GitHub, arXiv, stack exchange).  And of course the miniF2F problems are in many cases standard competition problems so their natural language versions are very possibly in the training data.</p>",
        "id": 361564510,
        "sender_full_name": "Jason Rute",
        "timestamp": 1685191433
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"115715\">@Jason Rute</span> The general pre-training dataset is the pile and the math-specific set is available <a href=\"https://huggingface.co/datasets/hoskinson-center/proof-pile\">here</a>. I agree the natural language versions are likely in the pile, although the formal versions are almost certainly not (another example of data decontamination being an ill posed problem).</p>",
        "id": 361606502,
        "sender_full_name": "Zhangir Azerbayev",
        "timestamp": 1685203805
    }
]