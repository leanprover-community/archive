[
    {
        "content": "<p>Meme-y title aside, I believe that vibe coding is what people want, and Lean is in a good position to deliver a vibe-coding solution that actually works.</p>\n<p>I have made a demo app at <a href=\"http://ProvablyCorrectVibeCoding.com\">ProvablyCorrectVibeCoding.com</a>, in which:</p>\n<ul>\n<li>The user creates a formal specification for a Lean coding task. Or take an existing problem from <a href=\"http://www.codeproofarena.com:8000/\">Code with Proofs: the Arena</a>. (Upcoming feature: autoformalize from natural language problem description and a test set)</li>\n<li>An AI agent attempts to output code with proof of correctness. The AI is an LLM (e.g. Sonnet/o3/Deepseek/Gemini/Grok4) with user-provided API key, armed with <a href=\"https://github.com/GasStationManager/LeanTool\">LeanTool</a>. LeanTool provides not only ability to iteratively fix syntax errors, it also facilitates hallucination detection via property-based testing.</li>\n<li>The solution is checked against the specification using <a href=\"https://github.com/GasStationManager/SafeVerify\">SafeVerify</a>. If the solution passes, the user now has an implementation of the coding task that is guaranteed to satisfy the specification.</li>\n</ul>\n<p>This demo is a proof-of-concept of a <a href=\"https://gasstationmanager.github.io/ai/2024/11/04/a-proposal.html\">vision</a> that I have been building towards via <a href=\"https://github.com/GasStationManager/\">these open-source projects</a>: a future with safe, hallucination-free coding AIs. We are of course quite a bit of distance from that goal, but hopefully this gives an idea of what that might look like. </p>\n<p>This is initial alpha release; please try it out and let me know what you think!  Much of my current research focus is on scaffolding that enables efficient inference-time scaling, in particular detecting hallucinations by leveraging the formal spec and feedback from Lean. If you are interested in collaborating, let me know!</p>",
        "id": 528912604,
        "sender_full_name": "GasStationManager",
        "timestamp": 1752601681
    },
    {
        "content": "<p>I really like your work, and I hope one day foundation models will catch up...</p>",
        "id": 528968028,
        "sender_full_name": "(deleted)",
        "timestamp": 1752630967
    },
    {
        "content": "<p>Speaking of collaborating, I have some training data.</p>",
        "id": 528968158,
        "sender_full_name": "(deleted)",
        "timestamp": 1752631127
    },
    {
        "content": "<p>And a lot of math problems to test your stuff on.</p>",
        "id": 528968213,
        "sender_full_name": "(deleted)",
        "timestamp": 1752631197
    },
    {
        "content": "<p>i think i've seen work, probably from Danqi Chen, on jointly generating code, specification, and doc.</p>\n<p>are you familiar with their work? i personally think this is a less-than-fundamental approach and we will eventually have a alpha-zero style better alternative</p>",
        "id": 528977080,
        "sender_full_name": "Ping J",
        "timestamp": 1752639323
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"511228\">@Huỳnh Trần Khanh</span>  Thanks!<br>\nBTW, you can try pure mathematical proof tasks on the demo app as well. Use the \"draft_sketch_prove\" workflow option which is suitable for proofs.</p>\n<p>As for training: while I don't have the budget or the expertise for any large-scale training, one promising direction in my opinion is to have LeanTool as part of a multi-turn RL environment, to fine-tune models to effectively use these tools to get useful information from interacting with Lean. Potentially relevant: <a href=\"https://github.com/willccbb/verifiers\">verifiers</a></p>",
        "id": 528977234,
        "sender_full_name": "GasStationManager",
        "timestamp": 1752639460
    },
    {
        "content": "<p><a href=\"https://arxiv.org/pdf/2310.17807\">https://arxiv.org/pdf/2310.17807</a></p>",
        "id": 528978763,
        "sender_full_name": "Ping J",
        "timestamp": 1752640591
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"937033\">@Ping J</span> I see you linked to the CLOVER paper. I think it is interesting; and broadly agree with the overall goals. But from my perspective as someone in large part motivated by AI Safety, I really think that the humans should \"own\" the specification, at least be very much in the loop when creating the specification and ultimately take responsibility for it.</p>\n<p>As for alpha-zero: in my <a href=\"https://gasstationmanager.github.io/ai/2024/11/04/a-proposal.html\">essay</a> I wrote (and still believe) that ultimately some kind of RL (possibly alpha-zero style) will be needed to achieve recursive self-improvement, and get us better and better coding AIs. But one of the missing pieces was: what would be an effective <em>search</em> part of alpha-zero for the coding domain?  Is it straight MCTS as in AlphaProof? Or perhaps something else. I wanted to explore this space, and once we have a good idea of how to do search/inference-time scaling, we can incorporate it into an RL pipeline (e.g. see  above post).</p>",
        "id": 528980063,
        "sender_full_name": "GasStationManager",
        "timestamp": 1752641504
    }
]