[
    {
        "content": "<p>Hi everyone, </p>\n<p>My team has released Llemma, an open language model for mathematics with 7B and 34B parameter versions. Llemma was initialized with Code Llama weights, and further trained for up to 200B tokens on mathematical documents.</p>\n<p>You can view some of Llemma's outputs on our <a href=\"https://llemma-demo.github.io/\">sample explorer</a> website.</p>\n<p>We put a special emphasis on including formal proofs in our training set, for example, by using <span class=\"user-mention\" data-user-id=\"110087\">@Scott Morrison</span>'s <a href=\"https://github.com/semorrison/lean-training-data\">lean-training-data</a> tool to extract goal/tactic pairs. With few-shot prompting only, Llemma outperforms COPRA and almost matches ReProver on MiniF2F. </p>\n<p><a href=\"http://arxiv.org/abs/2310.10631\">ArXiv</a> <br>\n<a href=\"https://huggingface.co/EleutherAI/llemma_34b\">Models</a> <br>\n<a href=\"https://huggingface.co/datasets/EleutherAI/proof-pile-2\">Data</a> <br>\n<a href=\"https://github.com/EleutherAI/math-lm\">Code</a> <br>\n<a href=\"https://blog.eleuther.ai/llemma/\">Blog post</a> <br>\n<a href=\"https://llemma-demo.github.io/\">Sample Explorer</a></p>",
        "id": 397146680,
        "sender_full_name": "Zhangir Azerbayev",
        "timestamp": 1697560746
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"284997\">@Zhangir Azerbayev</span> I look forward to trying it out! Just a quick note: I noticed the \"our paper\" link at the bottom of the readme on the huggingface page is broken, and just links to the same huggingface page: <a href=\"https://huggingface.co/EleutherAI/llemma_7b\">https://huggingface.co/EleutherAI/llemma_7b</a></p>",
        "id": 397147316,
        "sender_full_name": "Adam Topaz",
        "timestamp": 1697561029
    },
    {
        "content": "<p>Is this something one can actually use or only a research announcement? I mean, is there a tactic I can run in Lean to get suggestions from this model?</p>",
        "id": 397147573,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1697561125
    },
    {
        "content": "<p>The huggingface page says that this was trained on <code>Proof-Pile-2</code>. Just to clarify, does that dataset now include goal/tactic pairs extracted with <code>lean-training-data</code>?</p>",
        "id": 397148369,
        "sender_full_name": "Adam Topaz",
        "timestamp": 1697561451
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"243562\">Adam Topaz</span> <a href=\"#narrow/stream/219941-Machine-Learning-for-Theorem-Proving/topic/Llemma/near/397148369\">said</a>:</p>\n<blockquote>\n<p>The huggingface page says that this was trained on <code>Proof-Pile-2</code>. Just to clarify, does that dataset now include goal/tactic pairs extracted with <code>lean-training-data</code>?</p>\n</blockquote>\n<p>EDIT: They are separately extracted, but put into <code>algebraic_stack/*/lean_proofsteps.jsonl.zst</code> in the dataset.</p>\n<blockquote>\n<p>B.1.2 LEAN PROOFSTEPS</p>\n<p>We extract a dataset of (tactic state, next tactic) pairs from Mathlib 4 (mathlib Community, 2020) using the lean-training-data (Morrison, 2023) tool. We use Mathlib 4 commit c779bd5, which was created on August 20th 2023.</p>\n</blockquote>",
        "id": 397149789,
        "sender_full_name": "Utensil Song",
        "timestamp": 1697562031
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"243562\">Adam Topaz</span> <a href=\"#narrow/stream/219941-Machine-Learning-for-Theorem-Proving/topic/Llemma/near/397148369\">said</a>:</p>\n<blockquote>\n<p>The huggingface page says that this was trained on <code>Proof-Pile-2</code>. Just to clarify, does that dataset now include goal/tactic pairs extracted with <code>lean-training-data</code>?</p>\n</blockquote>\n<p>This dataset includes the goal/tactic pairs.</p>",
        "id": 397150970,
        "sender_full_name": "Zhangir Azerbayev",
        "timestamp": 1697562544
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"243562\">Adam Topaz</span> <a href=\"#narrow/stream/219941-Machine-Learning-for-Theorem-Proving/topic/Llemma/near/397147316\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"284997\">Zhangir Azerbayev</span> I look forward to trying it out! Just a quick note: I noticed the \"our paper\" link at the bottom of the readme on the huggingface page is broken, and just links to the same huggingface page: <a href=\"https://huggingface.co/EleutherAI/llemma_7b\">https://huggingface.co/EleutherAI/llemma_7b</a></p>\n</blockquote>\n<p>Ah thanks for catching this. Will update rn.</p>",
        "id": 397151171,
        "sender_full_name": "Zhangir Azerbayev",
        "timestamp": 1697562628
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110031\">Patrick Massot</span> <a href=\"#narrow/stream/219941-Machine-Learning-for-Theorem-Proving/topic/Llemma/near/397147573\">said</a>:</p>\n<blockquote>\n<p>Is this something one can actually use or only a research announcement? I mean, is there a tactic I can run in Lean to get suggestions from this model?</p>\n</blockquote>\n<p>There is nothing you can use yet. Llemma is more of a research platform, which has to be finetuned and packaged in a front-end before it's directly useful. Systems like Morph Prover v0 can substitute in Llemma as their base model and expect a substantial gain in capabilities.</p>",
        "id": 397151680,
        "sender_full_name": "Zhangir Azerbayev",
        "timestamp": 1697562855
    },
    {
        "content": "<p>Thanks for this clarification.</p>",
        "id": 397154003,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1697563801
    },
    {
        "content": "<p>6 hours ago, TheBloke has uploaded the quantized version of Llemma, both <a href=\"http://TheBloke/llemma_7b-GGUF\">7B</a> and <a href=\"http://TheBloke/llemma_34b-GGUF\">34B</a>, which means that making small tweaks to the server script of tactic <a href=\"https://github.com/wellecks/llmstep#using-a-different-model\"><code>llm-step</code></a> can make Llemma available in Lean, maybe also need to tweak how <code>llm_step</code> feeds the goal states to LLM.</p>",
        "id": 397222778,
        "sender_full_name": "Utensil Song",
        "timestamp": 1697600724
    },
    {
        "content": "<p>I've manually created some prompts from tactic states inside some Mathlib proofs or some <a href=\"https://leanprover-community.github.io/mwe.html\">#mwe</a> from Zulip following <a href=\"https://github.com/wellecks/llemma_formal2formal/blob/f96fdb1642b2f21bed85c19640b6f1511abb1116/proofsearch.py#L58\">the few shot prompt template</a> which is \"Given the Lean 4 tactic state, suggest a next tactic.\" and few-shot examples with stop string <code>---</code>), Llemma (7B q8_0 gguf) generates good-looking Lean 4 proofs with no success so far (correct lemma with wrong tactic, inaccurate lemma name, hallucinated lemma names etc.):</p>\n<p><a href=\"/user_uploads/3121/wuuj_FKQjFG11xsNh-LBorSx/image.png\">image.png</a><br>\n<a href=\"/user_uploads/3121/DHKTW6xG9q8eVepsSHGGWPb8/image.png\">image.png</a><br>\n<a href=\"/user_uploads/3121/Wrg4kA7s2AsAjDewyFwXeyvw/image.png\">image.png</a></p>\n<div class=\"message_inline_image\"><a href=\"/user_uploads/3121/wuuj_FKQjFG11xsNh-LBorSx/image.png\" title=\"image.png\"><img src=\"/user_uploads/3121/wuuj_FKQjFG11xsNh-LBorSx/image.png\"></a></div><div class=\"message_inline_image\"><a href=\"/user_uploads/3121/DHKTW6xG9q8eVepsSHGGWPb8/image.png\" title=\"image.png\"><img src=\"/user_uploads/3121/DHKTW6xG9q8eVepsSHGGWPb8/image.png\"></a></div><div class=\"message_inline_image\"><a href=\"/user_uploads/3121/Wrg4kA7s2AsAjDewyFwXeyvw/image.png\" title=\"image.png\"><img src=\"/user_uploads/3121/Wrg4kA7s2AsAjDewyFwXeyvw/image.png\"></a></div><p>For now, it seems to be a new <a href=\"https://minerva-demo.github.io/#category=Algebra&amp;index=1\">Minerva</a>, not ready for using it in proving yet, although it has a Formal-to-formal (Lean 4) example in the paper which worked after a few regenerations:</p>\n<p><a href=\"/user_uploads/3121/F8wr84s-lfq7A7myfDz8YPNo/image.png\">image.png</a></p>\n<div class=\"message_inline_image\"><a href=\"/user_uploads/3121/F8wr84s-lfq7A7myfDz8YPNo/image.png\" title=\"image.png\"><img src=\"/user_uploads/3121/F8wr84s-lfq7A7myfDz8YPNo/image.png\"></a></div><p>P.S. some times <code>---</code> is not output, so it doesn't know to stop, as shown above.</p>\n<p>Configs and chatlog attached:</p>\n<ul>\n<li><a href=\"/user_uploads/3121/emXxBwtGwU63Oht0vxy-1Yzj/llemma_tactics.preset.json\">llemma_tactics.preset.json</a></li>\n<li><a href=\"/user_uploads/3121/CPNZ_mexOBKU3PgIPzpcdfYa/1697610957354.chat.json\">chat.json</a></li>\n</ul>\n<p>Disclaimer: chat log is cherry-picked to demonstrate better results, only tactic state, no original statement due to too many attempts.</p>",
        "id": 397245800,
        "sender_full_name": "Utensil Song",
        "timestamp": 1697612981
    }
]