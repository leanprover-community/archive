[
    {
        "content": "<p><a href=\"https://deepmind.google/discover/blog/alphaevolve-a-gemini-powered-coding-agent-for-designing-advanced-algorithms/\">https://deepmind.google/discover/blog/alphaevolve-a-gemini-powered-coding-agent-for-designing-advanced-algorithms/</a><br>\nNew LLM based coding agent for algorithm discovery. It uses evolutionary search with automated evaluation to generate and optimize code. They claim to have improved data center scheduling, TPU design, and found improvements upon Strassens algorithm and other open math problems</p>",
        "id": 518124102,
        "sender_full_name": "Ivan Eric",
        "timestamp": 1747244206
    },
    {
        "content": "<blockquote>\n<p>AlphaEvolve’s procedure found an algorithm to multiply 4x4 complex-valued matrices using 48 scalar multiplications, improving upon <a href=\"https://en.wikipedia.org/wiki/Strassen_algorithm\">Strassen’s 1969 algorithm</a> that was previously known as the best in this setting. This finding demonstrates a significant advance over our previous work, <a href=\"https://deepmind.google/discover/blog/discovering-novel-algorithms-with-alphatensor/\">AlphaTensor</a>, which specialized in matrix multiplication algorithms, and for 4x4 matrices, only found improvements for binary arithmetic.<br>\nTo investigate AlphaEvolve’s breadth, we applied the system to over 50 open problems in mathematical analysis, geometry, combinatorics and number theory. The system’s flexibility enabled us to set up most experiments in a matter of hours. In roughly 75% of cases, it rediscovered state-of-the-art solutions, to the best of our knowledge.<br>\nAnd in 20% of cases, AlphaEvolve improved the previously best known solutions, making progress on the corresponding open problems. For example, it advanced the <a href=\"https://en.wikipedia.org/wiki/Kissing_number\">kissing number problem</a>. This geometric challenge has <a href=\"https://plus.maths.org/content/newton-and-kissing-problem\">fascinated mathematicians for over 300 years</a> and concerns the maximum number of non-overlapping spheres that touch a common unit sphere. AlphaEvolve discovered a configuration of 593 outer spheres and established a new lower bound in 11 dimensions [previous record: 592].</p>\n</blockquote>\n<p>From paper:</p>\n<blockquote>\n<p>Notably, for multiplying two 4 × 4 matrices, applying the algorithm of Strassen [92] recursively results in an algorithm with 49 multiplications, which works over any field. For the very specific case of multiplying in the field with 2 elements, Fawzi et al. [25] (AlphaTensor) found an algorithm with 47 multiplications. For 56 years, designing an algorithm with fewer than 49 multiplications over any field with characteristic 0 was an open problem. AlphaEvolve is the first method to find an algorithm to multiply two 4 × 4 complex-valued matrices using 48 multiplications.</p>\n</blockquote>",
        "id": 518130319,
        "sender_full_name": "Junyan Xu",
        "timestamp": 1747246326
    },
    {
        "content": "<p>Three candidate number theory problems that come to my mind which could potentially be studied with AlphaEvolve:</p>\n<ul>\n<li>\n<p><a href=\"https://en.wikipedia.org/wiki/Abc_conjecture#Highest-quality_triples\">High-quality abc triples</a> (there are already computer search running for these)</p>\n</li>\n<li>\n<p>Mahler measure: apparently people are already using evolutionary approaches<br>\n<a href=\"https://web.ma.utexas.edu/users/jmc5946/john_clark_thesis.pdf\">https://web.ma.utexas.edu/users/jmc5946/john_clark_thesis.pdf</a><br>\n<a href=\"/user_uploads/3121/lhtsdYmrB3JbMRPQuiymVcos/image.png\">image.png</a></p>\n<div class=\"message_inline_image\"><a href=\"/user_uploads/3121/lhtsdYmrB3JbMRPQuiymVcos/image.png\" title=\"image.png\"><img data-original-content-type=\"image/png\" data-original-dimensions=\"884x811\" src=\"/user_uploads/thumbnail/3121/lhtsdYmrB3JbMRPQuiymVcos/image.png/840x560.webp\"></a></div></li>\n<li>\n<p>Optimization of trigonometric polynomials (I don't know if anyone keep track of records for such things)</p>\n</li>\n</ul>\n<p><a href=\"/user_uploads/3121/bFAbVlx0F4QXK6yutMSQBIG1/image.png\">image.png</a></p>\n<div class=\"message_inline_image\"><a href=\"/user_uploads/3121/bFAbVlx0F4QXK6yutMSQBIG1/image.png\" title=\"image.png\"><img data-original-content-type=\"image/png\" data-original-dimensions=\"830x687\" src=\"/user_uploads/thumbnail/3121/bFAbVlx0F4QXK6yutMSQBIG1/image.png/840x560.webp\"></a></div>",
        "id": 518134718,
        "sender_full_name": "Junyan Xu",
        "timestamp": 1747247680
    },
    {
        "content": "<p>My instinct is that high-quality ABC triples would not be a good problem for this framework because of the arithmetic nature of the subtlety. The applications are mostly about shaving off decimal places or algebra. For example would one expect this kind of tool to be good at primality generation or factoring? ABC triples is kind of like that and my instinct is that a different tool is required. I'd love to be proved wrong!</p>",
        "id": 518158737,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1747256721
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"657719\">@Terence Tao</span> was involved in the results involving harmonic analysis inequalities, additive combinatorics, and packing mentioned in the announcement: <a href=\"https://mathstodon.xyz/@tao/114508029896631083\">https://mathstodon.xyz/@tao/114508029896631083</a></p>",
        "id": 518383220,
        "sender_full_name": "Junyan Xu",
        "timestamp": 1747337043
    },
    {
        "content": "<p>I am passing on this thread to some of my colleagues in the algorithms side. There are a lot of potential function based analyses problems which are considered hard. If they are accepting proposals for problems somewhere, I might be able to forward such a link or form as well to people in the algorithms community</p>",
        "id": 518404065,
        "sender_full_name": "Shreyas Srinivas",
        "timestamp": 1747344735
    },
    {
        "content": "<p>Nvm.  I found the link</p>",
        "id": 518405627,
        "sender_full_name": "Shreyas Srinivas",
        "timestamp": 1747345462
    },
    {
        "content": "<p><a href=\"https://arxiv.org/abs/2511.02864\">https://arxiv.org/abs/2511.02864</a></p>",
        "id": 554016283,
        "sender_full_name": "Ching-Tsun Chou",
        "timestamp": 1762412429
    },
    {
        "content": "<p>This is probably DeepMind people bragging about their latest Alpha-tool, and only has minimal relationship to Lean (although the results are genuine)</p>",
        "id": 554021508,
        "sender_full_name": "Jeremy Tan",
        "timestamp": 1762415029
    },
    {
        "content": "<p>AlphaEvolve is extremely awesome, but nothing to do with Lean.</p>",
        "id": 554046579,
        "sender_full_name": "Kim Morrison",
        "timestamp": 1762423205
    },
    {
        "content": "<p>The paper linked above does mention Lean and even link to Zulip, so maybe at least tangentially related? Maybe a better fit for the ML channel.</p>",
        "id": 554047965,
        "sender_full_name": "Chris Henson",
        "timestamp": 1762423576
    },
    {
        "content": "<p>4 messages were moved here from <a class=\"stream-topic\" data-stream-id=\"113488\" href=\"/#narrow/channel/113488-general/topic/AlphaEvolve\">#general &gt; AlphaEvolve</a> by <span class=\"user-mention silent\" data-user-id=\"110031\">Patrick Massot</span>.</p>",
        "id": 554050125,
        "sender_full_name": "Notification Bot",
        "timestamp": 1762424176
    },
    {
        "content": "<p>Interesting! It is indeed tangentially related.</p>\n<p>I think the takeaway is \"people are making conjectures based on AI-driven experiments/optimisations, and then successfully handing these conjectures off to neural provers writing Lean\".</p>",
        "id": 554053819,
        "sender_full_name": "Kim Morrison",
        "timestamp": 1762425242
    },
    {
        "content": "<p>In particular, on page 4 of the paper it remarks that:</p>\n<blockquote>\n<p>Even more strikingly, for the finite field Kakeya problem (cf. Problem 6.1), AlphaEvolve discovered an interesting general construction. When we fed this programmatic solution to the agent called Deep Think [148], it successfully derived a proof of its correctness and a closedform formula for its size. This proof was then fully formalized in the Lean proof assistant using another AI tool, AlphaProof [147]. This workflow, combining pattern discovery (AlphaEvolve), symbolic proof generation (Deep Think), and formal verification (AlphaProof), serves as a concrete example of how specialized AI systems can be integrated. It suggests a future potential methodology where a combination of AI tools can assist in the process of moving from an empirically observed pattern (suggested by the model) to a formally verified mathematical result, fully automated or semi-automated.</p>\n</blockquote>\n<p>where the lean proof is <a href=\"https://github.com/google-deepmind/alphaevolve_repository_of_problems/blob/main/experiments/finite_field_kakeya_problem/lean_proof/kakeya.lean\">here</a></p>",
        "id": 554059288,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1762426747
    },
    {
        "content": "<p>It’s  impressive how inconsistent at whitespacing this AI-generated code is.</p>",
        "id": 554065963,
        "sender_full_name": "Robin Carlier",
        "timestamp": 1762428766
    },
    {
        "content": "<p>It would be interesting if AlphaEvolve can discover an algorithm that is also a proof of some deep general construction (like RSK-algorithm). I am reading through this work <a href=\"https://arxiv.org/abs/2511.02864\">https://arxiv.org/abs/2511.02864</a> by prof. Tao and DeepMind, and didn't find such examples yet</p>",
        "id": 554129857,
        "sender_full_name": "Dmitry Rybin",
        "timestamp": 1762444981
    },
    {
        "content": "<p>Having read the paper some more: this is wild.</p>",
        "id": 554207920,
        "sender_full_name": "Kim Morrison",
        "timestamp": 1762471862
    },
    {
        "content": "<p>I would love to know the \"overhead factor\", i.e. the compression factor between AlphaProof's proof and a human written (or even just human-cleaned-up) one. I haven't actually loaded up the proof, but skimming it there are many redundant looking steps.</p>",
        "id": 554208056,
        "sender_full_name": "Kim Morrison",
        "timestamp": 1762471934
    },
    {
        "content": "<p>You mean to say that <code>induction π</code> is not an essential step of the proof?</p>",
        "id": 554269596,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1762506181
    },
    {
        "content": "<p>As I understand it, the goal here was more \"the system produced a Lean proof to ensure the argument was correct\" rather than \"the system produced a Lean proof as an artifact to explain the proof to humans\", so no explicit cleanup step was involved</p>",
        "id": 554270095,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1762506320
    },
    {
        "content": "<p>There is some similarity with CryptOpt, which does give formal guarantees (in Rocq).<br>\n<a href=\"https://arxiv.org/abs/2211.10665\">https://arxiv.org/abs/2211.10665</a></p>",
        "id": 554283342,
        "sender_full_name": "Bas Spitters",
        "timestamp": 1762510432
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110087\">Kim Morrison</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/AlphaEvolve/near/554208056\">said</a>:</p>\n<blockquote>\n<p>I would love to know the \"overhead factor\", i.e. the compression factor between AlphaProof's proof and a human written (or even just human-cleaned-up) one. I haven't actually loaded up the proof, but skimming it there are many redundant looking steps.</p>\n</blockquote>\n<p>I remember seeing a model for golfing lean proofs on zulip some time earlier? Maybe that one could help us to make the code more organized and readable. (But it seems that they haven't released the model to the public yet)</p>\n<p>Edit: the discussion thread for that model is <a class=\"stream-topic\" data-stream-id=\"219941\" href=\"/#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/ProofOptimizer/with/547497725\">#Machine Learning for Theorem Proving &gt; ProofOptimizer</a></p>",
        "id": 554316648,
        "sender_full_name": "Wang Jingting",
        "timestamp": 1762520508
    },
    {
        "content": "<p>The new paper <em><a href=\"https://arxiv.org/abs/2511.13391\">Finding Kissing Numbers with Game-theoretic Reinforcement Learning</a></em> (submitted Nov 17) broke kissing number records in dimensions 25 to 31. It's interesting that the three recent breakthroughs improved disjoint records: AlphaEvolve (May 2025) improved 11-dimensional record from 592 to 593, <a href=\"https://arxiv.org/abs/2411.04916\">Cohn and Li</a> (Nov 2024) broke the records from 17 to 21 dimensions, and now this.</p>",
        "id": 560947606,
        "sender_full_name": "Junyan Xu",
        "timestamp": 1764452983
    }
]