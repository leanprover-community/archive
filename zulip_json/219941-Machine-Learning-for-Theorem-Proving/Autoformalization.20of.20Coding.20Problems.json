[
    {
        "content": "<p>As part of my push for <a href=\"https://gasstationmanager.github.io/ai/2024/11/04/a-proposal.html\">creating coding As able to prove the correctness of its own code</a>,<br>\nI am working on autoformalization of coding problem datasets, i.e. translating problem descriptions into formal specifications in Lean.</p>\n<p>A major challenge of autoformalization efforts is the evaluation of the quality of the translations in a scalable manner.<br>\nFor coding problems, the situation may be better, especially if the dataset comes with test cases for each problem. In short, we can repurpose these test cases to serve as checks on the fidelity of the translations. If the translation is faithful, the formal specification and the test cases should be compatible, and this check can be automated.</p>\n<p>See <a href=\"https://github.com/GasStationManager/FormalizeWithTest\">here</a> for details and preliminary results on my proof of concept. With a sample of 30 problems (taken from the code_contests data set), I used Sonnet to translate them into formal specifications in Lean, resulting in 17 specifications without syntax errors. My verification procedure was able to prove that 10 of these are compatible with their test cases.<br>\n</p>\n<p>I think we can already scale this up to produce autoformalized data sets of a pretty good size.</p>",
        "id": 485012158,
        "sender_full_name": "GasStationManager",
        "timestamp": 1732848955
    },
    {
        "content": "<p>Comments are welcome! A couple of questions:</p>\n<ul>\n<li>right now my proof procedure (beginning of <a href=\"https://github.com/GasStationManager/FormalizeWithTest/blob/main/verify.py\">this file</a> ) consists of trying a kitchen sink of all the tactics I know about. Any advice on building a good automated proof script for simple proof tasks? I did try the lean-smt solver but perhaps I'm not using it the best way. Same with Aesop. What about lean-auto / duper?</li>\n</ul>",
        "id": 485012606,
        "sender_full_name": "GasStationManager",
        "timestamp": 1732849279
    },
    {
        "content": "<ul>\n<li>anyone else here working on autoformalization? With autoformalization of mathematical theorems, a similar approach could work partially: use e.g. Plausible to try to generate counterexamples. But if your formalized theorem statement passes the test cases, it could still just be a different statement from the natural language version, one just happens to be also true. With coding problems that is not an issues because it asks for a function, so it is very unlikely to satisfy the test cases by accident.  </li>\n<li>So if you are training an autoformalization agent, it might be beneficial to also train on coding problems, even if your goal is math, because you get much nicer ground truth feedback from the coding problem test cases...</li>\n</ul>",
        "id": 485013979,
        "sender_full_name": "GasStationManager",
        "timestamp": 1732850064
    },
    {
        "content": "<p>I am working on Autoformalization and the test I use if \"roundtrip\" - informalize and get an LLM to compare the statements. This is not perfect but is mostly correct with \"o1-mini\" comparing statements (using \"GPT-4o\" for both formalization and informalization)</p>",
        "id": 485057971,
        "sender_full_name": "Siddhartha Gadgil",
        "timestamp": 1732873083
    },
    {
        "content": "<p>The main techniques I’ve seen in the literature are (a) trying to automatically prove the statement correct, incorrect, or vacuous (hypotheses imply false), (b) round tripping (either at level of text or at an embedding level or using an LLM to verify), (c) automatically proving that two translations are equivalent and using the largest cluster of pairwise equivalent translations, (d) using a LLM to score the translation, (e) using feedback from Lean (and possibly automatic fixes) to fix bugs and make sure the code compiles.  But this whole field is new and there is a lot of room for new ideas and better implementations of existing ideas.</p>",
        "id": 485089614,
        "sender_full_name": "Jason Rute",
        "timestamp": 1732883606
    },
    {
        "content": "<p>Then there's also David Silver's <a href=\"https://www.youtube.com/watch?v=pkpJMNjvgXw\">assertion</a> that autoformalization doesn't have to be correct; as long as some theorem statement is produced, they can be used as training data; and that's how they trained AlphaProof. Has anyone else tried that approach to train a theorem prover?</p>\n<div class=\"youtube-video message_inline_image\"><a data-id=\"pkpJMNjvgXw\" href=\"https://www.youtube.com/watch?v=pkpJMNjvgXw\"><img src=\"https://uploads.zulipusercontent.net/8c88bdeba1e183e61d929f221da7801223f42660/68747470733a2f2f692e7974696d672e636f6d2f76692f706b704a4d4e6a766758772f64656661756c742e6a7067\"></a></div>",
        "id": 485151792,
        "sender_full_name": "GasStationManager",
        "timestamp": 1732908762
    },
    {
        "content": "<p><a href=\"https://arxiv.org/abs/2405.14333\">DeepSeek-Prover</a> (and <a href=\"https://arxiv.org/abs/2408.08152\">DeepSeek-Prover v1.5</a> which uses the same training) are very close to AlphaProof in that respect.  They formalize a large number of scraped math problems in different ways and use both the correct and incorrect formalizations.  (That is also where I first heard about also checking for vacuously true formalizations.)</p>",
        "id": 485152548,
        "sender_full_name": "Jason Rute",
        "timestamp": 1732909228
    },
    {
        "content": "<p>(Also there has been a large number of autoformalization papers in the last few months and I’m behind on reading them all.)</p>",
        "id": 485152700,
        "sender_full_name": "Jason Rute",
        "timestamp": 1732909327
    },
    {
        "content": "<p>Re: using feedback from Lean, I can confirm that it is very useful. A lot of times the LLM outputs will have syntax errors. Some LLMs (like Sonnet) are almost there, and getting feedback from Lean allows them to fix their code. I made the simple script <a href=\"https://github.com/GasStationManager/LeanTool\">LeanTool</a> for this; might be of interest to others.</p>",
        "id": 485153091,
        "sender_full_name": "GasStationManager",
        "timestamp": 1732909607
    },
    {
        "content": "<p>Also as for using incorrect formalizations, the first paper using GPT-style LLMs for autoformalization (<a href=\"https://arxiv.org/abs/2205.12615\">https://arxiv.org/abs/2205.12615</a>) also showed you can use a large number of mostly wrong formalizations to train a theorem prover with RL, but I don’t think they used proving the theorem false as a training objective. (Although some papers also use successful parts of partial proofs, like say if you can prove one case but not the other, to add more training data.  I don’t know if that paper did that.)</p>",
        "id": 485153173,
        "sender_full_name": "Jason Rute",
        "timestamp": 1732909670
    },
    {
        "content": "<p>Re feedback: This is also a big technique now in theorem proving.  A number of papers use symbolic methods and/or editor feedback to fix broken LLM generated proofs.  The pass rates are much higher than the LLM proof alone.  I survey such papers in another thread.</p>",
        "id": 485153500,
        "sender_full_name": "Jason Rute",
        "timestamp": 1732909846
    },
    {
        "content": "<p>The list is in this thread, but there are already a number of newer papers like CobbleStone (in Coq). <a href=\"#narrow/stream/219941-Machine-Learning-for-Theorem-Proving/topic/Proper.20LLM.20Lean4.20Integration.20with.20recursive.20checks.20for.20error\">https://leanprover.zulipchat.com/#narrow/stream/219941-Machine-Learning-for-Theorem-Proving/topic/Proper.20LLM.20Lean4.20Integration.20with.20recursive.20checks.20for.20error</a>.  It is just so easy for folks to experiment with this approach.</p>",
        "id": 485154120,
        "sender_full_name": "Jason Rute",
        "timestamp": 1732910211
    },
    {
        "content": "<p>Thanks very much for the pointers!</p>",
        "id": 485156109,
        "sender_full_name": "GasStationManager",
        "timestamp": 1732911505
    },
    {
        "content": "<p>I've always thought that the Draft-Sketch-Prove type of approach holds a lot of promise; if we want to utilize automated tools like SMT /SAT solvers (and I think we do), then that is a natural way to divide the labor. However most papers using this type of approach appear to implement in Isabelle, apparently due to the availability of the sledgehammer tool in Isabelle. Does Lean have a comparable set of tools for automatic proofs today? (Even if only a subset is available, perhaps some tasks can be filled by LLMs...)</p>",
        "id": 485170229,
        "sender_full_name": "GasStationManager",
        "timestamp": 1732920953
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"776090\">GasStationManager</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Autoformalization.20of.20Coding.20Problems/near/485170229\">said</a>:</p>\n<blockquote>\n<p>I've always thought that the Draft-Sketch-Prove type of approach holds a lot of promise; if we want to utilize automated tools like SMT /SAT solvers (and I think we do), then that is a natural way to divide the labor. However most papers using this type of approach appear to implement in Isabelle, apparently due to the availability of the sledgehammer tool in Isabelle. Does Lean have a comparable set of tools for automatic proofs today? (Even if only a subset is available, perhaps some tasks can be filled by LLMs...)</p>\n</blockquote>\n<p>A hammer in Lean is under development (for some pointers, see lean-auto and Duper). There are also purely LLM-based tools like LLMLean and LeanCopilot.</p>\n<p>Orthogonally, a significant issue for re-creating Draft Sketch Prove in Lean is that there is very little sketch-style data in Lean. To illustrate, many proofs in Isabelle look like (when translated to Lean syntax):</p>\n<div class=\"codehilite\" data-code-language=\"Lean4\"><pre><span></span><code><span class=\"kn\">example</span><span class=\"w\"> </span><span class=\"o\">:</span><span class=\"w\"> </span><span class=\"n\">G</span><span class=\"w\"> </span><span class=\"o\">:=</span>\n<span class=\"w\">  </span><span class=\"k\">have</span><span class=\"w\"> </span><span class=\"n\">h1</span><span class=\"w\"> </span><span class=\"o\">:=</span><span class=\"w\"> </span><span class=\"k\">by</span><span class=\"w\"> </span><span class=\"n\">sledgehammer</span>\n<span class=\"w\">  </span><span class=\"k\">have</span><span class=\"w\"> </span><span class=\"n\">h2</span><span class=\"w\"> </span><span class=\"o\">:=</span><span class=\"w\"> </span><span class=\"k\">by</span><span class=\"w\"> </span><span class=\"n\">sledgehammer</span><span class=\"w\"> </span><span class=\"o\">[</span><span class=\"n\">h1</span><span class=\"o\">]</span>\n<span class=\"w\">  </span><span class=\"k\">have</span><span class=\"w\"> </span><span class=\"n\">h3</span><span class=\"w\"> </span><span class=\"o\">:=</span><span class=\"w\"> </span><span class=\"k\">by</span><span class=\"w\"> </span><span class=\"n\">sledgehammer</span><span class=\"w\"> </span><span class=\"o\">[</span><span class=\"n\">h1</span><span class=\"o\">,</span><span class=\"w\"> </span><span class=\"n\">h2</span><span class=\"o\">]</span>\n<span class=\"w\">  </span><span class=\"k\">show</span><span class=\"w\"> </span><span class=\"n\">G</span><span class=\"w\"> </span><span class=\"k\">by</span><span class=\"w\"> </span><span class=\"n\">sledgehammer</span><span class=\"w\"> </span><span class=\"o\">[</span><span class=\"n\">h1</span><span class=\"o\">,</span><span class=\"w\"> </span><span class=\"n\">h2</span><span class=\"o\">,</span><span class=\"w\"> </span><span class=\"n\">h3</span><span class=\"o\">]</span>\n</code></pre></div>\n<p>and therefore it is natural in Isabelle to train models that generate only the informal/formal \"sketch\" part <code>h1, h2, h3</code> because of abundance of data; then you can finish off by hammer. On the other hand, Lean proofs are usually</p>\n<div class=\"codehilite\" data-code-language=\"Lean4\"><pre><span></span><code><span class=\"kn\">example</span><span class=\"w\"> </span><span class=\"o\">:</span><span class=\"w\"> </span><span class=\"n\">G</span><span class=\"w\"> </span><span class=\"o\">:=</span><span class=\"w\"> </span><span class=\"k\">by</span>\n<span class=\"w\">  </span><span class=\"n\">tactic1</span><span class=\"w\"> </span><span class=\"c1\">-- suffices to show G'</span>\n<span class=\"w\">  </span><span class=\"n\">tactic2</span><span class=\"w\"> </span><span class=\"c1\">-- suffices to show G''</span>\n<span class=\"w\">  </span><span class=\"n\">tactic3</span><span class=\"w\"> </span><span class=\"c1\">-- solves G''</span>\n</code></pre></div>\n<p>and here these tactics cannot be replaced by 3 hammer invocations (note that hammers work by translating to a format for external provers, and therefore can either completely solve a goal or completely fail). So the problem of generating \"sketches\" that can be finished off by hammers for Lean is much harder than in Isabelle (where you have papers like Draft, Sketch, Prove and SubgoalXL), simply due to lack of training data.</p>",
        "id": 485171535,
        "sender_full_name": "Thomas Zhu",
        "timestamp": 1732922122
    },
    {
        "content": "<p>Perhaps this is getting far from the original topic. On autoformalization my opinion is that for RL training data, correctness of the formalized version doesn't matter. If I interpret correctly, AlphaProof tries 100 formalizations per problem (1M informal problems -&gt; 100M formal problems). It begins to matter for generating benchmarks from e.g. high school competitions, where correctness is crucial</p>",
        "id": 485171993,
        "sender_full_name": "Thomas Zhu",
        "timestamp": 1732922536
    },
    {
        "content": "<p>Arguably the sketch of a good Lean proof is the sequence of lemmas involved (in that long proofs are best split up into separate lemmas rather than having a single long <code>by</code> tactic block).</p>",
        "id": 485178211,
        "sender_full_name": "Joseph Myers",
        "timestamp": 1732928125
    },
    {
        "content": "<p>You might not be able to prove each individual lemma by a hammer, but the smaller the lemmas are, surely the easier it would be for an AI to reconstruct proofs for each of them.</p>",
        "id": 485178305,
        "sender_full_name": "Joseph Myers",
        "timestamp": 1732928211
    },
    {
        "content": "<p>Actually my main interest is in code generation (and proof of its correctness). In this setting, often the LLM can already articulate in natural language why their code is correct. So perhaps we just need a good formalizer to translate it into a formal sketch (coming back to the topic of this thread).</p>",
        "id": 485179349,
        "sender_full_name": "GasStationManager",
        "timestamp": 1732929115
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"266253\">Joseph Myers</span> <a href=\"#narrow/stream/219941-Machine-Learning-for-Theorem-Proving/topic/Autoformalization.20of.20Coding.20Problems/near/485178305\">said</a>:</p>\n<blockquote>\n<p>You might not be able to prove each individual lemma by a hammer, but the smaller the lemmas are, surely the easier it would be for an AI to reconstruct proofs for each of them.</p>\n</blockquote>\n<p>I agree there is some equivalence between have-style, declarative proofs and short lemmas preceding a proof. Plus, if a lemma is not solvable by hammer, one can always propose lemmas for this lemma and recurse. On the machine learning side, one would need to train a lemma generator, which requires extracting meaningful (theorem, lemma) pairs from human written proofs; this recursive lemma pipeline is explored by this paper <a href=\"https://arxiv.org/pdf/2411.01829\">https://arxiv.org/pdf/2411.01829</a> (though in Isabelle)</p>",
        "id": 485189336,
        "sender_full_name": "Thomas Zhu",
        "timestamp": 1732938111
    },
    {
        "content": "<p>Small update: I have ported these autoformalized problems to <a href=\"http://www.codeproofarena.com:8000/challenges\">Code with Proofs: the Arena</a> demo site. They go from challenge 38 \"beautifulTable\" to challenge 47 \"dice_game\". You're welcome to try them out!</p>",
        "id": 485816965,
        "sender_full_name": "GasStationManager",
        "timestamp": 1733223106
    }
]