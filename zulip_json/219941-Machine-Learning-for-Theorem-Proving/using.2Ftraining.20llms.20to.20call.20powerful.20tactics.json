[
    {
        "content": "<p>what would it take to build an ai agent for theorem proving that will actually use tactics more powerful than the 'elementary' ones?</p>",
        "id": 509798783,
        "sender_full_name": "Jared green",
        "timestamp": 1743630022
    },
    {
        "content": "<p>specifically, synthesizing subgoals and then placing a power tactic that might close them</p>",
        "id": 509799337,
        "sender_full_name": "Jared green",
        "timestamp": 1743630324
    },
    {
        "content": "<p>Does <a href=\"https://storage.googleapis.com/deepmind-media/DeepMind.com/Blog/imo-2024-solutions/P2/index.html\"><code>use H$ D.2.2 (φ _ *(L+1)-1) (L.le_sub_of_add_le (by nlinarith[((b.1* b.2+1).totient_pos).2 Nat.succ_pos']))▸(((Nat.dvd_gcd) ( this).1)) this.right</code></a> count as a \"powerful tactic\"?</p>",
        "id": 509800128,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1743630677
    },
    {
        "content": "<p>no, the short ones like aesop, duper...</p>",
        "id": 509800626,
        "sender_full_name": "Jared green",
        "timestamp": 1743630937
    },
    {
        "content": "<p>the ones intended to be general</p>",
        "id": 509800735,
        "sender_full_name": "Jared green",
        "timestamp": 1743630984
    },
    {
        "content": "<p>Thor does this in Isabelle by calling Sledgehammer as a tactic more or less.  Draft-Sketch-Prove (and successors) is even closer to what you want.  It uses an LLM to write a proof sketch and uses SledgeHammer to fill in the holes in the sketch.</p>",
        "id": 509807521,
        "sender_full_name": "Jason Rute",
        "timestamp": 1743634330
    },
    {
        "content": "<p>But AlphaProof also synthesized fairly advanced subgoals.  I think that is more important than whether or not those subgoals can be filled in with a single tactic call.</p>",
        "id": 509807747,
        "sender_full_name": "Jason Rute",
        "timestamp": 1743634447
    },
    {
        "content": "<p>I believe the solution is to have a library of prompt instructions that covers the Lean features that are not well represented in training data. I have a very primitive version in <a href=\"https://github.com/GasStationManager/LeanTool\">Leantool</a>, where the system prompt introduced the LLM to features like omega, exact?, aesop, and LeanSearchClient's <a href=\"https://www.moogle.ai/\">#moogle</a>. This will require additional prompt engineering efforts to make it work well, e.g. adding  examples.<br>\nIf you have (or can write) a good prompt that teaches a Lean feature, let me know and I'd be happy to add it to LeanTool..</p>",
        "id": 509813669,
        "sender_full_name": "GasStationManager",
        "timestamp": 1743638027
    },
    {
        "content": "<p>i have no prompt engineering 'skills', i sort of expected something that would be trained from the start with that in mind. if you get a pretrained model to do it, i think you would just add the new power tactic to a list of mcp templates.</p>",
        "id": 509848927,
        "sender_full_name": "Jared green",
        "timestamp": 1743659083
    },
    {
        "content": "<p>given how existing agents work you either need to incentivize exploration or execute the tactic when some mechanically checkable condition is met</p>",
        "id": 510740007,
        "sender_full_name": "Leni Aniva",
        "timestamp": 1744050521
    }
]