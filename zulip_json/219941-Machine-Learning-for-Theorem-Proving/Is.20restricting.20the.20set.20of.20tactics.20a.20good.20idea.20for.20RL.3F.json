[
    {
        "content": "<p>As hinted in a previous post, I am just interested in this question...</p>\n<p>More specifically, I imagine a reinforcement learning agent interacting with Lean, which only spits the following tokens:</p>\n<ul>\n<li><code>induction</code>: as the universal elimination rule.</li>\n<li><code>constructor</code> (or maybe <code>refine</code>): as the universal introduction rule.</li>\n<li><code>let</code>: as the universal cut rule.</li>\n<li><code>rw</code>: for better handling of equalities.</li>\n<li>A few language primitives including <code>fun</code> (lambda), <code>-&gt;</code> (Pi types), local variables, etc: for constructing data.</li>\n<li>A few pre-defined inductive types including <code>PSigma</code>, natural numbers and well-founded trees: they are used in the original Martin-Löf type theory and <a href=\"https://jashug.github.io/papers/whynotw.pdf\">can be used to encode most inductive types</a>.</li>\n<li><code>apply?</code>: for unification search within whole context (I imagine being able to <em>refer to theorems by statements instead of names</em> can be a boost to performance; this serves a similar role as retrieval augmentation).<ul>\n<li>Maybe there can be an interactive exploration of the discrimination tree, where the agent can choose to expand some node and Lean lists its child nodes like in a file explorer tree.</li>\n</ul>\n</li>\n<li>A special tactic which calls <em>all</em> important automations in parallel (e.g. <code>simp</code>, <code>linarith</code>, <code>aesop</code>, etc), trying to close the current goal.</li>\n</ul>\n<p>This should still be <em>complete</em> in that any well-typed term is constructible, and can possibly cut down on the number of branches each step, with less \"duplicated\" actions (e.g. <code>use</code> and <code>constructor</code> essentially do the same thing). So for example trajectory sampling can be more effective...?</p>",
        "id": 478836686,
        "sender_full_name": "Zhanrong Qiao",
        "timestamp": 1729828423
    },
    {
        "content": "<p>I mean, I think you could restrict to just <code>intro [freshname]</code>, <code>let [freshname] := [localname] [localname]</code>, <code>let [freshname] := [libraryname]</code>, and <code>apply [localname]</code> -- where [localname] is a local hypothesis, and [libraryname] is a named theorem already declared. This lets you construct any expression tree, so it's obviously _complete_ in the sense you give! But also, obviously, very impractical. :)</p>",
        "id": 478992067,
        "sender_full_name": "Alex Meiburg",
        "timestamp": 1729892527
    },
    {
        "content": "<p>My point is that when you try to reduce the search space, you also lose out on some things that might make life easier; _and_ you lose out on side information. A model trained on existing proofs will see that humans use <code>use</code> and <code>constructor</code> in different places, even though they're equivalent, and that will (ironically?) teach them additional useful(!) facts about problem structure.</p>",
        "id": 478992120,
        "sender_full_name": "Alex Meiburg",
        "timestamp": 1729892611
    },
    {
        "content": "<p>For example, why do you want to have <code>rw</code> but not <code>conv</code> or <code>simp_rw</code>? What about <code>measurability</code>?</p>\n<p>And while <code>let</code> may be a universal cut rule, if you use to produce local values of type Prop, then (at least in the default Lean infoview) those proof terms will clutter up the context a lot, making it very hard to actually understand and advance the local context. For that reason <code>have</code> could be good.</p>",
        "id": 478992419,
        "sender_full_name": "Alex Meiburg",
        "timestamp": 1729892835
    },
    {
        "content": "<p>Yes, that is equivalent! Actually many find term mode and tactic mode equally usable, as long as stronger tactics like <code>simp_rw</code> etc. are not needed (I agree I should put <code>simp_rw</code> instead of <code>rw</code> in my list). Mathlib contains many lemmas written entirely without tactics. As for <code>have</code>: maybe we can change the infoview to hide terms with types in <code>Prop</code>? There is definitional proof irrelevance nevertheless.</p>\n<p>However, I doubt the importance of \"side information\" the tactics might carry, as different people already <em>prefer</em> to use different tactics (e.g. some prefer <code>refine</code> instead of <code>constructor</code> and <code>use</code> because it lets you write shorter proofs) and Mathlib is already a mixture of styles. And code comments would make up for the side information.</p>\n<p>For things like <code>ring</code> or <code>measurability</code>, I would add it to the \"special tactic of all available automations\" if it does not take significant amount of time to run (the heavier tactics will be the bottleneck nevertheless).</p>",
        "id": 479005970,
        "sender_full_name": "Zhanrong Qiao",
        "timestamp": 1729902343
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"450398\">Zhanrong Qiao</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Is.20restricting.20the.20set.20of.20tactics.20a.20good.20idea.20for.20RL.3F/near/479005970\">said</a>:</p>\n<blockquote>\n<p>Yes, that is equivalent! Actually many find term mode and tactic mode equally usable, as long as stronger tactics like <code>simp_rw</code> etc. are not needed (I agree I should put <code>simp_rw</code> instead of <code>rw</code> in my list). Mathlib contains many lemmas written entirely without tactics. As for <code>have</code>: maybe we can change the infoview to hide terms with types in <code>Prop</code>? There is definitional proof irrelevance nevertheless.</p>\n<p>However, I doubt the importance of \"side information\" the tactics might carry, as different people already <em>prefer</em> to use different tactics (e.g. some prefer <code>refine</code> instead of <code>constructor</code> and <code>use</code> because it lets you write shorter proofs) and Mathlib is already a mixture of styles. And code comments would make up for the side information.</p>\n<p>For things like <code>ring</code> or <code>measurability</code>, I would add it to the \"special tactic of all available automations\" if it does not take significant amount of time to run (the heavier tactics will be the bottleneck nevertheless).</p>\n</blockquote>\n<p>How many basic tactics would you need to simulate the \"heavier\" tactics? Because if it's a lot, then you're just creating more branch points. Or if you do as <span class=\"user-mention\" data-user-id=\"448405\">@Alex Meiburg</span> is saying, then you just defer the bigger branch points to the selection of the right \"localname\" and \"libraryname\" which would have a huge number of possibilities</p>",
        "id": 479008050,
        "sender_full_name": "Sid",
        "timestamp": 1729904425
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"246665\">Sid</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Is.20restricting.20the.20set.20of.20tactics.20a.20good.20idea.20for.20RL.3F/near/479008050\">said</a>:</p>\n<blockquote>\n<p>How many basic tactics would you need to simulate the \"heavier\" tactics? Because if it's a lot, then you're just creating more branch points. Or if you do as <span class=\"user-mention silent\" data-user-id=\"448405\">Alex Meiburg</span> is saying, then you just defer the bigger branch points to the selection of the right \"localname\" and \"libraryname\" which would have a huge number of possibilities</p>\n</blockquote>\n<p>I let simple and heavy automation tactics run in parallel so:</p>\n<ul>\n<li>When simple tactics e.g. <code>measurability</code> are able to prove the claim, other running tactics can be terminated immediately;</li>\n<li>If the case cannot be handled by simple tactics, they should not take too much time to fail and the heavier tactics might find a proof;</li>\n</ul>\n<p>And I suggest an interactive discrimination tree exactly for reducing possibilities when choosing an appropriate libraryname: one might claim a proposition by (partial) statement, which only involves data, and data constructors are normally smaller in number than theorems; then unification search like <code>exact?</code> is used to check if this claim is a known proposition.</p>",
        "id": 479008553,
        "sender_full_name": "Zhanrong Qiao",
        "timestamp": 1729904954
    },
    {
        "content": "<p>The construction of a proposition can be split into multiple steps, indeed this just creates more branch points. But a low branching factor also means that a policy table (or anything approximating it) can be much smaller (simpler). If there is a value function instead, choosing a policy involves much less evaluations.</p>",
        "id": 479008966,
        "sender_full_name": "Zhanrong Qiao",
        "timestamp": 1729905469
    },
    {
        "content": "<p>My point of view is that this sort of thing needs to be rigorously experimented with to know for sure either way.  I am doubtful it would work, since big tactics give a lot of power, but maybe it could.  Also a few more points: (1) it would be harder to get training data for a restricted set of tactics.  However, It is possible by decomposing tactics or using RL with synthetic theorems.  (2) I think proper RL would help to better handle the issue of multiple equivalent tactics by making the model more opinionated.  (3) At least one use case of AI for Lean would be to have it output idiomatic proofs.  If you mess with the tactics too much, it could be far from idiomatic (but as we have seen with the AlphaProof proofs, that also happens with RL).</p>",
        "id": 479009271,
        "sender_full_name": "Jason Rute",
        "timestamp": 1729905821
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"115715\">Jason Rute</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Is.20restricting.20the.20set.20of.20tactics.20a.20good.20idea.20for.20RL.3F/near/479009271\">said</a>:</p>\n<blockquote>\n<p>My point of view is that this sort of thing needs to be rigorously experimented with to know for sure either way.  I am doubtful it would work, since big tactics give a lot of power, but maybe it could.  Also a few more points: (1) it would be harder to get training data for a restricted set of tactics.  However, It is possible by decomposing tactics or using RL with synthetic theorems.  (2) I think proper RL would help to better handle the issue of multiple equivalent tactics by making the model more opinionated.  (3) At least one use case of AI for Lean would be to have it output idiomatic proofs.  If you mess with the tactics too much, it could be far from idiomatic (but as we have seen with the AlphaProof proofs, that also happens with RL).</p>\n</blockquote>\n<p>Thank you! I just want to confirm if this is not obviously wrong... Surely big tactics are included, I am just considering combining them into one (or a few); IIRC there is similar practice in Isabelle (?). As for idiomatic proofs, they might be reconstructed later, but <em>during proof search</em> they are not the primary concern.</p>",
        "id": 479009631,
        "sender_full_name": "Zhanrong Qiao",
        "timestamp": 1729906219
    },
    {
        "content": "<p>One thing that might be relevant is -- if you're using a probabilistic policy to generate the next actions, there's already going to be a soft version of selection going on -- as some actions will have a much lower probability than others. Also a low branching factor is good but if it's leading to longer proof length, then the search space will not necessarily decrease.</p>",
        "id": 479022592,
        "sender_full_name": "Sid",
        "timestamp": 1729920191
    },
    {
        "content": "<p>Is anyone actually using the internals of <code>apply?</code> to do lookup during tree search? Once it had built the discrimination tree it is very fast, and it computes lazily so you can ask for as many results as needed.</p>",
        "id": 479028632,
        "sender_full_name": "Kim Morrison",
        "timestamp": 1729927179
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"246665\">Sid</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Is.20restricting.20the.20set.20of.20tactics.20a.20good.20idea.20for.20RL.3F/near/479022592\">said</a>:</p>\n<blockquote>\n<p>One thing that might be relevant is -- if you're using a probabilistic policy to generate the next actions, there's already going to be a soft version of selection going on -- as some actions will have a much lower probability than others. Also a low branching factor is good but if it's leading to longer proof length, then the search space will not necessarily decrease.</p>\n</blockquote>\n<p>Yes. But (1) selection requires more learning, and (2) the search space in mathematical theorem proving is always recursively enumerable (has cardinality ω) and there is no way to essentially decrease it.</p>",
        "id": 479032999,
        "sender_full_name": "Zhanrong Qiao",
        "timestamp": 1729931852
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110087\">Kim Morrison</span> <a href=\"#narrow/stream/219941-Machine-Learning-for-Theorem-Proving/topic/Is.20restricting.20the.20set.20of.20tactics.20a.20good.20idea.20for.20RL.3F/near/479028632\">said</a>:</p>\n<blockquote>\n<p>Is anyone actually using the internals of <code>apply?</code> to do lookup during tree search? Once it had built the discrimination tree it is very fast, and it computes lazily so you can ask for as many results as needed.</p>\n</blockquote>\n<p>Not that I’m aware, but also that would only be relevant to a few tactics like exact, apply, and refine, right?</p>",
        "id": 479041596,
        "sender_full_name": "Jason Rute",
        "timestamp": 1729940126
    },
    {
        "content": "<p>Premise/lemma/argument selection is much more general.</p>",
        "id": 479041616,
        "sender_full_name": "Jason Rute",
        "timestamp": 1729940153
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"115715\">Jason Rute</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Is.20restricting.20the.20set.20of.20tactics.20a.20good.20idea.20for.20RL.3F/near/479041616\">said</a>:</p>\n<blockquote>\n<p>Premise/lemma/argument selection is much more general.</p>\n</blockquote>\n<p>The point of premise/lemma/argument selection is that they are more likely to be <em>used</em> somewhere in the proof, where they (conceptually) close a subgoal. Using <code>apply?</code> at the point that some known theorem might be <em>used</em> should have similar effects?</p>",
        "id": 479043013,
        "sender_full_name": "Zhanrong Qiao",
        "timestamp": 1729941420
    },
    {
        "content": "<p>The problem with apply? and exact? Is that it requires a very specific syntactic match, so it wouldn’t be able to find a good simp lemma for example.  It might be possible to make good use of apply? in some system, but I don’t think it would replace neural argument selection.</p>",
        "id": 479043361,
        "sender_full_name": "Jason Rute",
        "timestamp": 1729941756
    },
    {
        "content": "<p>Tagging simp lemmas is indeed difficult (a concept/design of some \"normal form\" is needed). But in the case of a congruence closure tactic, in theory they can just put the whole context into consideration by checking the discr tree for each individual rewrite?</p>",
        "id": 479043685,
        "sender_full_name": "Zhanrong Qiao",
        "timestamp": 1729942106
    },
    {
        "content": "<p>I agree that neural argument selection will not be replaced, since sometimes a fuzzy match might suggest a possible direction for a proof.</p>",
        "id": 479043859,
        "sender_full_name": "Zhanrong Qiao",
        "timestamp": 1729942303
    },
    {
        "content": "<p>Yes, for a number of tactics, like rw, exact, apply you could do some form of constrained decoding with discrimination trees.</p>",
        "id": 479049690,
        "sender_full_name": "Jason Rute",
        "timestamp": 1729947999
    },
    {
        "content": "<p>I suspect this is a mistake to say <code>apply?</code> only suggests <code>apply</code> tactics! Just because <code>apply</code> is so fundamental and general.</p>",
        "id": 479118392,
        "sender_full_name": "Kim Morrison",
        "timestamp": 1730020571
    },
    {
        "content": "<p>Similarly there is <code>rw?</code> which suggests rewrites which will actually work.</p>",
        "id": 479118404,
        "sender_full_name": "Kim Morrison",
        "timestamp": 1730020598
    },
    {
        "content": "<p>And <code>have?</code> for forward reasoning.</p>",
        "id": 479118407,
        "sender_full_name": "Kim Morrison",
        "timestamp": 1730020606
    },
    {
        "content": "<p>Unless someone has specific evidence that these are too slow, it seems crazy to leave these suggestions on the ground.</p>",
        "id": 479118423,
        "sender_full_name": "Kim Morrison",
        "timestamp": 1730020642
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110087\">Kim Morrison</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Is.20restricting.20the.20set.20of.20tactics.20a.20good.20idea.20for.20RL.3F/near/479028632\">said</a>:</p>\n<blockquote>\n<p>Once it had built the discrimination tree it is very fast,</p>\n</blockquote>\n<p>What's the recommended way to preheat this cache?</p>",
        "id": 479120657,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1730022912
    },
    {
        "content": "<p>Excellent question, to which I don't know the answer. :-)</p>",
        "id": 479171435,
        "sender_full_name": "Kim Morrison",
        "timestamp": 1730069383
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"450398\">Zhanrong Qiao</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Is.20restricting.20the.20set.20of.20tactics.20a.20good.20idea.20for.20RL.3F/near/479032999\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"246665\">Sid</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Is.20restricting.20the.20set.20of.20tactics.20a.20good.20idea.20for.20RL.3F/near/479022592\">said</a>:</p>\n<blockquote>\n<p>One thing that might be relevant is -- if you're using a probabilistic policy to generate the next actions, there's already going to be a soft version of selection going on -- as some actions will have a much lower probability than others. Also a low branching factor is good but if it's leading to longer proof length, then the search space will not necessarily decrease.</p>\n</blockquote>\n<p>Yes. But (1) selection requires more learning, and (2) the search space in mathematical theorem proving is always recursively enumerable (has cardinality ω) and there is no way to essentially decrease it.</p>\n</blockquote>\n<p>(1) Agreed (2) Sure but in practice we have finite resources and so the number of nodes in the search tree that can be enumerated is going to be bounded by a constant. Given that constraint, if you replace a node with a large number of children with multiple nodes, each with a small number of children, is the latter better? It's not clear to me.</p>",
        "id": 479176655,
        "sender_full_name": "Sid",
        "timestamp": 1730074329
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110087\">Kim Morrison</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Is.20restricting.20the.20set.20of.20tactics.20a.20good.20idea.20for.20RL.3F/near/479028632\">said</a>:</p>\n<blockquote>\n<p>Is anyone actually using the internals of <code>apply?</code> to do lookup during tree search? Once it had built the discrimination tree it is very fast, and it computes lazily so you can ask for as many results as needed.</p>\n</blockquote>\n<p>Apologies for the basic question (still early in terms of learning Lean) -- my understanding was that <code>apply?</code> works on the current active goal out of the list of goals and so for a particular application of <code>apply?</code>, only one match query is required. What do you mean by multiple results? Do you mean if an index is maintained for all the expressions <code>apply?</code> has been used for, then every time <code>apply?</code> is tried, one can try and match against all past such expressions in the index?</p>",
        "id": 479177313,
        "sender_full_name": "Sid",
        "timestamp": 1730074898
    },
    {
        "content": "<p><code>apply?</code> returns a list of suggestions (unless one actually closes the goal --- then it stops). You can ask for this list to be any length.</p>",
        "id": 479178267,
        "sender_full_name": "Kim Morrison",
        "timestamp": 1730075580
    },
    {
        "content": "<p>If I remember correctly, you can probably actually get a continuation out of it that lets you keep asking for one more, but the code was refactored at some point and this may require some tweaks to get access to the continuation.</p>",
        "id": 479178301,
        "sender_full_name": "Kim Morrison",
        "timestamp": 1730075622
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110087\">Kim Morrison</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Is.20restricting.20the.20set.20of.20tactics.20a.20good.20idea.20for.20RL.3F/near/479178267\">said</a>:</p>\n<blockquote>\n<p><code>apply?</code> returns a list of suggestions (unless one actually closes the goal --- then it stops). You can ask for this list to be any length.</p>\n</blockquote>\n<p>Ahh ok. How does it decide which term to try and match the goal with next when generating the list of suggestions? From what I understand matching is a unification procedure right and so we don't know beforehand which terms might match the goal.</p>",
        "id": 479183854,
        "sender_full_name": "Sid",
        "timestamp": 1730080458
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"246665\">Sid</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Is.20restricting.20the.20set.20of.20tactics.20a.20good.20idea.20for.20RL.3F/near/479176655\">said</a>:</p>\n<blockquote>\n<p>(1) Agreed (2) Sure but in practice we have finite resources and so the number of nodes in the search tree that can be enumerated is going to be bounded by a constant. Given that constraint, if you replace a node with a large number of children with multiple nodes, each with a small number of children, is the latter better? It's not clear to me.</p>\n</blockquote>\n<p>Also not clear to me, but many RL methods simply cannot effectively handle too many children (value-based or Q-function-based), and policy-based using LLM is equivalent to creating multiple nodes (LLMs output tokens one-by-one, and each token is conceptually a node with a smaller number of children). And say if each node has 10 children, the added internal nodes will only take up ~1/10 of the total number of nodes.</p>",
        "id": 479191898,
        "sender_full_name": "Zhanrong Qiao",
        "timestamp": 1730087336
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"246665\">Sid</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Is.20restricting.20the.20set.20of.20tactics.20a.20good.20idea.20for.20RL.3F/near/479183854\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"110087\">Kim Morrison</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Is.20restricting.20the.20set.20of.20tactics.20a.20good.20idea.20for.20RL.3F/near/479178267\">said</a>:</p>\n<blockquote>\n<p><code>apply?</code> returns a list of suggestions (unless one actually closes the goal --- then it stops). You can ask for this list to be any length.</p>\n</blockquote>\n<p>Ahh ok. How does it decide which term to try and match the goal with next when generating the list of suggestions? From what I understand matching is a unification procedure right and so we don't know beforehand which terms might match the goal.</p>\n</blockquote>\n<p>It builds a discrimination tree of all lemmas in the environment. We can then look up the goal in this discrimination tree to efficiently find lemmas that could possibly match, then filter by actually trying to apply them. Both the loop and <code>apply</code> are surprisingly fast.</p>",
        "id": 479192540,
        "sender_full_name": "Kim Morrison",
        "timestamp": 1730087819
    },
    {
        "content": "<p>(similar story for <code>rw?</code>)</p>",
        "id": 479192559,
        "sender_full_name": "Kim Morrison",
        "timestamp": 1730087833
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"246665\">Sid</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Is.20restricting.20the.20set.20of.20tactics.20a.20good.20idea.20for.20RL.3F/near/479183854\">said</a>:</p>\n<blockquote>\n<p>Ahh ok. How does it decide which term to try and match the goal with next when generating the list of suggestions? From what I understand matching is a unification procedure right and so we don't know beforehand which terms might match the goal.</p>\n</blockquote>\n<p>Unification depends on both terms having the same shape (except metavariables which might match anything). Most lemmas, even after substituting metavariables into universal quantifiers, still have e.g. a non-meta head variable so if this does not match the goal then we can skip it, and the same goes for all subterms. A tree can be used to classify lemmas by their non-meta parts. So in many cases we can still filter out lots of things which definitely do not unify... (There are probably many details which I do not know about how Lean actually implements this though)</p>",
        "id": 479197224,
        "sender_full_name": "Zhanrong Qiao",
        "timestamp": 1730091152
    },
    {
        "content": "<p>I am guessing this looks more like the Emacs agda-mode, just with a list of predictions for what can be used to \"refine\"... Has anyone tried applying machine learning to an interface like the agda-mode?</p>",
        "id": 492532723,
        "sender_full_name": "Zhanrong Qiao",
        "timestamp": 1736351501
    }
]