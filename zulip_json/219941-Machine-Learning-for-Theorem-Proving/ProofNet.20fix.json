[
    {
        "content": "<p>Hello everyone,</p>\n<p>Interest in the ProofNet benchmark has been growing in the ML community for both automated theorem proving and autoformalization. I believe it is a very interesting benchmark, in particular because it contains unique formalizations (and it is excluded from training sets such as ProofPile 2).<br>\nHowever, during my experiments, I noticed that current Lean 4 versions of this benchmark contain a non-negligible number of formalization errors: I estimate that more than 25% of the (natural language, formal) pairs contain inaccuracies (different semantic meaning). A significant portion of these errors also appear to be present in the original Lean 3 version.<br>\nI spent some time fixing these errors. The updated benchmark is available here for exploration and comparison with existing ProofNet versions: <a href=\"https://proofnet4-fix.streamlit.app/\">https://proofnet4-fix.streamlit.app/</a>. While I am fairly confident in most of the fixes, I am not a Lean or Mathlib expert, so it's possible I overlooked errors or introduced new mistakes. Feedback and critiques are highly welcome ^^</p>\n<p>My current plan is:</p>\n<ul>\n<li>to release the updated benchmark as \"ProofNet 1.1\" to avoid comparison issues in future works.</li>\n<li>to release it exclusively on HuggingFace to minimize the risk of data contamination.</li>\n</ul>\n<p>While I advocate for better benchmarks in general, I believe it’s best to avoid having multiple variations of the benchmark whenever possible. Before moving forward, I’d appreciate any thoughts from the community on alternative approaches or considerations I might be missing.</p>\n<p>Thank you in advance for your input!</p>",
        "id": 480759065,
        "sender_full_name": "Auguste Poiroux",
        "timestamp": 1730824096
    },
    {
        "content": "<p>MiniF2F has the same problems.  The Lean benchmarks are a big mess.  How does putting it on huggingface reduce data contamination?</p>",
        "id": 480760579,
        "sender_full_name": "Jason Rute",
        "timestamp": 1730824571
    },
    {
        "content": "<p>By data contamination, I meant \"reducing the risk for the benchmark to be included in LLM training data\". For pretraining data, I believe Github repos are scraped more often than HuggingFace datasets. But maybe I am mistaken?</p>",
        "id": 480760905,
        "sender_full_name": "Auguste Poiroux",
        "timestamp": 1730824696
    },
    {
        "content": "<p>I think Huggingface datasets are prime training material.</p>",
        "id": 480761053,
        "sender_full_name": "Jason Rute",
        "timestamp": 1730824744
    },
    {
        "content": "<p>Also, isn’t ProofNet intentionally automatically translated?  So such errors are inevitable and sort of part of the benchmark, no?  (The benchmark probably should have been to prove/disprove the theorem.)</p>",
        "id": 480761161,
        "sender_full_name": "Jason Rute",
        "timestamp": 1730824782
    },
    {
        "content": "<p>Well, good to know for HuggingFace datasets, it's quite unfortunate. Do you have any recommendation then?<br>\nOne of the goal of ProofNet is to assess autoformalization performance by comparing predictions with ground truth formalizations (paper where it was introduced <a href=\"https://arxiv.org/abs/2302.12433\">https://arxiv.org/abs/2302.12433</a>). I don't think it was automatically translated, but <span class=\"user-mention\" data-user-id=\"284997\">@Zhangir Azerbayev</span> can confirm. (it would seem weird to me to report the best autoformalization method at 16% otherwise)</p>",
        "id": 480762104,
        "sender_full_name": "Auguste Poiroux",
        "timestamp": 1730825093
    },
    {
        "content": "<p>Sorry.  I misremembered.</p>",
        "id": 480763650,
        "sender_full_name": "Jason Rute",
        "timestamp": 1730825624
    },
    {
        "content": "<p>Canary strings are supposed to be the way to keep this stuff out of the training data.</p>",
        "id": 480763825,
        "sender_full_name": "Jason Rute",
        "timestamp": 1730825698
    },
    {
        "content": "<p>But it might be too late for ProofNet (even a fixed up version)</p>",
        "id": 480766632,
        "sender_full_name": "Jason Rute",
        "timestamp": 1730826716
    },
    {
        "content": "<p>(deleted)</p>",
        "id": 480766637,
        "sender_full_name": "Jason Rute",
        "timestamp": 1730826717
    },
    {
        "content": "<p>Damn, the field is moving super fast ^^ Lean 4 versions of ProofNet have been there for 9 months at best (this is the first one to the best of my knowledge: <a href=\"https://github.com/rahul3613/ProofNet-lean4\">https://github.com/rahul3613/ProofNet-lean4</a>). Jokes aside, I agree that for ATP results it might be too late.<br>\nHowever, for autoformalization, it is definitely not too late in my opinion. Current published results are evaluated by hand. I saw that at ICLR there is a submission (<a href=\"https://openreview.net/attachment?id=hUb2At2DsQ&amp;name=pdf\">https://openreview.net/attachment?id=hUb2At2DsQ&amp;name=pdf</a> not my work) where they develop a reference-based metric. Since reference-based metrics solely depend on the quality of the reference labels, there is interest in having good benchmarks (otherwise results might be biased towards models making mistakes similar to human ones).</p>",
        "id": 480768347,
        "sender_full_name": "Auguste Poiroux",
        "timestamp": 1730827323
    },
    {
        "content": "<p>I asked ChatGPT to 'complete' the problem statement, from ProofNet:</p>\n<div class=\"codehilite\" data-code-language=\"Lean4\"><pre><span></span><code><span class=\"o\">{</span><span class=\"s2\">\"name\"</span><span class=\"o\">:</span><span class=\"w\"> </span><span class=\"s2\">\"exercise_1_16a\"</span><span class=\"o\">,</span><span class=\"w\"> </span><span class=\"s2\">\"split\"</span><span class=\"o\">:</span><span class=\"w\"> </span><span class=\"s2\">\"valid\"</span><span class=\"o\">,</span><span class=\"w\"> </span><span class=\"s2\">\"informal_prefix\"</span><span class=\"o\">:</span><span class=\"w\"> </span><span class=\"s2\">\"/-- Suppose $k </span><span class=\"se\">\\\\</span><span class=\"s2\">geq 3, x, y </span><span class=\"se\">\\\\</span><span class=\"s2\">in </span><span class=\"se\">\\\\</span><span class=\"s2\">mathbb{R}^k, |x - y| = d &gt; 0$, and $r &gt; 0$. Prove that if $2r &gt; d$,</span>\n</code></pre></div>\n<p>and it output the exactly correct completion from the dataset:</p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"o\">{</span><span class=\"s2\">\"name\"</span><span class=\"o\">:</span><span class=\"w\"> </span><span class=\"s2\">\"exercise_1_16a\"</span><span class=\"o\">,</span><span class=\"w\"> </span><span class=\"s2\">\"split\"</span><span class=\"o\">:</span><span class=\"w\"> </span><span class=\"s2\">\"valid\"</span><span class=\"o\">,</span><span class=\"w\"> </span><span class=\"s2\">\"informal_prefix\"</span><span class=\"o\">:</span><span class=\"w\"> </span><span class=\"s2\">\"/-- Suppose $k </span><span class=\"se\">\\\\</span><span class=\"s2\">geq 3$, $x, y </span><span class=\"se\">\\\\</span><span class=\"s2\">in </span><span class=\"se\">\\\\</span><span class=\"s2\">mathbb{R}^k$, $|x - y| = d &gt; 0$, and $r &gt; 0$. Prove that if $2r &gt; d$, then there exists a point $z </span><span class=\"se\">\\\\</span><span class=\"s2\">in </span><span class=\"se\">\\\\</span><span class=\"s2\">mathbb{R}^k$ such that $|x - z| = r$ and $|y - z| = r$. --/\"</span>\n</code></pre></div>\n<p>so it has _definitely_ been trained on, and memorized, significant parts of ProofNet. Note that the variable \"z\" was not even mentioned in my prompt.</p>",
        "id": 480987582,
        "sender_full_name": "Alex Meiburg",
        "timestamp": 1730921671
    },
    {
        "content": "<p>Although ChatGPT also has search.  I don’t know how it exactly works but it could be just fetching that live from the internet.  (But maybe it shows you a link in that case.)</p>",
        "id": 480987881,
        "sender_full_name": "Jason Rute",
        "timestamp": 1730921805
    },
    {
        "content": "<p>I'm pretty sure this was not with search, because (1) it responded much faster than is typical for a search-augmented answer (which I've seen it do -- there's usually a few second delay), (2) I'm on the free plan which _shouldn't_ have search, and (3) it typically gives links when it does search and it didn't here.</p>",
        "id": 480988088,
        "sender_full_name": "Alex Meiburg",
        "timestamp": 1730921901
    },
    {
        "content": "<p>Oh, I just realized its completion wasn't quite right. It's supposed to be \"there exist infinitely many points z\", not \"there exists a point z\". But otherwise it's right</p>\n<p>Still enough for me to say yeah, that's memorization</p>",
        "id": 480988190,
        "sender_full_name": "Alex Meiburg",
        "timestamp": 1730921952
    },
    {
        "content": "<p>In my opinion, memorization of the informal statement is not enough to conclude about data contamination. In fact, these informal statements have been extracted from existing text books (see ProofNet papers), on which ChatGPT may have been trained. Additionally, memorizing the informal statements is not an issue, because what we care about is formalization capabilities. To me the real issue is if the model has been trained on/memorized the formalizations.</p>",
        "id": 481007538,
        "sender_full_name": "Auguste Poiroux",
        "timestamp": 1730930288
    },
    {
        "content": "<p>impressive work &amp; really looking forward to your release. (btw. perhaps the Lean 4 version of MiniF2F should also be inspected. It also has a great number of inaccurate and even incorrect formal statements.)</p>",
        "id": 489480174,
        "sender_full_name": "Qi Liu",
        "timestamp": 1734440479
    }
]