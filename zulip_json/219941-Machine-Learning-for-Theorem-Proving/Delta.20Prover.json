[
    {
        "content": "<p>What is the relation of this paper on Lean 4 by ByteDance to Seed Prover? <a href=\"https://arxiv.org/abs/2507.15225\">https://arxiv.org/abs/2507.15225</a>  This prover is called Delta Prover.  Is it the same?  Is this the paper/report for this project?</p>",
        "id": 530752265,
        "sender_full_name": "Jason Rute",
        "timestamp": 1753442646
    },
    {
        "content": "<p>Oh this is an agent based approach using existing LLMs, so maybe not.  It it is something different, I can move this to its own conversation.</p>",
        "id": 530753231,
        "sender_full_name": "Jason Rute",
        "timestamp": 1753443036
    },
    {
        "content": "<p>From here, Seed Prover and Delta Prover seem to be different sister projects.  Maybe one is trained and the other an agentic loop?  <a href=\"https://github.com/ByteDance-Seed/Seed-Prover\">https://github.com/ByteDance-Seed/Seed-Prover</a></p>",
        "id": 530753711,
        "sender_full_name": "Jason Rute",
        "timestamp": 1753443219
    },
    {
        "content": "<p>Lol speculation</p>",
        "id": 530758643,
        "sender_full_name": "(deleted)",
        "timestamp": 1753445106
    },
    {
        "content": "<p>But honestly using a DSL is a very obvious way to circumvent the lack of training on Lean for off the shelf LLMs</p>",
        "id": 530758744,
        "sender_full_name": "(deleted)",
        "timestamp": 1753445140
    },
    {
        "content": "<p>But also very laborious...</p>",
        "id": 530758794,
        "sender_full_name": "(deleted)",
        "timestamp": 1753445159
    },
    {
        "content": "<p>6 messages were moved here from <a class=\"stream-topic\" data-stream-id=\"219941\" href=\"/#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Seed.20Prover.20Achieves.20Silver-Level.20Score.20at.20IMO.202025/with/530669026\">#Machine Learning for Theorem Proving &gt; Seed Prover Achieves Silver-Level Score at IMO 2025</a> by <span class=\"user-mention silent\" data-user-id=\"115715\">Jason Rute</span>.</p>",
        "id": 530758980,
        "sender_full_name": "Notification Bot",
        "timestamp": 1753445227
    },
    {
        "content": "<p>Phew. Much better home for this discussion.</p>",
        "id": 530759134,
        "sender_full_name": "(deleted)",
        "timestamp": 1753445284
    },
    {
        "content": "<p>By \"speculation\" I mean the connection is extremely tenuous</p>",
        "id": 530759158,
        "sender_full_name": "(deleted)",
        "timestamp": 1753445294
    },
    {
        "content": "<p>What connection?  Between Seed Prover and Delta Prover?</p>",
        "id": 530759258,
        "sender_full_name": "Jason Rute",
        "timestamp": 1753445327
    },
    {
        "content": "<p>Yeah that's right. Delta Prover to me is a way to coax existing LLMs into writing Lean code through an intermediate DSL.</p>",
        "id": 530759374,
        "sender_full_name": "(deleted)",
        "timestamp": 1753445363
    },
    {
        "content": "<p>I was just confused that ByteDance had two Lean AI prover projects achieving a very high score on MiniF2F.  But it turns out they do.  (Although we don't know how Seed Prover works, and what exactly they were using for the \"Seed Prover\" IMO results.)</p>",
        "id": 530759890,
        "sender_full_name": "Jason Rute",
        "timestamp": 1753445514
    },
    {
        "content": "<p>The corresponding authors are <span class=\"user-mention\" data-user-id=\"683807\">@yichi zhou</span>  <span class=\"user-mention\" data-user-id=\"268918\">@Pan Lu</span>  and <span class=\"user-mention\" data-user-id=\"816748\">@Hang Li</span></p>",
        "id": 530760844,
        "sender_full_name": "Jason Rute",
        "timestamp": 1753445817
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"115715\">Jason Rute</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Delta.20Prover/near/530759890\">said</a>:</p>\n<blockquote>\n<p>I was just confused that ByteDance had two Lean AI prover projects achieving a very high score on MiniF2F.  But it turns out they do.  (Although we don't know how Seed Prover works, and what exactly they were using for the \"Seed Prover\" IMO results.)</p>\n</blockquote>\n<p>DeltaProver and SeedProver are two systems. Some techniques in DeltaProver are used in SeedProver. SeedProver joins IMO 2025.</p>",
        "id": 530796093,
        "sender_full_name": "Zheng Yuan",
        "timestamp": 1753456297
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"115715\">Jason Rute</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Delta.20Prover/near/530753231\">said</a>:</p>\n<blockquote>\n<p>Oh this is an agent based approach using existing LLMs, so maybe not.  It it is something different, I can move this to its own conversation.</p>\n</blockquote>\n<p>Yes, SeedProver is a self-trained model with some agentic loop evolved from DeltaProver. DeltaProver is a research project on agentic loop.</p>",
        "id": 530796469,
        "sender_full_name": "Zheng Yuan",
        "timestamp": 1753456414
    },
    {
        "content": "<p>This is an interesting paper, with a significant result (state-of-the-art on MiniF2F, using only a generalist model). After a quick read, I have two questions.</p>\n<p>First, one of the most interesting and novel aspects of their pipeline is their \"Iterative Decomposition Repair\" proposal: when a Draft-Sketch-Prove attempt fails, the whole process starts again, _with additional feedback_ regarding what subgoals could not be proved in the previous attempt. I would be very interested in seeing precisely how they prompt the model to leverage such feedback. However, I did not find this information in the prompting templates provided in appendix.</p>\n<p>Second, a central point of the paper seems to be that Lean4 is not directly suitable for implementing Draft-Sketch-Prove (as opposed to Isabelle), hence the introduction of a custom DSL for managing and gluing subproofs. Citing the paper:</p>\n<blockquote>\n<p>DSP uses the formal language Isabella, while current Lean 4 lack robust support for managing decomposed sub-problems. Specifically, there is no convenient way to simultaneously: (i) store decomposed sub-problems; (ii) extract them as formal statements; and (iii) integrate their individual proofs back into a unified whole proof. For instance, using the have tactic is inadequate for (iii), while listing sub-problems as lemmas falls short for (ii).</p>\n</blockquote>\n<p>I am not sure I get this point and how <code>have</code> is inadequate for their purposes. The Lean language server can be used to validate a sketch that containing sorries, extract the current goal for each sorries, and validate a subproof in context by substituting the associated \"sorry\" with it and querying the LSP again. Admittedly, this whole process could be further facilitated by the existing tooling but I do not get the necessity of introducing a completely new DSL for managing subgoals, and the insistence on such a DSL in the paper, which I see as a minor engineering detail. Am I missing something?</p>",
        "id": 530816561,
        "sender_full_name": "Jonathan Laurent",
        "timestamp": 1753463687
    },
    {
        "content": "<p>My feeling is the paper doesn't tell the whole story and the DSL is much more extensive than what is detailed in the paper.</p>",
        "id": 530819558,
        "sender_full_name": "(deleted)",
        "timestamp": 1753464831
    },
    {
        "content": "<p>To the point of being something more similar to Waterproof.</p>",
        "id": 530819799,
        "sender_full_name": "(deleted)",
        "timestamp": 1753464927
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"511228\">@Huỳnh Trần Khanh</span>  Nothing in the paper is hinting at that. What makes you suspect this?</p>",
        "id": 530822725,
        "sender_full_name": "Jonathan Laurent",
        "timestamp": 1753466171
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"890848\">@Jonathan Laurent</span> FYI, a lot of the features of <a href=\"https://github.com/GasStationManager/LeanTool\">LeanTool</a> are geared towards making DSP work in Lean: automatic extraction of goals from sorrys, and the recent feature to try a (list of) hammer tactics on a sorry. And with LeanTool available as an MCP server, you could easily compose it with other tools. I am really enjoying using LeanTool and <a href=\"https://www.leanexplore.com/\">LeanExplore</a> together, and then it is not hard to prompt (say) Sonnet 4 into doing (recursive) DSP style proving. See <a href=\"https://github.com/GasStationManager/LeanTool/blob/main/examples/pabc_claude.lean\">here</a> for some example proofs.</p>\n<p>The DSL approach is potentially interesting, as a way to manage sub-goals on a larger scale. I will need to try to understand it further. For my use cases though, I often have sorrys inside of recursive functions, and it might not be possible to extract the goal into a lemma outside of the function.</p>",
        "id": 530837752,
        "sender_full_name": "GasStationManager",
        "timestamp": 1753472510
    },
    {
        "content": "<p>I suspect that the DSL is much more extensive than what is claimed in the paper because the paper keeps mentioning the DSL a lot. I did an experiment where I pasted a long specification for a DSL into a reasoning model and the model consistently wrote correct code. Claude Code, even when armed with LeanTool and LeanExplore, still struggles with writing correct Lean code. Therefore, I suspect that the DSL covers much more than just subgoal decomposition.</p>",
        "id": 530871703,
        "sender_full_name": "(deleted)",
        "timestamp": 1753491639
    },
    {
        "content": "<p>I propose that we replicate this paper. We know that making a DSL is the winning formula, so we have the general direction already.</p>",
        "id": 530891465,
        "sender_full_name": "(deleted)",
        "timestamp": 1753505299
    },
    {
        "content": "<p>Probably pretty expensive? You totally could cook up an AI researcher right now if you had funding. I would not doubt if that is the next thing to be done...</p>",
        "id": 530894416,
        "sender_full_name": "Justin Asher",
        "timestamp": 1753507040
    },
    {
        "content": "<p>Well I already plan to replicate the paper myself so... After the AlphaGeometry transpilation project this project will be next...</p>",
        "id": 530894527,
        "sender_full_name": "(deleted)",
        "timestamp": 1753507117
    },
    {
        "content": "<p>I have free time and cash, I just need motivation</p>",
        "id": 530894620,
        "sender_full_name": "(deleted)",
        "timestamp": 1753507173
    },
    {
        "content": "<p>As for the cost, I don't think inference costs a lot, but it requires a lot of my time, which I think is a justifiable use of my time since I can exploit the work commercially</p>",
        "id": 530894743,
        "sender_full_name": "(deleted)",
        "timestamp": 1753507265
    },
    {
        "content": "<p>Are you formalizing problems for work? You can totally use LLMs to do that. (Like in the paper.)</p>",
        "id": 530894956,
        "sender_full_name": "Justin Asher",
        "timestamp": 1753507393
    },
    {
        "content": "<p>Yeah that's right I plan to use the strategy in the paper, which is to create an entirely new language for subgoal decomposition. After that, I also create a language for finer details of the proof. I try to make it close enough to Lean, but also different enough from Lean so the LLM doesn't use its existing intuition about Lean and end up generating broken code.</p>",
        "id": 530895230,
        "sender_full_name": "(deleted)",
        "timestamp": 1753507559
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"115715\">@Jason Rute</span> Delta-Prover is a separate project focused on researching test-time strategies. However, the test-time strategy used in Seed Prover is an extension of Delta Prover’s approach. </p>\n<p>Acturally, in seed prover, we found a smarter way to effectively scale up at test time without relying on a new DSL. Details of Seed Prover’s test-time strategy will be available in our technical report.</p>",
        "id": 530896031,
        "sender_full_name": "yichi zhou",
        "timestamp": 1753508062
    }
]