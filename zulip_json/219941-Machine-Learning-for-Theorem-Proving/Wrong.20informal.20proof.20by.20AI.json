[
    {
        "content": "<p><strong>AI prompt:</strong> How to prove this, give me proof in English (not code). Please prove with elementary approach only</p>\n<p>p : ℕ<br>\nhp : Nat.Prime p<br>\nh : ∀ (q : ℕ), Nat.Prime q → q &lt; p → Squarefree (p % q)<br>\nhp_le3 : ¬p ≤ 3<br>\nhp_gt3 : 3 &lt; p<br>\nhp_ge4 : 4 ≤ p<br>\nhp_ge5 : 5 ≤ p<br>\nhp_gt4 : 4 &lt; p<br>\nhdiv_three : ∀ {q : ℕ}, Nat.Prime q → q ∣ p - 4 → q = 3<br>\nb : ℕ<br>\nhb : p - 4 = 3 ^ b<br>\nhp_eq : p = 3 ^ b + 4<br>\nhb_ge : ¬b ≤ 2<br>\nhb_gt2 : 2 &lt; b<br>\nhb3 : 3 ≤ b<br>\n⊢ False</p>",
        "id": 541584891,
        "sender_full_name": "(deleted)",
        "timestamp": 1758863175
    },
    {
        "content": "<p>The above is the prompt I sent to Gemini Deep Think. This is the initial answer</p>",
        "id": 541584918,
        "sender_full_name": "(deleted)",
        "timestamp": 1758863195
    },
    {
        "content": "<p><em>view revision history for the proof</em></p>",
        "id": 541584989,
        "sender_full_name": "(deleted)",
        "timestamp": 1758863251
    },
    {
        "content": "<p>And the problem with the above proof is it only considers the easiest case, b=3, and thinks it's enough. So, the problem with AI generated informal proofs is there's no guarantee that they are correct, and so they have little industrial value.</p>",
        "id": 541585071,
        "sender_full_name": "(deleted)",
        "timestamp": 1758863317
    },
    {
        "content": "<p>This is the proof generated by GPT-5 pro. I haven't checked the proof but it doesn't look as obviously wrong.</p>",
        "id": 541585185,
        "sender_full_name": "(deleted)",
        "timestamp": 1758863406
    },
    {
        "content": "<p><a href=\"https://chatgpt.com/s/t_68d62f201ba081919055f0ce8d2640a6\">https://chatgpt.com/s/t_68d62f201ba081919055f0ce8d2640a6</a></p>",
        "id": 541585207,
        "sender_full_name": "(deleted)",
        "timestamp": 1758863421
    },
    {
        "content": "<p>The long ai-generated output here distracts from what you are trying to say.  Maybe put the ai output in spoiler blocks or some other collapsible block.</p>",
        "id": 541588826,
        "sender_full_name": "Jason Rute",
        "timestamp": 1758865985
    },
    {
        "content": "<p>I do realize that, but I can't do it :(</p>",
        "id": 541589712,
        "sender_full_name": "(deleted)",
        "timestamp": 1758866581
    },
    {
        "content": "<p>But my main message here is during my day to day work, I rely on AI generated proofs. But they can be wrong, in a frustrating way.</p>",
        "id": 541589834,
        "sender_full_name": "(deleted)",
        "timestamp": 1758866648
    },
    {
        "content": "<p>I sang Gemini Deep Think's praises as previously I'd never encountered an incorrect proof from Gemini Deep Think. Too bad, now there's one.</p>",
        "id": 541589905,
        "sender_full_name": "(deleted)",
        "timestamp": 1758866693
    },
    {
        "content": "<p>OK I did what I could.</p>",
        "id": 541590809,
        "sender_full_name": "(deleted)",
        "timestamp": 1758867273
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"511228\">Huỳnh Trần Khanh</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Wrong.20informal.20proof.20by.20AI/near/541589712\">said</a>:</p>\n<blockquote>\n<p>I do realize that, but I can't do it :(</p>\n</blockquote>\n<div class=\"spoiler-block\"><div class=\"spoiler-header\">\n<p>Markdown code for spoiler</p>\n</div><div class=\"spoiler-content\" aria-hidden=\"true\">\n<div class=\"codehilite\" data-code-language=\"Markdown\"><pre><span></span><code><span class=\"sb\">```spoiler</span><span class=\"w\"> </span>ChatGPT5 Response\n<span class=\"s\">I’m an AI model output</span>\n<span class=\"sb\">```</span>\n</code></pre></div>\n</div></div>",
        "id": 541592509,
        "sender_full_name": "Jason Rute",
        "timestamp": 1758868244
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"511228\">Huỳnh Trần Khanh</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Wrong.20informal.20proof.20by.20AI/near/541584891\">said</a>:</p>\n<blockquote>\n<p><strong>AI prompt:</strong> How to prove this, give me proof in English (not code). Please prove with elementary approach only</p>\n</blockquote>\n<p>Yeah, I think the key value prop is verifiable correctness.   For any real lean question the model would always check its output against a compiler.</p>\n<p>Informal anything is likely to cause a lot of disappointment / hallucination and I'd even go so far as arguing not something labs should prioritize.   I don't think 'AGI' is a productive goal and is just going to lead to scheming AI.  <a href=\"https://www.arxiv.org/pdf/2509.15541\">https://www.arxiv.org/pdf/2509.15541</a></p>",
        "id": 541736906,
        "sender_full_name": "Deleted User 968128",
        "timestamp": 1758916743
    },
    {
        "content": "<p>OpenAI has pretty much admitted that hallucinations are impossible to fix with current model architectures.  The beauty of domains like code and lean is that it can be fixed, because if it fails to run, you're good to go (ignoring various edge cases, ofc, but those are already limited and can be limited further)</p>",
        "id": 541737375,
        "sender_full_name": "Deleted User 968128",
        "timestamp": 1758916953
    },
    {
        "content": "<p><a href=\"https://arxiv.org/pdf/2509.04664\">https://arxiv.org/pdf/2509.04664</a></p>",
        "id": 541737407,
        "sender_full_name": "Deleted User 968128",
        "timestamp": 1758916973
    }
]