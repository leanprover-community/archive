[
    {
        "content": "<p>I just tried this problem with Perplexity.AI, ChatGPT and <a href=\"http://Claude.ai\">Claude.ai</a>.  The first two could not get it after about 10 tries each.  Claude got it on the 7th try.  All of them gave extensive reasoning for every attempt.  The problem is  </p>\n<blockquote>\n<p>Create X and Y such that scipy.stats.spearmanr(X,Y) = 0.5 exactly.</p>\n</blockquote>\n<p>Claude's solution was</p>\n<div class=\"codehilite\" data-code-language=\"Lean4\"><pre><span></span><code><span class=\"w\">    </span><span class=\"n\">X</span><span class=\"w\"> </span><span class=\"bp\">=</span><span class=\"w\"> </span><span class=\"n\">np</span><span class=\"bp\">.</span><span class=\"n\">array</span><span class=\"o\">([</span><span class=\"mi\">1</span><span class=\"o\">,</span><span class=\"w\"> </span><span class=\"mi\">2</span><span class=\"o\">,</span><span class=\"w\"> </span><span class=\"mi\">3</span><span class=\"o\">,</span><span class=\"w\"> </span><span class=\"mi\">4</span><span class=\"o\">,</span><span class=\"w\"> </span><span class=\"mi\">5</span><span class=\"o\">])</span>\n<span class=\"w\">    </span><span class=\"n\">Y</span><span class=\"w\"> </span><span class=\"bp\">=</span><span class=\"w\"> </span><span class=\"n\">np</span><span class=\"bp\">.</span><span class=\"n\">array</span><span class=\"o\">([</span><span class=\"mi\">1</span><span class=\"o\">,</span><span class=\"w\"> </span><span class=\"mi\">4</span><span class=\"o\">,</span><span class=\"w\"> </span><span class=\"mi\">2</span><span class=\"o\">,</span><span class=\"w\"> </span><span class=\"mi\">5</span><span class=\"o\">,</span><span class=\"w\"> </span><span class=\"mi\">3</span><span class=\"o\">])</span>\n</code></pre></div>\n<p>which is 0.5 within rounding error, so 0.49999999999999994 on my computer.</p>\n<p>It would be interesting to understand why this problem is hard for LLMs.</p>",
        "id": 496767100,
        "sender_full_name": "Lars Ericson",
        "timestamp": 1738240990
    },
    {
        "content": "<p>This has nothing to do with Lean, right? So really it's off-topic for this Zulip.</p>",
        "id": 496769942,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1738241812
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"110038\">@Kevin Buzzard</span> it's off topic if you think this reasoning supplied by Claude is not checkable by Lean, and if you think why a problem is hard for an LLM is off topic for this thread:</p>\n<div class=\"codehilite\" data-code-language=\"Lean4\"><pre><span></span><code><span class=\"w\">    </span><span class=\"bp\">#</span><span class=\"w\"> </span><span class=\"n\">Let</span><span class=\"w\"> </span><span class=\"n\">me</span><span class=\"w\"> </span><span class=\"n\">verify</span><span class=\"o\">:</span>\n<span class=\"w\">    </span><span class=\"bp\">#</span><span class=\"w\"> </span><span class=\"n\">Rank</span><span class=\"w\"> </span><span class=\"n\">differences</span><span class=\"w\"> </span><span class=\"n\">d</span><span class=\"o\">:</span><span class=\"w\"> </span><span class=\"o\">[</span><span class=\"mi\">0</span><span class=\"o\">,</span><span class=\"w\"> </span><span class=\"bp\">-</span><span class=\"mi\">2</span><span class=\"o\">,</span><span class=\"w\"> </span><span class=\"mi\">1</span><span class=\"o\">,</span><span class=\"w\"> </span><span class=\"bp\">-</span><span class=\"mi\">1</span><span class=\"o\">,</span><span class=\"w\"> </span><span class=\"mi\">2</span><span class=\"o\">]</span>\n<span class=\"w\">    </span><span class=\"bp\">#</span><span class=\"w\"> </span><span class=\"n\">d</span><span class=\"bp\">²</span><span class=\"w\"> </span><span class=\"bp\">=</span><span class=\"w\"> </span><span class=\"o\">[</span><span class=\"mi\">0</span><span class=\"o\">,</span><span class=\"w\"> </span><span class=\"mi\">4</span><span class=\"o\">,</span><span class=\"w\"> </span><span class=\"mi\">1</span><span class=\"o\">,</span><span class=\"w\"> </span><span class=\"mi\">1</span><span class=\"o\">,</span><span class=\"w\"> </span><span class=\"mi\">4</span><span class=\"o\">]</span>\n<span class=\"w\">    </span><span class=\"bp\">#</span><span class=\"w\"> </span><span class=\"bp\">Σ</span><span class=\"n\">d</span><span class=\"bp\">²</span><span class=\"w\"> </span><span class=\"bp\">=</span><span class=\"w\"> </span><span class=\"mi\">10</span><span class=\"w\"> </span><span class=\"bp\">✓</span>\n</code></pre></div>\n<p>If you look at this dialogue, you will see that this problem has nothing to do with numerical approximation and Python/scipy, and everything to do with formal reasoning.  Every attempt by Perplexity was backed by incorrect formal reasoning:<br>\n<a href=\"https://www.perplexity.ai/search/create-x-and-y-such-that-scipy-UDtcx8LFTLSgvsuDfKHobg\">https://www.perplexity.ai/search/create-x-and-y-such-that-scipy-UDtcx8LFTLSgvsuDfKHobg</a></p>",
        "id": 496770416,
        "sender_full_name": "Lars Ericson",
        "timestamp": 1738241946
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"110038\">@Kevin Buzzard</span> Historically, this <a class=\"stream\" data-stream-id=\"219941\" href=\"/#narrow/channel/219941-Machine-Learning-for-Theorem-Proving\">#Machine Learning for Theorem Proving</a> topic has been a bit loose abut things needing to be just about Lean.  <span class=\"user-mention\" data-user-id=\"364351\">@Lars Ericson</span> But it also feels a bit oddly specific and I’m not clear the utility.  Why sci.stats.spearman?  Why not ask it a pure math question?  Why those three models and not a reasoning model?  There are many now, many of which are free: o1-mini, QwQ, DeepSeek-r1, Gemini Flash Thinking.  (Also a nitpick: “formal reasoning” is a strange term to be using on a formal theorem provers chat.  “Mathematical reasoning” might be better, since I assume there is no formal language being used.)</p>",
        "id": 496776754,
        "sender_full_name": "Jason Rute",
        "timestamp": 1738243768
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"115715\">@Jason Rute</span> , this particular problem wasn't randomly constructed.  I am working on the <a href=\"https://hub.crunchdao.com/competitions/broad-1/\">Broad Institute Autoimmune Disorder Challenge</a>.  The scoring function for this challenge uses Spearman rank correlation.  Spearman correlation is not differentiable: it involves a sorting operation.  It is really a kind of discrete math calculation.  To make a machine learning model which optimizes this correlation, it is necessary to construct a differentiable approximation to Spearman correlation.  I asked an LLM to recommend one.  I wanted to test the quality of the approximation.  It occurred to me to ask the LLM for a test example with a mathematically exact answer like 1/2.  When I asked for this example, it turned out to be hard for the 3 LLMs I asked, all of which were free to me up to a point.  I wasn't worried about polling specifically free ones.  (Of which DeepSeek is <a href=\"https://api-docs.deepseek.com/quick_start/pricing\">not</a>.)  Free-to-use was not the issue.  Why it was hard to reason about turned out to be the interesting issue.</p>\n<p>In the case of Claude, it took 7 tries to get the \"formal\" or \"mathematical\" or whatever reasoning right.  Here is an example of what turned out to be incorrect reasoning from Claude:</p>\n<div class=\"codehilite\" data-code-language=\"Lean4\"><pre><span></span><code><span class=\"n\">For</span><span class=\"w\"> </span><span class=\"n\">n</span><span class=\"bp\">=</span><span class=\"mi\">4</span><span class=\"o\">:</span>\n<span class=\"n\">The</span><span class=\"w\"> </span><span class=\"n\">Spearman</span><span class=\"w\"> </span><span class=\"n\">formula</span><span class=\"w\"> </span><span class=\"n\">is</span><span class=\"o\">:</span><span class=\"w\"> </span><span class=\"n\">ρ</span><span class=\"w\"> </span><span class=\"bp\">=</span><span class=\"w\"> </span><span class=\"mi\">1</span><span class=\"w\"> </span><span class=\"bp\">-</span><span class=\"w\"> </span><span class=\"o\">(</span><span class=\"mi\">6</span><span class=\"w\"> </span><span class=\"bp\">*</span><span class=\"w\"> </span><span class=\"bp\">Σ</span><span class=\"n\">d</span><span class=\"bp\">²</span><span class=\"o\">)</span><span class=\"w\"> </span><span class=\"bp\">/</span><span class=\"w\"> </span><span class=\"o\">(</span><span class=\"n\">n</span><span class=\"w\"> </span><span class=\"bp\">*</span><span class=\"w\"> </span><span class=\"o\">(</span><span class=\"n\">n</span><span class=\"bp\">²</span><span class=\"w\"> </span><span class=\"bp\">-</span><span class=\"w\"> </span><span class=\"mi\">1</span><span class=\"o\">))</span>\n<span class=\"n\">For</span><span class=\"w\"> </span><span class=\"n\">ρ</span><span class=\"w\"> </span><span class=\"bp\">=</span><span class=\"w\"> </span><span class=\"mf\">0.5</span><span class=\"o\">:</span>\n<span class=\"mf\">0.5</span><span class=\"w\"> </span><span class=\"bp\">=</span><span class=\"w\"> </span><span class=\"mi\">1</span><span class=\"w\"> </span><span class=\"bp\">-</span><span class=\"w\"> </span><span class=\"o\">(</span><span class=\"mi\">6</span><span class=\"w\"> </span><span class=\"bp\">*</span><span class=\"w\"> </span><span class=\"bp\">Σ</span><span class=\"n\">d</span><span class=\"bp\">²</span><span class=\"o\">)</span><span class=\"w\"> </span><span class=\"bp\">/</span><span class=\"w\"> </span><span class=\"o\">(</span><span class=\"mi\">4</span><span class=\"w\"> </span><span class=\"bp\">*</span><span class=\"w\"> </span><span class=\"o\">(</span><span class=\"mi\">16</span><span class=\"w\"> </span><span class=\"bp\">-</span><span class=\"w\"> </span><span class=\"mi\">1</span><span class=\"o\">))</span>\n<span class=\"mf\">0.5</span><span class=\"w\"> </span><span class=\"bp\">=</span><span class=\"w\"> </span><span class=\"mi\">1</span><span class=\"w\"> </span><span class=\"bp\">-</span><span class=\"w\"> </span><span class=\"o\">(</span><span class=\"mi\">6</span><span class=\"w\"> </span><span class=\"bp\">*</span><span class=\"w\"> </span><span class=\"bp\">Σ</span><span class=\"n\">d</span><span class=\"bp\">²</span><span class=\"o\">)</span><span class=\"w\"> </span><span class=\"bp\">/</span><span class=\"w\"> </span><span class=\"mi\">60</span>\n<span class=\"bp\">-</span><span class=\"mf\">0.5</span><span class=\"w\"> </span><span class=\"bp\">=</span><span class=\"w\"> </span><span class=\"bp\">-</span><span class=\"o\">(</span><span class=\"mi\">6</span><span class=\"w\"> </span><span class=\"bp\">*</span><span class=\"w\"> </span><span class=\"bp\">Σ</span><span class=\"n\">d</span><span class=\"bp\">²</span><span class=\"o\">)</span><span class=\"w\"> </span><span class=\"bp\">/</span><span class=\"w\"> </span><span class=\"mi\">60</span>\n<span class=\"bp\">Σ</span><span class=\"n\">d</span><span class=\"bp\">²</span><span class=\"w\"> </span><span class=\"bp\">=</span><span class=\"w\"> </span><span class=\"mi\">5</span>\n</code></pre></div>\n<p>Here is Perplexity's explanation of why it thinks it is hard:</p>\n<blockquote>\n<p>The difficulty lies in the nature of Spearman's rank correlation coefficient, which is based on the ranks of the data rather than the raw values. This makes it less straightforward to manipulate compared to other correlation measures like Pearson's correlation.</p>\n</blockquote>\n<p>Perplexity in its attempts used probabilistic arguments and constructions to try to get there.  Claude used math that looking more discrete and combinatoric.  Where the LLMs go to in the math space seems interesting to me.</p>\n<p>As a side-note (off topic for Lean?), here is the differentiable approximation (in Python):</p>\n<div class=\"codehilite\" data-code-language=\"Lean4\"><pre><span></span><code><span class=\"kn\">def</span><span class=\"w\"> </span><span class=\"n\">spearmanr_approx</span><span class=\"o\">(</span><span class=\"n\">x</span><span class=\"o\">,</span><span class=\"w\"> </span><span class=\"n\">y</span><span class=\"o\">,</span><span class=\"w\"> </span><span class=\"n\">regularization_strength</span><span class=\"bp\">=</span><span class=\"mf\">0.5</span><span class=\"o\">):</span>\n<span class=\"w\">    </span><span class=\"s2\">\"\"\"</span>\n<span class=\"s2\">    Differentiable approximation of Spearman's rank correlation.</span>\n\n<span class=\"s2\">    Args:</span>\n<span class=\"s2\">        x, y: Input tensors of shape (N,).</span>\n<span class=\"s2\">        regularization_strength: Controls softness of ranking (higher is more relaxed).</span>\n\n<span class=\"s2\">    Returns:</span>\n<span class=\"s2\">        Approximate Spearman correlation coefficient.</span>\n\n<span class=\"s2\">    author:</span>\n<span class=\"s2\">        https://chatgpt.com/share/679b64fc-dd94-8006-b1ef-7ba628c80386</span>\n<span class=\"s2\">    \"\"\"</span>\n<span class=\"w\">    </span><span class=\"bp\">#</span><span class=\"w\"> </span><span class=\"n\">Convert</span><span class=\"w\"> </span><span class=\"n\">inputs</span><span class=\"w\"> </span><span class=\"n\">to</span><span class=\"w\"> </span><span class=\"n\">float</span><span class=\"w\"> </span><span class=\"n\">tensors</span>\n<span class=\"w\">    </span><span class=\"n\">x</span><span class=\"o\">,</span><span class=\"w\"> </span><span class=\"n\">y</span><span class=\"w\"> </span><span class=\"bp\">=</span><span class=\"w\"> </span><span class=\"n\">x</span><span class=\"bp\">.</span><span class=\"n\">float</span><span class=\"o\">(),</span><span class=\"w\"> </span><span class=\"n\">y</span><span class=\"bp\">.</span><span class=\"n\">float</span><span class=\"o\">()</span>\n\n<span class=\"w\">    </span><span class=\"bp\">#</span><span class=\"w\"> </span><span class=\"n\">Compute</span><span class=\"w\"> </span><span class=\"n\">soft</span><span class=\"w\"> </span><span class=\"n\">ranks</span>\n<span class=\"w\">    </span><span class=\"n\">ranks_x</span><span class=\"w\"> </span><span class=\"bp\">=</span><span class=\"w\"> </span><span class=\"n\">torchsort</span><span class=\"bp\">.</span><span class=\"n\">soft_rank</span><span class=\"o\">(</span><span class=\"n\">x</span><span class=\"bp\">.</span><span class=\"n\">unsqueeze</span><span class=\"o\">(</span><span class=\"mi\">0</span><span class=\"o\">),</span><span class=\"w\"> </span><span class=\"n\">regularization_strength</span><span class=\"bp\">=</span><span class=\"n\">regularization_strength</span><span class=\"o\">)</span><span class=\"bp\">.</span><span class=\"n\">squeeze</span><span class=\"o\">(</span><span class=\"mi\">0</span><span class=\"o\">)</span>\n<span class=\"w\">    </span><span class=\"n\">ranks_y</span><span class=\"w\"> </span><span class=\"bp\">=</span><span class=\"w\"> </span><span class=\"n\">torchsort</span><span class=\"bp\">.</span><span class=\"n\">soft_rank</span><span class=\"o\">(</span><span class=\"n\">y</span><span class=\"bp\">.</span><span class=\"n\">unsqueeze</span><span class=\"o\">(</span><span class=\"mi\">0</span><span class=\"o\">),</span><span class=\"w\"> </span><span class=\"n\">regularization_strength</span><span class=\"bp\">=</span><span class=\"n\">regularization_strength</span><span class=\"o\">)</span><span class=\"bp\">.</span><span class=\"n\">squeeze</span><span class=\"o\">(</span><span class=\"mi\">0</span><span class=\"o\">)</span>\n\n<span class=\"w\">    </span><span class=\"bp\">#</span><span class=\"w\"> </span><span class=\"n\">Compute</span><span class=\"w\"> </span><span class=\"n\">Pearson</span><span class=\"w\"> </span><span class=\"n\">correlation</span><span class=\"w\"> </span><span class=\"n\">on</span><span class=\"w\"> </span><span class=\"n\">soft</span><span class=\"w\"> </span><span class=\"n\">ranks</span>\n<span class=\"w\">    </span><span class=\"n\">mean_x</span><span class=\"o\">,</span><span class=\"w\"> </span><span class=\"n\">mean_y</span><span class=\"w\"> </span><span class=\"bp\">=</span><span class=\"w\"> </span><span class=\"n\">ranks_x</span><span class=\"bp\">.</span><span class=\"n\">mean</span><span class=\"o\">(),</span><span class=\"w\"> </span><span class=\"n\">ranks_y</span><span class=\"bp\">.</span><span class=\"n\">mean</span><span class=\"o\">()</span>\n<span class=\"w\">    </span><span class=\"n\">cov_xy</span><span class=\"w\"> </span><span class=\"bp\">=</span><span class=\"w\"> </span><span class=\"o\">((</span><span class=\"n\">ranks_x</span><span class=\"w\"> </span><span class=\"bp\">-</span><span class=\"w\"> </span><span class=\"n\">mean_x</span><span class=\"o\">)</span><span class=\"w\"> </span><span class=\"bp\">*</span><span class=\"w\"> </span><span class=\"o\">(</span><span class=\"n\">ranks_y</span><span class=\"w\"> </span><span class=\"bp\">-</span><span class=\"w\"> </span><span class=\"n\">mean_y</span><span class=\"o\">))</span><span class=\"bp\">.</span><span class=\"n\">mean</span><span class=\"o\">()</span>\n<span class=\"w\">    </span><span class=\"n\">std_x</span><span class=\"w\"> </span><span class=\"bp\">=</span><span class=\"w\"> </span><span class=\"n\">ranks_x</span><span class=\"bp\">.</span><span class=\"n\">std</span><span class=\"o\">(</span><span class=\"n\">unbiased</span><span class=\"bp\">=</span><span class=\"n\">False</span><span class=\"o\">)</span>\n<span class=\"w\">    </span><span class=\"n\">std_y</span><span class=\"w\"> </span><span class=\"bp\">=</span><span class=\"w\"> </span><span class=\"n\">ranks_y</span><span class=\"bp\">.</span><span class=\"n\">std</span><span class=\"o\">(</span><span class=\"n\">unbiased</span><span class=\"bp\">=</span><span class=\"n\">False</span><span class=\"o\">)</span>\n\n<span class=\"w\">    </span><span class=\"n\">return</span><span class=\"w\"> </span><span class=\"n\">cov_xy</span><span class=\"w\"> </span><span class=\"bp\">/</span><span class=\"w\"> </span><span class=\"o\">(</span><span class=\"n\">std_x</span><span class=\"w\"> </span><span class=\"bp\">*</span><span class=\"w\"> </span><span class=\"n\">std_y</span><span class=\"w\"> </span><span class=\"bp\">+</span><span class=\"w\"> </span><span class=\"mi\">1</span><span class=\"n\">e</span><span class=\"bp\">-</span><span class=\"mi\">6</span><span class=\"o\">)</span><span class=\"w\">  </span><span class=\"bp\">#</span><span class=\"w\"> </span><span class=\"n\">Small</span><span class=\"w\"> </span><span class=\"n\">epsilon</span><span class=\"w\"> </span><span class=\"n\">to</span><span class=\"w\"> </span><span class=\"n\">avoid</span><span class=\"w\"> </span><span class=\"n\">division</span><span class=\"w\"> </span><span class=\"k\">by</span><span class=\"w\"> </span><span class=\"n\">zero</span>\n</code></pre></div>\n<p>Should we say that finding differentiable approximations to a discontinuous function is outside the scope of what Lean can or should formalize?</p>",
        "id": 496789283,
        "sender_full_name": "Lars Ericson",
        "timestamp": 1738247076
    },
    {
        "content": "<p>I think <a href=\"https://ai.google.dev/gemini-api/docs/thinking\">Gemini Flash Think</a> gets it right on the first try (which might be multiple tries if you look at the reasoning trace):</p>\n<blockquote>\n<p>This confirms that X = [1, 2, 3] and Y = [1, 3, 2] (or equivalently X = [0, 1, 2] and Y = [0, 2, 1], or any data that has these ranks) will give a Spearman rank correlation of exactly 0.5.</p>\n</blockquote>",
        "id": 496791998,
        "sender_full_name": "Jason Rute",
        "timestamp": 1738247765
    },
    {
        "content": "<p>I suspect many other reasoning models might as well, but it seems this model might be able to run code in the thinking which would help if so.</p>",
        "id": 496792657,
        "sender_full_name": "Jason Rute",
        "timestamp": 1738247965
    },
    {
        "content": "<p>I just tried ChatGPT with the new \"reasoning\" button turned on (so it uses o3-mini) and I think it got it right.  (I'm too lazy to plug it into Python.)</p>\n<blockquote>\n<p>Thus, one acceptable answer is:<br>\n* X=[1,2,3,4,5]<br>\n* Y=[1,4,2,5,3]</p>\n<p>This choice ensures that <code>scipy.stats.spearmanr(X, Y)</code> returns 0.5 exactly.</p>\n</blockquote>",
        "id": 497127486,
        "sender_full_name": "Jason Rute",
        "timestamp": 1738382911
    },
    {
        "content": "<p><a href=\"https://chatgpt.com/share/679d9e5a-a7b0-8001-826f-5d0fefbd7a66\">https://chatgpt.com/share/679d9e5a-a7b0-8001-826f-5d0fefbd7a66</a></p>",
        "id": 497127518,
        "sender_full_name": "Jason Rute",
        "timestamp": 1738382957
    },
    {
        "content": "<p>So I think it is safe to say the assumption of this question is wrong.  Reasoning models (but not non-reasoning LLMs) are to be able to figure this problem out.</p>",
        "id": 497127828,
        "sender_full_name": "Jason Rute",
        "timestamp": 1738383217
    },
    {
        "content": "<p>Consider this prompt: </p>\n<blockquote>\n<p>Construct X,Y with Spearman correlation of exactly 1/2</p>\n</blockquote>\n<p>Perplexity gets it right the first try: <a href=\"https://www.perplexity.ai/search/construct-x-y-with-spearman-co-Y5UuFvxNS_WQv5kKkl3J6g\">https://www.perplexity.ai/search/construct-x-y-with-spearman-co-Y5UuFvxNS_WQv5kKkl3J6g</a></p>\n<p>Google Gemini <a href=\"/user_uploads/3121/WzmTuNS2TBbZlqszcy0IVjal/gemini.txt\">gets it right after coaching it to reduce the vector size. </a></p>\n<p>ChatGPT 4o gets it wrong 9 times in a row, and then asks for money before it will answer any further questions: <a href=\"https://chatgpt.com/share/679d9837-6cb0-8006-8cfe-074158133a47\">https://chatgpt.com/share/679d9837-6cb0-8006-8cfe-074158133a47</a></p>\n<p>All 3 LLMs employ reasoning where the steps involve integer arithmetic and order relations.  All of the reasoning narratives could be directly translated to elementary proof-checking steps in Lean.  Natural Number Game elementary, not FLT math.</p>\n<p>I know it is possible to make domain-specific LLMs that do better on the first try.  If you can do that and that's your goal, you are done.  If you are interested in modes of reasoning, flaws in reasoning, different approaches to reasoning, and how that impacts the performance of LLMs that approach the same problem in different ways, then this example is very efficient at eliciting those differences.</p>\n<p>The reason I am bringing this up is that AI/math benchmarking has become a <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Open.20open.20benchmarks\">topic of interest</a>.  There was some issue about some LLM manufacturers getting early access to good benchmarks and using that to tip the scales on perception.  To me the best way to un-tip the scales is to publicly discuss benchmark problems which elicit distinct and revealing behavior from different LLMs.  This is (demonstrably) such a problem.  So, from my perspective, yay.  One problem at a time, one could build up a repertoire of such problems that elicit distinct and useful insights about LLM reasoning methods.  They don't need to be secret, NDAd or held back in any way.  You could train against them, but if you had enough of them (say 300), it wouldn't be possible to train against 290 of them and have a reasonable expectation of getting the other 10 right, without actually developing some skills.  In that sense, it's a benchmark that can be completely public, and people can train against it all they want, but if they don't train a good model, they won't do well on the held-out problems.  To use another analogy, a good set of benchmark questions is like a public key, where the good trainable model is the private key.  Here I am assuming that you are given models to benchmark that differ in their architecture but are trained from scratch on a common set of training data.  Obviously this doesn't pragmatically apply to commercial LLMs where the training data and methods are a trade secret.</p>",
        "id": 497128096,
        "sender_full_name": "Lars Ericson",
        "timestamp": 1738383463
    },
    {
        "content": "<p>Note that for all of these, I did the work of plugging them into Python, and in my use of ChatGPT, it was wrong every time, after telling me up and down that it was right.</p>",
        "id": 497128249,
        "sender_full_name": "Lars Ericson",
        "timestamp": 1738383541
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"364351\">@Lars Ericson</span> Just so I’m clear, my points are as follows:</p>\n<ul>\n<li>I agree it is good to come up with problems that the current models can’t solve.</li>\n<li>But I don’t see much value with coming up with <em>reasoning</em> problems and only testing them on <em>non-reasoning</em> models (perplexity, Claude sonnet, ChatGPT 4o, Gemini without “thinking”, etc).  These models may reason a little bit, but they don’t have the robust systematic exploration of the problem that the full reasoning models have.</li>\n<li>My limited experiments with the new free reasoning models have shown that this problem is easy for them.   This includes Gemini Flash <strong>Thinking</strong> and o3-mini (which came out yesterday and is accessible via ChatGPT with the <strong>reason</strong> button turned on).  I also just tried <a href=\"https://huggingface.co/spaces/Qwen/QwQ-32B-preview\">QwQ-32B-preview</a> and DeepSeek-r1 (use the app with DeepThink turned on).  They also got it correct on the first try.</li>\n<li>So I think we need harder test problems for the reasoning models.</li>\n</ul>",
        "id": 497151387,
        "sender_full_name": "Jason Rute",
        "timestamp": 1738404743
    },
    {
        "content": "<p>There is a difference between problems that are hard from a mathematician's point of view and problems that may be easy for the latest LLM but still confirm or elucidate properties of the LLM.  These might be called <a href=\"https://www.lcfi.ac.uk/news-events/blog/post/cognitive-psychology-for-ai-evaluation\">cognitive psychology tests for AI evaluation</a>.  For example you can test how many things an LLM can remember, how many things it can remember across prompts, whether it can perform addition, and so on.  In the gpt-4o example above, it was wrong 9 times, and convinced each time that it was right.  It could be that this state of being convinced represents a unique measurable cognitive feature, in the same sense that short term memory size (3 to 5 in humans) is a distinct feature.  That makes the Spearman question indicative from a cog sci of AI point of view, if not from a \"does an AI model exist that can do this\" point of view.</p>\n<p>What I am hearing you say is that the topic of cog sci for AI evaluation is out of scope for this thread.  Which is fine.  Just trying to clarify.</p>",
        "id": 497167983,
        "sender_full_name": "Lars Ericson",
        "timestamp": 1738419453
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"115715\">@Jason Rute</span> regarding the point \"But I don’t see much value with coming up with <em>reasoning</em> problems and only testing them on <em>non-reasoning</em> models\": Suppose you were testing 10 LLMs without knowing their names or their architectures, and wanted to determine if the model had a feature called \"Reasoning\" in a reliable, repeatable way.  What questions would you ask the model to elicit the presence or absence of that feature?  Here I am using the word \"Reasoning\" not as a thing that philosophers might discuss but just as a label for a thing called a \"reasoning model\" that is being added as an architectural feature to recent LLMs.    For non-philosopher context, here is some AI blather from a DeepSeek-R1 implementation on the properties that define a \"reasoning model\": <a href=\"https://www.perplexity.ai/search/what-llms-are-reasoning-models-BgmndsTHSP.TO319kGdvuA\">https://www.perplexity.ai/search/what-llms-are-reasoning-models-BgmndsTHSP.TO319kGdvuA</a></p>",
        "id": 497300469,
        "sender_full_name": "Lars Ericson",
        "timestamp": 1738537651
    },
    {
        "content": "<p><a href=\"https://arxiv.org/abs/2502.07087\">https://arxiv.org/abs/2502.07087</a></p>",
        "id": 500719568,
        "sender_full_name": "Lars Ericson",
        "timestamp": 1739990883
    }
]