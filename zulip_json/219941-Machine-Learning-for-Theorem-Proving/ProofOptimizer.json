[
    {
        "content": "<p>FYI<br>\nFinally we have a golfing model, looks exciting to me. It seems they are focused on golfing LLM-generated proofs and didn't attempt to golf mathlib proofs though.<br>\n<a href=\"https://x.com/minimario1729/status/1980262731099037915\">https://x.com/minimario1729/status/1980262731099037915</a><br>\n<a href=\"https://proof-optimizer.github.io/\">https://proof-optimizer.github.io/</a></p>",
        "id": 546178244,
        "sender_full_name": "Junyan Xu",
        "timestamp": 1761037099
    },
    {
        "content": "<p>It's a bit scary that their collection of input proofs which the attempt to golf during training seems to be entirely generated by GoedelProver. Surely a more diverse set of proofs would be better?</p>",
        "id": 546785675,
        "sender_full_name": "Kim Morrison",
        "timestamp": 1761263663
    },
    {
        "content": "<p>This is great, I think this branch of work is pretty important. Some questions:</p>\n<p>Is (there any plan to make) the model or code available open source?<br>\nWhat happens if the model is run on human-written proofs from mathlib? Could this reduce compile time and file length while keeping human-readability intact?</p>",
        "id": 547351687,
        "sender_full_name": "Bolton Bailey",
        "timestamp": 1761591426
    },
    {
        "content": "<p>This is a well-written paper! Congrats to the authors.</p>\n<p>We ideally should just have a repository of RL environments that we train a single large coding model on to do all of these tasks. I do not think fine-tuning small models for specific Lean related tasks is ideal, as there should be a decent amount of transfer learning going on between the tasks.</p>",
        "id": 547497725,
        "sender_full_name": "Justin Asher",
        "timestamp": 1761659119
    }
]