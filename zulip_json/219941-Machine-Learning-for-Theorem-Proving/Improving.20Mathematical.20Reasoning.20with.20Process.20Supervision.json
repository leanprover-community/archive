[
    {
        "content": "<p><a href=\"https://openai.com/research/improving-mathematical-reasoning-with-process-supervision\">https://openai.com/research/improving-mathematical-reasoning-with-process-supervision</a></p>",
        "id": 362598626,
        "sender_full_name": "Tyler Josephson ⚛️",
        "timestamp": 1685578379
    },
    {
        "content": "<p>Here's a link to the \"MATH dataset\" they used for testing: <a href=\"https://github.com/hendrycks/math/\">https://github.com/hendrycks/math/</a></p>",
        "id": 362851128,
        "sender_full_name": "Adam Topaz",
        "timestamp": 1685645366
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"424214\">Tyler Josephson ⚛️</span> <a href=\"#narrow/stream/219941-Machine-Learning-for-Theorem-Proving/topic/Improving.20Mathematical.20Reasoning.20with.20Process.20Supervision/near/362598626\">发言道</a>：</p>\n<blockquote>\n<p><a href=\"https://openai.com/research/improving-mathematical-reasoning-with-process-supervision\">https://openai.com/research/improving-mathematical-reasoning-with-process-supervision</a></p>\n</blockquote>\n<p>Here is the paper related to the blog: <a href=\"https://cdn.openai.com/improving-mathematical-reasoning-with-process-supervision/Lets_Verify_Step_by_Step.pdf\">https://cdn.openai.com/improving-mathematical-reasoning-with-process-supervision/Lets_Verify_Step_by_Step.pdf</a></p>",
        "id": 362925199,
        "sender_full_name": "RexWang",
        "timestamp": 1685678521
    },
    {
        "content": "<p>I have just completed a thorough read-through of the recent paper, and as a novice in the field of theorem proving, here are some initial insights I've gathered, subject to potential refinement:</p>\n<p>1  Given the multi-step nature intrinsic to theorem proving, it seems like an excellent field for implementing this particular method.</p>\n<p>2  The notion of outcome-based supervision draws some parallels to expert iteration, as seen in previous theorem proving papers. In this approach, the validity of intermediary steps is assessed based on the final result. However, identifying the erroneous step in theorem proving appears challenging. OpenAI tackles this issue by enlisting human annotators. Implementing a similar strategy could indeed represent progress in this field.</p>",
        "id": 363512899,
        "sender_full_name": "Dongwei Jiang",
        "timestamp": 1685889910
    },
    {
        "content": "<p>As I continue to ponder over this, I can't help but wonder: Might elements of process-based supervision already exist within Lean? It's worth noting that we often receive error notifications when employing inappropriate tactics. </p>\n<p>Additionally, the paper's use of scores to establish the correct reasoning path reminds me of the best-first search method, something I've seen incorporated in several theorem proving research works. </p>\n<p>Yet, a thought lingers: If only we had some means to discern whether we're straying down an incorrect proof path—especially in cases that don't necessarily register as errors in Lean...</p>",
        "id": 363586127,
        "sender_full_name": "Dongwei Jiang",
        "timestamp": 1685925037
    }
]