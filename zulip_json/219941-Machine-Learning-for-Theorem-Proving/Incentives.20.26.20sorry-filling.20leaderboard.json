[
    {
        "content": "<p>I really enjoyed <span class=\"user-mention\" data-user-id=\"115715\">@Jason Rute</span> 's talk <em><a href=\"https://youtu.be/JAJCydIRAwA?si=9KReX2iUEcvf1Wqr\">The last mile</a></em> yesterday. The question raised about incentives that can nudge progress towards tools of practical use is I think a fundamental one. There has been lots of discussion about  benchmarks and their limitations here, so here is an idle attempt at formulating another format.</p>\n<p>Could filling sorry's in public repositories (as explored in LeanAgent, and also mentioned in Jason's talk) be turned into some form of open competition? Something like a leaderboard server with an API, where competing algorithms can fetch a sorry and send back their proof, and the leaderboard keeping track of which team is most successful at filling sorries? (Using some form of ELO-rating, where each sorry counts as a single game so that a team can raise on the board by filling a sorry that a competitor could not).</p>\n<p>Could this be feasible? Would it be useful? Could researchers be enticed to participate in this?</p>\n<div class=\"youtube-video message_inline_image\"><a data-id=\"JAJCydIRAwA\" href=\"https://youtu.be/JAJCydIRAwA?si=9KReX2iUEcvf1Wqr\"><img src=\"https://uploads.zulipusercontent.net/d0cf1b772f3284b7170509d65f83361a1d81d8ad/68747470733a2f2f692e7974696d672e636f6d2f76692f4a414a43796449524177412f64656661756c742e6a7067\"></a></div>",
        "id": 494119396,
        "sender_full_name": "Lenny Taelman",
        "timestamp": 1737025919
    },
    {
        "content": "<p>I would love to see machines helping me to prove FLT. I am perhaps two weeks away from having a coherent proof of finite-dimensionality of spaces of quaternionic modular forms, modulo a bunch of sorried theorems all of which will have LaTeX proofs; in particular no missing mathematical information and no sorried data. The problem is that I actually want to get this done -- I think it will be a nice paper -- so I don't just want to leave it as a challenge really, I would like to get it over the line.</p>",
        "id": 494128971,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1737029221
    },
    {
        "content": "<p>What I had in mind would definitely not require to “leave” things as a challenge, I am guessing (hoping) there will always be enough open sorries around. Even if they are open for just a short time window, as long as more than one ‘model’ gets to have an attempt it is a potential data point to distinguish their performance and refine their elo scores.</p>",
        "id": 494140230,
        "sender_full_name": "Lenny Taelman",
        "timestamp": 1737032385
    },
    {
        "content": "<p>There's also no reason that agents can't work on \"old\" sorries as practice problems.</p>",
        "id": 494247651,
        "sender_full_name": "Kim Morrison",
        "timestamp": 1737067933
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110087\">Kim Morrison</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Incentives/near/494247651\">said</a>:</p>\n<blockquote>\n<p>There's also no reason that agents can't work on \"old\" sorries as practice problems.</p>\n</blockquote>\n<p>I agree there's probably some way to incorporate \"old\" sorries as part of some evaluation/incentive/leaderboard, but some care would probably be needed to avoid a situation where the framework primarily incentivizes models that are disproportionately good at remembering what proof was used to close an old sorry. If only new sorries are being considered, then there's much less danger of the answer just being in the training set.</p>",
        "id": 494278754,
        "sender_full_name": "Josh Clune",
        "timestamp": 1737086284
    },
    {
        "content": "<p>To test the assumption that there will always be enough \"new\" open sorries around, I scraped github for lean sorries whose blame date is at most 7 days old. I obtained 63 sorries from 8 repositories. Here is the unfiltered list:<br>\n<a href=\"/user_uploads/3121/pTUNA8BjdQWDhklOCxK3xW5W/sorry_urls.txt\">sorry_urls.txt</a></p>",
        "id": 494428060,
        "sender_full_name": "Lenny Taelman",
        "timestamp": 1737142950
    },
    {
        "content": "<p>Not quite sure how to interpret all this, the variation is huge. But much of it should be valid validation material...</p>",
        "id": 494428197,
        "sender_full_name": "Lenny Taelman",
        "timestamp": 1737143010
    },
    {
        "content": "<p>There's lots missing in that list, in particular FLT and Carleson aren't mentioned, but both have many <code>sorry</code>s.</p>",
        "id": 494448929,
        "sender_full_name": "Kim Morrison",
        "timestamp": 1737151811
    },
    {
        "content": "<p>Further, I think scraping branches <em>other than</em> <code>main</code>/<code>master</code> will get more <code>sorry</code>s.</p>",
        "id": 494448998,
        "sender_full_name": "Kim Morrison",
        "timestamp": 1737151853
    },
    {
        "content": "<p>Further, what we really need are \"reproducible <code>sorry</code>s\", i.e. given a URL, you can <code>git clone</code> it, run <code>lake exe cache get</code> then <code>lake build X.Y.Z</code> and reliably get the warning message about the sorry (ideally have the state at the sorry printed too).</p>",
        "id": 494449257,
        "sender_full_name": "Kim Morrison",
        "timestamp": 1737151975
    },
    {
        "content": "<p>There's then a problem with de-duplicating. Suppose we see \"the same\" sorry on two different branches of the same repository. When do they count as identical? Even if you pretty print the goal and they are identical, one <code>sorry</code> could be solvable because that branch has acquired the necessary preliminary lemmas, while the other <code>sorry</code> isn't.</p>",
        "id": 494449554,
        "sender_full_name": "Kim Morrison",
        "timestamp": 1737152107
    },
    {
        "content": "<p>Perhaps the right thing to do is to index all found sorries by their (hashed) pretty printed goal, but keep the git url (possibly plus timestamp?) for every discovered appearance of that <code>sorry</code>.</p>\n<p>Then, for most purposes solving any one version of \"that\" sorry can count as victory, and if you want to be really thorough you could then try out that same proof on all the other appearances.</p>",
        "id": 494450155,
        "sender_full_name": "Kim Morrison",
        "timestamp": 1737152404
    },
    {
        "content": "<p>I propose the following architecture:</p>\n<ul>\n<li>a file <code>known_lean_repos.json</code>, initially just an array of URLs</li>\n<li>a script to scrape Reservoir at add to <code>known_lean_repos.json</code></li>\n<li>a script to query the Github API to add to <code>known_lean_repos.json</code></li>\n<li>a file <code>observed_sorries.json</code>, containing initially an array of tuples:<ul>\n<li>git URL (containing a git SHA, not HEAD or a branch name) </li>\n<li>a line number</li>\n<li>and a timestamp <code>first_observed</code></li>\n</ul>\n</li>\n<li>now upgrade <code>known_lean_repos.json</code> to so each URL also has an associated <code>last_scraped</code> timestamp field</li>\n<li>a script <code>scrape_for_sorries &lt;repo_url&gt; &lt;timestamp&gt;</code> which<ul>\n<li>clones the repo</li>\n<li>looks at every commit since <code>timestamp</code></li>\n<li>finds added lines containing <code>sorry</code> (don't even worry for now whether it is a real sorry or a comment!)</li>\n<li>adds these to <code>observed_sorries.json</code></li>\n<li>when finished, update the <code>last_scraped</code> timestamp in <code>known_lean_repos.json</code></li>\n</ul>\n</li>\n<li>now the tricky part, a script <code>elaborate_sorry &lt;git URL&gt; &lt;line number&gt;</code><ul>\n<li>I propose that this is implemented as much as possible as new functionality in the REPL / Pantograph / your favourite tool</li>\n<li>clones the repo if not already present</li>\n<li>checks out the commit</li>\n<li>runs <code>lake exe cache get</code> and/or <code>lake build</code> as appropriate</li>\n<li>elaborates the file, identifies which declaration contains the relevant line containing the sorry, and attempts to report the goal state at the sorry</li>\n<li>result: add an entry to <code>elaborated_sorries.json</code> (or possibly this can be combined with `observed_sorries.json?) with a status, either: \"could not find repo\", \"could not find commit\", \"could not find sorry\", \"could not elaborate declaration at line number\", or a successful pretty printed goal state</li>\n</ul>\n</li>\n<li>and then we probably want <code>indexed_sorries.json</code>, which is dictionary from pretty printed goal states to URLs where that <code>sorry</code> was observed in the wild (but this can be regenerated at any time from the other files).</li>\n</ul>\n<p>This is completely half-baked --- thinking as I type! Please pick it apart!</p>\n<p>This seems very doable with current technology, and I think having this infrastructure up and running would enable lots of interesting things.</p>",
        "id": 494456196,
        "sender_full_name": "Kim Morrison",
        "timestamp": 1737155988
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110087\">Kim Morrison</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Incentives.20.26.20sorry-filling.20leaderboard/near/494448929\">said</a>:</p>\n<blockquote>\n<p>There's lots missing in that list, in particular FLT and Carleson aren't mentioned, but both have many <code>sorry</code>s.</p>\n</blockquote>\n<p>Just to make clear, this is a list of sorries whose blame date is less than 7 days old, so it might be that no sorries were added to FLT and Carleson in the past few days?</p>",
        "id": 494492640,
        "sender_full_name": "Lenny Taelman",
        "timestamp": 1737186925
    },
    {
        "content": "<p>Reproducibility is crucial indeed, but sounds feasible.</p>\n<p>I'm not sure if duplicates would really be an issue for the leaderboard thing, at least if there are not too many (so some very basic filtering might suffice). And if some sorries are not solvable because of lemmas missing that is fine as well.  In general, with an ELO approach as outlined above it really doesn't matter if many problems are unsolvable, as long as there are enough solvable ones. </p>\n<p>Of course having a clean completely deduplicated list might be useful for other things as well!</p>",
        "id": 494493285,
        "sender_full_name": "Lenny Taelman",
        "timestamp": 1737187436
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110087\">Kim Morrison</span> <a href=\"#narrow/stream/219941-Machine-Learning-for-Theorem-Proving/topic/Incentives.20.26.20sorry-filling.20leaderboard/near/494448929\">said</a>:</p>\n<blockquote>\n<p>There's lots missing in that list, in particular FLT and Carleson aren't mentioned, but both have many <code>sorry</code>s.</p>\n</blockquote>\n<p>Yes but I've been running LT25 and working on new latex material on a branch and having problems bumping so I bet there was nothing with a blame 7 or fewer days old on main</p>",
        "id": 494496702,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1737189904
    },
    {
        "content": "<p>suppose the person creating the repo realises one of the things they tried to prove was actually invalid, and deletes it without recording the fact anywhere. what would you do then?</p>",
        "id": 494529043,
        "sender_full_name": "Jared green",
        "timestamp": 1737214638
    },
    {
        "content": "<p>even if they did record the fact that it was invalid, how would you know?</p>",
        "id": 494529278,
        "sender_full_name": "Jared green",
        "timestamp": 1737214834
    },
    {
        "content": "<p>and what if they were incorrect in deciding that?</p>",
        "id": 494529328,
        "sender_full_name": "Jared green",
        "timestamp": 1737214878
    },
    {
        "content": "<p>I don't think I would do anything at all? Surely there will always be sorries that are unprovable simply because they are false. As long as there are enough valid sorries that are within reach of competing algorithms (a big if...), that should not matter. But maybe you are referring to something else?</p>",
        "id": 494534306,
        "sender_full_name": "Lenny Taelman",
        "timestamp": 1737218895
    },
    {
        "content": "<p>having a way to prove some sorries invalid would slow the accumulation of those unsolved because of it</p>",
        "id": 494538761,
        "sender_full_name": "Jared green",
        "timestamp": 1737222226
    },
    {
        "content": "<p>and i mean invalid rather than false as that is undecidable</p>",
        "id": 494539596,
        "sender_full_name": "Jared green",
        "timestamp": 1737222641
    },
    {
        "content": "<p>I don't think bad sorries are a problem at all. They are great test cases for <code>plausible</code>, and examples for the even harder problem of \"solving a <code>sorry</code> by correcting the statement\".</p>",
        "id": 494564996,
        "sender_full_name": "Kim Morrison",
        "timestamp": 1737237909
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"479731\">Lenny Taelman</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Incentives.20.26.20sorry-filling.20leaderboard/near/494428060\">said</a>:</p>\n<blockquote>\n<p>To test the assumption that there will always be enough \"new\" open sorries around, I scraped github for lean sorries whose blame date is at most 7 days old.</p>\n</blockquote>\n<p>I love that you scraped this. But it's also interesting to see how it breaks down.</p>\n<ul>\n<li>It looks like 17 of them are from someone doing the Mathematics in Lean tutorial</li>\n<li>Another 20 (the <code>Ostrowski</code>) are from someone making a backup of a file when replacing it with a rewrite; so those 20 sorries are not actually new</li>\n<li>Another 2 are from a pared-down MIL tutorial (the <code>Demo/session1</code>), and 1 more is autogenerated code - that I don't think currently wants that sorry filled, although it might be interesting as training data.</li>\n</ul>\n<p>That leaves 23 on the list. Of those, 12 are from my(!) repo about quantum information, and I can confirm that those are new and mostly-provable sorries. But like you said, variation is huge, we had about three months of none of us putting anything in that repo. And other very active repos, like FLT, just didn't have anything added this week.</p>\n<p>But, this would be an interesting number to track; some sort of time-averaged number of sorries that \"look\" new across time.</p>",
        "id": 494709035,
        "sender_full_name": "Alex Meiburg",
        "timestamp": 1737342513
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"448405\">Alex Meiburg</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Incentives.20.26.20sorry-filling.20leaderboard/near/494709035\">said</a>:</p>\n<blockquote>\n<p>sorries that \"look\" new across time.</p>\n</blockquote>\n<p>Should it not be possible to look at the context of the sorry and convert it into a <a href=\"https://en.wikipedia.org/wiki/Minimal_reproducible_example\">minimal reproducible example</a> and then keep those in a database?</p>\n<p>I seem to recall Jason noting this but did not see such in the slides, perhaps it was said in the presentation. ( The video is down for editing so could not check.)</p>",
        "id": 494792518,
        "sender_full_name": "Eric Taucher",
        "timestamp": 1737374568
    },
    {
        "content": "<p>Another piece of information that should be recorded in such a database when an AI model has reasoning ability is the reasoning/thought process. </p>\n<p>While these reasoning models are not perfect, they often have seen more patterns than most people and sometimes will note something in the thought process that might trigger a new way to solve the problem even though the model failed at the task. So while the solution generated in trying to solve the sorry would fail the check by Lean as an acceptable proof, the the thought process should not be discarded because the AI failed to find a solution.</p>",
        "id": 494796743,
        "sender_full_name": "Eric Taucher",
        "timestamp": 1737375841
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"366057\">Eric Taucher</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Incentives.20.26.20sorry-filling.20leaderboard/near/494792518\">said</a>:</p>\n<blockquote>\n<p>Should it not be possible to look at the context of the sorry and convert it into a <a href=\"https://en.wikipedia.org/wiki/Minimal_reproducible_example\">minimal reproducible example</a> and then keep those in a database?</p>\n</blockquote>\n<p>It absolutely should be, in theory. As Kim pointed out, there's subtleties where the context of \"what other lemmas are proved already in the repo\" (or even \"what version of Lean/Mathlib are you building on\") effectively changes the proof environment. Or what about, an identical proof statement and identical theorems in context, but a different <code>open Classical</code> or similar earlier in the file? Serializing the whole environment is doable in practice but is going to be a very fine-grained partition. What is necessary or not for faithful a MWE is a big ambiguous. (At a minimum, you need to recursively include any defs and theorems referenced - but that is a very bare minimum)</p>\n<p>If I were to design a database system for tracking this ... I think something like, \"the text representation of the theorem statement + the goal state at the location of the sorry\" is probably a 99% accurate indicator of morally equivalent sorries. Then you could have several unique identifiers (repo URL+ git commit + filename + line number) associated to that, that represent slight variations in environment for what is essentially the same problem.</p>",
        "id": 494855324,
        "sender_full_name": "Alex Meiburg",
        "timestamp": 1737391458
    },
    {
        "content": "<p>Yes, I don't think we should attempt at this point to serialize the environment at sorries in an entirely self-contained way. The \"serialization\" will need to consist of a git repo URL, a commit sha, and then rely on <code>lake</code> to build dependencies. That part can all be locally cached.</p>",
        "id": 494943788,
        "sender_full_name": "Kim Morrison",
        "timestamp": 1737421528
    },
    {
        "content": "<p>But we need simple standalone tools to do this.</p>",
        "id": 494943831,
        "sender_full_name": "Kim Morrison",
        "timestamp": 1737421559
    },
    {
        "content": "<p>The REPL has functionality for processing a local file, but this should be extended to something that can load a git URL/commit sha/filename triple.</p>",
        "id": 494943913,
        "sender_full_name": "Kim Morrison",
        "timestamp": 1737421588
    },
    {
        "content": "<p>I've now cleaned up and improved the code, see <a href=\"https://github.com/LennyTaelman/SorryScraper\">https://github.com/LennyTaelman/SorryScraper</a>. It also finds many more sorries. Attached is the output of a new run, with 51 sorries that are less than 1 day old (based on the git blame date).<br>\n<a href=\"/user_uploads/3121/Dgu5GBPPHBANvDgrpsK-nmL5/sorries.txt\">sorries.txt</a>.</p>",
        "id": 495032446,
        "sender_full_name": "Lenny Taelman",
        "timestamp": 1737461113
    },
    {
        "content": "<p>This actually looks like a much more interesting sample of sorries. It contains recent sorries by <span class=\"user-mention\" data-user-id=\"488648\">@Xavier Roblot</span>, <span class=\"user-mention\" data-user-id=\"111080\">@Floris van Doorn</span>, <span class=\"user-mention\" data-user-id=\"720007\">@Daniel Soukup</span>, <span class=\"user-mention\" data-user-id=\"459699\">@Joël Riou</span>,, <span class=\"user-mention\" data-user-id=\"634338\">@Michael Rothgang</span>, <span class=\"user-mention\" data-user-id=\"622397\">@Daniel Morrison</span>, and a couple of anonymous contributors. If any of those are willing to comment on those sorries (are they new, or just copied from older code? how hard do you expect them to be? any other comments?), that would be very much appreciated!</p>",
        "id": 495037008,
        "sender_full_name": "Lenny Taelman",
        "timestamp": 1737462584
    },
    {
        "content": "<p>I'm just going to paste in the contents of <code>sorries.txt</code> to make them clickable:</p>\n<p><a href=\"https://github.com/fpvandoorn/carleson/blob/1d0d61deb511bf80f43f0c8f71da274b0c8659f8/Carleson/HolderVanDerCorput.lean#L97\">https://github.com/fpvandoorn/carleson/blob/1d0d61deb511bf80f43f0c8f71da274b0c8659f8/Carleson/HolderVanDerCorput.lean#L97</a><br>\n<a href=\"https://github.com/fpvandoorn/carleson/blob/1d0d61deb511bf80f43f0c8f71da274b0c8659f8/Carleson/HolderVanDerCorput.lean#L105\">https://github.com/fpvandoorn/carleson/blob/1d0d61deb511bf80f43f0c8f71da274b0c8659f8/Carleson/HolderVanDerCorput.lean#L105</a><br>\n<a href=\"https://github.com/fpvandoorn/carleson/blob/1d0d61deb511bf80f43f0c8f71da274b0c8659f8/Carleson/HolderVanDerCorput.lean#L112\">https://github.com/fpvandoorn/carleson/blob/1d0d61deb511bf80f43f0c8f71da274b0c8659f8/Carleson/HolderVanDerCorput.lean#L112</a><br>\n<a href=\"https://github.com/fpvandoorn/carleson/blob/1d0d61deb511bf80f43f0c8f71da274b0c8659f8/Carleson/HolderVanDerCorput.lean#L171\">https://github.com/fpvandoorn/carleson/blob/1d0d61deb511bf80f43f0c8f71da274b0c8659f8/Carleson/HolderVanDerCorput.lean#L171</a><br>\n<a href=\"https://github.com/fpvandoorn/carleson/blob/451f4568375c1be265a0beb82adb601f9a3ee74d/Carleson/HardyLittlewood.lean#L384\">https://github.com/fpvandoorn/carleson/blob/451f4568375c1be265a0beb82adb601f9a3ee74d/Carleson/HardyLittlewood.lean#L384</a><br>\n<a href=\"https://github.com/hargoniX/fil-rb/blob/495b941eb72c0200039f8750f41d067de617e3a3/Filrb/Internal/Model.lean#L189\">https://github.com/hargoniX/fil-rb/blob/495b941eb72c0200039f8750f41d067de617e3a3/Filrb/Internal/Model.lean#L189</a><br>\n<a href=\"https://github.com/hargoniX/fil-rb/blob/495b941eb72c0200039f8750f41d067de617e3a3/Filrb/Internal/Model.lean#L195\">https://github.com/hargoniX/fil-rb/blob/495b941eb72c0200039f8750f41d067de617e3a3/Filrb/Internal/Model.lean#L195</a><br>\n<a href=\"https://github.com/hargoniX/fil-rb/blob/495b941eb72c0200039f8750f41d067de617e3a3/Filrb/Internal/Model.lean#L198\">https://github.com/hargoniX/fil-rb/blob/495b941eb72c0200039f8750f41d067de617e3a3/Filrb/Internal/Model.lean#L198</a><br>\n<a href=\"https://github.com/hargoniX/fil-rb/blob/495b941eb72c0200039f8750f41d067de617e3a3/Filrb/Internal/Model.lean#L236\">https://github.com/hargoniX/fil-rb/blob/495b941eb72c0200039f8750f41d067de617e3a3/Filrb/Internal/Model.lean#L236</a><br>\n<a href=\"https://github.com/joelriou/topcat-model-category/blob/05b734528674155c6c54f2c49d2867762f5f4765/TopCatModelCategory/SSet/FundamentalGroupoid.lean#L18\">https://github.com/joelriou/topcat-model-category/blob/05b734528674155c6c54f2c49d2867762f5f4765/TopCatModelCategory/SSet/FundamentalGroupoid.lean#L18</a><br>\n<a href=\"https://github.com/joelriou/topcat-model-category/blob/05b734528674155c6c54f2c49d2867762f5f4765/TopCatModelCategory/SSet/FundamentalGroupoid.lean#L20\">https://github.com/joelriou/topcat-model-category/blob/05b734528674155c6c54f2c49d2867762f5f4765/TopCatModelCategory/SSet/FundamentalGroupoid.lean#L20</a><br>\n<a href=\"https://github.com/joelriou/topcat-model-category/blob/05b734528674155c6c54f2c49d2867762f5f4765/TopCatModelCategory/SSet/FundamentalGroupoid.lean#L22\">https://github.com/joelriou/topcat-model-category/blob/05b734528674155c6c54f2c49d2867762f5f4765/TopCatModelCategory/SSet/FundamentalGroupoid.lean#L22</a><br>\n<a href=\"https://github.com/joelriou/topcat-model-category/blob/05b734528674155c6c54f2c49d2867762f5f4765/TopCatModelCategory/SSet/FundamentalGroupoid.lean#L90\">https://github.com/joelriou/topcat-model-category/blob/05b734528674155c6c54f2c49d2867762f5f4765/TopCatModelCategory/SSet/FundamentalGroupoid.lean#L90</a><br>\n<a href=\"https://github.com/joelriou/topcat-model-category/blob/05b734528674155c6c54f2c49d2867762f5f4765/TopCatModelCategory/SSet/FundamentalGroupoid.lean#L96\">https://github.com/joelriou/topcat-model-category/blob/05b734528674155c6c54f2c49d2867762f5f4765/TopCatModelCategory/SSet/FundamentalGroupoid.lean#L96</a><br>\n<a href=\"https://github.com/joelriou/topcat-model-category/blob/05b734528674155c6c54f2c49d2867762f5f4765/TopCatModelCategory/SSet/Homotopy.lean#L20\">https://github.com/joelriou/topcat-model-category/blob/05b734528674155c6c54f2c49d2867762f5f4765/TopCatModelCategory/SSet/Homotopy.lean#L20</a><br>\n<a href=\"https://github.com/joelriou/topcat-model-category/blob/05b734528674155c6c54f2c49d2867762f5f4765/TopCatModelCategory/SSet/Homotopy.lean#L69\">https://github.com/joelriou/topcat-model-category/blob/05b734528674155c6c54f2c49d2867762f5f4765/TopCatModelCategory/SSet/Homotopy.lean#L69</a><br>\n<a href=\"https://github.com/joelriou/topcat-model-category/blob/05b734528674155c6c54f2c49d2867762f5f4765/TopCatModelCategory/SSet/Subcomplex.lean#L499\">https://github.com/joelriou/topcat-model-category/blob/05b734528674155c6c54f2c49d2867762f5f4765/TopCatModelCategory/SSet/Subcomplex.lean#L499</a><br>\n<a href=\"https://github.com/leanprover-community/mathlib4/blob/cd410875f97a5e8ffd93b683739483202ad99651/Mathlib/Geometry/Manifold/HasNiceBoundary.lean#L154\">https://github.com/leanprover-community/mathlib4/blob/cd410875f97a5e8ffd93b683739483202ad99651/Mathlib/Geometry/Manifold/HasNiceBoundary.lean#L154</a><br>\n<a href=\"https://github.com/leanprover-community/mathlib4/blob/7c2926281641c28dc9181cac4f3738d4bb2a4e0f/Mathlib/Algebra/Azumaya/Basic.lean#L321\">https://github.com/leanprover-community/mathlib4/blob/7c2926281641c28dc9181cac4f3738d4bb2a4e0f/Mathlib/Algebra/Azumaya/Basic.lean#L321</a><br>\n<a href=\"https://github.com/leanprover-community/mathlib4/blob/7c2926281641c28dc9181cac4f3738d4bb2a4e0f/Mathlib/Algebra/Azumaya/Basic.lean#L327\">https://github.com/leanprover-community/mathlib4/blob/7c2926281641c28dc9181cac4f3738d4bb2a4e0f/Mathlib/Algebra/Azumaya/Basic.lean#L327</a><br>\n<a href=\"https://github.com/leanprover-community/mathlib4/blob/237526a5ca997d8087fc2e48476189b9ba2b59c2/Mathlib/LinearAlgebra/ExteriorPower/HodgeStar.lean#L71\">https://github.com/leanprover-community/mathlib4/blob/237526a5ca997d8087fc2e48476189b9ba2b59c2/Mathlib/LinearAlgebra/ExteriorPower/HodgeStar.lean#L71</a><br>\n<a href=\"https://github.com/leanprover-community/mathlib4/blob/237526a5ca997d8087fc2e48476189b9ba2b59c2/Mathlib/LinearAlgebra/ExteriorPower/WedgeProduct.lean#L38\">https://github.com/leanprover-community/mathlib4/blob/237526a5ca997d8087fc2e48476189b9ba2b59c2/Mathlib/LinearAlgebra/ExteriorPower/WedgeProduct.lean#L38</a><br>\n<a href=\"https://github.com/leanprover-community/mathlib4/blob/237526a5ca997d8087fc2e48476189b9ba2b59c2/Mathlib/LinearAlgebra/ExteriorPower/WedgeProduct.lean#L44\">https://github.com/leanprover-community/mathlib4/blob/237526a5ca997d8087fc2e48476189b9ba2b59c2/Mathlib/LinearAlgebra/ExteriorPower/WedgeProduct.lean#L44</a><br>\n<a href=\"https://github.com/leanprover-community/mathlib4/blob/c853daa166b9dd80ed9735c71db69a20561a613f/Mathlib/NumberTheory/NumberField/CanonicalEmbedding/NormLessThanOne.lean#L315\">https://github.com/leanprover-community/mathlib4/blob/c853daa166b9dd80ed9735c71db69a20561a613f/Mathlib/NumberTheory/NumberField/CanonicalEmbedding/NormLessThanOne.lean#L315</a><br>\n<a href=\"https://github.com/leanprover-community/mathlib4/blob/c853daa166b9dd80ed9735c71db69a20561a613f/Mathlib/NumberTheory/NumberField/CanonicalEmbedding/NormLessThanOne.lean#L316\">https://github.com/leanprover-community/mathlib4/blob/c853daa166b9dd80ed9735c71db69a20561a613f/Mathlib/NumberTheory/NumberField/CanonicalEmbedding/NormLessThanOne.lean#L316</a><br>\n<a href=\"https://github.com/leanprover-community/mathlib4/blob/c853daa166b9dd80ed9735c71db69a20561a613f/Mathlib/NumberTheory/NumberField/CanonicalEmbedding/NormLessThanOne.lean#L340\">https://github.com/leanprover-community/mathlib4/blob/c853daa166b9dd80ed9735c71db69a20561a613f/Mathlib/NumberTheory/NumberField/CanonicalEmbedding/NormLessThanOne.lean#L340</a><br>\n<a href=\"https://github.com/leanprover-community/mathlib4/blob/c853daa166b9dd80ed9735c71db69a20561a613f/Mathlib/NumberTheory/NumberField/CanonicalEmbedding/NormLessThanOne.lean#L343\">https://github.com/leanprover-community/mathlib4/blob/c853daa166b9dd80ed9735c71db69a20561a613f/Mathlib/NumberTheory/NumberField/CanonicalEmbedding/NormLessThanOne.lean#L343</a><br>\n<a href=\"https://github.com/leanprover-community/mathlib4/blob/c853daa166b9dd80ed9735c71db69a20561a613f/Mathlib/NumberTheory/NumberField/CanonicalEmbedding/NormLessThanOne.lean#L345\">https://github.com/leanprover-community/mathlib4/blob/c853daa166b9dd80ed9735c71db69a20561a613f/Mathlib/NumberTheory/NumberField/CanonicalEmbedding/NormLessThanOne.lean#L345</a><br>\n<a href=\"https://github.com/leanprover-community/mathlib4/blob/c853daa166b9dd80ed9735c71db69a20561a613f/Mathlib/NumberTheory/NumberField/CanonicalEmbedding/NormLessThanOne.lean#L346\">https://github.com/leanprover-community/mathlib4/blob/c853daa166b9dd80ed9735c71db69a20561a613f/Mathlib/NumberTheory/NumberField/CanonicalEmbedding/NormLessThanOne.lean#L346</a><br>\n<a href=\"https://github.com/leanprover-community/mathlib4/blob/c853daa166b9dd80ed9735c71db69a20561a613f/Mathlib/NumberTheory/NumberField/CanonicalEmbedding/NormLessThanOne.lean#L347\">https://github.com/leanprover-community/mathlib4/blob/c853daa166b9dd80ed9735c71db69a20561a613f/Mathlib/NumberTheory/NumberField/CanonicalEmbedding/NormLessThanOne.lean#L347</a><br>\n<a href=\"https://github.com/leanprover-community/mathlib4/blob/c853daa166b9dd80ed9735c71db69a20561a613f/Mathlib/NumberTheory/NumberField/CanonicalEmbedding/NormLessThanOne.lean#L368\">https://github.com/leanprover-community/mathlib4/blob/c853daa166b9dd80ed9735c71db69a20561a613f/Mathlib/NumberTheory/NumberField/CanonicalEmbedding/NormLessThanOne.lean#L368</a><br>\n<a href=\"https://github.com/leanprover-community/mathlib4/blob/c853daa166b9dd80ed9735c71db69a20561a613f/Mathlib/NumberTheory/NumberField/CanonicalEmbedding/NormLessThanOne.lean#L399\">https://github.com/leanprover-community/mathlib4/blob/c853daa166b9dd80ed9735c71db69a20561a613f/Mathlib/NumberTheory/NumberField/CanonicalEmbedding/NormLessThanOne.lean#L399</a><br>\n<a href=\"https://github.com/leanprover-community/mathlib4/blob/c853daa166b9dd80ed9735c71db69a20561a613f/Mathlib/NumberTheory/NumberField/CanonicalEmbedding/NormLessThanOne.lean#L400\">https://github.com/leanprover-community/mathlib4/blob/c853daa166b9dd80ed9735c71db69a20561a613f/Mathlib/NumberTheory/NumberField/CanonicalEmbedding/NormLessThanOne.lean#L400</a><br>\n<a href=\"https://github.com/leanprover-community/mathlib4/blob/c853daa166b9dd80ed9735c71db69a20561a613f/Mathlib/NumberTheory/NumberField/CanonicalEmbedding/NormLessThanOne.lean#L424\">https://github.com/leanprover-community/mathlib4/blob/c853daa166b9dd80ed9735c71db69a20561a613f/Mathlib/NumberTheory/NumberField/CanonicalEmbedding/NormLessThanOne.lean#L424</a><br>\n<a href=\"https://github.com/leanprover-community/mathlib4/blob/c853daa166b9dd80ed9735c71db69a20561a613f/Mathlib/NumberTheory/NumberField/CanonicalEmbedding/NormLessThanOne.lean#L427\">https://github.com/leanprover-community/mathlib4/blob/c853daa166b9dd80ed9735c71db69a20561a613f/Mathlib/NumberTheory/NumberField/CanonicalEmbedding/NormLessThanOne.lean#L427</a><br>\n<a href=\"https://github.com/leanprover-community/mathlib4/blob/c853daa166b9dd80ed9735c71db69a20561a613f/Mathlib/NumberTheory/NumberField/CanonicalEmbedding/NormLessThanOne.lean#L429\">https://github.com/leanprover-community/mathlib4/blob/c853daa166b9dd80ed9735c71db69a20561a613f/Mathlib/NumberTheory/NumberField/CanonicalEmbedding/NormLessThanOne.lean#L429</a><br>\n<a href=\"https://github.com/leanprover-community/mathlib4/blob/c853daa166b9dd80ed9735c71db69a20561a613f/Mathlib/NumberTheory/NumberField/CanonicalEmbedding/NormLessThanOne.lean#L430\">https://github.com/leanprover-community/mathlib4/blob/c853daa166b9dd80ed9735c71db69a20561a613f/Mathlib/NumberTheory/NumberField/CanonicalEmbedding/NormLessThanOne.lean#L430</a><br>\n<a href=\"https://github.com/leanprover-community/mathlib4/blob/c853daa166b9dd80ed9735c71db69a20561a613f/Mathlib/NumberTheory/NumberField/CanonicalEmbedding/NormLessThanOne.lean#L431\">https://github.com/leanprover-community/mathlib4/blob/c853daa166b9dd80ed9735c71db69a20561a613f/Mathlib/NumberTheory/NumberField/CanonicalEmbedding/NormLessThanOne.lean#L431</a><br>\n<a href=\"https://github.com/leanprover-community/mathlib4/blob/c853daa166b9dd80ed9735c71db69a20561a613f/Mathlib/NumberTheory/NumberField/CanonicalEmbedding/PolarCoord.lean#L252\">https://github.com/leanprover-community/mathlib4/blob/c853daa166b9dd80ed9735c71db69a20561a613f/Mathlib/NumberTheory/NumberField/CanonicalEmbedding/PolarCoord.lean#L252</a><br>\n<a href=\"https://github.com/leanprover-community/mathlib4/blob/c853daa166b9dd80ed9735c71db69a20561a613f/Mathlib/NumberTheory/NumberField/CanonicalEmbedding/PolarCoord.lean#L270\">https://github.com/leanprover-community/mathlib4/blob/c853daa166b9dd80ed9735c71db69a20561a613f/Mathlib/NumberTheory/NumberField/CanonicalEmbedding/PolarCoord.lean#L270</a><br>\n<a href=\"https://github.com/leanprover-community/mathlib4/blob/c853daa166b9dd80ed9735c71db69a20561a613f/Mathlib/Sandbox.lean#L233\">https://github.com/leanprover-community/mathlib4/blob/c853daa166b9dd80ed9735c71db69a20561a613f/Mathlib/Sandbox.lean#L233</a><br>\n<a href=\"https://github.com/leanprover-community/mathlib4/blob/c853daa166b9dd80ed9735c71db69a20561a613f/Mathlib/Sandbox.lean#L257\">https://github.com/leanprover-community/mathlib4/blob/c853daa166b9dd80ed9735c71db69a20561a613f/Mathlib/Sandbox.lean#L257</a><br>\n<a href=\"https://github.com/m4lvin/lean4-pdl/blob/fb9f64ec5fc547d303efb4a9316eefe0118f7831/Pdl/Distance.lean#L566\">https://github.com/m4lvin/lean4-pdl/blob/fb9f64ec5fc547d303efb4a9316eefe0118f7831/Pdl/Distance.lean#L566</a><br>\n<a href=\"https://github.com/siddhartha-gadgil/LeanAide/blob/cd35740f0fd5b4e20f7f99ba8db190e88d5a6a2a/CodeGen/from_statement_12669426150657371507.lean#L116\">https://github.com/siddhartha-gadgil/LeanAide/blob/cd35740f0fd5b4e20f7f99ba8db190e88d5a6a2a/CodeGen/from_statement_12669426150657371507.lean#L116</a><br>\n<a href=\"https://github.com/siddhartha-gadgil/LeanAide/blob/cd35740f0fd5b4e20f7f99ba8db190e88d5a6a2a/CodeGen/from_statement_12669426150657371507.lean#L161\">https://github.com/siddhartha-gadgil/LeanAide/blob/cd35740f0fd5b4e20f7f99ba8db190e88d5a6a2a/CodeGen/from_statement_12669426150657371507.lean#L161</a><br>\n<a href=\"https://github.com/siddhartha-gadgil/LeanAide/blob/c5b492594bec960b38c8aaab513dd9d6fe9ce50e/CodeGen/from_statement_13190426273245751.lean#L111\">https://github.com/siddhartha-gadgil/LeanAide/blob/c5b492594bec960b38c8aaab513dd9d6fe9ce50e/CodeGen/from_statement_13190426273245751.lean#L111</a><br>\n<a href=\"https://github.com/urkud/DeRhamCohomology/blob/36294892d98704ed045ed43c086b39ee8cd43247/DeRhamCohomology/ContinuousAlternatingMap/Wedge.lean#L77\">https://github.com/urkud/DeRhamCohomology/blob/36294892d98704ed045ed43c086b39ee8cd43247/DeRhamCohomology/ContinuousAlternatingMap/Wedge.lean#L77</a><br>\n<a href=\"https://github.com/urkud/DeRhamCohomology/blob/36294892d98704ed045ed43c086b39ee8cd43247/DeRhamCohomology/ContinuousAlternatingMap/Wedge.lean#L86\">https://github.com/urkud/DeRhamCohomology/blob/36294892d98704ed045ed43c086b39ee8cd43247/DeRhamCohomology/ContinuousAlternatingMap/Wedge.lean#L86</a><br>\n<a href=\"https://github.com/urkud/DeRhamCohomology/blob/36294892d98704ed045ed43c086b39ee8cd43247/DeRhamCohomology/ContinuousAlternatingMap/Wedge.lean#L90\">https://github.com/urkud/DeRhamCohomology/blob/36294892d98704ed045ed43c086b39ee8cd43247/DeRhamCohomology/ContinuousAlternatingMap/Wedge.lean#L90</a><br>\n<a href=\"https://github.com/urkud/DeRhamCohomology/blob/36294892d98704ed045ed43c086b39ee8cd43247/DeRhamCohomology/ContinuousAlternatingMap/Wedge.lean#L98\">https://github.com/urkud/DeRhamCohomology/blob/36294892d98704ed045ed43c086b39ee8cd43247/DeRhamCohomology/ContinuousAlternatingMap/Wedge.lean#L98</a><br>\n<a href=\"https://github.com/urkud/DeRhamCohomology/blob/36294892d98704ed045ed43c086b39ee8cd43247/DeRhamCohomology/ContinuousAlternatingMap/Wedge.lean#L101\">https://github.com/urkud/DeRhamCohomology/blob/36294892d98704ed045ed43c086b39ee8cd43247/DeRhamCohomology/ContinuousAlternatingMap/Wedge.lean#L101</a></p>",
        "id": 495037195,
        "sender_full_name": "Kim Morrison",
        "timestamp": 1737462645
    },
    {
        "content": "<p>The first 3 Carleson ones look moderately easy, easy, and easy.</p>",
        "id": 495037473,
        "sender_full_name": "Kim Morrison",
        "timestamp": 1737462727
    },
    {
        "content": "<p>The first three <code>topcat-model-category</code> sorries are definitions where one needs to understand the intent of the declaration name --- not just any inhabitant will do!</p>",
        "id": 495037653,
        "sender_full_name": "Kim Morrison",
        "timestamp": 1737462793
    },
    {
        "content": "<p>Most of the DeRhamCohomology sorries look easy to moderate.</p>",
        "id": 495037777,
        "sender_full_name": "Kim Morrison",
        "timestamp": 1737462841
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110087\">Kim Morrison</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Incentives.20.26.20sorry-filling.20leaderboard/near/495037653\">said</a>:</p>\n<blockquote>\n<p>The first three <code>topcat-model-category</code> sorries are definitions where one needs to understand the intent of the declaration name --- not just any inhabitant will do!</p>\n</blockquote>\n<p>Ouch, good point! Those should be out for any kind of theorem-proving competition. That should be part of some actual lean-validation process...</p>",
        "id": 495037825,
        "sender_full_name": "Lenny Taelman",
        "timestamp": 1737462846
    },
    {
        "content": "<p>I guess when we build the next step, that finds the goal at each of these sorries, we not only need to report the goal, but the type of the goal (i.e. is it in Prop or Type u).</p>",
        "id": 495038039,
        "sender_full_name": "Kim Morrison",
        "timestamp": 1737462931
    },
    {
        "content": "<p>The LeanAide examples are fake sorries --- they are comments, not code!</p>",
        "id": 495038118,
        "sender_full_name": "Kim Morrison",
        "timestamp": 1737462961
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110087\">Kim Morrison</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Incentives.20.26.20sorry-filling.20leaderboard/near/495038118\">said</a>:</p>\n<blockquote>\n<p>The LeanAide examples are fake sorries --- they are comments, not code!</p>\n</blockquote>\n<p>At least that should be easy to filter out ;-)</p>",
        "id": 495038246,
        "sender_full_name": "Lenny Taelman",
        "timestamp": 1737462989
    },
    {
        "content": "<p>Most of the <code>sorries</code> from my code are just there because I did not have the time to fill-in or I was not sure what the statement should be or if I would need it and are not really interesting. </p>\n<p>If you want a <code>sorry</code> for which I would be glad to get some help from AI because I don't see a clean and quick way to do it, you can have a look at this one : <a href=\"https://github.com/leanprover-community/mathlib4/blob/c853daa166b9dd80ed9735c71db69a20561a613f/Mathlib/Sandbox.lean#L257\">https://github.com/leanprover-community/mathlib4/blob/c853daa166b9dd80ed9735c71db69a20561a613f/Mathlib/Sandbox.lean#L257</a></p>",
        "id": 495038775,
        "sender_full_name": "Xavier Roblot",
        "timestamp": 1737463153
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"488648\">Xavier Roblot</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Incentives.20.26.20sorry-filling.20leaderboard/near/495038775\">said</a>:</p>\n<blockquote>\n<p>Most of the <code>sorries</code> from my code are just there because I did not have the time to fill-in or I was not sure what the statement should be or if I would need it and are not really interesting. </p>\n</blockquote>\n<p>Do you expect some of them to be true and provable?</p>",
        "id": 495038983,
        "sender_full_name": "Lenny Taelman",
        "timestamp": 1737463211
    },
    {
        "content": "<p>\"not really interesting\" doesn't mean that they wouldn't be interesting for a AI benchmark,</p>",
        "id": 495039065,
        "sender_full_name": "Kim Morrison",
        "timestamp": 1737463236
    },
    {
        "content": "<p>Most of them are missing definition or incomplete statements, I think. Let me have another look.</p>",
        "id": 495039134,
        "sender_full_name": "Xavier Roblot",
        "timestamp": 1737463262
    },
    {
        "content": "<p>The question is not \"is this hard and you would be interested in knowing the answer\", but rather \"is this easy and you wish an AI would grind it out for you so you don't need to bother\".</p>",
        "id": 495039143,
        "sender_full_name": "Kim Morrison",
        "timestamp": 1737463264
    },
    {
        "content": "<p>Or even: is it easy and doable, so it can help us \"rate\" AI systems, and motivate developers. I think a `good' sorry for this purpose is any sorry that is easy enough that it might be fillable by <em>some</em> AI system, but hard enough that it won't be filled by <em>all</em> of them.</p>",
        "id": 495039222,
        "sender_full_name": "Lenny Taelman",
        "timestamp": 1737463299
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110087\">Kim Morrison</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Incentives.20.26.20sorry-filling.20leaderboard/near/495039143\">said</a>:</p>\n<blockquote>\n<p>The question is not \"is this hard and you would be interested in knowing the answer\", but rather \"is this easy and you wish an AI would grind it out for you so you don't need to bother\".</p>\n</blockquote>\n<p>Well, I think it is the case in the example I sent above. I know how to prove it but I don't want to do it because it would be tedious. Although that example might be a bit too difficult.</p>",
        "id": 495039393,
        "sender_full_name": "Xavier Roblot",
        "timestamp": 1737463353
    },
    {
        "content": "<p>Great. I think this is more than enough to go on --- Lenny's list has a non-trivial fraction of relevant-to-AI training sorries, and so we should be doing this scraping regularly, recording the results, and building the tooling to analyse these sorries!</p>",
        "id": 495039734,
        "sender_full_name": "Kim Morrison",
        "timestamp": 1737463463
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"479731\">Lenny Taelman</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Incentives.20.26.20sorry-filling.20leaderboard/near/495037008\">said</a>:</p>\n<blockquote>\n<p>This actually looks like a much more interesting sample of sorries. It contains recent sorries by <span class=\"user-mention silent\" data-user-id=\"488648\">Xavier Roblot</span>, <span class=\"user-mention silent\" data-user-id=\"111080\">Floris van Doorn</span>, <span class=\"user-mention silent\" data-user-id=\"720007\">Daniel Soukup</span>, <span class=\"user-mention silent\" data-user-id=\"459699\">Joël Riou</span>,, <span class=\"user-mention silent\" data-user-id=\"634338\">Michael Rothgang</span>, <span class=\"user-mention silent\" data-user-id=\"622397\">Daniel Morrison</span>, and a couple of anonymous contributors. If any of those are willing to comment on those sorries (are they new, or just copied from older code? how hard do you expect them to be? any other comments?), that would be very much appreciated!</p>\n</blockquote>\n<p>Regarding mine, this is very much work in progress. Some sorries are relatively easy, some are more difficult, and require specific mathematical arguments, which I would not expect AI to solve.</p>",
        "id": 495042100,
        "sender_full_name": "Joël Riou",
        "timestamp": 1737464256
    },
    {
        "content": "<p>The following statements are true and provable (with various difficulty): <br>\n<a href=\"https://github.com/leanprover-community/mathlib4/blob/c853daa166b9dd80ed9735c71db69a20561a613f/Mathlib/NumberTheory/NumberField/CanonicalEmbedding/NormLessThanOne.lean#L315\">https://github.com/leanprover-community/mathlib4/blob/c853daa166b9dd80ed9735c71db69a20561a613f/Mathlib/NumberTheory/NumberField/CanonicalEmbedding/NormLessThanOne.lean#L315</a><br>\n<a href=\"https://github.com/leanprover-community/mathlib4/blob/c853daa166b9dd80ed9735c71db69a20561a613f/Mathlib/NumberTheory/NumberField/CanonicalEmbedding/NormLessThanOne.lean#L316\">https://github.com/leanprover-community/mathlib4/blob/c853daa166b9dd80ed9735c71db69a20561a613f/Mathlib/NumberTheory/NumberField/CanonicalEmbedding/NormLessThanOne.lean#L316</a><br>\n<a href=\"https://github.com/leanprover-community/mathlib4/blob/c853daa166b9dd80ed9735c71db69a20561a613f/Mathlib/NumberTheory/NumberField/CanonicalEmbedding/NormLessThanOne.lean#L340\">https://github.com/leanprover-community/mathlib4/blob/c853daa166b9dd80ed9735c71db69a20561a613f/Mathlib/NumberTheory/NumberField/CanonicalEmbedding/NormLessThanOne.lean#L340</a><br>\n<a href=\"https://github.com/leanprover-community/mathlib4/blob/c853daa166b9dd80ed9735c71db69a20561a613f/Mathlib/NumberTheory/NumberField/CanonicalEmbedding/NormLessThanOne.lean#L343\">https://github.com/leanprover-community/mathlib4/blob/c853daa166b9dd80ed9735c71db69a20561a613f/Mathlib/NumberTheory/NumberField/CanonicalEmbedding/NormLessThanOne.lean#L343</a><br>\n<a href=\"https://github.com/leanprover-community/mathlib4/blob/c853daa166b9dd80ed9735c71db69a20561a613f/Mathlib/NumberTheory/NumberField/CanonicalEmbedding/NormLessThanOne.lean#L345\">https://github.com/leanprover-community/mathlib4/blob/c853daa166b9dd80ed9735c71db69a20561a613f/Mathlib/NumberTheory/NumberField/CanonicalEmbedding/NormLessThanOne.lean#L345</a><br>\n<a href=\"https://github.com/leanprover-community/mathlib4/blob/c853daa166b9dd80ed9735c71db69a20561a613f/Mathlib/NumberTheory/NumberField/CanonicalEmbedding/NormLessThanOne.lean#L346\">https://github.com/leanprover-community/mathlib4/blob/c853daa166b9dd80ed9735c71db69a20561a613f/Mathlib/NumberTheory/NumberField/CanonicalEmbedding/NormLessThanOne.lean#L346</a></p>",
        "id": 495047027,
        "sender_full_name": "Xavier Roblot",
        "timestamp": 1737465724
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"459699\">Joël Riou</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Incentives.20.26.20sorry-filling.20leaderboard/near/495042100\">said</a>:</p>\n<blockquote>\n<p>Regarding mine, this is very much work in progress. Some sorries are relatively easy, some are more difficult, and require specific mathematical arguments, which I would not expect AI to solve.</p>\n</blockquote>\n<p>That is the best mix!</p>",
        "id": 495050609,
        "sender_full_name": "Jason Rute",
        "timestamp": 1737466712
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110087\">Kim Morrison</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Incentives.20.26.20sorry-filling.20leaderboard/near/495037473\">said</a>:</p>\n<blockquote>\n<p>The first 3 Carleson ones look moderately easy, easy, and easy.</p>\n</blockquote>\n<p>In fact, the second one is false since it's missing <code>I \\ne \\top</code> :-)<br>\nI think this will be common: many sorry's will be false since a hypothesis is missing.</p>",
        "id": 495056512,
        "sender_full_name": "Floris van Doorn",
        "timestamp": 1737468128
    },
    {
        "content": "<p>I guess you can handle this situation by \"raising the stakes\" --- an AI agent is allowed to suggest proofs that use extra hypotheses, and if the human accepts it, the AI gets a <em>bigger</em> reward than usual.</p>\n<p>Another possibility when considering adding a hypothesis is to ask an agent to demonstrate that the additional hypothesis is available at any existing call sites (if there are any).</p>",
        "id": 495058075,
        "sender_full_name": "Kim Morrison",
        "timestamp": 1737468428
    },
    {
        "content": "<p>Yet another possibility is to award <em>disproving</em> sorries.</p>",
        "id": 495058404,
        "sender_full_name": "Lenny Taelman",
        "timestamp": 1737468492
    },
    {
        "content": "<p>I'm really hoping that by the end of this year, as soon as you type <code>:=</code> after a theorem statement a counterexample generator that actually works will start running in the background... <span aria-label=\"fingers crossed\" class=\"emoji emoji-1f91e\" role=\"img\" title=\"fingers crossed\">:fingers_crossed:</span></p>",
        "id": 495062229,
        "sender_full_name": "Kim Morrison",
        "timestamp": 1737469243
    },
    {
        "content": "<p>Also, models like DeepSeek-Prover also have been trained to also be able to show theorems are false or trivially true (where the hypotheses are inconsistent).  That could be another target.</p>",
        "id": 495062536,
        "sender_full_name": "Jason Rute",
        "timestamp": 1737469295
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"243562\">@Adam Topaz</span> and I have been discussing a <code>weighted_sorry</code>. We could upstream a prototype if people like the concept.<br>\nOur thoughts:</p>\n<ul>\n<li><code>weighted_sorry n</code> indicates an expectation that circa <code>n</code> lines of Lean code will be needed to fill in this sorry.</li>\n<li>AIs can use <code>n</code> to choose which sorries to work on</li>\n<li>AIs can also also train to predict <code>n</code>, in order to turn <code>sorry</code> into <code>weighted_sorry n</code>.</li>\n</ul>",
        "id": 495094883,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1737476452
    },
    {
        "content": "<p>The prototype can currently be found in <a href=\"https://github.com/adamtopaz/NodeGraph\">NodeGraph</a> -- the declaration graphs display the total weight of any given node.</p>",
        "id": 495095438,
        "sender_full_name": "Adam Topaz",
        "timestamp": 1737476598
    },
    {
        "content": "<p>This list already reveals an obvious problem. Some of those sorries are in a student project and it would probably be very bad to ruin this project by proving them. If you really build this tool then I think you should ask permission from each repository author to play with their sorries in this way. This would be <em>lot</em> more polite.</p>",
        "id": 495161437,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1737500913
    },
    {
        "content": "<p>Sure, it would be good to ask before sending them PRs, but it isn't clear that such a feature wouldn't be helpful to a lot of students.  Right now AI systems aren't that good so it isn't like it would do their project for them, and it might help them get unstuck on theorems where they just don't know the syntax (or by telling them there is an obvious contradiction in their theorem statement).  Of course, it is probably situation-specific.</p>\n<p>Also, it might be good to separate the two situations: (1) the system collects the sorry data (and tries to prove theorems). (2) the system notifies the authors of a solution via a PR to the project.  This might be a case where one does the former but not the latter.</p>",
        "id": 495174118,
        "sender_full_name": "Jason Rute",
        "timestamp": 1737507465
    },
    {
        "content": "<p>Is the weight in <code>weighted_sorry</code> meant to be the total number of lines to add (including building up API / proving other required lemmas) to get a <code>sorry</code>-free proof, or the number of lines to get a proof that is locally <code>sorry</code>-free but may depend on other pre-existing lemmas that use <code>sorry</code>, or just the number of lines expected locally for that specific <code>sorry</code> (possibly adding new lemmas, not counted in the value of <code>n</code>, that also need proving, in addition to existing lemmas that use <code>sorry</code>)?</p>",
        "id": 495179787,
        "sender_full_name": "Joseph Myers",
        "timestamp": 1737510491
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110031\">Patrick Massot</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Incentives.20.26.20sorry-filling.20leaderboard/near/495161437\">said</a>:</p>\n<blockquote>\n<p>This list already reveals an obvious problem. Some of those sorries are in a student project and it would probably be very bad to ruin this project by proving them. If you really build this tool then I think you should ask permission from each repository author to play with their sorries in this way. This would be <em>lot</em> more polite.</p>\n</blockquote>\n<p>Indeed it is important to realise that not everyone with a public repository is waiting for help (from humans or machines). As for permission, there are many degrees possible, with at the extremes:</p>\n<ul>\n<li>most restrictive: do not include any sorries in a database without prior consent of repo owner</li>\n<li>least restrictive: when a sorry is machine-filled and a pull-request is automatically made, include a link to \"stop sending me pull requests\" (this is probably necessary anyway, as a protection against a bug in the system generating too many PRs)</li>\n</ul>\n<p>As for \"ruining a project\", I would think that this is not so likely to happen. I imagine (perhaps naively) that a student would be thrilled to find out that they have reduced the problem to small enough sub-goals that a machine can fill. (Just as I was thrilled when I discovered that <code>aesop</code> or <code>exact?</code> could fill in sorries that I thought I had to sweat through myself). I would also guess (maybe even more naively) that progress in machine proving is gradual enough that a supervisor would have a reasonable idea as to which student projects would still be interesting enough to pursue.</p>",
        "id": 495214181,
        "sender_full_name": "Lenny Taelman",
        "timestamp": 1737530491
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"266253\">Joseph Myers</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Incentives.20.26.20sorry-filling.20leaderboard/near/495179787\">said</a>:</p>\n<blockquote>\n<p>Is the weight in <code>weighted_sorry</code> meant to be the total number of lines to add (including building up API / proving other required lemmas) to get a <code>sorry</code>-free proof, or the number of lines to get a proof that is locally <code>sorry</code>-free but may depend on other pre-existing lemmas that use <code>sorry</code>, or just the number of lines expected locally for that specific <code>sorry</code> (possibly adding new lemmas, not counted in the value of <code>n</code>, that also need proving, in addition to existing lemmas that use <code>sorry</code>)?</p>\n</blockquote>\n<p>This is not completely specced out yet. But my mental model is that <code>n</code> represents the number of lines that need to be added to close the <code>sorry</code>, where the proof may depend on other <code>weighted_sorry</code>s.</p>\n<p>So the total number of lines to make a given statement sorry-free would be the sum of all the <code>n</code> that are expected to be necessary for the proof.<br>\nI guess this means that <code>weighted_sorry</code> should maybe include pointers to sorried results that are expected to be needed in the proof?</p>\n<p>One thing is clear: whatever semantics we choose, the value of <code>n</code> will probably have to be updated regularly as work on the proof progresses.</p>",
        "id": 495215730,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1737531184
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"479731\">@Lenny Taelman</span> are you thinking it would be opt-in or opt-out?</p>",
        "id": 495286050,
        "sender_full_name": "Jared green",
        "timestamp": 1737553507
    },
    {
        "content": "<p>I don't think that's for me to decide, but opt-out is certainly much easier to accomplish. There are actually several parallel questions here, and the answer may be different for them:</p>\n<ol>\n<li>Can we scrape your sorries and make the resulting database available (e.g. for people who want to do statistics, test their theorem-proving systems, etcetera)</li>\n<li>Can we use this database to create a 'leaderboard' to continuously evaluate automated systems and compare their performance (my original intention: create a benchmark/incentive that is more closely aligned with mathematical practice)</li>\n<li>Should automated systems (on themselves, or through the  leaderboard) be allowed to make unsolicited pull-requests to fill sorries in your repositories?</li>\n</ol>\n<p>I would actually be very interested in hearing what people think about these questions.</p>",
        "id": 495287309,
        "sender_full_name": "Lenny Taelman",
        "timestamp": 1737553848
    },
    {
        "content": "<p>Of course once we make the database, we cannot enforce how others use it. But at least we could provide some guidelines as to what the community considers good behaviour (if there is consensus...)</p>",
        "id": 495287743,
        "sender_full_name": "Lenny Taelman",
        "timestamp": 1737553973
    },
    {
        "content": "<p>I think 1 should be opt out, 2 maybe opt out, and 3 opt in.</p>",
        "id": 495287782,
        "sender_full_name": "Jason Rute",
        "timestamp": 1737553984
    },
    {
        "content": "<p>I also think the answers should not be set in stone, actual experience with such tools may give good reasons to adjust things...</p>",
        "id": 495288193,
        "sender_full_name": "Lenny Taelman",
        "timestamp": 1737554087
    },
    {
        "content": "<p>Especially for (1) if it is an Apache or MIT licensed project one is effectively saying that others are free to mess around with the code.</p>",
        "id": 495288704,
        "sender_full_name": "Jason Rute",
        "timestamp": 1737554215
    },
    {
        "content": "<p>Sure, but I would hope that such a project has some community support, and not just \"everyone dislikes it but it is legally allowed\".</p>",
        "id": 495289204,
        "sender_full_name": "Lenny Taelman",
        "timestamp": 1737554331
    },
    {
        "content": "<p>True</p>",
        "id": 495289266,
        "sender_full_name": "Jason Rute",
        "timestamp": 1737554347
    },
    {
        "content": "<p>surely releasing something under a permissive license(or even straight into the public domain) is an active choice that would imply openness to such activities, right? like it wouldnt just be the law's idea to allow it, but the individual's. but especially when there is a statement saying 'contributions are welcome/encouraged' in the readme.</p>",
        "id": 495313328,
        "sender_full_name": "Jared green",
        "timestamp": 1737560506
    },
    {
        "content": "<p>I would think that a generic student project either has no license, or is forked from a repository which might have one (possibly without a student thinking about that). In other words: have a permissive licence does not mean \"I'm open to AI proposing pull requests\". (It certainly doesn't for me.)</p>",
        "id": 495319662,
        "sender_full_name": "Michael Rothgang",
        "timestamp": 1737562239
    },
    {
        "content": "<p>for a forked project, you would find the original, which would have a subset of the same sorries. the license is a choice in the original. one with no license, if it is dormant should probably be treated like it has a permissive license, otherwise permission should probably be sought.</p>",
        "id": 495325333,
        "sender_full_name": "Jared green",
        "timestamp": 1737563747
    },
    {
        "content": "<p>I disagree with the \"dormant\" part. (And otherwise think Jason's distinction 1/2/3 above is good.)</p>",
        "id": 495325557,
        "sender_full_name": "Michael Rothgang",
        "timestamp": 1737563812
    },
    {
        "content": "<p>IANAL, but as far as the law is concerned and I understand it: code released with no explicit license defaults to retaining full copyright, which includes the restriction of not distributing copies, and making no derivative works. Building a system that scrapes code from public repos with no license and \"works on it\" is legally gray.</p>\n<p>What that means in practice is messy, of course. If someone has a repository with no license, and I make a PR offering a bug fix (which includes forking the repo - a 'derivative work'), it would be pretty bizarre to say that I violated copyright law by doing so. But as Lenny said, 'technically legally allowed' is a low bar.</p>",
        "id": 495334565,
        "sender_full_name": "Alex Meiburg",
        "timestamp": 1737566587
    },
    {
        "content": "<p>it seems we may need a lawyers help on this then</p>",
        "id": 495391482,
        "sender_full_name": "Jared green",
        "timestamp": 1737588206
    },
    {
        "content": "<p>No, I think we should stay clear of that. When in doubt, ask the repo owner for permission.</p>",
        "id": 495424206,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1737608221
    },
    {
        "content": "<p>Hi! I was just thinking about this a little, and it seems much more helpful to keep this opt-in:</p>\n<ul>\n<li>With an opt-in system for formal verification projects, there could be better support for reproducing a <code>sorry</code> or a <code>proof_wanted</code> in lean4web for mathlib4 or just gitpod.</li>\n<li>As far as I know, there is a very finite list of independent permissively licensed formalization projects, many of which the authors are active participants of the lean4 community or have at least chatted in the leanprover Zulip a few times, so trying to scale for a problem that doesn't exist yet, and probably won't exist for quite some time, seems unnecessary. Even if lean4's popularity were to suddenly explode, having an established opt-in system would encourage people to make their repositories easier to reproduce, which seems beneficial for everyone involved.</li>\n</ul>",
        "id": 496264209,
        "sender_full_name": "Tristan Figueroa-Reid",
        "timestamp": 1738044637
    },
    {
        "content": "<p>I think just starting off with a simple list of known formalization projects and an automated scraper that clones each repository, finds <code>sorry</code>s or <code>proof_wanted</code>s, and has GitHub links and open PRs targeting said <code>sorry</code>s (like <span class=\"user-mention\" data-user-id=\"387244\">@Yaël Dillies</span>'s project) would be something that would help new contributors (and eventually AI) make beneficial contributions to the general lean formalization community.</p>",
        "id": 496264379,
        "sender_full_name": "Tristan Figueroa-Reid",
        "timestamp": 1738044750
    },
    {
        "content": "<p>Half baked idea that might work with regards to selecting <code>sorry</code> code , consider tagging such with a custom Lean attribute. I have created and used attributes in other functional programming languages, e.g. F#, but not with Lean so not sure if this will work. </p>\n<p>The idea is simply that the attribute is added, possibly with arguments, and then the code collecting the <code>sorry</code> items can easily identify if this should be included. I suspect that Lean attributes can be much more fine grained in that right now it seems the entire repository would be opt-in/out but with an attribute, the selection is very fine grained.</p>\n<p>If the code checking for the attribute starts with an empty <code>sorry</code> datastore for that repository then the removal of the attribute would mean that the item would no longer be included in the <code>sorry</code> datastore which would be an added benefit. </p>\n<p>Anyway, just an idea.</p>",
        "id": 496288436,
        "sender_full_name": "Eric Taucher",
        "timestamp": 1738055637
    },
    {
        "content": "<p>I think <code>leanprover-community/batteries</code>'s <code>proof_wanted</code> is the best form of this <span aria-label=\"+1\" class=\"emoji emoji-1f44d\" role=\"img\" title=\"+1\">:+1:</span></p>",
        "id": 496418322,
        "sender_full_name": "Tristan Figueroa-Reid",
        "timestamp": 1738095991
    },
    {
        "content": "<p>I just wrote a little website for this that auto updates and comes with raw data: <a href=\"https://leodog896.github.io/unsolved-lean/\">leodog896.github.io/unsolved-lean/</a></p>",
        "id": 496474226,
        "sender_full_name": "Tristan Figueroa-Reid",
        "timestamp": 1738128788
    },
    {
        "content": "<p>(note that the proof_wanted and sorry-collecting code is quite hacky - I tried to shortcut it by using a highlighter, because I couldn't figure out how to parse a lean4 file without evaluating every file, but it turns out the highlighter I used doesn't work with <code>--</code> commits anyways.)</p>",
        "id": 496475367,
        "sender_full_name": "Tristan Figueroa-Reid",
        "timestamp": 1738129680
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"479731\">@Lenny Taelman</span> I contributed solutions for two Olympiad problems to Compfiles:</p>\n<p><a href=\"https://github.com/dwrensha/compfiles\">https://github.com/dwrensha/compfiles</a></p>\n<p>while I am not the maintainer and if you'd like to get more definitive answers you'd have to ask the maintainer <span class=\"user-mention\" data-user-id=\"243791\">@David Renshaw</span>, here is my understanding of how this particular project works:</p>\n<p>1) My expectation is that the maintainer would welcome pull requests that solve most of the sorries in the repo, even very old ones. For example, my expectation is that David would be happy to see a formal solution to this 2015 problem, which according to git blame has had a sorry for ~ 2 years already:</p>\n<p><a href=\"https://github.com/dwrensha/compfiles/blob/main/Compfiles/Imo2015P2.lean#L32\">https://github.com/dwrensha/compfiles/blob/main/Compfiles/Imo2015P2.lean#L32</a></p>\n<p>In fact, one of my contributions has been to finish a proof that was already ~ a third of the way there.</p>\n<p>I suspect there might be less excitement about a solution that is poorly readable or if it compiles very slowly. But if an AI system produces a human-quality solution without any kind of cheating, then I expect David would be happy to accept a contribution. But I think old sorries are good benchmark material.</p>\n<p>2) There is a very good dashboard which tells you a lot more about each problem, e.g. we can look at all the IMO problems here:</p>\n<p><a href=\"https://dwrensha.github.io/compfiles/imo.html\">https://dwrensha.github.io/compfiles/imo.html</a></p>\n<p>If it's green it means there is a full solution -- no sorries for you :). If it's yellow the statement of the problem is formalised, but not the solution -- there is at least one sorry! If it's grey, nothing is formalised yet.</p>\n<p>3) If you click on a specific problem, e.g. this 2015 problem I linked to earlier, you will often get a link to an <strong>informal</strong> solution, in this case you need to click on \"Art of Problem Solving\" or \"Evan Chen\" links:</p>\n<p><a href=\"https://dwrensha.github.io/compfiles/problems/Compfiles.Imo2015P2.html\">https://dwrensha.github.io/compfiles/problems/Compfiles.Imo2015P2.html</a></p>\n<p>This is interesting, because it means that usually there is already an informal solution out there, and <strong>all</strong> that the AI needs to do is formalise that solution :).</p>\n<p>4) The quality of continuous integration, how fast things compile, how up-to-date everything is, is very high. It took me very little time to get set up with the project just by following the instructions on github, and the dashboard, etc... all of this is automatically built by the CI.</p>\n<p>Overall, I think the project would be perfect for what you're trying to do, there should be ~ over 50 high quality sorries there, and if you can bundle the informal solutions with the formal problem statements you might get a high quality autoformalisation benchmark out of this.</p>",
        "id": 497416149,
        "sender_full_name": "Adam Kurkiewicz",
        "timestamp": 1738584585
    },
    {
        "content": "<p>This looks like a wonderful and mature project, very polished indeed. I think indeed that auto-proving and auto-formalizing these problems would be a good test for formal math models.</p>\n<p>It is however a bit orthogonal to what I had in mind:</p>\n<ul>\n<li>I wanted to focus on <em>research math</em> (for lack of better term) as opposed to <em>olympiad math</em>, as there is already quite some work towards the latter. I'd rather interpret research math broadly, and I don't think it is necessarily harder than olympiad math (looking up the right lemma to finish a proof is also research math; in fact a big part of what I do on a daily basis...). It is however different than olympiad math, and in many ways far more messy and heterogeneous. </li>\n<li>The aim would be to stimulate the development of models towards something that may be useful in daily research math. A tool that is able to solve existing sorries in ongoing formalization problems is in my opinion by definition a tool that would be useful. </li>\n<li>The idea would be that there may be some continuously evolving <em>leaderboard</em>, incentivising people to produce models that do well on things we care about.</li>\n<li>Once there is a model that actually scores high enough, one can try to think about making it into a tool that is actually useable in practice... </li>\n</ul>\n<p>I admit, all the above is just vane dreaming, and it may be very naive. The tests discussed above confirm that there is a big enough continuous supply of new sorries of varying level, for this to be possible at least in principle.</p>\n<p>The biggest obstacle of course is to convince people to take part. The first step would be to establish that <em>some</em> existing model out there obtains a non-zero score.</p>\n<p>So let me ask this here: any suggestions as to which existing model/system might be worth hooking up to see if it can establish a non-zero base line score?</p>",
        "id": 497442364,
        "sender_full_name": "Lenny Taelman",
        "timestamp": 1738591120
    },
    {
        "content": "<p>I haven't tried it yet, but I'd like to try Aider:</p>\n<p><a href=\"https://aider.chat/\">https://aider.chat/</a></p>\n<p>And then set it up to use maybe o3-mini (high) for architect and Claude Sonnet 3.5 for editor. But unfortunately most of those off-the-shelf systems are not amazing at Lean 4 (they still confuse syntax with Lean 3, hallucinate lemmas, make outright syntax errors, etc...). Claude Sonnet 3.5 has been the best for me so far, but only for very simple things (not whole sorries). I think getting a non-zero baseline might be hard. And while there are some research-quality tools out there, I haven't really tried installing them yet.</p>\n<p>I think creating a benchmark to specifically elicit this kind of non-zero base line performance could be a noble goal in itself, even if the focus isn't pure maths (yet).</p>",
        "id": 497462882,
        "sender_full_name": "Adam Kurkiewicz",
        "timestamp": 1738595829
    },
    {
        "content": "<p>It looks like David enabled Lean Copilot on a separate branch last month in Compfiles, so maybe I will try that too:</p>\n<p><a href=\"https://github.com/dwrensha/compfiles/compare/main...lean-copilot\">https://github.com/dwrensha/compfiles/compare/main...lean-copilot</a></p>\n<p>Although I expect if that could solve any sorries they wouldn't make it to the benchmark, because they would have already been solved</p>",
        "id": 497468997,
        "sender_full_name": "Adam Kurkiewicz",
        "timestamp": 1738597169
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"479731\">@Lenny Taelman</span>  What is the next step to stand up a v0 of a sorry leader board? This is a cool project and I would love to help.</p>\n<p>Is it to create a prototype for the <code>elaborate_sorry &lt;git URL&gt;</code> script:</p>\n<p><span class=\"user-mention silent\" data-user-id=\"110087\">Kim Morrison</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Incentives.20.26.20sorry-filling.20leaderboard/near/494456196\">said</a>:</p>\n<blockquote>\n<ul>\n<li>now the tricky part, a script <code>elaborate_sorry &lt;git URL&gt; &lt;line number&gt;</code><ul>\n<li>I propose that this is implemented as much as possible as new functionality in the REPL / Pantograph / your favourite tool</li>\n<li>clones the repo if not already present</li>\n<li>checks out the commit</li>\n<li>runs <code>lake exe cache get</code> and/or <code>lake build</code> as appropriate</li>\n<li>elaborates the file, identifies which declaration contains the relevant line containing the sorry, and attempts to report the goal state at the sorry</li>\n<li>result: add an entry to <code>elaborated_sorries.json</code> (or possibly this can be combined with `observed_sorries.json?) with a status, either: \"could not find repo\", \"could not find commit\", \"could not find sorry\", \"could not elaborate declaration at line number\", or a successful pretty printed goal state</li>\n</ul>\n</li>\n</ul>\n</blockquote>",
        "id": 501366975,
        "sender_full_name": "Austin Letson",
        "timestamp": 1740310545
    },
    {
        "content": "<p>Exactly, the next step would to produce a database of <em>reproducable</em> sorries, as opposed to just things that syntactically look like sorries. I have some rough code now to do that using REPL, (in <code>src/offline_sorries.py</code> at <a href=\"https://github.com/LennyTaelman/SorryScraper\">this repo</a>) but it needs to be cleaned up, and there are compatibility issues between REPL and some lean repos that I have not yet figured out. Also: I am not yet convinced that REPL is the right tool for this, I would also want to have a look at the alternatives (such as Pantograph).</p>\n<p>In any case, it looks like this is doable in principle, and it should be not too hard to build a continuously updating database of reproducible sorries. </p>\n<p>Once this code is robust enough, I think the next challenge is to build a basic `client' which takes a database entry as input, reproduces it, and tries to prove it. The fist milestone would be to have such a client that gets a non-zero score, then others can try to beat it ;-).</p>\n<p>Any help would be very welcome, I'll send you a DM to chat about this. Others are of course also welcome to join!</p>",
        "id": 501380076,
        "sender_full_name": "Lenny Taelman",
        "timestamp": 1740320872
    },
    {
        "content": "<p>Okay, thanks for the summary of current status. I look forward to the first non-zero score!</p>\n<p>I experimented with Pantograph this morning, taking the <code>new_sorries.json</code> output from SorryScraper, downloading/building the Lean repos and then feeding the sorrys into Pantograph. I quickly ran into issue with Lean versions. Pantograph requires that the Lean version of the project and Pantograph be the same and Pantograph is currently on 4.15.0. This might be a configuration issue on my end so, I created an issue to ask if newer versions are supported.</p>\n<p>repl has version tags which would make this issue easier. Potentially we should include the lean version with each sorry.</p>\n<p>Are the compatibility issues with repl across an entire repo or for specific sorrys?</p>",
        "id": 501415135,
        "sender_full_name": "Austin Letson",
        "timestamp": 1740348910
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"599027\">@Leni Aniva</span> , do you think you can add tags for all compatible toolchains (ideally both stables and release candidates)? And keep doing this going forward? This is going to be critical for adoption.</p>",
        "id": 501438850,
        "sender_full_name": "Kim Morrison",
        "timestamp": 1740368118
    },
    {
        "content": "<p>This is actually something the <span class=\"user-mention\" data-user-id=\"699684\">@Austin Letson</span> may be interested in, given their great work in lean-action: how can we let users sign up (we could maybe even make opt-in the default in default lake templates) for receiving regular reminders (or maybe even automated PRs) about creating tags for new toolchains, as everything Mathlib and upstream does?</p>",
        "id": 501439043,
        "sender_full_name": "Kim Morrison",
        "timestamp": 1740368241
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110087\">Kim Morrison</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Incentives.20.26.20sorry-filling.20leaderboard/near/501438850\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"599027\">Leni Aniva</span> , do you think you can add tags for all compatible toolchains (ideally both stables and release candidates)? And keep doing this going forward? This is going to be critical for adoption.</p>\n</blockquote>\n<p>Tags? Not branches? I can do this going forward. The reason I suggest branches is because it leaves rooms for future bug fixes. In Pantograph's repository I have the branch <code>fixed/v4.16.0-rc2</code> for example, and that branch is pinned to <code>v4.16.0-rc2</code>. My current approach is to keep up with the newest Lean version</p>",
        "id": 501439150,
        "sender_full_name": "Leni Aniva",
        "timestamp": 1740368304
    },
    {
        "content": "<p>There has been another <a href=\"https://github.com/stanford-centaur/PyPantograph/issues/75\">suggestion here</a> to separate the versioning of PyP and P. Exactly why this is done is not very clear to me, but if we go along with this route, we would need to keep manifest files in PyP and each PyP would support multiple P versions. I've been waiting on the solution to this so I haven't made the tag yet.</p>",
        "id": 501439248,
        "sender_full_name": "Leni Aniva",
        "timestamp": 1740368399
    },
    {
        "content": "<p>Pantograph can currently import/export goal states and these can be used to communicate a goal across machines, but the exported goals don't have tagging information about their environment. i.e. the Lean version, mathlib version, etc. If its necessary I can engineer such a feature into Pantograph. IMO the best way to transport a frozen sorry across machines is not via binary files. These files are anchored to the Lean versions that produced them. The best way would be to encode each goal as a theorem in readable text</p>",
        "id": 501440345,
        "sender_full_name": "Leni Aniva",
        "timestamp": 1740369175
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"479731\">@Lenny Taelman</span> I think I was able to fix one of the compatibility issues with repl by allowing the user to specify the required version to pull from the repl repo. In order to support this across the whole pipeline, I think we will need to pull the lean version when we pull a new sorry.</p>\n<p>I created <a href=\"https://github.com/LennyTaelman/SorryScraper/pull/1\">a PR</a> to add support for  specifying a repl version when running <code>offline_sorries.py</code></p>",
        "id": 501532851,
        "sender_full_name": "Austin Letson",
        "timestamp": 1740401029
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110087\">Kim Morrison</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Incentives.20.26.20sorry-filling.20leaderboard/near/501439043\">said</a>:</p>\n<blockquote>\n<p>This is actually something the <span class=\"user-mention silent\" data-user-id=\"699684\">Austin Letson</span> may be interested in, given their great work in lean-action: how can we let users sign up (we could maybe even make opt-in the default in default lake templates) for receiving regular reminders (or maybe even automated PRs) about creating tags for new toolchains, as everything Mathlib and upstream does?</p>\n</blockquote>\n<p>I think this could be handled by <a href=\"https://github.com/oliver-butterley/lean-update\">lean-update</a>. We could add a step after lean-update creates the update commit to also add a tag to that commit?</p>",
        "id": 501542094,
        "sender_full_name": "Austin Letson",
        "timestamp": 1740403354
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"111040\">@Adam Kurkiewicz</span>  mentioned Aider above; I have not played with aider much myself, but was able to set it up to connect to <a href=\"https://github.com/GasStationManager/LeanTool\">LeanTool</a>, which then allows the LLM to talk to Lean directly in a feedback loop to fix its errors. <br>\nE.g. to use the demo proxy server already up at <a href=\"http://www.codeproofarena.com:8800/v1\">http://www.codeproofarena.com:8800/v1</a> , do the following:</p>\n<div class=\"codehilite\" data-code-language=\"Lean4\"><pre><span></span><code><span class=\"kn\">export</span><span class=\"w\"> </span><span class=\"n\">OPENAI_API_BASE</span><span class=\"bp\">=</span><span class=\"n\">http</span><span class=\"o\">:</span><span class=\"bp\">//</span><span class=\"n\">www</span><span class=\"bp\">.</span><span class=\"n\">codeproofarena</span><span class=\"bp\">.</span><span class=\"n\">com</span><span class=\"o\">:</span><span class=\"mi\">8800</span><span class=\"bp\">/</span><span class=\"n\">v1</span>\n<span class=\"kn\">export</span><span class=\"w\"> </span><span class=\"n\">OPENAI_API_KEY</span><span class=\"bp\">=&lt;</span><span class=\"n\">your</span><span class=\"w\"> </span><span class=\"n\">api</span><span class=\"w\"> </span><span class=\"n\">key</span><span class=\"w\"> </span><span class=\"n\">for</span><span class=\"w\"> </span><span class=\"n\">your</span><span class=\"w\"> </span><span class=\"n\">chosen</span><span class=\"w\"> </span><span class=\"n\">model</span><span class=\"bp\">&gt;</span>\n\n<span class=\"bp\">#</span><span class=\"w\"> </span><span class=\"n\">Prefix</span><span class=\"w\"> </span><span class=\"n\">the</span><span class=\"w\"> </span><span class=\"n\">model</span><span class=\"w\"> </span><span class=\"n\">name</span><span class=\"w\"> </span><span class=\"k\">with</span><span class=\"w\"> </span><span class=\"n\">openai</span><span class=\"bp\">/</span>\n<span class=\"n\">aider</span><span class=\"w\"> </span><span class=\"c1\">--model openai/sonnet</span>\n</code></pre></div>\n<p>Anyone with experience using Aider? Have a sorry that you'd like to try? I am interested in hearing your experience on how it works..</p>",
        "id": 501641915,
        "sender_full_name": "GasStationManager",
        "timestamp": 1740428979
    },
    {
        "content": "<p><a href=\"https://meet.jit.si/442340967776119#config.startWithVideoMuted=false\">Rejoindre l'appel vidéo.</a></p>",
        "id": 518213249,
        "sender_full_name": "M D Z 20",
        "timestamp": 1747289260
    },
    {
        "content": "<p>(I'm assuming the above was some kind of misclick but didn't delete it in case it was some prearranged meeting which I missed)</p>",
        "id": 518224400,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1747293767
    }
]