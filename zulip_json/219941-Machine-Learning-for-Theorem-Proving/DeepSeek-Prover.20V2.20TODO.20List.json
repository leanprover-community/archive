[
    {
        "content": "<p>There have been a lot of discussions recently on the DeepSeek-Prover results and no feedback yet from the team.  I was told from <span class=\"user-mention\" data-user-id=\"481527\">@Huajian Xin</span>  they were on holiday until Monday.  When they get back and look at this, here is a summary and recommended TODO list of stuff that needs to be addressed (if the DeepSeek team is reading this):</p>",
        "id": 516083350,
        "sender_full_name": "Jason Rute",
        "timestamp": 1746405866
    },
    {
        "content": "<ul>\n<li>It seems that they only used the Lean REPL to check for correctness (in Lean 4.9.0) (according to <span class=\"user-mention\" data-user-id=\"481527\">@Huajian Xin</span>).  There was a bug discovered with at least three of their proofs (one proof in MiniF2F, and two of the 7B Putnam solutions).  The bug was in the front end of Lean.  Your model learned that if it gave a proof with <code>apply?</code> (which introduces a <code>sorry</code>) along with a type jump in the proof, then Lean 4.9.0 would not report the uses of sorry, not add it to the environment, and not check the proof with the kernel.  (It’s not a bug in the kernel, just in the front end, and it has already been fixed in newer versions of Lean, but we don’t know if anyone previously knew about this bug.  Details can be found in <a class=\"stream-topic\" data-stream-id=\"270676\" href=\"/#narrow/channel/270676-lean4/topic/apply.3F.20might.20suppress.20other.20warnings.2Ferrors/with/515641973\">#lean4 &gt; apply? might suppress other warnings/errors</a> and in <a class=\"stream-topic\" data-stream-id=\"219941\" href=\"/#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/DeepSeek-Prover.20V2/with/515338707\">#Machine Learning for Theorem Proving &gt; DeepSeek-Prover V2</a>.)  Any “proof” the model finds with <code>apply?</code> is likely wrong (although it is in principle possible to solve a goal with <code>apply?</code> when it works like <code>exact?</code>).</li>\n</ul>",
        "id": 516083357,
        "sender_full_name": "Jason Rute",
        "timestamp": 1746405878
    },
    {
        "content": "<ul>\n<li>It was interesting that their model found it, but at the same time, it could have been caught with the following workflow:<ul>\n<li><code>lake build</code> all the proofs (would not have caught it, but it is still important to do)</li>\n<li>Use <code>#print axioms</code> to check that the only axioms in each proof were <code>propext</code>, <code>Classical.choice</code>, and <code>Quot.sound</code>.  This would have caught it, not because it would have printed a <code>SorryAx</code> axiom (as intended), but because the bug prevented the theorem from getting added to the environment (and therefore it was never checked by Lean’s kernel).  <code>#print axioms</code> just complains about the theorem not existing.</li>\n<li>Extract the proofs and use <a href=\"https://github.com/leanprover/lean4checker\"><code>lean4checker</code></a> to test them.  In general, this is the gold standard, but in your case, this would not have caught the error alone (since the incorrect theorem was never exported).  It might catch other errors, however.</li>\n<li>Use <span class=\"user-mention\" data-user-id=\"110596\">@Rob Lewis</span>'s autograder to check the proof against the reference.  It was not designed for this in Lean 4.9.0, and there needs to be a better solution going forward (so for DeepSeek v3, they should please upgrade Lean), but here is an example of <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/DeepSeek-Prover.20V2/near/515743601\">how it would work for their project</a>.  <span class=\"user-mention\" data-user-id=\"110087\">@Kim Morrison</span>  already checked their known bad MiniF2F proof with the autograder, but didn't have time to check all their proofs.</li>\n</ul>\n</li>\n</ul>",
        "id": 516083370,
        "sender_full_name": "Jason Rute",
        "timestamp": 1746405899
    },
    {
        "content": "<ul>\n<li>They should double-check all their proofs in any claimed benchmarks (using the above methods).  They should report any changes to the benchmark score.  (I think the miniF2F score will only change by one solution, so less than a percentage point, but they should please check everything, and not just the bad proof.  We don’t know about PutnamBench and ProverBench, since those solutions were not released yet, but it is also especially suspicious that they mention this <code>apply?</code> and <code>Cardinal.toNat</code> trick, which is a way to bump the type level in the proof to induce the bug, is common in the 7B model.)</li>\n</ul>",
        "id": 516083390,
        "sender_full_name": "Jason Rute",
        "timestamp": 1746405907
    },
    {
        "content": "<ul>\n<li>For PutnamBench, they should please have <span class=\"user-mention\" data-user-id=\"644040\">@George Tsoukalas</span> officially verify their solutions (then they can go on the <a href=\"https://trishullab.github.io/PutnamBench/leaderboard.html\">PutnamBench leaderboard</a>).  Also, <span class=\"user-mention\" data-user-id=\"644040\">@George Tsoukalas</span>, please confirm that you check <code>#print axioms</code> as that would catch the current bug in some of the published PutnamBench solutions.  Ideally you should also use <code>lean4checker</code> in addition to <code>#print axioms</code>.</li>\n</ul>",
        "id": 516083398,
        "sender_full_name": "Jason Rute",
        "timestamp": 1746405914
    },
    {
        "content": "<ul>\n<li>As for <code>ProverBench</code>, there are a number of errors in the benchmark problems (see <a class=\"stream-topic\" data-stream-id=\"219941\" href=\"/#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/ProverBench/with/515405915\">#Machine Learning for Theorem Proving &gt; ProverBench</a>), making the problems either false or vacuously true.  They should please fix all the errors and go through their benchmark rigorously before others use it.  (This happens every time there is a new benchmark, including MiniF2F, ProofNet, CombiBench, and ProverBench, but at the same time, I hope this field can rise up to having high-quality standards.  Without these standards, the benchmarks diverge, where some versions have fixed problems and some do not.  MiniF2F is one of the worst offenders, unfortunately.)</li>\n</ul>",
        "id": 516083414,
        "sender_full_name": "Jason Rute",
        "timestamp": 1746405926
    },
    {
        "content": "<ul>\n<li>Here are ways they can fix ProverBench:<ul>\n<li>Go through all the problems and identify errors.  Is it true in English?  Is it true as translated?  (Don’t just fix the few problems we tell you have errors.)</li>\n<li>Look for missing conditions?</li>\n<li>Look for issues with edge cases?</li>\n<li>Look for common issues with subtraction of natural numbers, division by 0, and issues with the base case <code>n = 0</code>.</li>\n<li>Be careful of implicit conditions in problems like distinctness conditions (e.g. in “Let x and y be two numbers”, does the English assume they are distinct?)</li>\n<li>Follow the approach from the DeepSeek v1 paper to use their powerful AI to find:<ul>\n<li>False problems</li>\n<li>Vacuously true problems (where the hypotheses imply False).</li>\n</ul>\n</li>\n<li>Consider manually writing private proofs of the trickier problems to make sure they are formalized correctly.</li>\n</ul>\n</li>\n</ul>",
        "id": 516083417,
        "sender_full_name": "Jason Rute",
        "timestamp": 1746405934
    },
    {
        "content": "<ul>\n<li>MiniF2F: There are far too many versions of MiniF2F, all with different variations of corrected problems.  There is no right solution here, but they should note that one proof in their paper is of a misformalized MiniF2F theorem (and that has caused them <a href=\"https://x.com/littmath/status/1917959880876400919\">some embarrassment on X/twitter</a>).  One option is to continue to use Numina’s version of MiniF2F.  It is no more official than any other version, but it is where the state-of-the-art results currently are.  But note that Numina's version has many false and vacuously true problems (cc <span class=\"user-mention\" data-user-id=\"509372\">@Jia Li</span>).  Another option is to use <a href=\"https://github.com/harmonic-ai/datasets\">Harmonic’s version</a>.  (I don't know what Lean version they use, cc <span class=\"user-mention\" data-user-id=\"349892\">@Aidan Swope</span>, <span class=\"user-mention\" data-user-id=\"448405\">@Alex Meiburg</span>.)  Harmonic’s version is not that official (no one but them uses it), but it is the most cleaned up (I think they privately formalized a proof for every problem), and maybe it should become the official version (or used by someone to make an official version).  The only problem is that the valid-test splits are changed, so you would have to change them back to what literally everyone else uses for validation and test.  (MiniF2F is a huge mess.  It is bad that this field never cleaned it up months ago when there started to be multiple Lean 4 versions with different sets of corrected problems.  Further, it is possible that by running MiniF2F on a corrected dataset, one could increase their score just because their are fewer false problems.  Yes, some problems are vacuously true and DeepSeek-Prover can find some proofs of those, but I imagine more are false than vacuously true.)  Whatever they do, please don’t make yet another version of MiniF2F (at least not without building consensus)!</li>\n</ul>",
        "id": 516083486,
        "sender_full_name": "Jason Rute",
        "timestamp": 1746405976
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"115715\">Jason Rute</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/DeepSeek-Prover.20V2.20TODO.20List/near/516083398\">said</a>:</p>\n<blockquote>\n<ul>\n<li>For PutnamBench, they should please have <span class=\"user-mention silent\" data-user-id=\"644040\">George Tsoukalas</span> officially verify their solutions (then they can go on the <a href=\"https://trishullab.github.io/PutnamBench/leaderboard.html\">PutnamBench leaderboard</a>).  Also, <span class=\"user-mention silent\" data-user-id=\"644040\">George Tsoukalas</span>, please confirm that you check <code>#print axioms</code> as that would catch the current bug in some of the published PutnamBench solutions.  Ideally you should also use <code>lean4checker</code> in addition to <code>#print axioms</code>.</li>\n</ul>\n</blockquote>\n<p>To confirm, they have sent me the proofs. Since it is a fairly large number it will take some time to verify each one.</p>",
        "id": 516105007,
        "sender_full_name": "George Tsoukalas",
        "timestamp": 1746419276
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"115715\">Jason Rute</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/DeepSeek-Prover.20V2.20TODO.20List/near/516083486\">said</a>:</p>\n<blockquote>\n<p>The only problem is that the valid-test splits are changed, so you would have to change them back to what literally everyone else uses for validation and test.</p>\n</blockquote>\n<p>I just <a href=\"https://github.com/justincasher/miniF2F\">created a version</a> of the miniF2F using <a href=\"https://github.com/harmonic-ai/datasets/tree/main/minif2f\">Harmonic's dataset</a> and the original validation/test splits. Please let me know if you notice any mistakes! I can add the informal proofs and headers from <span class=\"user-mention\" data-user-id=\"584504\">@Kaiyu Yang</span>'s <a href=\"https://github.com/yangky11/miniF2F-lean4\">dataset</a>, if people would find this helpful.</p>",
        "id": 516110782,
        "sender_full_name": "Justin Asher",
        "timestamp": 1746423152
    },
    {
        "content": "<p>Harmonic minif2f is for <code>leanprover/lean4:v4.5.0-rc1</code>@ mathlib commit <code>8f013c457aea2ea1b0156c0c98043c9ed018529f</code></p>",
        "id": 516144663,
        "sender_full_name": "Eric Rodriguez",
        "timestamp": 1746436101
    },
    {
        "content": "<p>A couple comments:</p>\n<ul>\n<li>it was interesting to see that the model found and exploited this bug, but come to think of it this will be standard behavior of all models trained with RL: if the model finds an exploit through exploration, it will use it, because as far as it is concerned it is outputting correct proofs. </li>\n<li>this exploit would have been caught by a (careful) application of #print axioms, but the next one might not be</li>\n<li>With that in mind, my recommendation to all labs training prover models using RL, is to incorporate the safest possible proof checking in their <em>training</em> pipeline. There would be performance tradeoffs, but would be better than trying to fix it after significant amount of training compute has been spent.</li>\n</ul>",
        "id": 516206489,
        "sender_full_name": "GasStationManager",
        "timestamp": 1746453782
    }
]