[
    {
        "content": "<p>Josef Urban, who has been working on machine learning for theorem proving for decades, just posted an <a href=\"https://arxiv.org/abs/2601.03298\">arXiv preprint</a> about autoformalizing much of Munkres's topology textbook. Although he did not use Lean, I think his work is still on-topic here, and I'm curious about what others think of this project. Is there anything the Lean community can learn from Urban's experience? What did he do right and what (if anything) did he do wrong?</p>",
        "id": 566949749,
        "sender_full_name": "Timothy Chow",
        "timestamp": 1767881151
    },
    {
        "content": "<p>Really impressive <span class=\"user-mention\" data-user-id=\"223577\">@Josef Urban</span></p>\n<p><span class=\"user-mention\" data-user-id=\"478409\">@Timothy Chow</span> Codex and Claude Code seems to work surprisingly well out of the box on Megalodon. OpenAI and Anthropic probably don't have a RL pipeline for Megalodon, and still here we have a 130k lines formalization produced with these models. As said by <span class=\"user-mention\" data-user-id=\"223577\">@Josef Urban</span> in the introduction:</p>\n<blockquote>\n<p>Based on the fast progress, low cost, virtually unknown ITP/library, and the<br>\nsimple setup available to everyone, we believe that (auto)formalization may become quite easy and<br>\nubiquitous in 2026, regardless of which proof assistant is used.</p>\n</blockquote>\n<p>I am speculating here and sharing some early thoughts:<br>\nHere we see that LLMs can now be used to autoformalize large chunks of theorems. So, we are probably not very far from a time when a freshly designed proof assistant can be bootstrapped with a Mathlib-scale library using LLMs. The quality will probably not be great in the beginning, but still I think it is worth thinking about the consequences of that. Maybe new kinds of proof assistants designed for the LLM era will appear...</p>",
        "id": 566977555,
        "sender_full_name": "Auguste Poiroux",
        "timestamp": 1767888026
    },
    {
        "content": "<blockquote>\n<p>Maybe new kinds of proof assistants designed for the LLM era will appear...</p>\n</blockquote>\n<p>I think this is missing a point that is: a well-designed library is useful for many things other than checking that some statements are correct. Autoformalizing an introductory book is quite far from engineering a library like Mathlib in this aspect.</p>",
        "id": 566994051,
        "sender_full_name": "Lua Viana Reis",
        "timestamp": 1767892491
    },
    {
        "content": "<p>Yes, I do agree, because otherwise, already in February, we could get a 2 million lines \"library\" by having 10 people working for a month like Josef Urban.<br>\nI am just speculating about a future possibility, and that's also why I am mentioning new kinds of proof assistants. Maybe if designed in certain ways, it could help LLMs building nice libraries.</p>",
        "id": 566997171,
        "sender_full_name": "Auguste Poiroux",
        "timestamp": 1767893462
    },
    {
        "content": "<p>Random data:</p>\n<div class=\"codehilite\" data-code-language=\"Lean4\"><pre><span></span><code><span class=\"kn\">import</span><span class=\"w\"> </span><span class=\"n\">Mathlib</span><span class=\"bp\">.</span><span class=\"n\">Topology</span><span class=\"bp\">.</span><span class=\"n\">UrysohnsLemma</span>\n<span class=\"kn\">import</span><span class=\"w\"> </span><span class=\"n\">Mathlib</span><span class=\"bp\">.</span><span class=\"n\">Topology</span><span class=\"bp\">.</span><span class=\"n\">Metrizable</span><span class=\"bp\">.</span><span class=\"n\">Urysohn</span>\n<span class=\"kn\">import</span><span class=\"w\"> </span><span class=\"n\">Mathlib</span><span class=\"bp\">.</span><span class=\"n\">Topology</span><span class=\"bp\">.</span><span class=\"n\">TietzeExtension</span>\n<span class=\"bp\">#</span><span class=\"n\">trans_imports</span><span class=\"w\"> </span><span class=\"s2\">\"Mathlib.\"</span><span class=\"w\"> </span><span class=\"c1\">-- 1541</span>\n</code></pre></div>",
        "id": 567001491,
        "sender_full_name": "Junyan Xu",
        "timestamp": 1767895002
    },
    {
        "content": "<p>(Impressive as it is) the output of the autoformalized textbook is not likely to be useful to the intended audience of the textbook is it? The textbook is a pedagogical tool for learning topology, but the outputted proofs sound like they're long and possibly roundabout (judging by the paper calling out their lengths). To be useful to students the autoformalization has to be as easy to follow for the student as the prose is, and to be useful to a mathematician the autoformalization has to be able to deal with texts which are less precise about making sure they're digestible to their reader than a carefully authorized textbook, right? So the oversimplified takeaway is that this is a step somewhat in between those two goals?</p>",
        "id": 567015834,
        "sender_full_name": "Julian Berman",
        "timestamp": 1767900175
    },
    {
        "content": "<p>I donâ€™t think the goal of this project is pedogogy.</p>",
        "id": 567025034,
        "sender_full_name": "Jason Rute",
        "timestamp": 1767903378
    },
    {
        "content": "<p>I would like to see if this kind of approach can work in an LLM that can be run locally (like llama or mistral).</p>",
        "id": 567036323,
        "sender_full_name": "Miguel Marco",
        "timestamp": 1767907709
    },
    {
        "content": "<p>This is my first time posting here. Please forgive me if my comment is off-base as I am not familiar with how things work here.</p>\n<p>I read Professor Urban's paper and was also very impressed. I had a feeling that the automated formalization of mathematics textbooks was likely possible, but I am very excited to see a concrete example of it.</p>\n<p>Now, like Professor Urban, I am also experimenting with automated proving using coding agents (mainly Cursor and Codex CLI) by providing natural language proofs as context (although I use Lean). These general-purpose coding agents solve Putnam and IMO problems truly magnificently, just like other specialized AI agents. (Of course, I am not solving hundreds of problems exhaustively, so there is a possibility that I am seeing biased results...)</p>\n<p>And while they sometimes solve these competitive math problems almost on their own all the way to the end without user intervention, it is only since GPT-5.2 that they have become this dramatically better. Both GPT-5 and 5.1 had terrible so-called \"laziness\" and frequently required user intervention (although I could still manage to solve them), but I am experiencing that this has been dramatically improved now.</p>\n<p>By the way, I would like to ask a small question: Has anyone already carried out a Lean proof for <a href=\"https://github.com/harmonic-ai/IMO2025/blob/main/HarmonicLean/StatementOnly_IMO2025P6.lean\">IMO 2025 P6</a> ? I think I was probably able to solve it with my setup (although it required quite a bit of user intervention and the help of ChatGPT 5.2 Pro).</p>",
        "id": 568135309,
        "sender_full_name": "km",
        "timestamp": 1768460137
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"1007271\">km</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Autoformalization.20using.20Megalodon/near/568135309\">said</a>:</p>\n<blockquote>\n<p>This is my first time posting here. Please forgive me if my comment is off-base as I am not familiar with how things work here.</p>\n<p>I read Professor Urban's paper and was also very impressed. I had a feeling that the automated formalization of mathematics textbooks was likely possible, but I am very excited to see a concrete example of it.</p>\n<p>Now, like Professor Urban, I am also experimenting with automated proving using coding agents (mainly Cursor and Codex CLI) by providing natural language proofs as context (although I use Lean). These general-purpose coding agents solve Putnam and IMO problems truly magnificently, just like other specialized AI agents. (Of course, I am not solving hundreds of problems exhaustively, so there is a possibility that I am seeing biased results...)</p>\n<p>And while they sometimes solve these competitive math problems almost on their own all the way to the end without user intervention, it is only since GPT-5.2 that they have become this dramatically better. Both GPT-5 and 5.1 had terrible so-called \"laziness\" and frequently required user intervention (although I could still manage to solve them), but I am experiencing that this has been dramatically improved now.</p>\n<p>By the way, I would like to ask a small question: Has anyone already carried out a Lean proof for <a href=\"https://github.com/harmonic-ai/IMO2025/blob/main/HarmonicLean/StatementOnly_IMO2025P6.lean\">IMO 2025 P6</a> ? I think I was probably able to solve it with my setup (although it required quite a bit of user intervention and the help of ChatGPT 5.2 Pro).</p>\n</blockquote>\n<p>There are likely lots of proofs of seemingly open problems, which with very high certainty  includes a 6 month old IMO problem. Also a new topic would be more appropriate as it is not directly related to Josef Urbans Paper.</p>",
        "id": 568157085,
        "sender_full_name": "Franz Huschenbeth",
        "timestamp": 1768468737
    }
]