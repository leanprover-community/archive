[
    {
        "content": "<p>Just wanted to gather impressions at its Lean ability</p>",
        "id": 534348672,
        "sender_full_name": "Alok Singh",
        "timestamp": 1755152440
    },
    {
        "content": "<p>It wrote this full proof for me: <a href=\"https://github.com/dwrensha/compfiles/commit/b4a6b036c6160ea1316c415e150482f7bc3fa272\">https://github.com/dwrensha/compfiles/commit/b4a6b036c6160ea1316c415e150482f7bc3fa272</a><br>\n(I needed to correct some errors, but none were terribly difficult.)</p>",
        "id": 534462257,
        "sender_full_name": "David Renshaw",
        "timestamp": 1755171815
    },
    {
        "content": "<p>every time we get our hands on a new model we are always very excited. and we test it on our current problem and even when the solution provided by the model is bad we help it, we help fix the errors so we feel the model is up to some good.</p>\n<p>this is coming from your resident pessimist</p>",
        "id": 534467302,
        "sender_full_name": "(deleted)",
        "timestamp": 1755172581
    },
    {
        "content": "<p>We ran an experiment at the last community meeting <a href=\"https://www.youtube.com/watch?v=dUWiG12ZQ4g\">https://www.youtube.com/watch?v=dUWiG12ZQ4g</a> </p>\n<div class=\"youtube-video message_inline_image\"><a data-id=\"dUWiG12ZQ4g\" href=\"https://www.youtube.com/watch?v=dUWiG12ZQ4g\"><img src=\"https://uploads.zulipusercontent.net/43fd89d2e94fdb7dbd54d126ccc557fa99ffc861/68747470733a2f2f692e7974696d672e636f6d2f76692f645557694731325a5134672f6d7164656661756c742e6a7067\"></a></div><div class=\"spoiler-block\"><div class=\"spoiler-header\">\n</div><div class=\"spoiler-content\" aria-hidden=\"true\">\n<p>Not well but that was the expected outcome. </p>\n</div></div>\n<p>The improvement (for pro) at natural language research level math is noticable.</p>",
        "id": 534525725,
        "sender_full_name": "Matthew Ballard",
        "timestamp": 1755191266
    },
    {
        "content": "<p>Can I tag onto this thread and ask if people here have tested gemini deep think on research level math? Was thinking of getting a subscription but curious to hear what people's thoughts are before</p>",
        "id": 534588944,
        "sender_full_name": "Andy Jiang",
        "timestamp": 1755226498
    },
    {
        "content": "<p>The main limitation is you only get 5 queries a day.</p>",
        "id": 534589079,
        "sender_full_name": "(deleted)",
        "timestamp": 1755226651
    },
    {
        "content": "<p>but what is the level like? is it definitely above gpt5-pro for example? what sort of problems can it solve? I think it can be useful if the level is high enough</p>",
        "id": 534589700,
        "sender_full_name": "Andy Jiang",
        "timestamp": 1755227112
    },
    {
        "content": "<p>Hey everyone, I'm interested in an answer to the above question.</p>",
        "id": 534989858,
        "sender_full_name": "(deleted)",
        "timestamp": 1755536452
    },
    {
        "content": "<p>I'm on the fence. And I'm not sure whether I should get a subscription or not.</p>",
        "id": 534989931,
        "sender_full_name": "(deleted)",
        "timestamp": 1755536490
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"662620\">@Andy Jiang</span> I just spent the money. Here's what I got from Gemini:</p>\n<blockquote>\n<p>I ran into an issue and wasn't able to finish thinking through this request. Please try again, and don't worry, it didn't count against your Deep Think limit.</p>\n</blockquote>\n<p>Hmm... Not a good impression. Let me try again. I don't want to be pessimistic, I spent a good amount of money expecting it to be able to solve IMO problems...</p>",
        "id": 536648086,
        "sender_full_name": "(deleted)",
        "timestamp": 1756399789
    },
    {
        "content": "<p>I have a lot to gain if I get my hands on an AI that can solve such problems. So let me try again. If there's good news I'll tell you. This Deep Think thing could turn out to be a money printer honestly.</p>",
        "id": 536648397,
        "sender_full_name": "(deleted)",
        "timestamp": 1756399913
    },
    {
        "content": "<p>Second try: the thinking process stopped midway. Let me try the third time. And when I wake up, I'll tell you whether Gemini successfully solves the problem or not.</p>",
        "id": 536651339,
        "sender_full_name": "(deleted)",
        "timestamp": 1756401041
    },
    {
        "content": "<p>Third try: The result is quite good. The AI still makes logical errors as it does not completely adhere to the specification, but in general the deduction steps make sense and are not hand wavy.</p>",
        "id": 536654017,
        "sender_full_name": "(deleted)",
        "timestamp": 1756402107
    },
    {
        "content": "<p>While not magic, Gemini Deep Think will be an indispensable part of my day to day work.</p>",
        "id": 536655489,
        "sender_full_name": "(deleted)",
        "timestamp": 1756402605
    },
    {
        "content": "<p>My review: Gemini Deep Think demonstrates a high ability to follow the specification, to critique its own mistakes and to write a machine-checkable proof. With appropriate prompt engineering, it is possible to make Gemini Deep Think generate Lean 4 code with appropriate preprocessing and postprocessing steps.</p>",
        "id": 536656624,
        "sender_full_name": "(deleted)",
        "timestamp": 1756403080
    },
    {
        "content": "<p>I will figure out how to best use the tool. It has very high potential, despite the initial bugs.</p>",
        "id": 536656926,
        "sender_full_name": "(deleted)",
        "timestamp": 1756403203
    },
    {
        "content": "<p>I Use GPT-5 with my Github Copilot subscription. So i have more than 5 requests per day allowed <span aria-label=\"grinning face with smiling eyes\" class=\"emoji emoji-1f601\" role=\"img\" title=\"grinning face with smiling eyes\">:grinning_face_with_smiling_eyes:</span></p>\n<p>I'd say it's the best model at the moment for Lean with the new Deepseek as a contender. The plus with GPT-5 is that i have it integrated with VsCode, while i use the DeepSeek from their website. Deepseek 3.1 is really impressive. But it thinks really hard all the time (like Grok), so i don't use it that much.</p>\n<p>I use it mainly for proofs on Computer Science side. So my feedback may not scale under other math fields.</p>",
        "id": 536660056,
        "sender_full_name": "Alfredo Moreira-Rosa",
        "timestamp": 1756404447
    },
    {
        "content": "<p>Thank you, <span class=\"user-mention\" data-user-id=\"942100\">@ecyrbe</span>, for the feedback. Could you record a video of you using Copilot with GPT-5 to prove theorems? I watched Terence Tao's video but he had to fight Copilot a lot.</p>",
        "id": 536708993,
        "sender_full_name": "(deleted)",
        "timestamp": 1756435109
    },
    {
        "content": "<p>It's normal, terrence was using Copilot mostly in completion mode. completion mode don't use thinking models, it uses a fast but dumb model (GTP-4o at the moment) .<br>\nI use prompt/chat/agent mode in Copilot that allows to select the model between a refined list.<br>\nHere the list we get when using Copilot (for me it's the best of all worlds, because you get access to different LLM providers with just one subscription) :<br>\n<a href=\"/user_uploads/3121/O5DHm11s6lTWrf9qtHl0mUbN/image.png\">image.png</a></p>\n<div class=\"message_inline_image\"><a href=\"/user_uploads/3121/O5DHm11s6lTWrf9qtHl0mUbN/image.png\" title=\"image.png\"><img data-original-content-type=\"image/png\" data-original-dimensions=\"550x440\" src=\"/user_uploads/thumbnail/3121/O5DHm11s6lTWrf9qtHl0mUbN/image.png/840x560.webp\"></a></div>",
        "id": 536727805,
        "sender_full_name": "Alfredo Moreira-Rosa",
        "timestamp": 1756450227
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"942100\">@ecyrbe</span> Btw do you think there is scope to have a good niche editors completely focussed on writing math and doing research per se? Something that could run lean based verifications natively, have concepts across papers (external and also your own notes) indexed uniquely etc.?</p>",
        "id": 536921580,
        "sender_full_name": "Arjo",
        "timestamp": 1756567699
    },
    {
        "content": "<p>I think building plugins for existing editors is a better approach. Building niche editors is maintainance costly and without a big community budget i dont think it's worth the effort.</p>",
        "id": 536922086,
        "sender_full_name": "Alfredo Moreira-Rosa",
        "timestamp": 1756568223
    },
    {
        "content": "<p>Any specific kind of plugins that you would find very useful (doesn't have to simple could be unreasonably hard to implement as well)?</p>",
        "id": 536922301,
        "sender_full_name": "Arjo",
        "timestamp": 1756568417
    },
    {
        "content": "<p><a class=\"stream-topic\" data-stream-id=\"270676\" href=\"/#narrow/channel/270676-lean4/topic/Vibe.20Proofing/with/537584791\">#lean4 &gt; Vibe Proofing</a> </p>\n<p>Cross posting my experience.</p>",
        "id": 537585397,
        "sender_full_name": "West",
        "timestamp": 1756957982
    },
    {
        "content": "<p>For those interested, from conversation i have had in my faculty (Monash University, Australia) , professors are finding GPT 5 a lot more useful.</p>\n<p>They do not know Lean and such, their use cases involve asking for proofs where the reference is tedious or obscure.  They say prior versions were worse at similar tasks -- having more hallucinations.</p>\n<p>Knowing Lean however, i can imagine a world where you can formulate and ask for a proof , in a highly specific context for a sub-lemma, which may be tedious and straightforward in approach but lacks a  direct current reference/ lean code( not with something as general purpose / natural language as GPT5 though).</p>",
        "id": 537587478,
        "sender_full_name": "Yan Yablonovskiy üá∫üá¶",
        "timestamp": 1756959714
    },
    {
        "content": "<p>Is GPT5 acting as a search engine in finding those proofs, or is it coming up with those proofs with novel derivations?</p>",
        "id": 537714509,
        "sender_full_name": "Arnav Rawat",
        "timestamp": 1757004522
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"955901\">Arnav Rawat</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/How.20have.20you.20guys.20found.20GPT.205.3F/near/537714509\">said</a>:</p>\n<blockquote>\n<p>Is GPT5 acting as a search engine in finding those proofs, or is it coming up with those proofs with novel derivations?</p>\n</blockquote>\n<p>I know this thread is old, but here's how I used it. I had instructions on how to use the various dev tools, so it would those tools to find relevant theorems, then generate a proof and use the tools to test whether it was valid. It would do this in a loop until it finished the proof.</p>",
        "id": 553308018,
        "sender_full_name": "West",
        "timestamp": 1762150254
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"955304\">West</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/How.20have.20you.20guys.20found.20GPT.205.3F/near/553308018\">said</a>:</p>\n<blockquote>\n<p>I know this thread is old, but here's how I used it. I had instructions on how to use the various dev tools, so it would those tools to find relevant theorems, then generate a proof and use the tools to test whether it was valid. It would do this in a loop until it finished the proof.</p>\n</blockquote>\n<p>Did you formalize this process in terms of say LangGraph code or was it more loosely formalized, e.g. a set of local scripts?</p>\n<p>This general idea is something I was thinking about creating a LangGraph application to do, e.g. using say kimina-lean-server,  lean-explore, ...</p>",
        "id": 553312752,
        "sender_full_name": "Kelly Davis",
        "timestamp": 1762153604
    },
    {
        "content": "<p>Last week I wanted to advertise the impressiveness of consumer-accessible large reasoning models to somebody so I cooked up an example.</p>\n<p>I took a lemma from a paper I wrote years ago which I had proved with a somewhat laborious calculation and which I thought probably had a slick proof, but which I failed to find. Here is the lemma:<br>\n<a href=\"/user_uploads/3121/dcO9CcK8B-z8SKPCoa65ywvH/image.png\">image.png</a><br>\n(in this <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>K</mi><mo stretchy=\"false\">(</mo><mi>F</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">K(F)</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">K</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">F</span><span class=\"mclose\">)</span></span></span></span> is complex topological K-theory, and coefficients are complex numbers)</p>\n<div class=\"message_inline_image\"><a href=\"/user_uploads/3121/dcO9CcK8B-z8SKPCoa65ywvH/image.png\" title=\"image.png\"><img data-original-content-type=\"image/png\" data-original-dimensions=\"1308x278\" src=\"/user_uploads/thumbnail/3121/dcO9CcK8B-z8SKPCoa65ywvH/image.png/840x560.webp\"></a></div><p>I aksed GPT 5 Pro to prove this last Thursday evening. It thought for ~16 minutes and produced a correct short proof: about half a page compared to my 4--5 page laborious calculation.</p>\n<p>I think it would be fair to classify this as early grad school -level mathematics. The fact that a lemma, which I worked hard to prove over several days, 12 years ago, can now be proved <em>with a better proof</em> by a computer in 16 minutes made a fairly big impression on me.</p>",
        "id": 554048405,
        "sender_full_name": "Oliver Nash",
        "timestamp": 1762423694
    },
    {
        "content": "<p>Informal proof?</p>",
        "id": 554048787,
        "sender_full_name": "Jason Rute",
        "timestamp": 1762423805
    },
    {
        "content": "<p>Sorry yes: informal proof.</p>",
        "id": 554048853,
        "sender_full_name": "Oliver Nash",
        "timestamp": 1762423822
    },
    {
        "content": "<p>Since many people had good things to say , I would like to highlight a failure.</p>\n<p><a class=\"stream-topic\" data-stream-id=\"217875\" href=\"/#narrow/channel/217875-Is-there-code-for-X.3F/topic/Derivative.20of.20Holomorphic.20Functions/with/545104155\">#Is there code for X? &gt; Derivative of Holomorphic Functions</a> </p>\n<p>I used Codex with GPT-5 on this many times, and it always gave me:</p>\n<blockquote>\n<p>A couple blockers to fix it cleanly:</p>\n<ul>\n<li>The types differ: LHS is ‚ÑÇ, RHS is ‚Ñù. We should coerce the RHS:¬†(iteratedDeriv n g t : ‚ÑÇ).</li>\n<li>As stated, the lemma is generally false unless you assume enough regularity on¬†g¬†and that it indeed is the restriction of the holomorphic¬†cg. At minimum you‚Äôll need differentiability assumptions on¬†g¬†up to order¬†n¬†at¬†t¬†(or a global¬†ContDiff ‚Ñù ‚ä§ g). Then you can prove by induction using¬†iteratedDeriv_succ¬†and¬†HasDerivAt.comp_ofReal, together with the pointwise equality¬†ht¬†to switch to¬†(fun x : ‚Ñù ‚Ü¶ cg (x:‚ÑÇ))¬†and then to¬†g.</li>\n</ul>\n</blockquote>\n<p>Whereas you can see that aristotle solved it as is, as is shown in that thread. I wouldn't trust GPT-5 too much.</p>\n<div class=\"spoiler-block\"><div class=\"spoiler-header\">\n<p>full_output</p>\n</div><div class=\"spoiler-content\" aria-hidden=\"true\">\n<p>Let me search the codebase for the lemma or any references to \"cgiteratedDeriv_eq_giteratedDeriv\" and related iterated derivative lemmas to identify where to fix it.</p>\n<p>[11 tools called]</p>\n<p>I found your stub in <code>GibbsMeasure/Mathlib/Probability/Kernel/test.lean</code>:</p>\n<div class=\"codehilite\" data-code-language=\"1\"><pre><span></span><code>lemma cgiteratedDeriv_eq_giteratedDeriv (t : ‚Ñù) (n : ‚Ñï) (hcg: Differentiable ‚ÑÇ cg)\n  (ht : ‚àÄ x : ‚Ñù, cg (x : ‚ÑÇ) = g x) : iteratedDeriv n cg (t : ‚ÑÇ) = iteratedDeriv n g t := by\n</code></pre></div>\n<p>A couple blockers to fix it cleanly:<br>\n- The types differ: LHS is ‚ÑÇ, RHS is ‚Ñù. We should coerce the RHS: <code>(iteratedDeriv n g t : ‚ÑÇ)</code>.<br>\n- As stated, the lemma is generally false unless you assume enough regularity on <code>g</code> and that it indeed is the restriction of the holomorphic <code>cg</code>. At minimum you‚Äôll need differentiability assumptions on <code>g</code> up to order <code>n</code> at <code>t</code> (or a global <code>ContDiff ‚Ñù ‚ä§ g</code>). Then you can prove by induction using <code>iteratedDeriv_succ</code> and <code>HasDerivAt.comp_ofReal</code>, together with the pointwise equality <code>ht</code> to switch to <code>(fun x : ‚Ñù ‚Ü¶ cg (x:‚ÑÇ))</code> and then to <code>g</code>.</p>\n<p>Confirm:<br>\n- Should I change the RHS to <code>(iteratedDeriv n g t : ‚ÑÇ)</code>?<br>\n- What regularity hypotheses on <code>g</code> (e.g. <code>ContDiffAt ‚Ñù ‚ä§ g t</code>, or for all orders up to <code>n</code>) do you want?<br>\n- Is it acceptable to require <code>AnalyticAt ‚ÑÇ cg (t : ‚ÑÇ)</code> (which is implied if <code>cg</code> is holomorphic on a neighborhood), to avoid hand-carrying differentiability of all iterates?</p>\n<p>Once you confirm the intended assumptions, I‚Äôll implement the lemma (by induction on <code>n</code>) in <code>test.lean</code>.</p>\n</div></div>",
        "id": 554227562,
        "sender_full_name": "Yan Yablonovskiy üá∫üá¶",
        "timestamp": 1762483078
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"773147\">@Yan Yablonovskiy üá∫üá¶</span>  Are you using GPT-5 and not Codex the model? Both can be called via the Codex API, but the latter might work better than the former for functional programming tasks. Would be happy to hear more about your experiences.</p>\n<p><a href=\"https://openai.com/index/introducing-upgrades-to-codex/\">https://openai.com/index/introducing-upgrades-to-codex/</a></p>",
        "id": 554241907,
        "sender_full_name": "Justin Asher",
        "timestamp": 1762493873
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"240862\">Oliver Nash</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/How.20have.20you.20guys.20found.20GPT.205.3F/near/554048405\">said</a>:</p>\n<blockquote>\n<p>I took a lemma from a paper I wrote years ago which I had proved with a somewhat laborious calculation and which I thought probably had a slick proof, but which I failed to find. Here is the lemma:<br>\n...<br>\nI aksed GPT 5 Pro to prove this last Thursday evening. It thought for ~16 minutes and produced a correct short proof: about half a page compared to my 4--5 page laborious calculation.</p>\n<p>I think it would be fair to classify this as early grad school -level mathematics. The fact that a lemma, which I worked hard to prove over several days, 12 years ago, can now be proved <em>with a better proof</em> by a computer in 16 minutes made a fairly big impression on me.</p>\n</blockquote>\n<p>That GPT has probably ingested your paper as well as any improvements or stronger results in the literature should not go unsaid. Proving a theorem for the first time is of course the messiest and hardest.</p>",
        "id": 554244486,
        "sender_full_name": "David Michael Roberts",
        "timestamp": 1762495803
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"130272\">David Michael Roberts</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/How.20have.20you.20guys.20found.20GPT.205.3F/near/554244486\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"240862\">Oliver Nash</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/How.20have.20you.20guys.20found.20GPT.205.3F/near/554048405\">said</a>:</p>\n<blockquote>\n<p>I took a lemma from a paper I wrote years ago which I had proved with a somewhat laborious calculation and which I thought probably had a slick proof, but which I failed to find. Here is the lemma:<br>\n...<br>\nI aksed GPT 5 Pro to prove this last Thursday evening. It thought for ~16 minutes and produced a correct short proof: about half a page compared to my 4--5 page laborious calculation.</p>\n<p>I think it would be fair to classify this as early grad school -level mathematics. The fact that a lemma, which I worked hard to prove over several days, 12 years ago, can now be proved <em>with a better proof</em> by a computer in 16 minutes made a fairly big impression on me.</p>\n</blockquote>\n<p>That GPT has probably ingested your paper as well as any improvements or stronger results in the literature should not go unsaid. Proving a theorem for the first time is of course the messiest and hardest.</p>\n</blockquote>\n<p>GPT 5 was trained on almost all the Internet, right?</p>",
        "id": 554282093,
        "sender_full_name": "Anh Nguy·ªÖn",
        "timestamp": 1762510030
    },
    {
        "content": "<p>I find ChatGPT pretty much useless for writing in Lean because it cannot run <code>lake build</code> or any other command that would attempt to compile the code it comes up with. And its chances for getting anything nontrivial correct on a whim are very slim.</p>",
        "id": 558474573,
        "sender_full_name": "Martin Dvo≈ô√°k",
        "timestamp": 1763655810
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"417654\">Martin Dvo≈ô√°k</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/How.20have.20you.20guys.20found.20GPT.205.3F/near/558474573\">said</a>:</p>\n<blockquote>\n<p>I find ChatGPT pretty much useless for writing in Lean because it cannot run <code>lake build</code> or any other command that would attempt to compile the code it comes up with. And its chances for getting anything nontrivial correct on a whim are very slim.</p>\n</blockquote>\n<p>At least for that, I‚Äôd use cursor or codex or some model wrapped in the terminal so lake build would work</p>",
        "id": 558494235,
        "sender_full_name": "Alok Singh",
        "timestamp": 1763661059
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"417654\">@Martin Dvo≈ô√°k</span>, have you tried Codex (or Cursor, or Claude Code, etc)? Obviously the website interfaces are irrelevant.</p>",
        "id": 558533722,
        "sender_full_name": "Kim Morrison",
        "timestamp": 1763674544
    },
    {
        "content": "<p>I haven't. Are there any testimonials?</p>",
        "id": 558534301,
        "sender_full_name": "Martin Dvo≈ô√°k",
        "timestamp": 1763674785
    },
    {
        "content": "<p>Yes, they work well and can prove things. :-)</p>\n<p>They work even better with some specialized prompting. There is the \"lean4 skills\" plugin for Claude, which I haven't used. You could also try adopting a subset of my <a href=\"https://gist.github.com/kim-em/f9ff5571d253881640d847dffbc392eb\">~/.claude/CLAUDE.md</a> file.</p>",
        "id": 558537194,
        "sender_full_name": "Kim Morrison",
        "timestamp": 1763675930
    },
    {
        "content": "<p>This was mentioned by Anh Nguy·ªÖn in a <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Discussion.3A.20AI-written.20mathematical.20proofs/near/558558095\">different conversation</a> but seems worth cross-posting here as well: <a href=\"https://cdn.openai.com/pdf/4a25f921-e4e0-479a-9b38-5367b47e8fd0/early-science-acceleration-experiments-with-gpt-5.pdf#page8\">Early science acceleration experiments with GPT-5</a>.</p>",
        "id": 558652973,
        "sender_full_name": "Timothy Chow",
        "timestamp": 1763729822
    },
    {
        "content": "<p>Someone posted this, which was interesting:<br>\n<a href=\"https://www.reddit.com/r/singularity/comments/1p3sx47/some_experiments_in_mix_model_g351_lean_math/\">https://www.reddit.com/r/singularity/comments/1p3sx47/some_experiments_in_mix_model_g351_lean_math/</a></p>\n<p>If true, this could mean that there is large gap of capability not yet discovered by blending many models.</p>",
        "id": 558824314,
        "sender_full_name": "Deleted User 968128",
        "timestamp": 1763827021
    },
    {
        "content": "<p>I cross-pollinate Gemini, Claude, and ChatGPT as a regular part of my workflow. They all have strengths, blindspots. You can¬† get them into alignment and they're more than the some of their parts. Good way to filter out some hallucination too.</p>\n<p>I've been using Lean as a thought tool to understand perspectives (and some math and physics along with it). I use Gemini to architect and sketch a first draft. It's logical, less prone to pandering, and it'll correct my naivety. Chatgpt I find unreliable, but I'll sometimes make it argue with Gemini when Gemini's offbase. I use Claude for philosophizing, it's warmer in personality, and \"curious\".  Claude Code for the actual work, using <a href=\"https://github.com/oOo0oOo/lean-lsp-mcp\">lean-lsp-mcp</a> and <a href=\"https://github.com/cameronfreer/lean4-skills\">lean4 skills</a>. That way it can check the proof directly, look up tactics, run many attempts in parallel. It's really magic when it works.</p>",
        "id": 558885160,
        "sender_full_name": "typh",
        "timestamp": 1763894481
    },
    {
        "content": "<p>Surprising you'd have Claude in the mix as Claude Opus 4 scores 0.3%, with tasks costs of $351.75 on critp <a href=\"https://critpt.com/\">https://critpt.com/</a>, versus gpt 5 of 10% with task costs of $55.   On frontier math, it's 4.2% versus Gemini 3 at 18.8%.  <a href=\"https://epoch.ai/frontiermath\">https://epoch.ai/frontiermath</a></p>",
        "id": 558896246,
        "sender_full_name": "Deleted User 968128",
        "timestamp": 1763906209
    },
    {
        "content": "<p>Some time ago, I attended a public lecture by <a href=\"https://en.wikipedia.org/wiki/Jon_Edwards_(chess_player)\">Jon Edwards</a>, who at the time had recently won the 32nd World Correspondence Chess Championship. In this competition, you're allowed to use chess engines as much as you want. To get an edge, you therefore have to (1) mine databases better than your opponents do and (2) combine multiple chess engines better than your opponents do. I remember that he said that there was one engine (Houdini, I think, but I'm not sure) which was definitely not the strongest, but which would sometimes come up with important new lines if you ran it long enough.</p>\n<p>I've had similar experiences with SAT solvers, where a solver that doesn't do so well overall on a suite of benchmark problems will unexpectedly crush all the others on specific problems.</p>",
        "id": 558902847,
        "sender_full_name": "Timothy Chow",
        "timestamp": 1763912123
    },
    {
        "content": "<p>The general setup is relatively common in machine learning and goes by the name <a href=\"https://en.wikipedia.org/wiki/Mixture_of_experts\">Mixture of Experts</a> (MoE). There are many variations. Some of the larger LLMs even use MoE internally.</p>",
        "id": 558905413,
        "sender_full_name": "Kelly Davis",
        "timestamp": 1763914687
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"478409\">Timothy Chow</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/How.20have.20you.20guys.20found.20GPT.205.3F/near/558902847\">said</a>:</p>\n<blockquote>\n<p>I've had similar experiences with SAT solvers, where a solver that doesn't do so well overall on a suite of benchmark problems will unexpectedly crush all the others on specific problems.</p>\n</blockquote>\n<p><a href=\"https://www.quantamagazine.org/to-have-machines-make-math-proofs-turn-them-into-a-puzzle-20251110/\">https://www.quantamagazine.org/to-have-machines-make-math-proofs-turn-them-into-a-puzzle-20251110/</a></p>",
        "id": 558905637,
        "sender_full_name": "Deleted User 968128",
        "timestamp": 1763914886
    },
    {
        "content": "<p>Personally, I think a more globally collaborative attitude towards AGI would be healthy, especially if it achieves superior results.</p>",
        "id": 558905823,
        "sender_full_name": "Deleted User 968128",
        "timestamp": 1763915100
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"968128\">Tim Shephard</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/How.20have.20you.20guys.20found.20GPT.205.3F/near/558896246\">said</a>:</p>\n<blockquote>\n<p>Surprising you'd have Claude in the mix as Claude Opus 4 scores 0.3%, with tasks costs of $351.75 on critp <a href=\"https://critpt.com/\">https://critpt.com/</a>, versus gpt 5 of 10% with task costs of $55.   On frontier math, it's 4.2% versus Gemini 3 at 18%.  <a href=\"https://epoch.ai/frontiermath\">https://epoch.ai/frontiermath</a></p>\n</blockquote>\n<p>Claude does often pick the worst initial solution sketch of the three, which is why I use Gemini for that. I find Claude Code the best of the terminal agents for actually getting a task done though, in terms in my time.</p>",
        "id": 558923313,
        "sender_full_name": "typh",
        "timestamp": 1763932393
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"899863\">typh</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/How.20have.20you.20guys.20found.20GPT.205.3F/near/558923313\">said</a>:</p>\n<blockquote>\n<p>Claude does often pick the worst initial solution sketch of the three, which is why I use Gemini for that. I find Claude Code the best of the terminal agents for actually getting a task done though, in terms in my time.</p>\n</blockquote>\n<p>I'd like to understand this better.  Can you give a brief example of how Claude can perform better on a lean proof than Codex (now max) or Gemini?  </p>\n<p>Across every math benchmark I've seen (and tests that I've tried), it seems that Claude Opus 4.5 performs very poorly relative to OpenAI and Google.</p>",
        "id": 560176068,
        "sender_full_name": "Deleted User 968128",
        "timestamp": 1764082416
    },
    {
        "content": "<p>One possibility that I see is that Claude Code is the best at leveraging MCPs properly.  That would explain things, but speaks more to the vscode fork than the model itself.</p>",
        "id": 560180973,
        "sender_full_name": "Deleted User 968128",
        "timestamp": 1764083441
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"968128\">Tim Shephard</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/How.20have.20you.20guys.20found.20GPT.205.3F/near/560176068\">said</a>:</p>\n<blockquote>\n<p>I'd like to understand this better.  Can you give a brief example of how Claude can perform better on a lean proof than Codex (now max) or Gemini?  </p>\n</blockquote>\n<p>What Claude Code is better at, in my experience, is actually editing files and iterating on a task. I sense Anthropic is more invested in developer ergonomics in general. Even without MCP (in fact, it chronically forgets its MCP tools). My experiences with both codex and gemini-cli have been more frustrating than productive, even though yes, they might be better at math. When Claude can't solve a problem, I just get it to summarize what it's learned and switch back to [web] Gemini/ChatGPT.</p>\n<p>And note- I am a Lean beginner, with little math experience. My frictions are likely different from somebody deeper in the domain. I mostly do webdev.</p>",
        "id": 560217807,
        "sender_full_name": "typh",
        "timestamp": 1764093117
    },
    {
        "content": "<p>That more or less aligns with my experience. Gemini is way better at informal maths than Claude is, but Claude's \"personality\" in Claude Code is more effective. It explores the codebase more, tries things out, and is more persistent (sometime too persistent, when I'd prefer it to come back to me and say \"I'm confused\") than Codex. (However I haven't used Gemini in agent mode much at all.)</p>",
        "id": 560269779,
        "sender_full_name": "Kim Morrison",
        "timestamp": 1764113650
    }
]