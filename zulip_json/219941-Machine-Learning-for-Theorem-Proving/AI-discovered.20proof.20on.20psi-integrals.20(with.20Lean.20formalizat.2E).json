[
    {
        "content": "<p>Dear all,</p>\n<p>two weeks ago was the first time when an AI (namely GPT-5) solved one of the questions submitted to our AI benchmarking project <a href=\"https://improofbench.math.ethz.ch/\">IMProofBench</a> which was considered an open problem by the author (=me). It concerned intersection numbers on moduli spaces Mbar_g,n of curves: finding among all such descendant invariants</p>\n<p>&lt; tau_e1 ... tau_en &gt; = \\int_{Mbar_g,n} psi_1^e1 .... psi_n^enÂ  Â (*)</p>\n<p>the insertions e1, ..., en leading to the maximal value of (*), for fixed g,n. It turns out the maximum is achieved by distributing the numbers e1, ..., en as evenly as possible (while adding up to 3g-3+n). GPT-5 found a neat proof, completely ignoring the existing theory of descendant invariants (the Witten-Kontsevich theorem etc), just using abstract intersection-theoretic properties of the psi-classes (nefness + Khovanskii-Teissier log-concavity).</p>\n<p>I decided to write up both the result, and a bit of the context around it</p>\n<p><a href=\"/user_uploads/3121/0DBwoHh_b-o9VdElj11OLVJp/Extremal_Descendant_Integrals.pdf\">Extremal_Descendant_Integrals.pdf</a></p>\n<p>Apart from presenting the (largely unedited) proof given by the AI, I also decided to provide an alternative presentation of the argument: it combines </p>\n<ul>\n<li>a Lean formalized and self-contained optimization result, showing that a certain class of functions D(e1, ..., en) take their maximum on balanced vectors</li>\n<li>a geometric argument, with proof written by myself based on the GPT-5 argument, showing that the descendant invariants belong to this class of functions</li>\n</ul>\n<p>You can find the Lean blueprint here:<br>\n<a href=\"https://schmittj.github.io/balanced-vectors-blueprint/index.html\">https://schmittj.github.io/balanced-vectors-blueprint/index.html</a></p>\n<p>Lean file itself:<br>\n<a href=\"https://github.com/schmittj/balanced-vectors-blueprint/blob/13de9eeda635bc388e4dba68f514e3b42d339ae7/BalancedVectors.lean\">https://github.com/schmittj/balanced-vectors-blueprint/blob/13de9eeda635bc388e4dba68f514e3b42d339ae7/BalancedVectors.lean</a></p>\n<p>Before embarking on this formalization project yesterday, I had no prior experience with Lean, and all the code was generated by Claude Code (using the <a href=\"https://github.com/cameronfreer/lean4-skills\">lean 4 skill</a> developed by @cameronfreer) and ChatGPT 5.2.</p>\n<p>I would be very happy to hear any feedback on either:</p>\n<ul>\n<li>the mathematical result itself</li>\n<li>the chosen presentation and conventions on attribution of AI contributions</li>\n<li>the formalization above (in particular any potential mis-formalization, and also how the Lean code reads for experts)</li>\n</ul>",
        "id": 563828163,
        "sender_full_name": "Johannes Schmitt",
        "timestamp": 1765806706
    },
    {
        "content": "<p>So Iâ€™m clear, the AI proof was in natural language and the Lean proof was based on the AI proof, and was vibe coded by someone who doesnâ€™t know Lean well, is that correct?</p>",
        "id": 563828953,
        "sender_full_name": "Jason Rute",
        "timestamp": 1765806900
    },
    {
        "content": "<p>Yes, that's correct. The AI proof was checked both by myself and several colleagues of mine, and other colleagues (with more Lean experience) have had at least a cursory look on the Lean formalization.</p>",
        "id": 563829360,
        "sender_full_name": "Johannes Schmitt",
        "timestamp": 1765806990
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"740690\">Johannes Schmitt</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/AI-discovered.20proof.20on.20psi-integrals.20.28with.20Lean.20formalizat.2E.29/near/563828163\">said</a>:</p>\n<blockquote>\n<p>I would be very happy to hear any feedback on either:</p>\n<ul>\n<li>the mathematical result itself</li>\n<li>the chosen presentation and conventions on attribution of AI contributions</li>\n<li>the formalization above (in particular any potential mis-formalization, and also how the Lean code reads for experts)</li>\n</ul>\n</blockquote>\n<p>The formalization looks like a good candidate testing out the 'AI generated Lean proof format' proposed here: <a class=\"message-link\" href=\"/#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Discussion.3A.20AI-written.20mathematical.20proofs/near/556956066\">#Machine Learning for Theorem Proving &gt; Discussion: AI-written mathematical proofs @ ðŸ’¬</a>.  I have been working on the automated tool and would love to use this as a case study. Would you be alright with me refactoring this code and using it for that purpose?</p>",
        "id": 563836891,
        "sender_full_name": "Eric Vergo",
        "timestamp": 1765808639
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"988234\">@Eric Vergo</span> This sounds very interesting (will read up on your precise proposal), but please do go ahead with using this as a case study! Very happy to provide any assistance you might need.</p>",
        "id": 563837611,
        "sender_full_name": "Johannes Schmitt",
        "timestamp": 1765808821
    },
    {
        "content": "<p>\"Vibe-formalizing\" without prior Lean knowledge, impressive, I like it.</p>",
        "id": 563838210,
        "sender_full_name": "Auguste Poiroux",
        "timestamp": 1765808926
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"740690\">Johannes Schmitt</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/AI-discovered.20proof.20on.20psi-integrals.20.28with.20Lean.20formalizat.2E.29/near/563837611\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"988234\">Eric Vergo</span> This sounds very interesting (will read up on your precise proposal), but please do go ahead with using this as a case study! Very happy to provide any assistance you might need.</p>\n</blockquote>\n<p>Great, this will take me a day or two and I'll post here when things are ready.</p>",
        "id": 563840651,
        "sender_full_name": "Eric Vergo",
        "timestamp": 1765809522
    },
    {
        "content": "<p>Lean doesn't have even the definition of the moduli space of curves (indeed we need the moduli space of elliptic curves for FLT and it's a big hole right now) so it's hard to imagine that the Lean component is a substantial part of the overall proof?</p>",
        "id": 563875650,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1765817687
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110038\">Kevin Buzzard</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/AI-discovered.20proof.20on.20psi-integrals.20.28with.20Lean.20formalizat.2E.29/near/563875650\">said</a>:</p>\n<blockquote>\n<p>Lean doesn't have even the definition of the moduli space of curves (indeed we need the moduli space of elliptic curves for FLT and it's a big hole right now) so it's hard to imagine that the Lean component is a substantial part of the overall proof?</p>\n</blockquote>\n<p>From the report above:</p>\n<blockquote>\n<p>To our knowledge, the prerequisite results in algebraic geometry going into the proof (divisors on algebraic schemes, intersection numbers, nef classes, moduli spaces of curves, the Wittenâ€“Kontsevich theorem, etc) are not yet formalized in Lean. Thus we decided to split the proof in a purely combinatorial optimization result (Theorem 3.1), and a geometric part proved non-formally (Theorem 3.2)</p>\n</blockquote>",
        "id": 563877125,
        "sender_full_name": "Jason Rute",
        "timestamp": 1765818058
    },
    {
        "content": "<p>Maybe to give some quantitative context: the section containing the formalized proof is about 3.5 pages of the pdf; the informal version of the optimization result (that has been formalized) takes about 2.5 of these pages, the geometric result (which only has an informal proof) takes about 1 page. And I think that both of these parts have approximately the same density of claims-to-be-parsed per paragraph.</p>\n<p>For me the advantage of the formalization is: the optimization argument is one of these annoying, fiddly concatenations of inequalities and indices, where you have to be very careful to get everything right and not divide by zero. So the fact that this is now fully verified is quite reassuring, and for me as a reader, I would be happy to be able to focus on the (more interesting) geometric ingredients!</p>",
        "id": 563879101,
        "sender_full_name": "Johannes Schmitt",
        "timestamp": 1765818584
    },
    {
        "content": "<p>Scholze's challenge problem was to prove some technical statement about Ext groups (which we didn't have at the time) but the result was reduced in literally under ten lines of the pdf to a concrete statement about undergraduate level objects whose proof was about 8 pages and which the community formalised in six months. Formalising the remaining ten lines took us over a year :-)</p>",
        "id": 563891779,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1765822338
    },
    {
        "content": "<p>I have always pushed back against the idea that AI should be trusted to formalise definitions and even the statement that <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi mathvariant=\"script\">M</mi><mrow><mi>g</mi><mo separator=\"true\">,</mo><mi>n</mi></mrow></msub></mrow><annotation encoding=\"application/x-tex\">\\mathcal{M}_{g,n}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.9694em;vertical-align:-0.2861em;\"></span><span class=\"mord\"><span class=\"mord mathcal\">M</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.1514em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03588em;\">g</span><span class=\"mpunct mtight\">,</span><span class=\"mord mathnormal mtight\">n</span></span></span></span></span><span class=\"vlist-s\">â€‹</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2861em;\"><span></span></span></span></span></span></span></span></span></span> exists is highly nontrivial, however it would be an interesting test of mathlib to see if we could now (manually) formalise the definition of the functor and then one could ask AI to prove the theorem that it's representable (which would be the proof that completes the definition of the scheme).</p>",
        "id": 563892357,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1765822536
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110038\">Kevin Buzzard</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/AI-discovered.20proof.20on.20psi-integrals.20.28with.20Lean.20formalizat.2E.29/near/563891779\">said</a>:</p>\n<blockquote>\n<p>Scholze's challenge problem was to prove some technical statement about Ext groups (which we didn't have at the time) but the result was reduced in literally under ten lines of the pdf to a concrete statement about undergraduate level objects whose proof was about 8 pages and which the community formalised in six months. Formalising the remaining ten lines took us over a year :-)</p>\n</blockquote>\n<p>Indeed, I would imagine that formalizing the missing page from the proof above could easily be a multi-year project. All I was saying was that for a human expert in algebraic geometry, the time to think through that one page (during a referee process in a standard journal) might be comparable to the time they would spend checking all inequalities in the formalized optimization problem. So purely from the perspective of \"check this particular result, assuming the rest of the literature\", the decision to formalize the optimization part got about 50% of the benefit for about 0.01% of the amount of work it would take to formalize everything.</p>",
        "id": 563899842,
        "sender_full_name": "Johannes Schmitt",
        "timestamp": 1765825195
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110038\">Kevin Buzzard</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/AI-discovered.20proof.20on.20psi-integrals.20.28with.20Lean.20formalizat.2E.29/near/563892357\">said</a>:</p>\n<blockquote>\n<p>I have always pushed back against the idea that AI should be trusted to formalise definitions and even the statement that <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi mathvariant=\"script\">M</mi><mrow><mi>g</mi><mo separator=\"true\">,</mo><mi>n</mi></mrow></msub></mrow><annotation encoding=\"application/x-tex\">\\mathcal{M}_{g,n}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.9694em;vertical-align:-0.2861em;\"></span><span class=\"mord\"><span class=\"mord mathcal\">M</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.1514em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03588em;\">g</span><span class=\"mpunct mtight\">,</span><span class=\"mord mathnormal mtight\">n</span></span></span></span></span><span class=\"vlist-s\">â€‹</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2861em;\"><span></span></span></span></span></span></span></span></span></span> exists is highly nontrivial, however it would be an interesting test of mathlib to see if we could now (manually) formalise the definition of the functor and then one could ask AI to prove the theorem that it's representable (which would be the proof that completes the definition of the scheme).</p>\n</blockquote>\n<p>Of course as an algebraic and enumerative geometer I would be very happy to see algebraic geometry in general being more fleshed out, in particular with some concrete goal in mind, like the definition of the moduli spaces of curves!</p>\n<p>About potential AI involvement here: I agree that AI right now is not reliable enough to formalize extended theoretical constructions unsupervised in a way that we could trust. What I am wondering about is whether it would be acceptable for a human to formalize the chain of core statements and results, and AI to fill in the gaps. In a certain sense, the project above has about 5 definitions and 1 theorem, which is really all I care about, and which can be manually verified to be a correct formalization of the result I want. Then the AI filled in various lemmas and intermediate results, and from my perspective, as long as they make the final theorem compile, I am happy with that state of affairs. </p>\n<p>Of course the project above is not trying to build some large theoretical machinery or represent a significant slice of mathematical literature, so it might be that in those cases there are more stringent requirements even on intermediate notions and results. But I still feel that going forward, it might be useful to consider whether there are any parts of the process that one would be willing to hand off to AI helpers.</p>",
        "id": 563904494,
        "sender_full_name": "Johannes Schmitt",
        "timestamp": 1765825715
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110038\">Kevin Buzzard</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/AI-discovered.20proof.20on.20psi-integrals.20.28with.20Lean.20formalizat.2E.29/near/563892357\">said</a>:</p>\n<blockquote>\n<p>I have always pushed back against the idea that AI should be trusted to formalise definitions...</p>\n</blockquote>\n<p>Me too, and I think this should be the standard for the foreseeable future. The intent of the template is to quarantine all of the declarations that dont have a proof obligation(plus some other tings)  so they can get properly scrutinized. Kim also suggested that those declarations be pulled into Mathlib first, which makes sense to me.</p>",
        "id": 563905288,
        "sender_full_name": "Eric Vergo",
        "timestamp": 1765826056
    },
    {
        "content": "<p>I think it certainly makes sense that mathlib should end up as a \"canonical\" source for every mathematical definition being used today. This is the monorepo philosophy which has served us well so far.</p>",
        "id": 563916968,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1765829974
    },
    {
        "content": "<p>I agree that definitions should be carefully curated and thought out. Do you have an estimate which percentage of the development time goes into writing definitions, lemmas and theorems that might be used elsewhere vs. ad-hoc technical lemmas that are useful for precisely one purpose (one step in a bigger proof)? </p>\n<p>I could imagine the latter are much more amenable to potential outsourcing. I would be curious what percentage of the work hours they represent (or maybe I am fundamentally misunderstanding how things work when building the mathlib!).</p>",
        "id": 563917998,
        "sender_full_name": "Johannes Schmitt",
        "timestamp": 1765830323
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110038\">Kevin Buzzard</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/AI-discovered.20proof.20on.20psi-integrals.20.28with.20Lean.20formalizat.2E.29/near/563916968\">said</a>:</p>\n<blockquote>\n<p>I think it certainly makes sense that mathlib should end up as a \"canonical\" source for every mathematical definition being used today. This is the monorepo philosophy which has served us well so far.</p>\n</blockquote>\n<p>Absolutely. One of the reasons I am working on this is to prevent things from fracturing in the future. As the number of vibe-proven repos grows, so will the workload on the reviewers. If things get backlogged, people may start building on each others work before it gets into Mathlib, and that seems like something we want to avoid.</p>",
        "id": 563918235,
        "sender_full_name": "Eric Vergo",
        "timestamp": 1765830403
    },
    {
        "content": "<p>I was able to put this together today: <a href=\"https://github.com/e-vergo/Balanced_Vectors\">https://github.com/e-vergo/Balanced_Vectors</a></p>\n<p>There are a number of deviations from the original suggestion by Kim, but that is due to the fact that this repo contains 18 or so declarations that don't have a proof obligation. All of these can be found in Definitions.lean and are accompanied by a few lemmas that are used by other definitions. There are a few wrappers for things currently in Mathlib, but I don't think there are any meaningful opportunities to reduce the number of definitions. </p>\n<p>Once everything in definitions.lean is in Mathlib (which should go through the normal review process) the repo can be updated, reducing the review burden to the two MainTheorem files. If we want to enable people to submit AI generated proofs in this manner we are going to need to have a larger discussion about the specifics of the template/workflow; there are a number of design choices I made somewhat arbitrarily. </p>\n<p>Feedback on all levels is welcome.</p>",
        "id": 563947613,
        "sender_full_name": "Eric Vergo",
        "timestamp": 1765844836
    },
    {
        "content": "<p>Thanks so much for putting this together so quickly! Some comments:</p>\n<ul>\n<li>My guess is that to fit the pattern of the original suggestion, one would have to modify the main theorem to essentially expand out the various definitions that go in there (so it becomes standalone modulo mathlib), and then in the proof first reassemble all these properties noting that they fit the definitions from definitions.lean. I agree that this would make the main theorem more transparent, though of course increase the total number of lines. I personally think it might be worth it, but again I have very few Lean intuitions yet.</li>\n<li>The definitions themselves seemed somewhat ad-hoc to me, again unsure how much sense it makes to put them in the mathlib. If people see some potential I am happy to try submitting something for review.</li>\n<li>I would be very happy to acknowledge your work in the paper (probably planning to upload to the arxiv for tonight's deadline). Do you think it makes sense to include a link to your repo above? Has the proposal by Kim been formalized in any way? If you would like to suggest a paste-ready formulation, please be my guest!</li>\n</ul>\n<p>Also, since you had a bit of a look on the files, one curiosity I had:</p>\n<ul>\n<li>How would you rate the quality of the Lean code? I have heard that autoformalizers tend to produce very long, redundant code that can often be condensed by factors of x5 in the hands of an experienced Lean user. Does the code have the same redundant-slop quality, or is it mostly reasonable? Just curious!</li>\n</ul>",
        "id": 564001528,
        "sender_full_name": "Johannes Schmitt",
        "timestamp": 1765878723
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"740690\">Johannes Schmitt</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/AI-discovered.20proof.20on.20psi-integrals.20.28with.20Lean.20formalizat.2E.29/near/564001528\">said</a>:</p>\n<blockquote>\n<p>Thanks so much for putting this together so quickly! Some comments:</p>\n<ul>\n<li>My guess is that to fit the pattern of the original suggestion, one would have to modify the main theorem to essentially expand out the various definitions that go in there (so it becomes standalone modulo mathlib), and then in the proof first reassemble all these properties noting that they fit the definitions from definitions.lean. I agree that this would make the main theorem more transparent, though of course increase the total number of lines. I personally think it might be worth it, but again I have very few Lean intuitions yet.<br>\n</li>\n</ul>\n</blockquote>\n<p>I can't speak to whether or not the definitions are ad hoc, but Mathlib tends to want statements that are more general. If one were to 'upgrade' the definitions in this way it's likely that the main theorem here could go untouched because you can add additional lemmas saying that what you have now satisfies the more general definitions. I think this is what you are suggesting, and if you are interested in getting this result into mathlib that is probably the best route.Â </p>\n<p><span class=\"user-mention silent\" data-user-id=\"740690\">Johannes Schmitt</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/AI-discovered.20proof.20on.20psi-integrals.20.28with.20Lean.20formalizat.2E.29/near/564001528\">said</a>:</p>\n<blockquote>\n<ul>\n<li>I would be very happy to acknowledge your work in the paper (probably planning to upload to the arxiv for tonight's deadline). Do you think it makes sense to include a link to your repo above?Â <br>\n</li>\n</ul>\n</blockquote>\n<p>If you would like to acknowledge me and/or link to the repo I have no objections, but I am certainly not requesting it.</p>\n<p><span class=\"user-mention silent\" data-user-id=\"740690\">Johannes Schmitt</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/AI-discovered.20proof.20on.20psi-integrals.20.28with.20Lean.20formalizat.2E.29/near/564001528\">said</a>:</p>\n<blockquote>\n<p>Has the proposal by Kim been formalized in any way?<br>\n</p>\n</blockquote>\n<p>As far as I know it has not progressed past that post, and the tool I am working on is not ready yet. <a href=\"https://github.com/e-vergo/TAIL\">This is what I have so far</a>. It still doesn't have the functionality to account for in-project definitions as I am struggling to work through all of the exposed/public/private conditions required for using modules. If we want to standardize and adopt this, it is going to need feedback from quite a few stakeholders first. It is very much a work in progress, and in its early stages. </p>\n<p>This is the kind of thing that I could knock out in a day if I wrote something in python using text parsing, but I am building this purely in lean and using the environment inspection tools. I am hoping to have something to share more broadly in the next few days, but it may take longer than that as this is something that is a bit outside of my wheelhouse. No doubt that there are many people on this forum that could do a better job faster, but I get the sense here that the experts are becoming increasingly overloaded with work. I learn by getting my hands dirty though, so this is great experience for me.Â </p>\n<p><span class=\"user-mention silent\" data-user-id=\"740690\">Johannes Schmitt</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/AI-discovered.20proof.20on.20psi-integrals.20.28with.20Lean.20formalizat.2E.29/near/564001528\">said</a>:</p>\n<blockquote>\n<ul>\n<li>How would you rate the quality of the Lean code? I have heard that autoformalizers tend to produce very long, redundant code that can often be condensed by factors of x5 in the hands of an experienced Lean user. Does the code have the same redundant-slop quality, or is it mostly reasonable? Just curious!<br>\n</li>\n</ul>\n</blockquote>\n<p>Itâ€™s ok, but not perfect. Here is what my still-being-trained eyes see:</p>\n<p>There are small things like missing docstrings and inconsistent variable naming, but those can be cleaned up pretty easily. Also, it looks like nonzeroCount is unused so it can be discarded</p>\n<p>On the â€˜less reasonableâ€™ side, some of the proofs are long and difficult to follow; particularly unimodal_of_logconcave_palindromic. This proof can be broken up into smaller lemmas roughly corresponding to each of the top level â€˜haveâ€™ statements. This will help with readability and is generally a good practice. </p>\n<p>Another improvement is writing a helper lemma(s?) for the following repeated pattern:</p>\n<div class=\"codehilite\" data-code-language=\"Lean4\"><pre><span></span><code><span class=\"w\">  </span><span class=\"c1\">-- e is the slice at position e.i</span>\n<span class=\"w\">  </span><span class=\"k\">have</span><span class=\"w\"> </span><span class=\"n\">he_eq_slice</span><span class=\"w\"> </span><span class=\"o\">:</span><span class=\"w\"> </span><span class=\"n\">e</span><span class=\"w\"> </span><span class=\"bp\">=</span><span class=\"w\"> </span><span class=\"n\">sliceComposition</span><span class=\"w\"> </span><span class=\"n\">e</span><span class=\"w\"> </span><span class=\"n\">i</span><span class=\"w\"> </span><span class=\"n\">j</span><span class=\"w\"> </span><span class=\"n\">hij</span><span class=\"w\"> </span><span class=\"o\">(</span><span class=\"n\">e</span><span class=\"w\"> </span><span class=\"n\">i</span><span class=\"o\">)</span><span class=\"w\"> </span><span class=\"n\">hei_lo</span><span class=\"w\"> </span><span class=\"n\">hei_hi</span><span class=\"w\"> </span><span class=\"o\">:=</span><span class=\"w\"> </span><span class=\"k\">by</span>\n<span class=\"w\">    </span><span class=\"n\">refine</span><span class=\"w\"> </span><span class=\"n\">WeakComposition</span><span class=\"bp\">.</span><span class=\"n\">ext</span><span class=\"w\"> </span><span class=\"o\">(</span><span class=\"k\">fun</span><span class=\"w\"> </span><span class=\"n\">k</span><span class=\"w\"> </span><span class=\"bp\">=&gt;</span><span class=\"w\"> </span><span class=\"bp\">?_</span><span class=\"o\">)</span>\n<span class=\"w\">    </span><span class=\"n\">simp</span><span class=\"w\"> </span><span class=\"n\">only</span><span class=\"w\"> </span><span class=\"o\">[</span><span class=\"n\">sliceComposition</span><span class=\"o\">]</span>\n<span class=\"w\">    </span><span class=\"n\">by_cases</span><span class=\"w\"> </span><span class=\"n\">hki</span><span class=\"w\"> </span><span class=\"o\">:</span><span class=\"w\"> </span><span class=\"n\">k</span><span class=\"w\"> </span><span class=\"bp\">=</span><span class=\"w\"> </span><span class=\"n\">i</span>\n<span class=\"w\">    </span><span class=\"bp\">Â·</span><span class=\"w\"> </span><span class=\"n\">simp</span><span class=\"w\"> </span><span class=\"n\">only</span><span class=\"w\"> </span><span class=\"o\">[</span><span class=\"n\">hki</span><span class=\"o\">,</span><span class=\"w\"> </span><span class=\"n\">ite_true</span><span class=\"o\">]</span>\n<span class=\"w\">    </span><span class=\"bp\">Â·</span><span class=\"w\"> </span><span class=\"n\">by_cases</span><span class=\"w\"> </span><span class=\"n\">hkj</span><span class=\"w\"> </span><span class=\"o\">:</span><span class=\"w\"> </span><span class=\"n\">k</span><span class=\"w\"> </span><span class=\"bp\">=</span><span class=\"w\"> </span><span class=\"n\">j</span>\n<span class=\"w\">      </span><span class=\"bp\">Â·</span><span class=\"w\"> </span><span class=\"n\">simp</span><span class=\"w\"> </span><span class=\"n\">only</span><span class=\"w\"> </span><span class=\"o\">[</span><span class=\"n\">hkj</span><span class=\"o\">,</span><span class=\"w\"> </span><span class=\"n\">ite_true</span><span class=\"o\">,</span><span class=\"w\"> </span><span class=\"n\">if_neg</span><span class=\"w\"> </span><span class=\"n\">hij</span><span class=\"bp\">.</span><span class=\"n\">symm</span><span class=\"o\">]</span><span class=\"bp\">;</span><span class=\"w\"> </span><span class=\"n\">ring</span>\n<span class=\"w\">      </span><span class=\"bp\">Â·</span><span class=\"w\"> </span><span class=\"n\">simp</span><span class=\"w\"> </span><span class=\"n\">only</span><span class=\"w\"> </span><span class=\"o\">[</span><span class=\"n\">hki</span><span class=\"o\">,</span><span class=\"w\"> </span><span class=\"n\">hkj</span><span class=\"o\">,</span><span class=\"w\"> </span><span class=\"n\">ite_false</span><span class=\"o\">]</span>\n<span class=\"w\">  </span><span class=\"c1\">-- The modified composition is the slice at position e.i - 1</span>\n<span class=\"w\">  </span><span class=\"k\">have</span><span class=\"w\"> </span><span class=\"n\">hmod_eq_slice</span><span class=\"w\"> </span><span class=\"o\">:</span><span class=\"w\"> </span><span class=\"n\">e</span><span class=\"bp\">.</span><span class=\"n\">modify</span><span class=\"w\"> </span><span class=\"n\">i</span><span class=\"w\"> </span><span class=\"n\">j</span><span class=\"w\"> </span><span class=\"n\">hi</span><span class=\"w\"> </span><span class=\"n\">hij</span><span class=\"w\"> </span><span class=\"bp\">=</span><span class=\"w\"> </span><span class=\"n\">sliceComposition</span><span class=\"w\"> </span><span class=\"n\">e</span><span class=\"w\"> </span><span class=\"n\">i</span><span class=\"w\"> </span><span class=\"n\">j</span><span class=\"w\"> </span><span class=\"n\">hij</span><span class=\"w\"> </span><span class=\"o\">(</span><span class=\"n\">e</span><span class=\"w\"> </span><span class=\"n\">i</span><span class=\"w\"> </span><span class=\"bp\">-</span><span class=\"w\"> </span><span class=\"mi\">1</span><span class=\"o\">)</span><span class=\"w\"> </span><span class=\"n\">hem1_lo</span><span class=\"w\"> </span><span class=\"n\">hem1_hi</span><span class=\"w\"> </span><span class=\"o\">:=</span><span class=\"w\"> </span><span class=\"k\">by</span>\n<span class=\"w\">    </span><span class=\"n\">refine</span><span class=\"w\"> </span><span class=\"n\">WeakComposition</span><span class=\"bp\">.</span><span class=\"n\">ext</span><span class=\"w\"> </span><span class=\"o\">(</span><span class=\"k\">fun</span><span class=\"w\"> </span><span class=\"n\">k</span><span class=\"w\"> </span><span class=\"bp\">=&gt;</span><span class=\"w\"> </span><span class=\"bp\">?_</span><span class=\"o\">)</span>\n<span class=\"w\">    </span><span class=\"n\">simp</span><span class=\"w\"> </span><span class=\"n\">only</span><span class=\"w\"> </span><span class=\"o\">[</span><span class=\"n\">WeakComposition</span><span class=\"bp\">.</span><span class=\"n\">modify</span><span class=\"o\">,</span><span class=\"w\"> </span><span class=\"n\">sliceComposition</span><span class=\"o\">]</span>\n<span class=\"w\">    </span><span class=\"n\">by_cases</span><span class=\"w\"> </span><span class=\"n\">hki</span><span class=\"w\"> </span><span class=\"o\">:</span><span class=\"w\"> </span><span class=\"n\">k</span><span class=\"w\"> </span><span class=\"bp\">=</span><span class=\"w\"> </span><span class=\"n\">i</span>\n<span class=\"w\">    </span><span class=\"bp\">Â·</span><span class=\"w\"> </span><span class=\"n\">simp</span><span class=\"w\"> </span><span class=\"n\">only</span><span class=\"w\"> </span><span class=\"o\">[</span><span class=\"n\">hki</span><span class=\"o\">,</span><span class=\"w\"> </span><span class=\"n\">ite_true</span><span class=\"o\">]</span>\n<span class=\"w\">    </span><span class=\"bp\">Â·</span><span class=\"w\"> </span><span class=\"n\">by_cases</span><span class=\"w\"> </span><span class=\"n\">hkj</span><span class=\"w\"> </span><span class=\"o\">:</span><span class=\"w\"> </span><span class=\"n\">k</span><span class=\"w\"> </span><span class=\"bp\">=</span><span class=\"w\"> </span><span class=\"n\">j</span>\n<span class=\"w\">      </span><span class=\"bp\">Â·</span><span class=\"w\"> </span><span class=\"n\">simp</span><span class=\"w\"> </span><span class=\"n\">only</span><span class=\"w\"> </span><span class=\"o\">[</span><span class=\"n\">hkj</span><span class=\"o\">,</span><span class=\"w\"> </span><span class=\"n\">ite_true</span><span class=\"o\">,</span><span class=\"w\"> </span><span class=\"n\">if_neg</span><span class=\"w\"> </span><span class=\"n\">hij</span><span class=\"bp\">.</span><span class=\"n\">symm</span><span class=\"o\">]</span><span class=\"bp\">;</span><span class=\"w\"> </span><span class=\"n\">ring</span>\n<span class=\"w\">      </span><span class=\"bp\">Â·</span><span class=\"w\"> </span><span class=\"n\">simp</span><span class=\"w\"> </span><span class=\"n\">only</span><span class=\"w\"> </span><span class=\"o\">[</span><span class=\"n\">hki</span><span class=\"o\">,</span><span class=\"w\"> </span><span class=\"n\">hkj</span><span class=\"o\">,</span><span class=\"w\"> </span><span class=\"n\">ite_false</span><span class=\"o\">]</span>\n</code></pre></div>\n<p>This shows up on lines <a href=\"https://github.com/schmittj/balanced-vectors-blueprint/blob/13de9eeda635bc388e4dba68f514e3b42d339ae7/BalancedVectors.lean#L684\">684</a>, <a href=\"https://github.com/schmittj/balanced-vectors-blueprint/blob/13de9eeda635bc388e4dba68f514e3b42d339ae7/BalancedVectors.lean#L789\">789</a>,  and <a href=\"https://github.com/schmittj/balanced-vectors-blueprint/blob/13de9eeda635bc388e4dba68f514e3b42d339ae7/BalancedVectors.lean#L995\">995</a>.</p>",
        "id": 564113771,
        "sender_full_name": "Eric Vergo",
        "timestamp": 1765911786
    },
    {
        "content": "<p>I agree that this example doesn't fit cleanly into my original formulation: there are too many definitions needed for the statement of the theorem, that don't really belong in Mathlib. So I like the <code>Definitions.lean</code> file. I think it would be good if this file, and the README, contained a big warning message: \"To trust the claimed main result, and for it to be <em>meaningful</em> to have Lean check the actual proofs, you must read and understand that content of <code>Definitions.lean</code>.\"</p>",
        "id": 564140596,
        "sender_full_name": "Kim Morrison",
        "timestamp": 1765922581
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"988234\">@Eric Vergo</span>, a few quick comments:</p>\n<ul>\n<li>I got an error running <code>lake exe cache get</code> in the current state of the repo (\"error: external command 'git' exited with code 128\": <span class=\"user-mention\" data-user-id=\"315577\">@Mac Malone</span>, could we please <em>always</em> print the underlying error message when lake fails in a git operation?)</li>\n<li>You've used a <code>lakefile.lean</code>. That works, but our preference is for the ecosystem to use <code>lakefile.toml</code> where possible. You can just run <code>lake translate-config toml</code>.</li>\n</ul>",
        "id": 564140871,
        "sender_full_name": "Kim Morrison",
        "timestamp": 1765922708
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110087\">Kim Morrison</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/AI-discovered.20proof.20on.20psi-integrals.20.28with.20Lean.20formalizat.2E.29/near/564140596\">said</a>:</p>\n<blockquote>\n<p>I agree that this example doesn't fit cleanly into my original formulation: there are too many definitions needed for the statement of the theorem, that don't really belong in Mathlib. So I like the <code>Definitions.lean</code> file. I think it would be good if this file, and the README, contained a big warning message: \"To trust the claimed main result, and for it to be <em>meaningful</em> to have Lean check the actual proofs, you must read and understand that content of <code>Definitions.lean</code>.\"</p>\n</blockquote>\n<p>Warning added.</p>\n<p><span class=\"user-mention silent\" data-user-id=\"110087\">Kim Morrison</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/AI-discovered.20proof.20on.20psi-integrals.20.28with.20Lean.20formalizat.2E.29/near/564140871\">said</a>:</p>\n<blockquote>\n<ul>\n<li>I got an error running <code>lake exe cache get</code> in the current state of the repo </li>\n</ul>\n</blockquote>\n<p>I was unable to reproduce this on two machines. Let me know if there is anything I can do for this.</p>\n<p><span class=\"user-mention silent\" data-user-id=\"110087\">Kim Morrison</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/AI-discovered.20proof.20on.20psi-integrals.20.28with.20Lean.20formalizat.2E.29/near/564140871\">said</a>:</p>\n<blockquote>\n<ul>\n<li>You've used a <code>lakefile.lean</code>. That works, but our preference is for the ecosystem to use <code>lakefile.toml</code> where possible. You can just run <code>lake translate-config toml</code>.</li>\n</ul>\n</blockquote>\n<p>done.</p>",
        "id": 564147493,
        "sender_full_name": "Eric Vergo",
        "timestamp": 1765926397
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"988234\">@Eric Vergo</span>, I've just made three PRs to your repo, hopefully reducing the \"surface area\".</p>",
        "id": 564153274,
        "sender_full_name": "Kim Morrison",
        "timestamp": 1765930065
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"988234\">@Eric Vergo</span>, also, you don't have any CI setup on this repo. I recommend just running <code>lake new</code> in a fresh directory and then copying over the <code>.github</code> directory from the template that creates.</p>",
        "id": 564153374,
        "sender_full_name": "Kim Morrison",
        "timestamp": 1765930179
    },
    {
        "content": "<p>If you ping me once these PRs are merged I can do a second pass.</p>",
        "id": 564154076,
        "sender_full_name": "Kim Morrison",
        "timestamp": 1765930816
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"740690\">@Johannes Schmitt</span>, <span class=\"user-mention\" data-user-id=\"988234\">@Eric Vergo</span>, one way to reduce the amount that needs to be human verified here is to avoid defining the <code>WeakComposition.modify</code> function in <code>Definitions.lean</code> (because it requires a bunch of supporting lemmas), and instead just codify an <code>IsModification</code> predicate relating two <code>WeakComposition</code>s. Then <code>SatisfiesLogConcavity</code> can be stated much more cheaply.</p>\n<p>I could implement that easily.</p>",
        "id": 564169649,
        "sender_full_name": "Kim Morrison",
        "timestamp": 1765944483
    },
    {
        "content": "<p>(Standard naming says <code>SatisfiesLogConcavity</code> should be <code>IsLogConcave</code>, btw.)</p>",
        "id": 564169688,
        "sender_full_name": "Kim Morrison",
        "timestamp": 1765944517
    },
    {
        "content": "<p>Thank you so much, Eric and Kim, for your work and taking an interest! I agree with the modifications you proposed - please feel free to go ahead and/or tell me if there is something I can contribute to.</p>\n<p>The first version of the paper is now on arxiv ( <a href=\"https://arxiv.org/abs/2512.14575\">https://arxiv.org/abs/2512.14575</a> ) and I included the following reference to the project above:<br>\n<a href=\"/user_uploads/3121/zEyNnDzb8GFpjsnNUkBo6653/image.png\">image.png</a></p>\n<div class=\"message_inline_image\"><a href=\"/user_uploads/3121/zEyNnDzb8GFpjsnNUkBo6653/image.png\" title=\"image.png\"><img data-original-content-type=\"image/png\" data-original-dimensions=\"1395x235\" src=\"/user_uploads/thumbnail/3121/zEyNnDzb8GFpjsnNUkBo6653/image.png/840x560.webp\"></a></div><p>In a later update I would of course also acknowledge Kim's contributions, change links to point to the new refactored repository, and add a reference to Eric's TAIL project (if you like!).</p>",
        "id": 564176245,
        "sender_full_name": "Johannes Schmitt",
        "timestamp": 1765950204
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110038\">Kevin Buzzard</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/AI-discovered.20proof.20on.20psi-integrals.20.28with.20Lean.20formalizat.2E.29/near/563916968\">said</a>:</p>\n<blockquote>\n<p>I think it certainly makes sense that mathlib should end up as a \"canonical\" source for every mathematical definition being used today.</p>\n</blockquote>\n<p>I agree with the sentiment here, but taking it literally would mean that <code>riemannZeta 1 = (Î³ - Complex.log (4 * â†‘Ï€)) / 2</code> would become a canonical definition, which surely makes no sense.</p>",
        "id": 564247927,
        "sender_full_name": "Timothy Chow",
        "timestamp": 1765977087
    },
    {
        "content": "<p>While I cannot say anything on the feasibility of implementation, from my perspective it might be useful that some mathematical notions do not just have one, canonical definition, but a very tightly connected cluster of definitions, with strong heuristics how to convert between them and transfer properties, and when you need to call on that object, you have a choice to pick one of these notions, work with it, and whenever a construction needs another facet of that mathematical object, it can smoothly rotate into place for continuing a proof.</p>\n<p>Indeed, for some mathematical objects, it seems very hard to pick one completely canonical definition that will be the optimal one for any purpose (like the one given in the BOOK OF DEFINITIONS).</p>",
        "id": 564249552,
        "sender_full_name": "Johannes Schmitt",
        "timestamp": 1765977591
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110087\">Kim Morrison</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/AI-discovered.20proof.20on.20psi-integrals.20.28with.20Lean.20formalizat.2E.29/near/564154076\">said</a>:</p>\n<blockquote>\n<p>If you ping me once these PRs are merged I can do a second pass.</p>\n</blockquote>\n<p>Merged; generated docs are <a href=\"https://e-vergo.github.io/Balanced_Vectors/docs/BalancedVectors/MainTheorem.html#StatementOfTheorem\">here</a>.</p>",
        "id": 564350620,
        "sender_full_name": "Eric Vergo",
        "timestamp": 1766009176
    },
    {
        "content": "<p>95 messages were moved from this topic to <a class=\"stream-topic\" data-stream-id=\"287929\" href=\"/#narrow/channel/287929-mathlib4/topic/Mathlib.20as.20a.20source.20of.20definitions/with/564826082\">#mathlib4 &gt; Mathlib as a source of definitions</a> by <span class=\"user-mention silent\" data-user-id=\"240862\">Oliver Nash</span>.</p>",
        "id": 564826085,
        "sender_full_name": "Notification Bot",
        "timestamp": 1766234912
    }
]