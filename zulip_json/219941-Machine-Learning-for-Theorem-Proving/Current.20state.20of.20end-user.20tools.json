[
    {
        "content": "<p>A new year begins and I have a couple of new propaganda talks to prepare. As which each new round of talks, I try to figure out whether I could show anything using ML. There was one year when I could show autoformalization in Lean 3 using Zhangir and Ed’s Lean chat extension. But since then I was never able to find anything that could be seen as useful to users (as opposed to nice research projects) except for moogle/LeanSearch. Is there anything that is usable today and would propose either auto-formalization or suggest next step? Note that I don’t want to show Copilot since it seems to simply remember what I typed while preparing the demo.</p>",
        "id": 491866502,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1735987535
    },
    {
        "content": "<p>I use copilot and I agree that it's good at remembering, which makes it look even more exciting.</p>",
        "id": 491867608,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1735988575
    },
    {
        "content": "<p>LeanAide does some Autoformalization tolerably. I will send a demo video soon.</p>",
        "id": 491868657,
        "sender_full_name": "Siddhartha Gadgil",
        "timestamp": 1735989494
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110038\">Kevin Buzzard</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Current.20state.20of.20end-user.20tools/near/491867608\">said</a>:</p>\n<blockquote>\n<p>I use copilot and I agree that it's good at remembering, which makes it look even more exciting.</p>\n</blockquote>\n<p>I think there are already enough people whose full-time job is to lie about what LLMs can dot, they don’t need my help.</p>",
        "id": 491871341,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1735992029
    },
    {
        "content": "<p>I will definitely try LeanAide before my next talk.</p>",
        "id": 491871519,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1735992150
    },
    {
        "content": "<p>Some folks like <span class=\"user-mention\" data-user-id=\"110087\">@Kim Morrison</span> have said that Sonnet 3.5 is pretty good at getting Lean syntax right.  It however is not free (and you also need a free AI coding assistant plugin like <a href=\"http://Continue.dev\">Continue.dev</a> or a VS-Code AI-enabled clone like Cursor.  Those also work with all sorts of LLM models.)</p>",
        "id": 491873521,
        "sender_full_name": "Jason Rute",
        "timestamp": 1735993912
    },
    {
        "content": "<p>It is unfortunate that Lean syntax massively changed right in the middle of the AI boom.  This has created a lot of artificial problems that I think Isabelle doesn’t have.  (Rocq/Coq neither although Rocq’s/Coq’s lack of standard libraries is an interesting challenge.) It still might be possible there is a good prompt to get standard LLMs to avoid common mistakes like <code>import Mathlib.Data.Nat.Basic</code>.</p>",
        "id": 491873528,
        "sender_full_name": "Jason Rute",
        "timestamp": 1735993922
    },
    {
        "content": "<p>One thing I suggest is noting some examples you would like to see.  Then maybe someone with Sonnet  3.5 access or LeanAide access (<span class=\"user-mention\" data-user-id=\"266304\">@Siddhartha Gadgil</span> ) could let you know if current tools can do it.</p>",
        "id": 491873573,
        "sender_full_name": "Jason Rute",
        "timestamp": 1735993930
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"266304\">@Siddhartha Gadgil</span> is LeanAide able to use Sonnet 3.5 and other LLM APIs, or just OpenAI?</p>",
        "id": 491873575,
        "sender_full_name": "Jason Rute",
        "timestamp": 1735993932
    },
    {
        "content": "<p>LeanAide primarily uses the \"OpenAI API\", but this is supported by many models (e.g. Mistral on vLLM). I also have support for the Gemini API. In practice I am mostly using the OpenAI models.</p>\n<p>One thing I plan to try soon is to switch to using <a href=\"https://github.com/cmu-l3/llmlean\">LLMLean</a> instead of my small ad hoc (curl based) internal API. Ideally we should all use common packages for common tasks, and if some important support is missing then it can be contributed upstream.</p>",
        "id": 491874112,
        "sender_full_name": "Siddhartha Gadgil",
        "timestamp": 1735994409
    },
    {
        "content": "<p>Thanks Jason. I’m not interested in non-free tools or tools that force using a weird editor.</p>",
        "id": 491874209,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1735994501
    },
    {
        "content": "<p>Does LeanAide require a subscription to some LLM?</p>",
        "id": 491874285,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1735994546
    },
    {
        "content": "<p>In the default configuration <code>LeanAide</code> uses GPT-4o, so does require this. However, one can locally host (say using <code>vLLM</code>) another model and configure it to use the correct url.</p>\n<p>In my experiments, for at least a relatively easy set the model <code>Mathstral</code> from <em>Mistral</em> gave decent results. It can be run on a workstation with a single 20GB GPU (which my department has). Testing with other open models is something I would like, but am personally prioritising getting things working with the best models (and easiest to use) available.</p>",
        "id": 491874539,
        "sender_full_name": "Siddhartha Gadgil",
        "timestamp": 1735994774
    },
    {
        "content": "<p>I think many other public models also use OpenAI’s API syntax.</p>",
        "id": 491875019,
        "sender_full_name": "Jason Rute",
        "timestamp": 1735995168
    },
    {
        "content": "<p>Indeed, it has become the standard. Even Gemini supports it by public demand. LeanAide can use any such model - one just has to specify by url.</p>",
        "id": 491875068,
        "sender_full_name": "Siddhartha Gadgil",
        "timestamp": 1735995227
    },
    {
        "content": "<p>So it can use other models as long as someone has an API url/key and that API supports OpenAI’s standard?</p>",
        "id": 491875271,
        "sender_full_name": "Jason Rute",
        "timestamp": 1735995392
    },
    {
        "content": "<p>Yes for open models, at least if the configuration is of the form I expect. I have hosted models within our LAN with LLM and used them by specifying the url.</p>\n<p>As of now, there is no support for authentication other than OpenAI, Gemini and Azure-OpenAI. But this will be easy to add.</p>",
        "id": 491875394,
        "sender_full_name": "Siddhartha Gadgil",
        "timestamp": 1735995524
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110031\">Patrick Massot</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Current.20state.20of.20end-user.20tools/near/491871341\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"110038\">Kevin Buzzard</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Current.20state.20of.20end-user.20tools/near/491867608\">said</a>:</p>\n<blockquote>\n<p>I use copilot and I agree that it's good at remembering, which makes it look even more exciting.</p>\n</blockquote>\n<p>I think there are already enough people whose full-time job is to lie about what LLMs can dot, they don’t need my help.</p>\n</blockquote>\n<p>I don't follow - can you please elaborate on what you have against copilot?</p>",
        "id": 491878486,
        "sender_full_name": "Alex Kontorovich",
        "timestamp": 1735998217
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"115715\">Jason Rute</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Current.20state.20of.20end-user.20tools/near/491873528\">said</a>:</p>\n<blockquote>\n<p>It is unfortunate that Lean syntax massively changed right in the middle of the AI boom.  This has created a lot of artificial problems that I think Isabelle doesn’t have.  (Rocq/Coq neither although Rocq’s/Coq’s lack of standard libraries is an interesting challenge.) It still might be possible there is a good prompt to get standard LLMs to avoid common mistakes like <code>import Mathlib.Data.Nat.Basic</code>.</p>\n</blockquote>\n<p>Did anyone from the Lean community react to <a href=\"https://openai.com/form/rft-research-program/\">https://openai.com/form/rft-research-program/</a> ? I was half-tempted but decided I already had enough on my plate.</p>",
        "id": 491878561,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1735998263
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"252920\">Alex Kontorovich</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Current.20state.20of.20end-user.20tools/near/491878486\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"110031\">Patrick Massot</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Current.20state.20of.20end-user.20tools/near/491871341\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"110038\">Kevin Buzzard</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Current.20state.20of.20end-user.20tools/near/491867608\">said</a>:</p>\n<blockquote>\n<p>I use copilot and I agree that it's good at remembering, which makes it look even more exciting.</p>\n</blockquote>\n<p>I think there are already enough people whose full-time job is to lie about what LLMs can dot, they don’t need my help.</p>\n</blockquote>\n<p>I don't follow - can you please elaborate on what you have against copilot?</p>\n</blockquote>\n<p>Here specifically I mean the following sequence of actions does not produce accurate things to show in a talk:</p>\n<ul>\n<li>I prepare some Lean demo in VSCode, by typing everything myself.</li>\n<li>Then I wonder whether Copilot could have helped and I could show it during the talk, so I try turning on suggestios</li>\n<li>Now Copilot simply copy-paste what I did in step 1, because it remembers me typing it.</li>\n</ul>\n<p>I saw this happening and I remember Jeremy also had this issue (and it seems Kevin saw it too).</p>",
        "id": 491880768,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1736000358
    },
    {
        "content": "<p>This specific concern is completely independent from the general issues surrounding LLMs.</p>",
        "id": 491880794,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1736000391
    },
    {
        "content": "<p>Yes it happened to me precisely once and I laughed it off (and told the audience what had probably happened, because it hadn't happened in the rehearsal!)</p>",
        "id": 491880881,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1736000451
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"115715\">Jason Rute</span> <a href=\"#narrow/stream/219941-Machine-Learning-for-Theorem-Proving/topic/Current.20state.20of.20end-user.20tools/near/491873573\">said</a>:</p>\n<blockquote>\n<p>One thing I suggest is noting some examples you would like to see.  Then maybe someone with Sonnet  3.5 access or LeanAide access (<span class=\"user-mention silent\" data-user-id=\"266304\">Siddhartha Gadgil</span> ) could let you know if current tools can do it.</p>\n</blockquote>\n<p>I again want to strongly emphasis this.  It is often difficult or intimidating for users to directly try out new tools like LeanAide, Lean Copilot, or Continue.dev+Sonnet 3.5.  Also those who do know how to use the tools often don’t share their experiences.  I think a middle ground is for users to share problems they would like these tools to solve and those who are comfortable with the tools try those problems out on them.  Also it is just good in general for us to collect lists of problems we would like an AI tool to solve.  It isn’t ideal, but I think it would help.</p>",
        "id": 491883106,
        "sender_full_name": "Jason Rute",
        "timestamp": 1736002467
    },
    {
        "content": "<p>To get started, here is something I tried recently with limited success:</p>\n<blockquote>\n<p>Write a Lean 4 proof of the fact that the square of the sum of the first $n$ numbers is the sum of the first $n$ cubes.</p>\n</blockquote>",
        "id": 491883143,
        "sender_full_name": "Jason Rute",
        "timestamp": 1736002519
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"115715\">Jason Rute</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Current.20state.20of.20end-user.20tools/near/491883143\">said</a>:</p>\n<blockquote>\n<p>To get started, here is something I tried recently with limited success:</p>\n<blockquote>\n<p>Write a Lean 4 proof of the fact that the square of the sum of the first $n$ numbers is the sum of the first $n$ cubes.</p>\n</blockquote>\n</blockquote>\n<p>I agree with this idea. LeanAide is not yet ready for this level of autoformalization but this is a current focus so hopefully it will get better in a month or so. For now, it assumes that the formulas for sums of numbers and of cubes of numbers are known (we should recursively ask for the proofs of these, which is one of the things I have to work on).</p>",
        "id": 491886863,
        "sender_full_name": "Siddhartha Gadgil",
        "timestamp": 1736005906
    },
    {
        "content": "<p>If I ask Grok for example it gets the statement mostly right.  It just messes up the imports (like most models do) and doesn’t open Finset.  The proof is wrong on multiple accounts.</p>\n<div class=\"codehilite\" data-code-language=\"Lean4\"><pre><span></span><code><span class=\"kn\">import</span><span class=\"w\"> </span><span class=\"n\">Mathlib</span><span class=\"bp\">.</span><span class=\"n\">Data</span><span class=\"bp\">.</span><span class=\"n\">Nat</span><span class=\"bp\">.</span><span class=\"n\">Basic</span>\n<span class=\"kn\">import</span><span class=\"w\"> </span><span class=\"n\">Mathlib</span><span class=\"bp\">.</span><span class=\"n\">Data</span><span class=\"bp\">.</span><span class=\"n\">Nat</span><span class=\"bp\">.</span><span class=\"n\">Parity</span>\n<span class=\"kn\">import</span><span class=\"w\"> </span><span class=\"n\">Mathlib</span><span class=\"bp\">.</span><span class=\"n\">Tactic</span><span class=\"bp\">.</span><span class=\"n\">Linarith</span>\n\n<span class=\"kn\">theorem</span><span class=\"w\"> </span><span class=\"n\">sum_of_squares_is_sum_of_cubes</span><span class=\"w\"> </span><span class=\"o\">(</span><span class=\"n\">n</span><span class=\"w\"> </span><span class=\"o\">:</span><span class=\"w\"> </span><span class=\"n\">ℕ</span><span class=\"o\">)</span><span class=\"w\"> </span><span class=\"o\">:</span>\n<span class=\"w\">  </span><span class=\"o\">(</span><span class=\"bp\">∑</span><span class=\"w\"> </span><span class=\"n\">i</span><span class=\"w\"> </span><span class=\"k\">in</span><span class=\"w\"> </span><span class=\"n\">range</span><span class=\"w\"> </span><span class=\"n\">n</span><span class=\"o\">,</span><span class=\"w\"> </span><span class=\"n\">i</span><span class=\"o\">)</span><span class=\"bp\">^</span><span class=\"mi\">2</span><span class=\"w\"> </span><span class=\"bp\">=</span><span class=\"w\"> </span><span class=\"bp\">∑</span><span class=\"w\"> </span><span class=\"n\">i</span><span class=\"w\"> </span><span class=\"k\">in</span><span class=\"w\"> </span><span class=\"n\">range</span><span class=\"w\"> </span><span class=\"n\">n</span><span class=\"o\">,</span><span class=\"w\"> </span><span class=\"n\">i</span><span class=\"bp\">^</span><span class=\"mi\">3</span><span class=\"w\"> </span><span class=\"o\">:=</span><span class=\"w\"> </span><span class=\"k\">by</span>\n<span class=\"w\">  </span><span class=\"c1\">-- Use induction on n</span>\n<span class=\"w\">  </span><span class=\"n\">induction</span><span class=\"w\"> </span><span class=\"n\">n</span><span class=\"w\"> </span><span class=\"k\">with</span>\n<span class=\"w\">  </span><span class=\"bp\">|</span><span class=\"w\"> </span><span class=\"n\">zero</span><span class=\"w\"> </span><span class=\"bp\">=&gt;</span>\n<span class=\"w\">    </span><span class=\"c1\">-- Base case: when n is 0, both sums are 0</span>\n<span class=\"w\">    </span><span class=\"n\">simp</span><span class=\"w\"> </span><span class=\"n\">only</span><span class=\"w\"> </span><span class=\"o\">[</span><span class=\"n\">range_zero</span><span class=\"o\">,</span><span class=\"w\"> </span><span class=\"n\">sum_nil</span><span class=\"o\">,</span><span class=\"w\"> </span><span class=\"n\">pow_zero</span><span class=\"o\">,</span><span class=\"w\"> </span><span class=\"n\">zero_pow</span><span class=\"o\">]</span>\n<span class=\"w\">  </span><span class=\"bp\">|</span><span class=\"w\"> </span><span class=\"n\">succ</span><span class=\"w\"> </span><span class=\"n\">n</span><span class=\"w\"> </span><span class=\"n\">ih</span><span class=\"w\"> </span><span class=\"bp\">=&gt;</span>\n<span class=\"w\">    </span><span class=\"c1\">-- Step case: assume the theorem holds for n, prove for n+1</span>\n<span class=\"w\">    </span><span class=\"n\">simp</span><span class=\"w\"> </span><span class=\"n\">only</span><span class=\"w\"> </span><span class=\"o\">[</span><span class=\"n\">range_succ</span><span class=\"o\">,</span><span class=\"w\"> </span><span class=\"n\">sum_range_succ</span><span class=\"o\">,</span><span class=\"w\"> </span><span class=\"n\">pow_two</span><span class=\"o\">]</span>\n<span class=\"w\">    </span><span class=\"c1\">-- Expand both sides using the induction hypothesis</span>\n<span class=\"w\">    </span><span class=\"n\">rw</span><span class=\"w\"> </span><span class=\"o\">[</span><span class=\"n\">ih</span><span class=\"o\">,</span><span class=\"w\"> </span><span class=\"bp\">←</span><span class=\"w\"> </span><span class=\"n\">add_assoc</span><span class=\"o\">,</span><span class=\"w\"> </span><span class=\"n\">add_mul</span><span class=\"o\">,</span><span class=\"w\"> </span><span class=\"n\">mul_add</span><span class=\"o\">,</span><span class=\"w\"> </span><span class=\"n\">mul_comm</span><span class=\"w\"> </span><span class=\"o\">(</span><span class=\"n\">n</span><span class=\"w\"> </span><span class=\"bp\">*</span><span class=\"w\"> </span><span class=\"o\">(</span><span class=\"n\">n</span><span class=\"w\"> </span><span class=\"bp\">+</span><span class=\"w\"> </span><span class=\"mi\">1</span><span class=\"o\">))</span><span class=\"w\"> </span><span class=\"mi\">1</span><span class=\"o\">]</span>\n<span class=\"w\">    </span><span class=\"c1\">-- Simplify the expression</span>\n<span class=\"w\">    </span><span class=\"n\">ring</span>\n</code></pre></div>",
        "id": 491887291,
        "sender_full_name": "Jason Rute",
        "timestamp": 1736006276
    },
    {
        "content": "<p>(for example <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mn>2025</mn><mo>=</mo><msubsup><mo>∑</mo><mrow><mi>n</mi><mo>=</mo><mn>1</mn></mrow><mn>9</mn></msubsup><msup><mi>n</mi><mn>3</mn></msup></mrow><annotation encoding=\"application/x-tex\">2025=\\sum_{n=1}^9n^3</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6444em;\"></span><span class=\"mord\">2025</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.2537em;vertical-align:-0.2997em;\"></span><span class=\"mop\"><span class=\"mop op-symbol small-op\" style=\"position:relative;top:0em;\">∑</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.954em;\"><span style=\"top:-2.4003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">n</span><span class=\"mrel mtight\">=</span><span class=\"mord mtight\">1</span></span></span></span><span style=\"top:-3.2029em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">9</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2997em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">n</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">3</span></span></span></span></span></span></span></span></span></span></span> :-), certainly the only time I'll see that phenomenon in my lifetime! )</p>",
        "id": 491887408,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1736006372
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"266304\">@Siddhartha Gadgil</span> The sum of the first n numbers is in mathlib.  <a href=\"https://leanprover-community.github.io/mathlib4_docs/find/?pattern=Finset.sum_range_id#doc\">docs#Finset.sum_range_id</a></p>",
        "id": 491887415,
        "sender_full_name": "Jason Rute",
        "timestamp": 1736006383
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"115715\">@Jason Rute</span> Thanks for this. Seeing what is happening in my code immendiately suggests a logical improvement which I will implement (currently I only search for results used to prove a claim, I should search for the claims themselves too).</p>",
        "id": 491888003,
        "sender_full_name": "Siddhartha Gadgil",
        "timestamp": 1736006885
    },
    {
        "content": "<p>I don't need a copilot-type LLM to give me entire theorem statements (let alone correct, formalized proofs); even if it suggests statements that are <em>close</em> to what I need, that's already a great speed-up of my workflow. (I want <em>quasi-autoformalization</em>, where I'm allowed to interact with the LLM and correct its code, not try to get it to do everything perfectly all by itself.) In that sense, I find github's copilot, seamlessly integrated in VSCode, to already be extremely useful. In my opinion, the fact that it remembers something I deleted and suggests it next, thereby ruining a demo that's been practiced, is not reason not to show it to people as a useful resource...(?) (In the PEP I'm running at the JMM, I certainly plan to show people how to harness every chatbot I know of, in case it helps them formalize mathematics...)</p>",
        "id": 491889145,
        "sender_full_name": "Alex Kontorovich",
        "timestamp": 1736007970
    },
    {
        "content": "<p>I would love someone to do a systematic evaluation (even if not scientific) of all the major LLMs for code on Lean in a tool like GitHub Copilot, <a href=\"http://Continue.dev\">Continue.dev</a>, or Cursor.  Models like Codestral, Claude Sonnet 3.5, GPt-4o, GPT-4, Qwen-2.5-coder, Llama-3.5, Gemini, and more.  Also chat bots like ChatGPT, Gemini, Grok, etc., and reasoning chat bots like GPT-o1-mini/preview//pro, Gemini-2.0-flash-thinking, QwQ, DeepSeek-R1, etc.</p>",
        "id": 491889723,
        "sender_full_name": "Jason Rute",
        "timestamp": 1736008534
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"252920\">Alex Kontorovich</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Current.20state.20of.20end-user.20tools/near/491889145\">said</a>:</p>\n<blockquote>\n<p>In my opinion, the fact that it remembers something I deleted and suggests it next, thereby ruining a demo that's been practiced, is not reason not to show it to people as a useful resource...(?)</p>\n</blockquote>\n<p>This is not in a teaching context where I try to teach people how to formalize mathematics. It is in a context where I try to show what proof assistants can do today. So showing a LLM example where the LLM does everything perfectly because it saw it before would just be a lie.</p>",
        "id": 491890307,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1736009133
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"110031\">@Patrick Massot</span> is the only issue the copying?  Like if some other plugin didn’t remember erased code and gave ok-but-not-perfectly correct Lean code suggestions, would that be interesting to you?</p>",
        "id": 491890497,
        "sender_full_name": "Jason Rute",
        "timestamp": 1736009326
    },
    {
        "content": "<p>Yes, in that context that would be great.</p>",
        "id": 491890541,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1736009381
    },
    {
        "content": "<p>You could try <a href=\"http://continue.dev\">continue.dev</a> plugin with different models and see if they have this behavior.  I don’t know if the memorizing behavior of GitHub Copilot is through the model API or the plugin.  Or the more difficult-to-implement approach is to do the demo with a fresh problem every time, or to never fix the generate code for the example. :/ Another not ideal approach is to use a Chat interface like ChatGPT and copy and paste the code.</p>",
        "id": 491891285,
        "sender_full_name": "Jason Rute",
        "timestamp": 1736010137
    },
    {
        "content": "<p><a href=\"https://www.reddit.com/r/github/comments/1at5juv/comment/kr4lzw9/\">A Reddit thread</a> guesses that this Github CoPilot behavior is due to turning on the option “Allow GitHub to use my code snippets for product improvements”.</p>",
        "id": 491891688,
        "sender_full_name": "Jason Rute",
        "timestamp": 1736010504
    },
    {
        "content": "<p>(Repeating what I've said before, the Clause Sonnet powered code completion agent available in Cursor is night-and-day better than Github Copilot. Switching to Cursor was pretty much painless for me --- I still have to use VS Code for remote ssh sessions, but otherwise haven't noticed any other annoyance. I would love to hear others' experience with it.)</p>",
        "id": 491922862,
        "sender_full_name": "Kim Morrison",
        "timestamp": 1736038837
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"110087\">@Kim Morrison</span> Just like Lean-specific tools like LeanAide and Lean Copilot I think non-Lean-specific tools like Cursor+Sonnet are confusing to people (although they are probably easier to install and use).  Do you think you are the only Lean user using Cursor+Sonnet? I’ll try it out soon and let people know my thoughts but here are some quick questions for you or someone else who knows:</p>\n<ul>\n<li>is the cursor+sonnet experience due more to cursor or sonnet?  (Cursor is an IDE and Sonnet is a model.  I think Sonnet is not free.)</li>\n<li>how much does this setup cost  a month?</li>\n<li>does it help with Lean specific tasks like autoformalization or filling in a proof, or just generic programming like refactoring, boilerplate, and other standard stuff?</li>\n<li>what is a good user workflow for people doing formalization projects using Cursor+Sonnet?</li>\n<li>what are some tasks it really excels at?</li>\n<li>what does it suck at?</li>\n<li>Lean has a lot of hidden information like goal states or the error messages of tactics.  Is there any good way to expose this to the model?  Like pasting the goalstate or asking it to fix an error?</li>\n<li>is there any special setup?  Like can you change the system prompt to get the model to avoid common mistakes or learn how to query <code>#loogle</code>, <code>#moogle</code> or try tactics like <code>exact?</code>?</li>\n</ul>",
        "id": 491924924,
        "sender_full_name": "Jason Rute",
        "timestamp": 1736041123
    },
    {
        "content": "<p>(I don't know the answers to most of that) but I'll just mention that I know that the <a href=\"https://github.com/yetone/avante.nvim\">Neovim equivalent of Cursor</a> supports lots of models but tells users not to bother with anything other than Sonnet and that the other models have much worse performance.</p>",
        "id": 491925491,
        "sender_full_name": "Julian Berman",
        "timestamp": 1736041707
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"110087\">@Kim Morrison</span> To clarify, I didn’t mean it pejoratively when I asked if you are the only Cursor+Sonnet Lean user.  It is a legitamate question.</p>",
        "id": 491926101,
        "sender_full_name": "Jason Rute",
        "timestamp": 1736042340
    },
    {
        "content": "<p>You are the only one who talks about using that setup here on Zulip.</p>",
        "id": 491926147,
        "sender_full_name": "Jason Rute",
        "timestamp": 1736042397
    },
    {
        "content": "<ul>\n<li>The nice experience is both the interface and the model:<ul>\n<li>Cursor will suggest multiline edits, as well as include visual prompts that it has a suggestion further down the screen than your cursor, which <code>tab</code> will take you too.</li>\n<li>The model seems to know Lean 4 syntax well. It routinely suggestions well-formed <code>cases</code> and <code>induction</code> structured tactics, and I don't recall seeing <em>any</em> Lean 3 isms.</li>\n<li>Cursor seamlessly provides good context. I've been doing some boring work making the <code>Array</code> API match the <code>List</code> API, and Cursor regularly manages to suggest the next <code>Array</code> theorem (name, statement, and correct proof), apparently looking at the corresponding <code>List</code> file open in a different tab to work out what comes next, and seeing the pattern of how I've been proving the recent <code>Array</code> theorems.</li>\n</ul>\n</li>\n<li>I think I pay $20USD/month (or rather, the FRO does). I'd happily pay quite a bit more, tbh.</li>\n<li>It's worth noting that I've been really enjoying Cursor while I'm working through this tedious <code>List</code>/<code>Array</code> work, which has a lot of boilerplate. But I still regularly use it elsewhere.</li>\n<li>In terms of workflow, I don't attempt to use anything besides the \"out of the box\" experience. If tab completion suggests something good, I take it, but I don't attempt to prompt it at all.</li>\n<li>That said, the built in chat mode is great for writing shell/python/github scripts. I find it better than using ChatGPT canvas mode because the editor integration lets me see what changes it is suggesting more easily.</li>\n<li>I haven't done any experiments to work out how much of error messages it is reading, but I would really really like to know this! </li>\n<li>I have not investigated custom prompts.</li>\n</ul>",
        "id": 491938567,
        "sender_full_name": "Kim Morrison",
        "timestamp": 1736056160
    },
    {
        "content": "<p>I am giving a talk at the JMM where I would also like to showcase the state-of-the-art of autoformalization tools such as LeanCopilot, LLMlean, and LeanAide.  I've found each of these tools frustratingly difficult to set up, and unfortunately I've spent far more time trying to get them correctly installed than I've been able to actually experiment with them.  It's usually the first step of the installation in the readme file that trips me up.  The instructions always seem written with professional developers in mind.  </p>\n<p>Right now, in addition to github copilot (which I've never had issues getting to work), the only other tool that I have working now is LLMlean, so that's the one I will demo this week.</p>",
        "id": 492030782,
        "sender_full_name": "Jarod Alper",
        "timestamp": 1736138260
    },
    {
        "content": "<p>What is the talk?</p>",
        "id": 492036009,
        "sender_full_name": "Jason Rute",
        "timestamp": 1736141439
    },
    {
        "content": "<p>But I do agree the Lean-specific ones are very hard to set up (and far in perceived user performance from the research papers).  I am still having trouble getting Lean Copilot working again. I just tried Cursor today and it was very easy to setup (and showed a lot of potential).  (I’m not entirely sure how it is using Sonnet 3.5 since I don’t recalling having a paid Sonnet account.  Is it a trial period?)</p>",
        "id": 492036394,
        "sender_full_name": "Jason Rute",
        "timestamp": 1736141647
    },
    {
        "content": "<p>(I’m also giving a talk at JMM, but currently don’t plan to demo any tools.)</p>",
        "id": 492036492,
        "sender_full_name": "Jason Rute",
        "timestamp": 1736141729
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"115715\">@Jason Rute</span> <span class=\"user-mention\" data-user-id=\"490964\">@Jarod Alper</span> Please let me know what part of LeanAide installation is hard. I have updated the README at <a href=\"https://github.com/siddhartha-gadgil/LeanAide\">https://github.com/siddhartha-gadgil/LeanAide</a>. There are probably issues still, but if you let me know I will try to fix them.</p>",
        "id": 492040974,
        "sender_full_name": "Siddhartha Gadgil",
        "timestamp": 1736144110
    },
    {
        "content": "<blockquote>\n<p>Is it a trial period?</p>\n</blockquote>\n<p>Yes. I remember it lasting me about a week (I think it depends on number of queries, not a fixed amount of time.)</p>",
        "id": 492046048,
        "sender_full_name": "Kim Morrison",
        "timestamp": 1736146708
    },
    {
        "content": "<p>I was given 2 weeks recently for cursor/sonnet</p>",
        "id": 492058083,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1736152263
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"266304\">@Siddhartha Gadgil</span> I can give more details later, but I'm struggling to use it inside a new project.  New projects use <code>lakefile.toml</code> (run <code>elan update</code> first).  Also, when I fix that, it still isn't downloading the Mathlib cache.  I think because of lean/mathlib version differences.  See <a href=\"#narrow/channel/113489-new-members/topic/How.20to.20install.20LeanCopilot.3F/near/490799762\"><a class=\"stream-topic\" data-stream-id=\"113489\" href=\"/#narrow/channel/113489-new-members/topic/How.20to.20install.20LeanCopilot.3F\">#new members &gt; How to install LeanCopilot?</a></a> and the surrounding discussion.  I haven't tried directly working with the LeanAide repo yet.  I can try that later.</p>",
        "id": 492128681,
        "sender_full_name": "Jason Rute",
        "timestamp": 1736178125
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"115715\">Jason Rute</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Current.20state.20of.20end-user.20tools/near/492128681\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"266304\">Siddhartha Gadgil</span> I can give more details later, but I'm struggling to use it inside a new project.  New projects use <code>lakefile.toml</code> (run <code>elan update</code> first).  Also, when I fix that, it still isn't downloading the Mathlib cache.  I think because of lean/mathlib version differences.  See <a href=\"#narrow/channel/113489-new-members/topic/How.20to.20install.20LeanCopilot.3F/near/490799762\"><a class=\"stream-topic\" data-stream-id=\"113489\" href=\"/#narrow/channel/113489-new-members/topic/How.20to.20install.20LeanCopilot.3F\">#new members &gt; How to install LeanCopilot?</a></a> and the surrounding discussion.  I haven't tried directly working with the LeanAide repo yet.  I can try that later.</p>\n</blockquote>\n<p>Thanks. Besides toolchains not matching, there is an issue of embeddings being downloaded. I will sort these issues out in a couple of weeks and try to have a tag/branch for each stable toolchain/mathlib.</p>",
        "id": 492138800,
        "sender_full_name": "Siddhartha Gadgil",
        "timestamp": 1736181172
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"115715\">Jason Rute</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Current.20state.20of.20end-user.20tools/near/492036009\">said</a>:</p>\n<blockquote>\n<p>What is the talk?</p>\n</blockquote>\n<p><a href=\"https://meetings.ams.org/math/jmm2025/meetingapp.cgi/Paper/41640\">Embracing AI and Formalization: Experimenting with Tomorrow's Mathematical Tools</a></p>",
        "id": 492146466,
        "sender_full_name": "Jarod Alper",
        "timestamp": 1736183676
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"266304\">Siddhartha Gadgil</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Current.20state.20of.20end-user.20tools/near/492040974\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"115715\">Jason Rute</span> <span class=\"user-mention silent\" data-user-id=\"490964\">Jarod Alper</span> Please let me know what part of LeanAide installation is hard. I have updated the README at <a href=\"https://github.com/siddhartha-gadgil/LeanAide\">https://github.com/siddhartha-gadgil/LeanAide</a>. There are probably issues still, but if you let me know I will try to fix them.</p>\n</blockquote>\n<p>My first issue was not knowing where to put the <code>export OPENAI_API_KEY=&lt;your-open-ai-key&gt;</code> command.  I tried each of the files<code>.bash_profile</code>,  <code>.zprofile</code>, <code>.zshrc</code>, and <code>.bashrc</code>,  but it didn't work.  I also didn't know whether or not to include the angle brackets; I think not.   In the case of LLMlean, I had a similar issue and simply hard coded my API key into the LLMlean files.  There is also either a missing or an additional quotation mark in the command <code>require LeanCodePrompts from git \"https://github.com/siddhartha-gadgil/LeanAide\"@\"main</code><br>\nFor the record, I tried installing it both by cloning the LeanAide github repository and installing it in my existing Lean project, but neither worked for me. </p>\n<p>I had Lean Lean Copilot working a few months ago, but it stopped working at some point, probably after updating <code>mathlib</code>.</p>",
        "id": 492149879,
        "sender_full_name": "Jarod Alper",
        "timestamp": 1736184730
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"490964\">@Jarod Alper</span> Thanks. I will fix the README. </p>\n<p>The angle brackets are not needed, so example <code>export OPENAI_API_KEY=\"sk-proj-hhPtGBjdz14NO1KxDB5U_kWksdlkk3kJF</code>. For running LeanAide after cloning, here are the steps (and an alternative) from bash:</p>\n<div class=\"codehilite\" data-code-language=\"Bash\"><pre><span></span><code>./fetch.sh\n<span class=\"nb\">export</span><span class=\"w\"> </span><span class=\"nv\">OPENAI_API_KEY</span><span class=\"o\">=</span>&lt;your-open-ai-key&gt;\ncode<span class=\"w\"> </span>.\n</code></pre></div>\n<p>That is, we open <code>code</code> from a shell after setting the environment variable. One can also edit <code>.bashrc</code>, then open a <em>new</em> shell and launch code from that.</p>\n<p>As environment variables can be fiddly in some contexts, an alternative is to have your OPENAI API key as the contents of the file with path <code>rawdata/OPENAI_API_KEY</code>relative to the base of the LeanAide project.</p>\n<p>Using from another project smoothly will take some work from me (embeddings are toolchain specific so matching is an issue) but the repository by itself should work as above.</p>",
        "id": 492157341,
        "sender_full_name": "Siddhartha Gadgil",
        "timestamp": 1736187256
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"266304\">@Siddhartha Gadgil</span> Thank you! I was able to get it working.</p>",
        "id": 492441574,
        "sender_full_name": "Jarod Alper",
        "timestamp": 1736317422
    },
    {
        "content": "<p>I'll mention <a href=\"https://github.com/GasStationManager/LeanTool\">LeanTool</a> which I've been working on. I would say it is in an experimental stage, as I'm not aware of any user other than me. But I want to advocate for the general approach, of exposing to the AI all the features that makes lean a nice <em>interactive</em> theorem prover for human users: error message feedback for syntax errors;  goals from sorries; search engines like Moogle and LeanSearch; interactive commands like <code>apply?</code>, <code>plausible</code>, and automated proving tools like <code>aesop</code>, <code>Duper</code>,  and <code>lean-auto</code>.  The rationale is that general-purpose LLMs (open source or otherwise) will keep getting stronger in their general intelligence and reasoning abilities; we just need to provide the rest.</p>\n<p>Many of these features are not in the training data of these LLMs for various reasons, so to get the LLM to use them would require some prompting efforts. Some initial efforts in the <a href=\"https://github.com/GasStationManager/LeanTool\">repo</a>; but many folks here have more experience/expertise in the usage of these features, so suggestions are appreciated!</p>",
        "id": 492546187,
        "sender_full_name": "GasStationManager",
        "timestamp": 1736355354
    },
    {
        "content": "<p>(deleted)</p>",
        "id": 492566494,
        "sender_full_name": "Vedant Gupta",
        "timestamp": 1736362785
    },
    {
        "content": "<p>I've been scanning through all of the threads in <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving\">#Machine-Learning-for-Theorem-Proving</a> and am kind of surprised that there isn't more interest in DSP-V1.5. </p>\n<p>As far as I can see, this model has the \"best\" absolute performance on miniF2F/ProofNet. But (at least for me) it's gated by the fact that</p>\n<ol>\n<li>I can't run it easily.</li>\n<li>It's not very useful in covering the \"last mile\" of friction that makes it easy to integrate into a workflow. By \"last mile\" I mean the small sub-goals you often sorry at first before closing them at the end, because they are not hard enough to warrant immediate attention but also complicated enough to be annoying to deal with.</li>\n</ol>\n<p>Right now DSP-V1.5 is trained on whole-proof generation on the actual theorem text, rather than pairs of (context, goals) states. So although DSP-V1.5 can close pretty complicated goals (like <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Simple.20but.20hard.20puzzler.20for.20LLMs/near/489111901\">here</a>), it can't reason starting from the state in the middle of a proof. Or I guess it can, but only in an ad-hoc manner that consumes the entire text representation of the theorem again and attempts to continue the proof from that text.</p>\n<p>The other issue with these tools is that they don't update their knowledge based on new data the user might have just written. So if you're working on a new project with lemmas about some new object X, then the model has no idea what X is because it doesn't exist in the training data. </p>\n<p>(warning: I don't know much about ML and the following is highly-likely to be somewhat BS)</p>\n<p>Shouldn't it be possible to use the method done for DSP-V1.5 but use (context, goals) for the training data? Assuming the performance can be the same, this would be much easier to integrate into something like <a href=\"https://github.com/cmu-l3/llmlean\">LLMLean</a> or other gym environments. </p>\n<p>For the other issue, shouldn't there be some way to handle this with a RAG database? That's pretty much the extent of my knowledge on how this stuff works. (Does LeanCopilot try to do something like this?)</p>\n<p>But assuming these two issues can be fixed, the next step would be to add this as a backend to something like LLMLean or LeanCopilot to expose it as a tactic to end-users. There should be a considerable jump in the complexity of what \"last mile\"  goals can be closed.</p>",
        "id": 496473585,
        "sender_full_name": "Hanting Zhang",
        "timestamp": 1738128304
    },
    {
        "content": "<p>When you say (context, goals) what do you mean by context?  Local context?  If so that is what a number of papers do.  Have you looked at older papers like Hyper Tree Proof Search (or the new version ABEL)?  Also AlphaProof might work that way.</p>",
        "id": 496549442,
        "sender_full_name": "Jason Rute",
        "timestamp": 1738157659
    },
    {
        "content": "<p>But I’m a bit confused.  Doesn’t Deepseek-Prover v1.5 have the ability to start in the middle of a proof?  Isn’t that the point of the v1.5 tree search?  As for consuming the whole proof, if there is good prompt caching, this could mitigate the cost of long prompts in the tree search.</p>",
        "id": 496549464,
        "sender_full_name": "Jason Rute",
        "timestamp": 1738157666
    },
    {
        "content": "<p>As for keeping up-to-date, you can check out papers like LeanDojo, Graph2Tac (for Coq), Rango (for Coq), Mini CXT.  Also there are many more ways to keep a prover up-to-date and it isn’t clear what is best.  There is another thread on here discussing many options.</p>",
        "id": 496549472,
        "sender_full_name": "Jason Rute",
        "timestamp": 1738157669
    },
    {
        "content": "<p>Also finally, another thing with DeepSeek Prover is that it was only trained on competition type problems so it probably wouldn’t be useful in practice.   But it is a great paper I agree!</p>",
        "id": 496549739,
        "sender_full_name": "Jason Rute",
        "timestamp": 1738157753
    },
    {
        "content": "<p>DeepSeek Prover v1.5 can start in the middle of the proof. It consumes the current proof state as a comment.</p>",
        "id": 496551309,
        "sender_full_name": "Thomas Zhu",
        "timestamp": 1738158184
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"115715\">@Jason Rute</span> thanks for pointing out MiniCTX, I wasn't aware of it till now!</p>",
        "id": 496616934,
        "sender_full_name": "Hanting Zhang",
        "timestamp": 1738174899
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"631691\">Thomas Zhu</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Current.20state.20of.20end-user.20tools/near/496551309\">said</a>:</p>\n<blockquote>\n<p>DeepSeek Prover v1.5 can start in the middle of the proof. It consumes the current proof state as a comment.</p>\n</blockquote>\n<p>Yes, I see now. Somehow I missed this reading the paper, but appending as a comment makes total sense.</p>\n<p>Also, reading the MiniCTX paper, </p>\n<ol>\n<li>I would be really interested to see results using DSP-V1.5 instead of 4o. Do you guys have any plans to explore that direction?</li>\n</ol>",
        "id": 496618126,
        "sender_full_name": "Hanting Zhang",
        "timestamp": 1738175319
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"355764\">@Hanting Zhang</span> Yes, we have planned also evaluating DeepSeek-Prover v1.5 on miniCTX (previous discussion regarding this and also using DeepSeek-Prover in general <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Simple.20but.20hard.20puzzler.20for.20LLMs/near/489173792\">here</a>).</p>",
        "id": 496643009,
        "sender_full_name": "Thomas Zhu",
        "timestamp": 1738184702
    },
    {
        "content": "<p>You can also try DeepSeek-R1, which is also trained on the data of DeepSeek-Prover V1.5.</p>",
        "id": 496755248,
        "sender_full_name": "Huajian Xin",
        "timestamp": 1738237291
    },
    {
        "content": "<p>We are also planning to evaluate o1/o3, Sonnet, Gemini Thinking, and R1 on PutnamBench soon. While it is a competition problem dataset, the results will have at least some bearing on what are the best frontier models for Lean tasks are</p>",
        "id": 496863955,
        "sender_full_name": "George Tsoukalas",
        "timestamp": 1738269478
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"481527\">Huajian Xin</span> <a href=\"#narrow/stream/219941-Machine-Learning-for-Theorem-Proving/topic/Current.20state.20of.20end-user.20tools/near/496755248\">said</a>:</p>\n<blockquote>\n<p>You can also try DeepSeek-R1, which is also trained on the data of DeepSeek-Prover V1.5.</p>\n</blockquote>\n<p>Does it mean it was RL'd against lean compiler?</p>",
        "id": 497174195,
        "sender_full_name": "Andy Jiang",
        "timestamp": 1738424415
    },
    {
        "content": "<p>Anecdotally/unscientifically -- I'm personally still finding Sonnet to be more helpful than DS-R1 in helping me with my simplish Lean proofs.</p>",
        "id": 497175841,
        "sender_full_name": "Julian Berman",
        "timestamp": 1738425678
    },
    {
        "content": "<p>Today I was proving some inequality where one side was trivial and the other direction was not (and provided the side of the proof that was easy as input), and DS-R1 suggested some trivially incorrect symmetric argument (a la changing <code>left</code> to <code>right</code>), and Claude actually helped push me in the right direction.</p>",
        "id": 497175968,
        "sender_full_name": "Julian Berman",
        "timestamp": 1738425755
    }
]