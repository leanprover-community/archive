[
    {
        "content": "<p>Do tactic generators such as ReProver output ASTs or raw text that happens to compile? If so, does this cause a lot of lost time during fine tuning or are they pretty good at getting the syntax right</p>",
        "id": 479147795,
        "sender_full_name": "Srivatsa Srinivas",
        "timestamp": 1730047853
    },
    {
        "content": "<p>I believe LLMs are good at getting the syntax right after fine tuning. Nevertheless, I personally guess it might be beneficial if they can output something like AST nodes (so that it is possible to do more constrained decoding)...</p>",
        "id": 479149898,
        "sender_full_name": "Zhanrong Qiao",
        "timestamp": 1730049722
    },
    {
        "content": "<p>LLM-based theorem provers mostly use raw text, but to say \"happens to compile\" is missing the point of many systems including ReProver.  These systems are integrated with Lean, often in a tree search.  So they make suggestions for a tactic, and if that tactic fails (either because of a syntax error, or more likely because that tactic doesn't apply to that situation), then it will backtrack.  (It also backtracks just if the proof is not progressing after some tactic.)</p>",
        "id": 479155982,
        "sender_full_name": "Jason Rute",
        "timestamp": 1730055012
    },
    {
        "content": "<p>Lean's syntax is fairly complicated.  There are systems for other ITPs which use a grammar, either hard-coded (HOList, ASTactic) or extracted automatically from the ITP (Graph2Tac), but still, there is no guarantee that a suggested tactic will \"compile\", just that the right syntax is used for a given tactic.  (Edit: Also these systems are very limited as to what sort of terms you could put in the tactic.  You will not find any <code>have</code>-style tactics in them.)</p>",
        "id": 479156011,
        "sender_full_name": "Jason Rute",
        "timestamp": 1730055045
    },
    {
        "content": "<p>For simpler grammars, there is a notion of constrained decoding, where the LLM is only allowed to make certain token choices that align with a grammar.  A common use case of this is having the LLM produce JSON output.  But for Lean syntax that is really not practical.</p>",
        "id": 479156046,
        "sender_full_name": "Jason Rute",
        "timestamp": 1730055071
    },
    {
        "content": "<p>(By \"compile\", I took the question to mean that the proof is valid, i.e. type-check, but I guess you could be talking about parsing or elaboration.  Even writing general-purpose Lean automation that always parses would be difficult without direct access to Lean's internals, but it would be less challenging than requiring the proof to be valid.)</p>",
        "id": 479158726,
        "sender_full_name": "Jason Rute",
        "timestamp": 1730057474
    },
    {
        "content": "<p>Thanks for the explanation! I guess the rate at which syntactically wrong tactics are constructed creates a headache that is miniscule compared to the Herculean effort it would be to have a constrained decoding of Lean4</p>",
        "id": 479171171,
        "sender_full_name": "Srivatsa Srinivas",
        "timestamp": 1730069134
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"688984\">Srivatsa Srinivas</span> has marked this topic as resolved.</p>",
        "id": 479171185,
        "sender_full_name": "Notification Bot",
        "timestamp": 1730069150
    }
]