[
    {
        "content": "<p>This is the discussion thread for our announcement of the formalization of the Strong PNT. We want to ensure that we can make this technology useful for the community and massively accelerate formalization efforts. We are especially interested in hearing about ideal ergonomics of use, domains of expertise, documentation, and user interfaces.</p>",
        "id": 538916235,
        "sender_full_name": "Auguste Poiroux",
        "timestamp": 1757613106
    },
    {
        "content": "<p>Congrats on the very impressive work! Looking forward to learning more about the details and seeing new applications develop over time. I believe there is a lot of value in this approach.</p>",
        "id": 538919200,
        "sender_full_name": "Simon Sorg",
        "timestamp": 1757614550
    },
    {
        "content": "<p>Those are some monster proof bodies.</p>",
        "id": 538924654,
        "sender_full_name": "Matthew Ballard",
        "timestamp": 1757616840
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"321854\">@Auguste Poiroux</span> could you say a bit more about how much of the Lean code was:</p>\n<ol>\n<li>Written by an LLM?</li>\n<li>Written by a human?</li>\n<li>Written by an LLM but edited by a human?</li>\n</ol>",
        "id": 538924776,
        "sender_full_name": "Adam Topaz",
        "timestamp": 1757616898
    },
    {
        "content": "<p>How much of the terabytes of RAM could be saved if the agents were trained to abstract statements more?</p>",
        "id": 538924870,
        "sender_full_name": "Matthew Ballard",
        "timestamp": 1757616931
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"243562\">@Adam Topaz</span> yes sure. We have a few paragraphs about this in our <a href=\"https://github.com/math-inc/strongpnt?tab=readme-ov-file#details\">readme</a> file. Everything in <code>PNT1_ComplexAnalysis.lean</code>,Â <code>PNT2_LogDerivative.lean</code>,Â <code>PNT3_RiemannZeta.lean</code>, andÂ <code>PNT4_ZeroFreeRegion.lean</code> is generated by Gauss. <code>PNT5_StrongPNT.lean</code>,Â <code>Z0.lean</code>, andÂ <code>ZetaZeroFree.lean</code> are adapted from PNT+, i.e. a few statements were modified to fit the Strong PNT conclusion (in particular the exponent change), and proofs were repaired using Gauss.</p>",
        "id": 538929471,
        "sender_full_name": "Auguste Poiroux",
        "timestamp": 1757618580
    },
    {
        "content": "<p>I see, thanks! That is impressive. Can you say what \"Human Supervision\" means in practice?</p>",
        "id": 538929693,
        "sender_full_name": "Adam Topaz",
        "timestamp": 1757618658
    },
    {
        "content": "<p>Human supervision means that we refined the blueprint latex statements and proofs when the agent struggled to formalize a result.</p>",
        "id": 538930296,
        "sender_full_name": "Auguste Poiroux",
        "timestamp": 1757618891
    },
    {
        "content": "<p>Thanks for the clarification!</p>",
        "id": 538930416,
        "sender_full_name": "Adam Topaz",
        "timestamp": 1757618941
    },
    {
        "content": "<p>Did the LLM also generate the blueprint, or was it completely human written?</p>",
        "id": 538939742,
        "sender_full_name": "Thomas Zhu",
        "timestamp": 1757623199
    },
    {
        "content": "<p>The blueprint is human written. Some informal proofs are LLM-generated</p>",
        "id": 538940092,
        "sender_full_name": "Auguste Poiroux",
        "timestamp": 1757623389
    },
    {
        "content": "<p>How do you ensure that the Lean definitions and theorem statements are a correct formalization of the blueprint?</p>",
        "id": 538941483,
        "sender_full_name": "Ching-Tsun Chou",
        "timestamp": 1757624131
    },
    {
        "content": "<p>Could you say whether you trained Gauss on PNT repo or feed it with the API from PNT repo within the context (or else)?</p>",
        "id": 538941637,
        "sender_full_name": "Matteo Cipollina",
        "timestamp": 1757624240
    },
    {
        "content": "<p>Did the human manually break up lemmas in the blueprint based on the progress of the Guass agent?  For example, say the agent had trouble formalizing Lemma 4.123.  Therefore you rewrote its proof in terms of three more basic lemmas which would be easier for the agent? (I noticed many of the lemmas are really basic and if they are human written, I assume that is why they are their.)</p>",
        "id": 538942100,
        "sender_full_name": "Jason Rute",
        "timestamp": 1757624475
    },
    {
        "content": "<p>Yeah, I agree that most of the lemmas would really be thought of as implicit steps in an informal proof. I think calling it a \"high level blueprint\" is pretty generous. In any case, I still think this is a really impressive result!</p>",
        "id": 538942265,
        "sender_full_name": "Adam Topaz",
        "timestamp": 1757624553
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"321854\">Auguste Poiroux</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Math.2C.20Inc.2C.20and.20Gauss.20discussion/near/538930296\">said</a>:</p>\n<blockquote>\n<p>Human supervision means that we refined the blueprint latex statements and proofs when the agent struggled to formalize a result.</p>\n</blockquote>\n<p>Is it possible to give a sense of how much of the TeX files were written by humans?</p>",
        "id": 538944868,
        "sender_full_name": "Daniel Litt",
        "timestamp": 1757625851
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110637\">Ching-Tsun Chou</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Math.2C.20Inc.2C.20and.20Gauss.20discussion/near/538941483\">said</a>:</p>\n<blockquote>\n<p>How do you ensure that the Lean definitions and theorem statements are a correct formalization of the blueprint?</p>\n</blockquote>\n<p>It is an important part of the human supervision. We manually checked critical Lean statements, and refined/adapted corresponding informal statements in case of misformalization.</p>",
        "id": 538945289,
        "sender_full_name": "Auguste Poiroux",
        "timestamp": 1757626064
    },
    {
        "content": "<p>Is there an example of the \"human supervision\" you referred to above?  Namely, an example of a proof step that is too big for the agent to handle, what sort of feedbacks the human supervisor gets from the agent, and how the human supervisor breaks up the big step into small ones.</p>",
        "id": 538945771,
        "sender_full_name": "Ching-Tsun Chou",
        "timestamp": 1757626320
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"115715\">Jason Rute</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Math.2C.20Inc.2C.20and.20Gauss.20discussion/near/538942100\">said</a>:</p>\n<blockquote>\n<p>Did the human manually break up lemmas in the blueprint based on the progress of the Guass agent?  For example, say the agent had trouble formalizing Lemma 4.123.  Therefore you rewrote its proof in terms of three more basic lemmas which would be easier for the agent? (I noticed many of the lemmas are really basic and if they are human written, I assume that is why they are their.)</p>\n</blockquote>\n<p>Gauss performance improved over the course of the formalization. The closer you get to Strong PNT in the dependency graph, the larger the gaps are. But yes, I agree that our blueprint is quite dense in comparison to other projects. We are using the blueprint as an interface to guide Gauss in the formalization.</p>",
        "id": 538945876,
        "sender_full_name": "Auguste Poiroux",
        "timestamp": 1757626381
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"960598\">Daniel Litt</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Math.2C.20Inc.2C.20and.20Gauss.20discussion/near/538944868\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"321854\">Auguste Poiroux</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Math.2C.20Inc.2C.20and.20Gauss.20discussion/near/538930296\">said</a>:</p>\n<blockquote>\n<p>Human supervision means that we refined the blueprint latex statements and proofs when the agent struggled to formalize a result.</p>\n</blockquote>\n<p>Is it possible to give a sense of how much of the TeX files were written by humans?</p>\n</blockquote>\n<p>TeX files are written by humans</p>",
        "id": 538945948,
        "sender_full_name": "Auguste Poiroux",
        "timestamp": 1757626407
    },
    {
        "content": "<blockquote>\n<p>Gauss performance improved over the course of the formalization. The closer you get to Strong PNT in the dependency graph, the larger the gaps are.</p>\n</blockquote>\n<p>Did you start at the leaf nodes or the final goal?  Or a mix?</p>",
        "id": 538946807,
        "sender_full_name": "Jason Rute",
        "timestamp": 1757626871
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110637\">Ching-Tsun Chou</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Math.2C.20Inc.2C.20and.20Gauss.20discussion/near/538945771\">said</a>:</p>\n<blockquote>\n<p>Is there an example of the \"human supervision\" you referred to above?  Namely, an example of a proof step that is too big for the agent to handle, what sort of feedbacks the human supervisor gets from the agent, and how the human supervisor breaks up the big step into small ones.</p>\n</blockquote>\n<p>An example is <code>I_is_antiderivative</code> (upper right of the <a href=\"https://math-inc.github.io/strongpnt/blueprint/dep_graph_document.html\">dependency graph</a>). It has a whole dependency subgraph all for itself.<br>\nWhen the agent is not able to prove a statement, an analysis is provided at the end. Reasons span misformalization, proof step is too big, and sometimes incorrect informal statements. About \"how the human supervisor breaks up the big step\", mathematician's role is critical here to add intermediate statements.</p>",
        "id": 538948665,
        "sender_full_name": "Auguste Poiroux",
        "timestamp": 1757628001
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"115715\">Jason Rute</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Math.2C.20Inc.2C.20and.20Gauss.20discussion/near/538946807\">said</a>:</p>\n<blockquote>\n<blockquote>\n<p>Gauss performance improved over the course of the formalization. The closer you get to Strong PNT in the dependency graph, the larger the gaps are.</p>\n</blockquote>\n<p>Did you start at the leaf nodes or the final goal?  Or a mix?</p>\n</blockquote>\n<p>It's a mix, but mainly from the leaf nodes</p>",
        "id": 538948739,
        "sender_full_name": "Auguste Poiroux",
        "timestamp": 1757628039
    },
    {
        "content": "<p>8 messages were moved from this topic to <a class=\"stream-topic\" data-stream-id=\"219941\" href=\"/#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Danger.20of.20Autoformalizers.20.28e.2Eg.2E.20Gauss.29/with/538957071\">#Machine Learning for Theorem Proving &gt; Danger of Autoformalizers (e.g. Gauss)</a> by <span class=\"user-mention silent\" data-user-id=\"115715\">Jason Rute</span>.</p>",
        "id": 538957072,
        "sender_full_name": "Notification Bot",
        "timestamp": 1757634049
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"321854\">@Auguste Poiroux</span> Since you start from the leaves, is your algorithm greedy in that it takes the first formalization and proof of that formalization that it can prove, possibly compounding errors, or does it handle multiple formalization candidates, not committing to a formalization until human review, or until that formalization proves itself useful for filling in many later steps in the blueprint?  For example, maybe you need <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mn>1</mn><mi mathvariant=\"normal\">/</mi><mn>2</mn><mo>&lt;</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">1/2 &lt; 1</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\">1/2</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">&lt;</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6444em;\"></span><span class=\"mord\">1</span></span></span></span>, but it formalizes it as:</p>\n<div class=\"codehilite\" data-code-language=\"Lean4\"><pre><span></span><code><span class=\"kn\">theorem</span><span class=\"w\"> </span><span class=\"n\">half_less_than_one</span><span class=\"w\"> </span><span class=\"o\">:</span><span class=\"w\"> </span><span class=\"mi\">1</span><span class=\"bp\">/</span><span class=\"mi\">2</span><span class=\"w\"> </span><span class=\"bp\">&lt;</span><span class=\"w\"> </span><span class=\"mi\">1</span><span class=\"w\"> </span><span class=\"o\">:=</span><span class=\"w\"> </span><span class=\"k\">by</span><span class=\"w\"> </span><span class=\"n\">norm_num</span>\n</code></pre></div>\n<p>which, while a correct theorem, is a misformalization.  When you try to continue, you will eventually find this lemma is not useful in the places you intend to use it.  (This toy example, might be too simple, but I hope you see my point.)  Do you have to manually go in and clear out this bad lemma, or is your algorithm able to still consider alternate versions of the lemma in parallel, seeing which version is more useful for later steps?</p>",
        "id": 538971569,
        "sender_full_name": "Jason Rute",
        "timestamp": 1757643555
    },
    {
        "content": "<p>I thought it would be fun to run <code>tryAtEachStep exact?</code> on the repo. Here are its top findings, which seem to suggest that the code has lots of room to be compressed still:</p>\n<ol>\n<li><a href=\"https://github.com/math-inc/strongpnt/blob/2f5835c322314f55f1026ec2f139d704b7c45c69/StrongPNT/PNT1_ComplexAnalysis.lean#L4980-L5018\">uniqueDiffWithinAt_convex_complex</a> is a trivial consequence of <a href=\"https://leanprover-community.github.io/mathlib4_docs/Mathlib/Analysis/RCLike/TangentCone.html#uniqueDiffWithinAt_convex_of_isRCLikeNormedField\">uniqueDiffWithinAt_convex_of_isRCLikeNormedField</a>.</li>\n<li><a href=\"https://math-inc.github.io/strongpnt/docs/StrongPNT/PNT4_ZeroFreeRegion.html#lem_tsum_norm_vonMangoldt_depends_on_Re_cast\">lem_tsum_norm_vonMangoldt_depends_on_Re_cast</a> is a duplicate of <a href=\"https://math-inc.github.io/strongpnt/docs/StrongPNT/PNT4_ZeroFreeRegion.html#lem_tsum_norm_vonMangoldt_depends_on_Re\">lem_tsum_norm_vonMangoldt_depends_on_Re</a>.</li>\n<li><a href=\"https://github.com/math-inc/strongpnt/blob/2f5835c322314f55f1026ec2f139d704b7c45c69/StrongPNT/PNT3_RiemannZeta.lean#L3865-L3894\">enat_le_iff_forall_nat</a> is a trivial consequence of <a href=\"https://leanprover-community.github.io/mathlib4_docs/Mathlib/Data/ENat/Basic.html#ENat.forall_natCast_le_iff_le\">ENat.forall_natCast_le_iff_le</a></li>\n</ol>",
        "id": 538972620,
        "sender_full_name": "David Renshaw",
        "timestamp": 1757644315
    },
    {
        "content": "<p>Something I would <em>love</em> to see is how easily (or otherwise) Gauss copes with upgrading this repository to the latest <code>PrimeNumberTheoremAnd</code> (and <code>v4.22.0</code> of Lean+Mathlib).</p>\n<p>(There is an error in <code>PNT1_ComplexAnalysis.lean</code>, so this is not a triviality.)</p>",
        "id": 538975437,
        "sender_full_name": "Kim Morrison",
        "timestamp": 1757646710
    },
    {
        "content": "<p>Proof repair after upgrades is a sine qua non for autoformalizers to participate in the larger ecosystem. I hope it is very doable, but we need to see it happening!</p>",
        "id": 538975500,
        "sender_full_name": "Kim Morrison",
        "timestamp": 1757646776
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"115715\">@Jason Rute</span> this indeed happened a few times during our formalization of Strong PNT. In later steps, the agent sometimes simply skipped misformalized lemmas, and sometimes used them. Misformalizations are often not provable, and human supervision is necessary in these cases.</p>",
        "id": 539008851,
        "sender_full_name": "Auguste Poiroux",
        "timestamp": 1757665510
    },
    {
        "content": "<p>There was a question above which I think was unanswered: was the computer system trained on the human PNT effort led by Kontorovich/Tao before it started to help?</p>",
        "id": 539022619,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1757670026
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110038\">Kevin Buzzard</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Math.2C.20Inc.2C.20and.20Gauss.20discussion/near/539022619\">said</a>:</p>\n<blockquote>\n<p>There was a question above which I think was unanswered: was the computer system trained on the human PNT effort led by Kontorovich/Tao before it started to help?</p>\n</blockquote>\n<p>Sorry we missed the question. We did not train on the PNT+ project</p>",
        "id": 539026445,
        "sender_full_name": "Auguste Poiroux",
        "timestamp": 1757671285
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"321854\">Auguste Poiroux</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Math.2C.20Inc.2C.20and.20Gauss.20discussion/near/539026445\">ha scritto</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"110038\">Kevin Buzzard</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Math.2C.20Inc.2C.20and.20Gauss.20discussion/near/539022619\">said</a>:</p>\n<blockquote>\n<p>There was a question above which I think was unanswered: was the computer system trained on the human PNT effort led by Kontorovich/Tao before it started to help?</p>\n</blockquote>\n<p>Sorry we missed the question. We did not train on the PNT+ project</p>\n</blockquote>\n<p>Thanks, could you say whether as part of the human-made blueprint you provided 'API' blueprint within context to teach Gauss about PNT+? It's not part of generic LLM's training, except recently, so I assume the LLM will tend to use basic mathlib API rather than PNT+ unless carefully prompted.</p>",
        "id": 539029193,
        "sender_full_name": "Matteo Cipollina",
        "timestamp": 1757672305
    },
    {
        "content": "<p>(deleted)</p>",
        "id": 539032455,
        "sender_full_name": "Matteo Cipollina",
        "timestamp": 1757673444
    },
    {
        "content": "<p>(deleted)</p>",
        "id": 539032755,
        "sender_full_name": "Matteo Cipollina",
        "timestamp": 1757673566
    },
    {
        "content": "<p>(deleted)</p>",
        "id": 539032944,
        "sender_full_name": "Matteo Cipollina",
        "timestamp": 1757673632
    },
    {
        "content": "<p>This is perhaps a trivial consideration, but I tried to <code>grep</code> the words <code>structure</code> and <code>class</code> inside <code>StrongPNT</code> and found 0 occurrences. To me (and I hope this is not taken as a criticism, or as an underestimation of the incredible effort!) this shows to what extent this project differs from a human one. I would easily imagine that for such a big project, a human team -- or a human-led one -- would come up with useful structures or classes to organise the code, which would in turn reflect abstractions and concepts developed during the process.</p>",
        "id": 539038481,
        "sender_full_name": "Filippo A. E. Nuccio",
        "timestamp": 1757675675
    },
    {
        "content": "<p>I think I counted ~30 definitions and they were all really basic, sometimes trivial.  I think that is a current limitation of this work (and the almost everywhere abc theorem by Trinity).  I think a definition-heavy project like FLT would be a very different beast.  It probably isnâ€™t surprising that they chose theorems like this which use existing definitions and machinery.</p>",
        "id": 539039670,
        "sender_full_name": "Jason Rute",
        "timestamp": 1757676123
    },
    {
        "content": "<p>I don't think it's the AI fault that it did not build more abstraction per say. It's just a matter of guidance in the instruction you give them.<br>\nIf you make a set of context instruction to build abstractions using structures, class to abstract concepts, it will try to do so.<br>\nIt's the same on my software engineering field, if i just let the AI build functional code it will do so by writting some flat code without abstractions, but when i write an instruction file that says, what are the standard practices for my projects, the LLM follows them and write proper abstractions.</p>",
        "id": 539041735,
        "sender_full_name": "Alfredo Moreira-Rosa",
        "timestamp": 1757676808
    },
    {
        "content": "<p>Congratulations!<br>\nWhen Gauss used a misformalized lemma, what did the proof look like?<br>\nHow did it know to skip certain lemmas?Â <br>\nWhat is the price (compute-hours) of a single misformalized lemma?<br>\nHow often does Gauss reinvent the wheel?<br>\nWhat kind of rewards are you using? (per-step rewards (tactic correctness, goal-count delta, token length, and so on) plus sparse end-of-proof rewards (compilation success, lemma reuse, blueprint hit rate)?<br>\nAre you planning to release the model on HF?</p>",
        "id": 539048257,
        "sender_full_name": "Michael Bucko",
        "timestamp": 1757678930
    },
    {
        "content": "<p>As for rewards, it is not even clear if they are training a model?  This could just be a large agentic system using current existing models (or minimally fine-tuned models with no RL).</p>",
        "id": 539049091,
        "sender_full_name": "Jason Rute",
        "timestamp": 1757679147
    },
    {
        "content": "<p>Yes it seems pretty clear in the announcement that it's just an agentic setup.</p>",
        "id": 539051004,
        "sender_full_name": "Alfredo Moreira-Rosa",
        "timestamp": 1757679701
    },
    {
        "content": "<p>I asked about the lack of abstractions with the abc result at the INI talk announcing it. I don't think I was satisfied but since then I've come to the following feeling. </p>\n<p>If you look at the human input, it is still pretty thorough for a guide. From my experience, I would guess today that if you, as a math/lean expert, provided a structure with parents and fields and some semantic info, it would fill that in easily. A good test would be handling lightly sketched API for a new structure. </p>\n<p>The workflow would look not too dissimilar from today (yesterday?). Human experts decompose the problems and invent structures + API to model the mathematics. Work is attempted to fill in. Based on that work the humans would gain greater understanding and tweak the structures and approach. Then  work to fill things again would start. </p>\n<p>It is the work to fill things step that could really see the acceleration.</p>",
        "id": 539052473,
        "sender_full_name": "Matthew Ballard",
        "timestamp": 1757680141
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"115715\">Jason Rute</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Math.2C.20Inc.2C.20and.20Gauss.20discussion/near/539049091\">said</a>:</p>\n<blockquote>\n<p>As for rewards, it is not even clear if they are training a model?  This could just be a large agentic system using current existing models (or minimally fine-tuned models with no RL).</p>\n</blockquote>\n<p>I don't think it is a coincidence that Christian mentioned the propensity for GPT 5 to insert axioms in Lean code in the same podcast where he highlighted the PNT as a formalization target. <a class=\"message-link\" href=\"/#narrow/channel/113488-general/topic/Lean.20in.20the.20wild/near/537572770\">#general &gt; Lean in the wild @ ðŸ’¬</a></p>",
        "id": 539055540,
        "sender_full_name": "Matthew Ballard",
        "timestamp": 1757680977
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"252920\">@Alex Kontorovich</span> it would be great to hear your thoughts on this.  In particular, what do you feel it would have taken to do this manually?</p>",
        "id": 539069905,
        "sender_full_name": "Jason Rute",
        "timestamp": 1757684812
    },
    {
        "content": "<p>Sorry, I was traveling all day yesterday and am now about to go teach and have a slew of meetings with my grad students. I will be sure to collect my thoughts (which I've had some weeks to do, since they told me and Terry about this a while ago), and report them here, but it might take a few days... Overall I think it's a great achievement and shows just how close we are to potentially getting a lot more math formalized much more rapidly than before; but there are also many caveats... More soon!</p>",
        "id": 539077052,
        "sender_full_name": "Alex Kontorovich",
        "timestamp": 1757686701
    },
    {
        "content": "<p>How much does this cost</p>",
        "id": 539197093,
        "sender_full_name": "(deleted)",
        "timestamp": 1757733773
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"321854\">@Auguste Poiroux</span> I see that lean proofs contain a lot of comments, somewhat explaining the proof strategy. Were they also inserted by Gauss or by humans writing the blueprint? If it was Gauss, had it been explicitly instructed to do so, or is it due to some other reason?</p>",
        "id": 539255685,
        "sender_full_name": "Filippo A. E. Nuccio",
        "timestamp": 1757753680
    },
    {
        "content": "<p>LLMs in general insert lots of comments. In fact more than humans.</p>",
        "id": 539257758,
        "sender_full_name": "(deleted)",
        "timestamp": 1757756009
    },
    {
        "content": "<p>I am more and more certain this must be using some sort of tree search algorithm</p>",
        "id": 539357157,
        "sender_full_name": "(deleted)",
        "timestamp": 1757793139
    },
    {
        "content": "<p>To drive the LLM</p>",
        "id": 539357165,
        "sender_full_name": "(deleted)",
        "timestamp": 1757793146
    },
    {
        "content": "<p>Infinibranch is mentioned for a reason</p>",
        "id": 539357204,
        "sender_full_name": "(deleted)",
        "timestamp": 1757793181
    },
    {
        "content": "<p>Given that Infinibranch is publicly available, maybe someone should try setting up a tree search agent <span aria-label=\"eyes\" class=\"emoji emoji-1f440\" role=\"img\" title=\"eyes\">:eyes:</span> and see how it goes</p>",
        "id": 539357386,
        "sender_full_name": "(deleted)",
        "timestamp": 1757793354
    },
    {
        "content": "<p>Wow. Actually so much about the system is already publicly available. Treating the LLM as a low level component instead of an all powerful superintelligence really is a way to engineer an autonomous AI for formal verification.</p>",
        "id": 539357542,
        "sender_full_name": "(deleted)",
        "timestamp": 1757793525
    },
    {
        "content": "<p>This is an engineering problem. The high level idea is rather clear</p>",
        "id": 539357671,
        "sender_full_name": "(deleted)",
        "timestamp": 1757793636
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"776090\">@GasStationManager</span> would it be possible for SafeVerify to check this whole project up to the main theorem at the end?  Or does the fact that it is a multi file development mean that SafeVerify would just trust the imported files without checking them?</p>",
        "id": 539406300,
        "sender_full_name": "Jason Rute",
        "timestamp": 1757854459
    },
    {
        "content": "<p>It might be easy to concatonate this code into just one file if that is a limitation.</p>",
        "id": 539407627,
        "sender_full_name": "Jason Rute",
        "timestamp": 1757855614
    },
    {
        "content": "<p>(And for those who donâ€™t know, SafeVerify does stuff that other tools donâ€™t do like check the term proofs, check the axioms, and check that the theorem statement term didnâ€™t change in the presence of preceding code in the file.)</p>",
        "id": 539407682,
        "sender_full_name": "Jason Rute",
        "timestamp": 1757855662
    },
    {
        "content": "<p>This (vague) post by Tao might (or might not) be referring to this project.  <a href=\"https://mathstodon.xyz/@tao/115196924307085967\">https://mathstodon.xyz/@tao/115196924307085967</a></p>",
        "id": 539418437,
        "sender_full_name": "Jason Rute",
        "timestamp": 1757866099
    },
    {
        "content": "<p>I'm not 100% what he is referring to, but one thing might be Math Inc. contrasting the time it took this proof (about three weeks) with the time it took the original Lean PNT project (about 18 months).  Obviously, the original project had a large learning component to it.  The participants weren't Lean experts. Other formal proofs of the PNT, such as those by Jeremy Avigad, John Harrison, or Mario Carneiro, probably did it faster (and could certainly do it much faster today).</p>",
        "id": 539418443,
        "sender_full_name": "Jason Rute",
        "timestamp": 1757866104
    },
    {
        "content": "<p>Also, Tao mentions upstreaming to Mathlib.  If you rush to a proof, that is certainly not the same thing as taking the time to clean and review the code for maintainability and future application.  I think both the rushed AI approach and slow and careful human approach are valuable with independent strengths, but again, I could see the comparison of the two projects rubbing some the wrong way (especially if the mainstream news picks this up).  I think an interesting datapoint would be how easy it is for others to clean this code and incorporate it into the original PNT project.</p>",
        "id": 539418449,
        "sender_full_name": "Jason Rute",
        "timestamp": 1757866111
    },
    {
        "content": "<p>I guess there is also the aspect that this project in some ways \"scooped\" the original PNT project (which again was a learning opportunity).  So this means they have to shift their focus to other projects to learn Lean (which could be scooped as well).  <span class=\"user-mention\" data-user-id=\"110038\">@Kevin Buzzard</span>: Would you be happy or sad if Math Inc. scooped you on FLT?</p>",
        "id": 539419385,
        "sender_full_name": "Jason Rute",
        "timestamp": 1757866853
    },
    {
        "content": "<p>I would be elated!</p>",
        "id": 539419432,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1757866910
    },
    {
        "content": "<p>I am very unclear though about how well these things are going to be able to handle definitions, especially definitions in mathlib style, which is why I have another project focussing on formalising modern mathematical definitions in a mathlib-acceptable way (which I should really write a blog post about)</p>",
        "id": 539419520,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1757867000
    },
    {
        "content": "<p>I don't think this approach would currently scale to FLT.  For one, <span class=\"user-mention\" data-user-id=\"779159\">@Jared Duker Lichtman</span> would have to learn the proof. <span aria-label=\"rofl\" class=\"emoji emoji-1f923\" role=\"img\" title=\"rofl\">:rofl:</span></p>",
        "id": 539419567,
        "sender_full_name": "Jason Rute",
        "timestamp": 1757867055
    },
    {
        "content": "<p>I don't think we can MCTS our way to FLT <span aria-label=\"eyes\" class=\"emoji emoji-1f440\" role=\"img\" title=\"eyes\">:eyes:</span></p>",
        "id": 539424302,
        "sender_full_name": "(deleted)",
        "timestamp": 1757870327
    },
    {
        "content": "<p>What Math, Inc did was very expensive</p>",
        "id": 539424569,
        "sender_full_name": "(deleted)",
        "timestamp": 1757870517
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110038\">Kevin Buzzard</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Math.2C.20Inc.2C.20and.20Gauss.20discussion/near/539419520\">said</a>:</p>\n<blockquote>\n<p>I am very unclear though about how well these things are going to be able to handle definitions, especially definitions in mathlib style, which is why I have another project focussing on formalising modern mathematical definitions in a mathlib-acceptable way (which I should really write a blog post about)</p>\n</blockquote>\n<p>Please write the blog post.  I very much want to learn what exactly the \"mathlib style\" is.</p>",
        "id": 539437547,
        "sender_full_name": "Ching-Tsun Chou",
        "timestamp": 1757882068
    },
    {
        "content": "<p>For those in the Cambridge, MA area, Jared Duker Lichtman and Jesse Han are giving a presentation on this result at Harvard CMSA at noon today <time datetime=\"2025-09-16T16:00:00Z\">2025-09-16T12:00:00-04:00</time>  as part of the <a href=\"https://cmsa.fas.harvard.edu/event/mlgeometry/\">Geometry of Machine Learning workshop</a> and will also be speaking at MIT on Thursday <time datetime=\"2025-09-18T18:30:00Z\">2025-09-18T14:30:00-04:00</time>.  (I think you can also watch the CMSA talk on Zoom, you can register at the link above).</p>",
        "id": 539766983,
        "sender_full_name": "Andrew Sutherland",
        "timestamp": 1758028741
    },
    {
        "content": "<p>Is that <time datetime=\"2025-09-16T16:00:00Z\">2025-09-16T12:00:00-04:00</time>  and <time datetime=\"2025-09-18T18:30:00Z\">2025-09-18T14:30:00-04:00</time> ?</p>",
        "id": 539769046,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1758029271
    },
    {
        "content": "<p>I'm not sure if there's issues with the webinar, but I think the AlphaGeometry talk is meant to be right now, but I only see a blank screen</p>",
        "id": 539771812,
        "sender_full_name": "Eric Rodriguez",
        "timestamp": 1758029952
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"284160\">Eric Rodriguez</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Math.2C.20Inc.2C.20and.20Gauss.20discussion/near/539771812\">said</a>:</p>\n<blockquote>\n<p>I'm not sure if there's issues with the webinar, but I think the AlphaGeometry talk is meant to be right now, but I only see a blank screen</p>\n</blockquote>\n<p>livestream should be available now!</p>",
        "id": 539796790,
        "sender_full_name": "harry sanders",
        "timestamp": 1758035689
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"320522\">Andrew Sutherland</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Math.2C.20Inc.2C.20and.20Gauss.20discussion/near/539766983\">said</a>:</p>\n<blockquote>\n<p>For those in the Cambridge, MA area, Jared Duker Lichtman and Jesse Han are giving a presentation on this result at Harvard CMSA at noon today (Sep 16) as part of the <a href=\"https://cmsa.fas.harvard.edu/event/mlgeometry/\">Geometry of Machine Learning workshop</a> and will also be speaking at MIT on Thursday (Sep 18) at 2:30.  (I think you can also watch the CMSA talk on Zoom, you can register at the link above).</p>\n</blockquote>\n<p>Thanks for sharing! I just registered for the Harvard workshop, though a bit last minute â€” do you know if thereâ€™s still space to attend in person?</p>",
        "id": 539797383,
        "sender_full_name": "Zixiao Wang",
        "timestamp": 1758035838
    },
    {
        "content": "<p>Did Math Inc talk about technical details? I was outside for most of the talk</p>",
        "id": 539818733,
        "sender_full_name": "(deleted)",
        "timestamp": 1758042270
    },
    {
        "content": "<p>Judging from the questions, looks like no</p>",
        "id": 539819956,
        "sender_full_name": "(deleted)",
        "timestamp": 1758042651
    },
    {
        "content": "<p>Details on the MIT talk on Thursday are available <a href=\"https://calendar.mit.edu/event/special-number-theory-seminar\">here</a> (note the time is <time datetime=\"2025-09-18T18:30:00Z\">2025-09-18T14:30:00-04:00</time>). The MIT talk will not be on Zoom, but CMSA usually posts recordings within a few days.</p>",
        "id": 539829224,
        "sender_full_name": "Andrew Sutherland",
        "timestamp": 1758045722
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"511228\">Huá»³nh Tráº§n Khanh</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Math.2C.20Inc.2C.20and.20Gauss.20discussion/near/539818733\">said</a>:</p>\n<blockquote>\n<p>Did Math Inc talk about technical details? I was outside for most of the talk</p>\n</blockquote>\n<p>I attended the Math Inc talk at MIT today and it was interesting but very light on technical details. The talk was basically the same as the stuff already on the <a href=\"http://math.inc\">math.inc</a> website.</p>",
        "id": 540330554,
        "sender_full_name": "Anthony Wang",
        "timestamp": 1758233813
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"511228\">Huá»³nh Tráº§n Khanh</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Math.2C.20Inc.2C.20and.20Gauss.20discussion/near/539424302\">said</a>:</p>\n<blockquote>\n<p>I don't think we can MCTS our way to FLT <span aria-label=\"eyes\" class=\"emoji emoji-1f440\" role=\"img\" title=\"eyes\">:eyes:</span></p>\n</blockquote>\n<p>It will not just be MCTS but also retrieval augmented generation(RAG).  This is where the well formed mathlib helps quite a bit.  It's worth mentioning that DeepMind did quite well on IMO 2025 (versus OpenAI) on not just presenting proofs but readable proofs.  This is something LLMs excel at, and you will find as these tools mature the problem of generating good lean code will be a tractable  hurdle.  </p>\n<p>The true and challenging hurdle in all of this will be how well the agentic flow can find efficacious inspiration from the repos and research it has access to in order to make the necessary and correct leaps. </p>\n<p>And of course, it goes without saying, enfeeblement risk looms large in everything AI touches.</p>",
        "id": 540888697,
        "sender_full_name": "Deleted User 968128",
        "timestamp": 1758572294
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"968128\">Tim Shephard</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Math.2C.20Inc.2C.20and.20Gauss.20discussion/near/540888697\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"511228\">Huá»³nh Tráº§n Khanh</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Math.2C.20Inc.2C.20and.20Gauss.20discussion/near/539424302\">said</a>:</p>\n<blockquote>\n<p>I don't think we can MCTS our way to FLT <span aria-label=\"eyes\" class=\"emoji emoji-1f440\" role=\"img\" title=\"eyes\">:eyes:</span></p>\n</blockquote>\n<p>It will not just be MCTS but also retrieval augmented generation(RAG).  This is where the well formed mathlib helps quite a bit.  It's worth mentioning that DeepMind did quite well on IMO 2025 (versus OpenAI) on not just presenting proofs but readable proofs.  This is something LLMs excel at, and you will find as these tools mature the problem of generating good lean code will be a tractable  hurdle.  </p>\n<p>The true and challenging hurdle in all of this will be how well the agentic flow can find efficacious inspiration from the repos and research it has access to in order to make the necessary and correct leaps. </p>\n<p>And of course, it goes without saying, enfeeblement risk looms large in everything AI touches.</p>\n</blockquote>\n<p>What is enfeeblement risk? I think I might know but it would be good to get an expert definition.</p>",
        "id": 541428122,
        "sender_full_name": "Wrenna Robson",
        "timestamp": 1758797819
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"330967\">Wrenna Robson</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Math.2C.20Inc.2C.20and.20Gauss.20discussion/near/541428122\">said</a>:</p>\n<blockquote>\n<p>What is enfeeblement risk? I think I might know but it would be good to get an expert definition.</p>\n</blockquote>\n<p>I think the definition is more interesting when defined specifically for a narrow domain (like autoformalization), but generally the risk of weakening something along some dimension of capability due to some change.</p>\n<p>Something I learned recently is that Socratese thought the alphabet posed enfeeblement risk.  We know this, because his student Plato wrote it down. :)</p>",
        "id": 541482788,
        "sender_full_name": "Deleted User 968128",
        "timestamp": 1758812821
    },
    {
        "content": "<p>Well, he was wrong about that one I guess - but the phenomenon is real in general (I am less good at using log tables than someone of my background would have been sixty years ago, I suspect).</p>",
        "id": 541483965,
        "sender_full_name": "Wrenna Robson",
        "timestamp": 1758813084
    },
    {
        "content": "<p>To loop this back to Gauss, I think it behooves them to include a section on enfeeblement risk on their <a href=\"http://math.inc\">math.inc</a> website.  And, perhaps a novel but hopefully soon-to-be solved risk:  <a href=\"https://hbr.org/2025/09/ai-generated-workslop-is-destroying-productivity\">workslop risk</a>.</p>",
        "id": 541484265,
        "sender_full_name": "Deleted User 968128",
        "timestamp": 1758813153
    },
    {
        "content": "<p>Whether or not it's a problem remains to be seen I suppose. It is a concern for me with AI I think - I am really not enthusiastic about it as a technology/set of technologies in general - but we are where we are and there's interesting stuff to learn.</p>",
        "id": 541484270,
        "sender_full_name": "Wrenna Robson",
        "timestamp": 1758813154
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"968128\">Tim Shephard</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Math.2C.20Inc.2C.20and.20Gauss.20discussion/near/541484265\">said</a>:</p>\n<blockquote>\n<p>Right to a degree.  The phenomenon of 'book smarts' is real, I believe.</p>\n</blockquote>\n<p>Ah, yes, I see what you mean.</p>",
        "id": 541484523,
        "sender_full_name": "Wrenna Robson",
        "timestamp": 1758813211
    },
    {
        "content": "<p>The work above is interesting but yeah my goodness this is ugly work. Cool that it can do it but the abstraction and API design is bad to the point of being nearly useless in and of itself, I would say.</p>",
        "id": 541485330,
        "sender_full_name": "Wrenna Robson",
        "timestamp": 1758813410
    },
    {
        "content": "<p>Though I mean surely that is a matter of training rather than a fundamental capacity - certainly I would not make the latter claim.</p>",
        "id": 541485445,
        "sender_full_name": "Wrenna Robson",
        "timestamp": 1758813443
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"330967\">Wrenna Robson</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Math.2C.20Inc.2C.20and.20Gauss.20discussion/near/541485330\">said</a>:</p>\n<blockquote>\n<p>The work above is interesting but yeah my goodness this is ugly work. Cool that it can do it but the abstraction and API design is bad to the point of being nearly useless in and of itself, I would say.</p>\n</blockquote>\n<p>There is an idea I am noodling which is 'Proof Axiology'.  Spamming/workslopping out lean code is intriguing but might be much less valuable than some imagine at this point.  </p>\n<p>However, if there was a deeper investigation in creating rubrics around what proofs are of interest, this could help drive autoformalization engines like Gauss in a more productive manner.</p>\n<p>There is a similar problem right now in antibiotics discovery.   Teams are spamming out new discoveries, but there is limited resources to prove what is eficacious and this could be hindering finding real breakthroughs rather than helping.</p>",
        "id": 541487351,
        "sender_full_name": "Deleted User 968128",
        "timestamp": 1758813906
    },
    {
        "content": "<p>I would say even in human-authored lean code, \"what makes a good API\" is under-researched - I mean, people have opinions about it, but I am not aware of that much work (a little I think?) to transition that into research knowledge.</p>",
        "id": 541490014,
        "sender_full_name": "Wrenna Robson",
        "timestamp": 1758814564
    },
    {
        "content": "<p>Something like that would obviously also have utility here.</p>",
        "id": 541490092,
        "sender_full_name": "Wrenna Robson",
        "timestamp": 1758814580
    }
]