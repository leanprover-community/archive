[
    {
        "content": "<p>My sense is that Claude Code isn’t that useful yet in a Lean context because without custom engineering the agent doesn’t know the tactic state. Is that right? Curious if anyone tries it and has a positive experience.</p>\n<p><a href=\"https://www.anthropic.com/news/claude-3-7-sonnet\">https://www.anthropic.com/news/claude-3-7-sonnet</a></p>",
        "id": 501641830,
        "sender_full_name": "Geoffrey Irving",
        "timestamp": 1740428943
    },
    {
        "content": "<p>I tried Claude Code briefly. After a bit of prompting it was able to invoke <code>lake env lean &lt;file&gt;</code>, and try to fix its own syntax errors, but ended up not able to fix its syntax and got stuck in a loop. (The task prompt was \"prove that 3 is not even\")<br>\nWhat worked better for me is when I wrote a simple wrapper of LeanTool to export its tool as a Model Context Protocol (MCP) server, which can then be added to Claude Code. This provides somewhat more information than just calling Lean, as it also prints goal states from <code>sorry</code>s (using Pantograph).<br>\nSee <a href=\"https://github.com/GasStationManager/LeanTool?tab=readme-ov-file#example-set-up-with-claude-code\">here</a> for an example set up.</p>",
        "id": 501886911,
        "sender_full_name": "GasStationManager",
        "timestamp": 1740509531
    },
    {
        "content": "<p>This does make me wonder, if Claude can make use of more interactive Lean features; e.g. if one makes a MCP server wrapper for <span class=\"user-mention\" data-user-id=\"802311\">@Oliver Dressler</span>'s <a href=\"https://github.com/oOo0oOo/leanclient\">leanclient</a>, which exposes the Lean Language Server features. Which features would be useful to an LLM?</p>",
        "id": 501888545,
        "sender_full_name": "GasStationManager",
        "timestamp": 1740510094
    },
    {
        "content": "<p>Similarly for <a href=\"https://github.com/stanford-centaur/PyPantograph\">Pantograph</a> and other repl-like interfaces. Would Claude be able to use these for proof search?</p>",
        "id": 501892760,
        "sender_full_name": "GasStationManager",
        "timestamp": 1740511504
    },
    {
        "content": "<p>Recent LLMs are pretty good at tool use if prompted appropriately, so likely use.</p>",
        "id": 502018295,
        "sender_full_name": "Geoffrey Irving",
        "timestamp": 1740567713
    },
    {
        "content": "<p>doing the fvapps baselines, the simplest scaffold (a loop) elicited nontrivial ability to learn syntax that the core llm was wrong about, just error message no LSP wire-up</p>",
        "id": 502083461,
        "sender_full_name": "Quinn",
        "timestamp": 1740585593
    },
    {
        "content": "<p>i'm actually a little skeptical that LSP / goal state beats error message by a lot overall, but one choice over another might save a lot of tokens/dollars</p>",
        "id": 502089762,
        "sender_full_name": "Quinn",
        "timestamp": 1740587197
    },
    {
        "content": "<p>(deleted)</p>",
        "id": 546220310,
        "sender_full_name": "Eric Taucher",
        "timestamp": 1761049211
    },
    {
        "content": "<p>You really need at least <code>lean-lsp-mcp</code> to make Claude Code useful, because then it can enter a self feedback loop with the help of compiler error messages.</p>",
        "id": 546352009,
        "sender_full_name": "Gavin Zhao",
        "timestamp": 1761097171
    },
    {
        "content": "<p>I haven't found Claude Code on its own to be very helpful in writing Lean code.</p>",
        "id": 546352051,
        "sender_full_name": "Gavin Zhao",
        "timestamp": 1761097203
    },
    {
        "content": "<p>For tactics specifically, you can prompt it to write its tactic step by step and tell it to hover before the first character and at the end of the line to see how the context changes, and based on that try to find the next best possible tactic to apply or revise the current tactic.</p>",
        "id": 546352149,
        "sender_full_name": "Gavin Zhao",
        "timestamp": 1761097305
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"766285\">Gavin Zhao</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Claude.20Code/near/546352009\">said</a>:</p>\n<blockquote>\n<p>You really need at least <code>lean-lsp-mcp</code> to make Claude Code useful, because then it can enter a self feedback loop with the help of compiler error messages.</p>\n</blockquote>\n<p>I'm confused by this claim. Without an MCP, Claude Code is perfectly capable of reading Lean error messages from the IDE, and reacting to them.</p>",
        "id": 546785748,
        "sender_full_name": "Kim Morrison",
        "timestamp": 1761263725
    },
    {
        "content": "<p>I think instructing it to hover and use the MCP to read the goal is way less robust (and less generalizable) than simply reading the unsolved goal error messages which are automatically in context, without an MCP!</p>",
        "id": 546785808,
        "sender_full_name": "Kim Morrison",
        "timestamp": 1761263775
    },
    {
        "content": "<p>After the Cambridge, MA Lean meetup I created  a video showing what the workflow flow can look like using claude-code +  lean skills (<a href=\"https://github.com/cameronfreer/lean4-skills\">https://github.com/cameronfreer/lean4-skills</a>) + lean_lsp_mcp.  </p>\n<p><a href=\"https://youtu.be/zderx5uXoWE\">https://youtu.be/zderx5uXoWE</a></p>\n<div class=\"youtube-video message_inline_image\"><a data-id=\"zderx5uXoWE\" href=\"https://youtu.be/zderx5uXoWE\"><img src=\"https://uploads.zulipusercontent.net/fdae0cdaea41a9f552b44835d7ca6a43f9a05f6b/68747470733a2f2f692e7974696d672e636f6d2f76692f7a646572783575586f57452f6d7164656661756c742e6a7067\"></a></div><p>Caveats/Suggestions:</p>\n<ul>\n<li>Watch the video at 2-3x</li>\n<li>In this instance the setup produces poor lean code -- I really should  redo with a more compelling example but was too lazy; but hopefully this will give an indication of a possible workflow (which I do think will become quite powerful)<br>\n-</li>\n</ul>",
        "id": 546873213,
        "sender_full_name": "Nehal Patel",
        "timestamp": 1761305331
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"110087\">@Kim Morrison</span> in my recent experience, the error messages are the main thing Claude uses until the file fully compiles (possibly with sorries), but the various LSP MCP features are helpful for speeding up the process of filling sorries and refactoring and golfing, etc. In particular, I've seen <code>lean_multi_attempt</code> used for quickly finding the simplest successful option among several tactics, once a proof is mostly in place.</p>",
        "id": 546913389,
        "sender_full_name": "Cameron Freer",
        "timestamp": 1761316583
    },
    {
        "content": "<p>For more details on patterns where I've seen Claude productively use the LSP, see<br>\n<a href=\"https://github.com/cameronfreer/lean4-skills/blob/main/lean4-theorem-proving%2Freferences%2Flean-lsp-server.md\">https://github.com/cameronfreer/lean4-skills/blob/main/lean4-theorem-proving%2Freferences%2Flean-lsp-server.md</a></p>\n<p>(It's a rather opinionated description written by Claude based on what it found helpful over several hundred commits -- I don't know that its advice should be taken literally, but on the other hand it's not like Claude follows its own suggestions all that closely, even with the skill.)</p>",
        "id": 546921344,
        "sender_full_name": "Cameron Freer",
        "timestamp": 1761318729
    },
    {
        "content": "<blockquote>\n<p>I think instructing it to hover and use the MCP to read the goal is way less robust (and less generalizable) than simply reading the unsolved goal error messages which are automatically in context, without an MCP!</p>\n</blockquote>\n<p>This is useful in the case where Claude outputs a wrong proof that's a long list of tactics. Then, hovering becomes very useful because it can walk through the tactic application step by step (line by line) and see whether each application of the tactic changed the context as it expected. This allows it to do much more efficient/ganular changes rather than trying to reconcile the long list of tactics and the error message and figure out whether it's just a small mistake somewhere or the entire approach is wrong.</p>",
        "id": 547017029,
        "sender_full_name": "Gavin Zhao",
        "timestamp": 1761354997
    },
    {
        "content": "<p>My experience has been that it is way more efficient to insist that it never outputs a long list of tactics, and to only allow it to write one tactic at a time. Writing long tactic scripts in one shot is nearly always a failure, and then extremely time/token expensive to repair.</p>",
        "id": 547034458,
        "sender_full_name": "Kim Morrison",
        "timestamp": 1761375468
    },
    {
        "content": "<p>(deleted)</p>",
        "id": 547038026,
        "sender_full_name": "Eric Taucher",
        "timestamp": 1761379238
    },
    {
        "content": "<p>Apart from fixing errors, I've also found that inspecting the goals over MCP (at multiple points in an already-compiling proof) can be useful for automatically discovering where to attempt to split the proof into smaller lemmas -- see, e.g., this workflow that has worked reasonably well for me:<br>\n<a href=\"https://github.com/cameronfreer/lean4-skills/blob/main/plugins/lean4-theorem-proving/skills/lean4-theorem-proving/references/proof-refactoring.md#step-1-survey-the-proof\">https://github.com/cameronfreer/lean4-skills/blob/main/plugins/lean4-theorem-proving/skills/lean4-theorem-proving/references/proof-refactoring.md#step-1-survey-the-proof</a></p>",
        "id": 553474416,
        "sender_full_name": "Cameron Freer",
        "timestamp": 1762201606
    }
]