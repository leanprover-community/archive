[
    {
        "content": "<p>Lots of people on Twitter going on about this new \"make your own language model\" feature which OpenAI just demoed a day or so ago. What happens if you attempt to make an algebraic geometry chatbot e.g. by uploading a ton of stuff from the Stacks Project? Presumably these things are still hallucinating left right and centre? Is there really any breakthrough here or is it just about OpenAI enabling users to fine tune a model?</p>",
        "id": 400825332,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1699395682
    },
    {
        "content": "<p>I don't know whether openai is actually finetuning anything with this feature. As far as I understand, it just asks GPT to make a system prompt, and maybe provides some integration with a vector database for retrieval augmented generation (based on the documents you upload). OTOH, I think they did just introduce the ability to fine-tune GPT4.</p>",
        "id": 400826549,
        "sender_full_name": "Adam Topaz",
        "timestamp": 1699396342
    },
    {
        "content": "<p>Indeed:<br>\n<a href=\"/user_uploads/3121/oYKmszxwyGLDopqKh9R0ZS9y/Screenshot-2023-11-07-at-15-35-00-OpenAI-Platform.png\">Screenshot-2023-11-07-at-15-35-00-OpenAI-Platform.png</a></p>\n<div class=\"message_inline_image\"><a href=\"/user_uploads/3121/oYKmszxwyGLDopqKh9R0ZS9y/Screenshot-2023-11-07-at-15-35-00-OpenAI-Platform.png\" title=\"Screenshot-2023-11-07-at-15-35-00-OpenAI-Platform.png\"><img src=\"/user_uploads/3121/oYKmszxwyGLDopqKh9R0ZS9y/Screenshot-2023-11-07-at-15-35-00-OpenAI-Platform.png\"></a></div>",
        "id": 400826898,
        "sender_full_name": "Adam Topaz",
        "timestamp": 1699396519
    },
    {
        "content": "<p>Can you upload the entireity of the stacks project?</p>",
        "id": 400827540,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1699396838
    },
    {
        "content": "<p>I don't know. I did hear that they charge quite a lot for storage with this feature...</p>",
        "id": 400827634,
        "sender_full_name": "Adam Topaz",
        "timestamp": 1699396896
    },
    {
        "content": "<p>I only ask because I'm giving a talk to a bunch of undergrads in Edinburgh on Thursday and it's always nice to talk about recent developments.</p>",
        "id": 400827947,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1699397079
    },
    {
        "content": "<p>I don't know whether they even rolled out this feature to the public yet.</p>",
        "id": 400828055,
        "sender_full_name": "Adam Topaz",
        "timestamp": 1699397131
    },
    {
        "content": "<p>But at least it seems that I have access to the \"assistant\" variant at the API level.</p>",
        "id": 400828207,
        "sender_full_name": "Adam Topaz",
        "timestamp": 1699397208
    },
    {
        "content": "<p>Here's what I get by pasting the source of the <a href=\"https://raw.githubusercontent.com/stacks/stacks-project/master/schemes.tex\">Schemes chapter</a> (173,208 characters) of the Stacks project into <a href=\"https://claude.ai/\">Anthropic's Claude 2</a>, which has a 100k-token context length, without asking any questions (takes 30s-1min):<br>\n<a href=\"/user_uploads/3121/9fOlGMrwhJXFO6vy-nS8DJAt/image.png\">image.png</a></p>\n<div class=\"message_inline_image\"><a href=\"/user_uploads/3121/9fOlGMrwhJXFO6vy-nS8DJAt/image.png\" title=\"image.png\"><img src=\"/user_uploads/3121/9fOlGMrwhJXFO6vy-nS8DJAt/image.png\"></a></div>",
        "id": 400842871,
        "sender_full_name": "Junyan Xu",
        "timestamp": 1699404906
    },
    {
        "content": "<p>FWIW one of openaiâ€™s other announcements yesterday was an increased context window for gpt4. I think over 100K tokens?</p>",
        "id": 400843532,
        "sender_full_name": "Adam Topaz",
        "timestamp": 1699405205
    },
    {
        "content": "<p>Yeah! 128K iirc</p>",
        "id": 400843647,
        "sender_full_name": "Junyan Xu",
        "timestamp": 1699405246
    },
    {
        "content": "<p>You could also try <a href=\"https://www.reddit.com/r/LocalLLaMA/comments/166je92/llama2_with_128k_context_length_thanks_to_yarn/\">https://www.reddit.com/r/LocalLLaMA/comments/166je92/llama2_with_128k_context_length_thanks_to_yarn/</a></p>",
        "id": 400844189,
        "sender_full_name": "Junyan Xu",
        "timestamp": 1699405421
    },
    {
        "content": "<p>I was told the Morph people trained on some textbooks, maybe Stacks is there?</p>",
        "id": 400844420,
        "sender_full_name": "Junyan Xu",
        "timestamp": 1699405504
    },
    {
        "content": "<p>There's a 128K version of Mistral 7B as well: <a href=\"https://github.com/jquesnelle/yarn#mistral\">https://github.com/jquesnelle/yarn#mistral</a><br>\nand <a href=\"https://ai.meta.com/blog/code-llama-large-language-model-coding/\">Code Llama</a> natively supports 100K.</p>",
        "id": 400844775,
        "sender_full_name": "Junyan Xu",
        "timestamp": 1699405673
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"224323\">Junyan Xu</span> <a href=\"#narrow/stream/219941-Machine-Learning-for-Theorem-Proving/topic/OpenAI.20.22make.20your.20own.20GPT.22/near/400842871\">said</a>:</p>\n<blockquote>\n<p>Here's what I get by pasting the source of the <a href=\"https://raw.githubusercontent.com/stacks/stacks-project/master/schemes.tex\">Schemes chapter</a> (173,208 characters) of the Stacks project into <a href=\"https://claude.ai/\">Anthropic's Claude 2</a>, which has a 100k-token context length, without asking any questions (takes 30s-1min):<br>\n<a href=\"/user_uploads/3121/9fOlGMrwhJXFO6vy-nS8DJAt/image.png\">image.png</a></p>\n</blockquote>\n<p>Input length is a common pain point for transformer-based models. The original BERT model takes 512 tokens as input, but the Longformer model modified its attention mechanism to handle longer inputs.<br>\n<a href=\"https://huggingface.co/docs/transformers/model_doc/longformer\">https://huggingface.co/docs/transformers/model_doc/longformer</a></p>\n<p>However, my personal experience with the Longformer model was not as impressive as with the LLaMa2-70B transformer, although both have the same input length (4096 tokens). <br>\n<a href=\"https://huggingface.co/blog/llama2\">https://huggingface.co/blog/llama2</a></p>\n<p>Perhaps the capabilities of LLMs depend on more than just context length, e.g. how we fine-tune the model (reinforcement learning with human feedback). Note that further experiments are required to confirm it.</p>",
        "id": 401946175,
        "sender_full_name": "Min-Hsien Weng",
        "timestamp": 1699955292
    },
    {
        "content": "<p>is there some technical documentation going somewhat deep (e.g. 1-2 hour read) on how LLMs are fine tuned using reinforcement learning? does that tweak the parameters of the underlying model that predicts the next word, or is that another neural network or other computational layer on top?</p>",
        "id": 402087877,
        "sender_full_name": "Abhishek Anand",
        "timestamp": 1700003714
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"259905\">Abhishek Anand</span> <a href=\"#narrow/stream/219941-Machine-Learning-for-Theorem-Proving/topic/OpenAI.20.22make.20your.20own.20GPT.22/near/402087877\">said</a>:</p>\n<blockquote>\n<p>is there some technical documentation going somewhat deep (e.g. 1-2 hour read) on how LLMs are fine tuned using reinforcement learning? does that tweak the parameters of the underlying model that predicts the next word, or is that another neural network or other computational layer on top?</p>\n</blockquote>\n<p>This blog about reinforcement learning from human feedback (RLHF) is very useful. It explains how to improve large language models (LLMs) using RL without using too much technical terms. Highly recommended. <br>\n<a href=\"https://huggingface.co/blog/rlhf\">https://huggingface.co/blog/rlhf</a></p>\n<p>RLHF constructs a reward model that accurately reflects human preferences and utilizes this model to fine-tune LLMs, enabling them to generate text that closely aligns with human feedback. </p>\n<p>RLHF's fine-tuning method, using reinforcement learning, is quite different from other fine-tuning methods. It keeps the original LLM unchanged while making a copy, fine-tuning and updating the copy one. LLMs have a large number of parameters, so only some are updated during fine-tuning to improve efficiency. The update rule is to maximize the reward of the model by updating the parameters. </p>\n<p>So RLHF fine-tuning modifies the parameters of LLMs directly, unlike other fine-tuning methods that add new layers to the model.</p>",
        "id": 402380941,
        "sender_full_name": "Min-Hsien Weng",
        "timestamp": 1700108247
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"259905\">Abhishek Anand</span> <a href=\"#narrow/stream/219941-Machine-Learning-for-Theorem-Proving/topic/OpenAI.20.22make.20your.20own.20GPT.22/near/402087877\">said</a>:</p>\n<blockquote>\n<p>is there some technical documentation going somewhat deep (e.g. 1-2 hour read) on how LLMs are fine tuned using reinforcement learning? does that tweak the parameters of the underlying model that predicts the next word, or is that another neural network or other computational layer on top?</p>\n</blockquote>\n<p>I highly recommend <a href=\"https://www.youtube.com/watch?v=hhiLw5Q_UFg\">this talk</a> by John Schulman.</p>\n<div class=\"youtube-video message_inline_image\"><a data-id=\"hhiLw5Q_UFg\" href=\"https://www.youtube.com/watch?v=hhiLw5Q_UFg\"><img src=\"https://uploads.zulipusercontent.net/3dd6e6e4fc5ab5a04e84a5a1ce5c75c5abcc4c15/68747470733a2f2f692e7974696d672e636f6d2f76692f6868694c7735515f5546672f64656661756c742e6a7067\"></a></div>",
        "id": 402527922,
        "sender_full_name": "Zhangir Azerbayev",
        "timestamp": 1700158108
    }
]