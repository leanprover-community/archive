[
    {
        "content": "<p>Here's some nonsense from running untuned minGPT on mathlib.</p>\n<div class=\"codehilite\"><pre><span></span><code><span class=\"kn\">lemma</span> <span class=\"n\">max_mem_geom_prod</span> <span class=\"o\">(</span><span class=\"n\">p</span> <span class=\"o\">:</span> <span class=\"n\">α</span> <span class=\"bp\">→</span> <span class=\"n\">α</span><span class=\"o\">)</span> <span class=\"o\">:</span> <span class=\"n\">x</span> <span class=\"err\">∈</span> <span class=\"n\">prod</span> <span class=\"bp\">↔</span> <span class=\"bp\">∀</span><span class=\"n\">a</span><span class=\"o\">,</span> <span class=\"n\">x</span> <span class=\"err\">∈</span> <span class=\"n\">q</span> <span class=\"n\">a</span> <span class=\"o\">:=</span>\n<span class=\"k\">by</span> <span class=\"n\">simpa</span> <span class=\"n\">only</span> <span class=\"o\">[</span><span class=\"n\">mem_restrict_apply</span><span class=\"o\">,</span> <span class=\"n\">max_eq_trans</span><span class=\"o\">,</span> <span class=\"n\">max_eq_trans</span><span class=\"o\">,</span> <span class=\"n\">max_eq_trans</span><span class=\"o\">,</span> <span class=\"n\">max_eq_trans</span><span class=\"o\">]</span>\n\n<span class=\"kn\">lemma</span> <span class=\"n\">max_min_iff</span> <span class=\"o\">{</span><span class=\"n\">p</span> <span class=\"n\">q</span> <span class=\"o\">:</span> <span class=\"kt\">Prop</span><span class=\"o\">}</span> <span class=\"o\">[</span><span class=\"n\">decidable_pred</span> <span class=\"n\">p</span><span class=\"o\">]</span> <span class=\"o\">{</span><span class=\"n\">i</span> <span class=\"o\">:</span> <span class=\"n\">fin</span> <span class=\"n\">n</span><span class=\"o\">}</span> <span class=\"o\">{</span><span class=\"bp\">=</span> <span class=\"n\">s</span><span class=\"o\">}</span> <span class=\"o\">:</span>\n  <span class=\"n\">fin</span><span class=\"bp\">.</span><span class=\"n\">map</span> <span class=\"n\">f</span> <span class=\"bp\">↔</span> <span class=\"n\">p</span> <span class=\"n\">i</span> <span class=\"bp\">=</span> <span class=\"mi\">0</span> <span class=\"o\">:=</span>\n<span class=\"k\">by</span> <span class=\"n\">simp</span> <span class=\"o\">[</span><span class=\"n\">eq_top_iff</span><span class=\"o\">,</span> <span class=\"n\">fin</span><span class=\"bp\">.</span><span class=\"n\">coe_eq_val</span><span class=\"o\">]</span>\n\n<span class=\"c\">/-</span><span class=\"cm\">- The indexing type of a finite complete lattice subsemiring `α` -/</span>\n<span class=\"n\">def</span> <span class=\"n\">submodule</span><span class=\"bp\">.</span><span class=\"n\">set</span><span class=\"bp\">.</span><span class=\"n\">ker</span> <span class=\"o\">{</span><span class=\"n\">α</span><span class=\"o\">}</span> <span class=\"o\">[</span><span class=\"n\">semiring</span> <span class=\"n\">α</span><span class=\"o\">]</span> <span class=\"o\">(</span><span class=\"n\">s</span> <span class=\"n\">t</span> <span class=\"o\">:</span> <span class=\"n\">subsemiring</span> <span class=\"n\">α</span><span class=\"o\">)</span> <span class=\"o\">:</span> <span class=\"n\">semiring</span> <span class=\"o\">(</span><span class=\"n\">semiring</span><span class=\"bp\">.</span><span class=\"n\">map</span> <span class=\"n\">f</span><span class=\"o\">)</span> <span class=\"o\">:=</span>\n<span class=\"n\">submodule</span><span class=\"bp\">.</span><span class=\"n\">ext</span> <span class=\"err\">$</span> <span class=\"bp\">λ</span> <span class=\"n\">x</span><span class=\"o\">,</span> <span class=\"n\">submodule</span><span class=\"bp\">.</span><span class=\"n\">refl</span> <span class=\"bp\">_</span> <span class=\"bp\">_</span>\n\n<span class=\"kn\">section</span> <span class=\"n\">ring</span>\n\n<span class=\"kn\">variables</span> <span class=\"o\">{</span><span class=\"n\">x</span> <span class=\"n\">y</span> <span class=\"o\">:</span> <span class=\"n\">α</span><span class=\"o\">}</span> <span class=\"o\">{</span><span class=\"n\">β</span> <span class=\"o\">:</span> <span class=\"kt\">Type</span><span class=\"bp\">*</span><span class=\"o\">}</span> <span class=\"o\">[</span><span class=\"n\">ring</span> <span class=\"n\">y</span><span class=\"o\">]</span>\n\n<span class=\"c\">/-</span><span class=\"cm\">- Subtraction of a set `α` and `β` are infinite it induces its induced by a new ellowed; or `α` with the natural `y` in `fin n`.</span>\n<span class=\"cm\">-/</span>\n<span class=\"bp\">@</span><span class=\"o\">[</span><span class=\"kn\">inline</span><span class=\"o\">]</span> <span class=\"n\">def</span> <span class=\"n\">dum_of_card_eq_card_pow_eq_one</span> <span class=\"o\">[</span><span class=\"n\">finite_dimensional</span> <span class=\"n\">K</span> <span class=\"n\">V</span><span class=\"o\">]</span> <span class=\"o\">:</span> <span class=\"bp\">∀</span> <span class=\"o\">{</span><span class=\"n\">n</span> <span class=\"o\">:</span> <span class=\"bp\">ℕ</span><span class=\"o\">}</span> <span class=\"o\">{</span><span class=\"n\">x</span> <span class=\"o\">:</span> <span class=\"n\">K</span><span class=\"o\">},</span> <span class=\"n\">x</span> <span class=\"bp\">^</span> <span class=\"n\">n</span> <span class=\"bp\">=</span> <span class=\"mi\">1</span> <span class=\"bp\">↔</span> <span class=\"n\">x</span> <span class=\"bp\">^</span> <span class=\"o\">(</span><span class=\"n\">n</span> <span class=\"bp\">+</span> <span class=\"mi\">1</span><span class=\"o\">)</span> <span class=\"err\">∣</span> <span class=\"mi\">1</span> <span class=\"o\">:=</span>\n<span class=\"k\">begin</span>\n  <span class=\"n\">rw</span> <span class=\"o\">[</span><span class=\"err\">←</span> <span class=\"n\">card_units</span> <span class=\"n\">K</span> <span class=\"n\">p</span><span class=\"o\">,</span> <span class=\"err\">←</span> <span class=\"n\">cardinal</span><span class=\"bp\">.</span><span class=\"n\">lift_injective</span> <span class=\"err\">$</span> <span class=\"n\">is_unit_iff_eq_of_dim_eq</span><span class=\"o\">],</span>\n  <span class=\"n\">convert</span> <span class=\"n\">h</span> <span class=\"o\">{</span><span class=\"n\">n</span><span class=\"o\">}</span> <span class=\"o\">{</span><span class=\"n\">k</span> <span class=\"o\">:</span> <span class=\"bp\">ℤ</span><span class=\"o\">}</span> <span class=\"o\">(</span><span class=\"n\">hk</span> <span class=\"o\">:</span> <span class=\"n\">k</span> <span class=\"err\">∣</span> <span class=\"n\">f</span> <span class=\"n\">b</span><span class=\"o\">)</span> <span class=\"o\">(</span><span class=\"n\">hsucc</span> <span class=\"o\">:</span> <span class=\"bp\">¬</span> <span class=\"n\">cardinal</span><span class=\"o\">)</span> <span class=\"o\">:</span> <span class=\"n\">cardinal</span><span class=\"bp\">.</span><span class=\"o\">{</span><span class=\"n\">u</span><span class=\"o\">}</span> <span class=\"n\">k</span> <span class=\"err\">∈</span> <span class=\"n\">cardinal</span><span class=\"bp\">.</span><span class=\"o\">{</span><span class=\"n\">u</span><span class=\"o\">}</span> <span class=\"o\">:=</span>\n    <span class=\"k\">by</span> <span class=\"o\">{</span> <span class=\"n\">ext</span><span class=\"o\">,</span> <span class=\"n\">exact</span> <span class=\"bp\">⟨</span><span class=\"n\">nat</span><span class=\"bp\">.</span><span class=\"n\">find_min_fac</span> <span class=\"n\">hk</span><span class=\"bp\">⟩</span> <span class=\"o\">}</span><span class=\"bp\">⟩</span>\n\n<span class=\"kn\">theorem</span> <span class=\"n\">nat</span><span class=\"bp\">.</span><span class=\"n\">card_le_card</span> <span class=\"o\">{</span><span class=\"n\">α</span><span class=\"o\">}</span> <span class=\"o\">[</span><span class=\"n\">primcodable</span> <span class=\"n\">α</span><span class=\"o\">]</span> <span class=\"o\">:</span> <span class=\"bp\">@</span><span class=\"n\">primrec&#39;</span> <span class=\"mi\">2</span> <span class=\"o\">(</span><span class=\"bp\">λ</span> <span class=\"n\">v</span><span class=\"o\">,</span> <span class=\"n\">v</span><span class=\"bp\">.</span><span class=\"n\">comp</span> <span class=\"n\">u</span> <span class=\"n\">v</span><span class=\"o\">)</span> <span class=\"o\">:=</span>\n<span class=\"k\">by</span> <span class=\"n\">simp</span> <span class=\"o\">[</span><span class=\"n\">primrec</span><span class=\"bp\">.</span><span class=\"n\">prim</span><span class=\"o\">]</span>\n\n<span class=\"kn\">theorem</span> <span class=\"n\">unpaired&#39;</span> <span class=\"o\">{</span><span class=\"n\">α</span> <span class=\"o\">:</span> <span class=\"kt\">Type</span> <span class=\"n\">u</span><span class=\"o\">}</span> <span class=\"o\">:</span> <span class=\"n\">option</span> <span class=\"o\">(</span><span class=\"bp\">@</span><span class=\"n\">option</span> <span class=\"n\">α</span> <span class=\"bp\">→</span> <span class=\"n\">α</span><span class=\"o\">)</span> <span class=\"o\">:=</span>\n<span class=\"o\">(</span><span class=\"n\">primrec</span><span class=\"bp\">.</span><span class=\"n\">unpaired</span> <span class=\"o\">(</span><span class=\"bp\">λ</span> <span class=\"n\">v</span><span class=\"o\">,</span> <span class=\"n\">v</span><span class=\"bp\">.</span><span class=\"n\">tail</span><span class=\"o\">)</span> <span class=\"n\">unpaired</span>\n\n<span class=\"kn\">theorem</span> <span class=\"n\">unpaired&#39;</span> <span class=\"o\">{</span><span class=\"n\">α</span> <span class=\"o\">:</span> <span class=\"kt\">Type</span> <span class=\"n\">u</span><span class=\"o\">}</span> <span class=\"o\">:</span> <span class=\"n\">option</span> <span class=\"o\">(</span><span class=\"bp\">@</span><span class=\"n\">option</span> <span class=\"n\">α</span> <span class=\"bp\">→</span> <span class=\"n\">α</span> <span class=\"bp\">→</span> <span class=\"kt\">Prop</span><span class=\"o\">)</span> <span class=\"o\">:=</span> <span class=\"n\">dom</span> <span class=\"o\">(</span><span class=\"n\">α</span> <span class=\"bp\">→</span> <span class=\"n\">β</span><span class=\"o\">)</span>\n<span class=\"bp\">|</span> <span class=\"o\">(</span><span class=\"n\">Typed</span> <span class=\"n\">l</span><span class=\"o\">)</span> <span class=\"o\">:=</span> <span class=\"bp\">λ</span> <span class=\"n\">x</span> <span class=\"n\">y</span> <span class=\"n\">c</span> <span class=\"n\">a</span><span class=\"o\">,</span> <span class=\"k\">by</span> <span class=\"n\">simp</span> <span class=\"o\">[]</span>\n\n<span class=\"kn\">theorem</span> <span class=\"n\">unpaired&#39;</span> <span class=\"o\">{</span><span class=\"n\">α</span> <span class=\"o\">:</span> <span class=\"kt\">Type</span> <span class=\"n\">u</span><span class=\"o\">}</span> <span class=\"o\">:</span> <span class=\"bp\">∀</span> <span class=\"o\">{</span><span class=\"n\">β</span> <span class=\"o\">:</span> <span class=\"kt\">Type</span> <span class=\"n\">v</span><span class=\"o\">}</span> <span class=\"o\">{</span><span class=\"n\">x</span><span class=\"o\">}</span> <span class=\"o\">{</span><span class=\"n\">x</span> <span class=\"n\">y</span> <span class=\"o\">:</span> <span class=\"n\">Sort</span> <span class=\"n\">x</span><span class=\"o\">},</span>\n  <span class=\"o\">(</span><span class=\"n\">quot</span><span class=\"bp\">.</span><span class=\"n\">mk</span> <span class=\"n\">x</span> <span class=\"n\">y</span> <span class=\"n\">k</span> <span class=\"n\">x</span> <span class=\"bp\">=</span> <span class=\"n\">quot</span><span class=\"bp\">.</span><span class=\"n\">mk</span> <span class=\"n\">x</span> <span class=\"n\">y</span><span class=\"o\">)</span> <span class=\"bp\">↔</span> <span class=\"n\">x</span> <span class=\"bp\">=</span> <span class=\"n\">quot</span><span class=\"bp\">.</span><span class=\"n\">mk</span> <span class=\"n\">x</span> <span class=\"n\">y</span> <span class=\"o\">:=</span> <span class=\"n\">quot</span><span class=\"bp\">.</span><span class=\"n\">induction_on</span> <span class=\"n\">x</span> <span class=\"err\">$</span> <span class=\"bp\">λ</span> <span class=\"n\">αx</span> <span class=\"n\">y</span> <span class=\"n\">hxy</span><span class=\"o\">,</span>\n  <span class=\"n\">quot</span><span class=\"bp\">.</span><span class=\"n\">induction_on</span> <span class=\"n\">z</span> <span class=\"err\">$</span> <span class=\"bp\">λ</span> <span class=\"n\">β</span> <span class=\"bp\">⟨</span><span class=\"n\">β</span><span class=\"o\">,</span> <span class=\"n\">s</span><span class=\"o\">,</span> <span class=\"bp\">_⟩</span><span class=\"o\">,</span> <span class=\"n\">quot</span><span class=\"bp\">.</span><span class=\"n\">induction_on</span> <span class=\"n\">z</span> <span class=\"err\">$</span> <span class=\"bp\">λ</span> <span class=\"bp\">⟨</span><span class=\"n\">β</span><span class=\"o\">,</span> <span class=\"n\">s</span><span class=\"o\">,</span> <span class=\"bp\">_⟩</span><span class=\"o\">,</span> <span class=\"n\">subtype</span><span class=\"bp\">.</span><span class=\"n\">eq</span> <span class=\"err\">$</span> <span class=\"n\">subtype</span><span class=\"bp\">.</span><span class=\"n\">eq</span> <span class=\"bp\">_⟩</span>\n\n<span class=\"bp\">@</span><span class=\"o\">[</span><span class=\"n\">simp</span><span class=\"o\">]</span> <span class=\"kn\">theorem</span> <span class=\"n\">one_subtype_eq</span> <span class=\"o\">:</span> <span class=\"o\">(</span><span class=\"mi\">1</span> <span class=\"o\">:</span> <span class=\"n\">α</span><span class=\"o\">)</span> <span class=\"bp\">=</span> <span class=\"mi\">1</span> <span class=\"bp\">-</span> <span class=\"mi\">2</span> <span class=\"o\">:=</span> <span class=\"n\">rfl</span>\n\n<span class=\"bp\">@</span><span class=\"o\">[</span><span class=\"n\">simp</span><span class=\"o\">]</span> <span class=\"kn\">theorem</span> <span class=\"n\">one_def</span> <span class=\"o\">:</span> <span class=\"o\">(</span><span class=\"mi\">1</span> <span class=\"o\">:</span> <span class=\"n\">α</span><span class=\"o\">)</span> <span class=\"bp\">=</span> <span class=\"mi\">1</span> <span class=\"o\">:=</span> <span class=\"n\">rfl</span>\n\n<span class=\"kn\">lemma</span> <span class=\"n\">one_def</span> <span class=\"o\">:</span> <span class=\"o\">(</span><span class=\"mi\">1</span> <span class=\"o\">:</span> <span class=\"n\">α</span><span class=\"o\">)</span> <span class=\"bp\">=</span> <span class=\"mi\">1</span> <span class=\"bp\">+</span> <span class=\"mi\">1</span> <span class=\"o\">:=</span> <span class=\"n\">rfl</span>\n</code></pre></div>",
        "id": 207374216,
        "sender_full_name": "Iocta",
        "timestamp": 1597818452
    },
    {
        "content": "<p>this is amazing, definitely lean like if you don't look too closely</p>",
        "id": 207375754,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1597820204
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"253355\">@Iocta</span> Wow, that's nice!</p>",
        "id": 207375821,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1597820254
    },
    {
        "content": "<div class=\"codehilite\"><pre><span></span><code><span class=\"bp\">@</span><span class=\"o\">[</span><span class=\"n\">simp</span><span class=\"o\">]</span> <span class=\"kn\">theorem</span> <span class=\"n\">one_subtype_eq</span> <span class=\"o\">:</span> <span class=\"o\">(</span><span class=\"mi\">1</span> <span class=\"o\">:</span> <span class=\"n\">α</span><span class=\"o\">)</span> <span class=\"bp\">=</span> <span class=\"mi\">1</span> <span class=\"bp\">-</span> <span class=\"mi\">2</span> <span class=\"o\">:=</span> <span class=\"n\">rfl</span>\n</code></pre></div>\n\n\n<p>that's not a very good simp lemma</p>",
        "id": 207375825,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1597820257
    },
    {
        "content": "<p>But does the output typecheck?</p>",
        "id": 207375843,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1597820272
    },
    {
        "content": "<p>Ooh, <code>lemma one_def : (1 : α) = 1 + 1 := rfl</code></p>",
        "id": 207375895,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1597820288
    },
    {
        "content": "<p>the trick: <code>+</code> was defined as <code>\\lam x y, 1</code></p>",
        "id": 207375922,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1597820313
    },
    {
        "content": "<div class=\"codehilite\"><pre><span></span><code><span class=\"kn\">lemma</span> <span class=\"n\">max_min_iff</span> <span class=\"o\">{</span><span class=\"n\">p</span> <span class=\"n\">q</span> <span class=\"o\">:</span> <span class=\"kt\">Prop</span><span class=\"o\">}</span> <span class=\"o\">[</span><span class=\"n\">decidable_pred</span> <span class=\"n\">p</span><span class=\"o\">]</span> <span class=\"o\">{</span><span class=\"n\">i</span> <span class=\"o\">:</span> <span class=\"n\">fin</span> <span class=\"n\">n</span><span class=\"o\">}</span> <span class=\"o\">{</span><span class=\"bp\">=</span> <span class=\"n\">s</span><span class=\"o\">}</span> <span class=\"o\">:</span>\n</code></pre></div>\n\n\n<p>That looks like a syntax error at the end</p>",
        "id": 207375956,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1597820337
    },
    {
        "content": "<div class=\"codehilite\"><pre><span></span><code><span class=\"bp\">@</span><span class=\"o\">[</span><span class=\"kn\">inline</span><span class=\"o\">]</span> <span class=\"n\">def</span> <span class=\"n\">dum_of_card_eq_card_pow_eq_one</span> <span class=\"o\">[</span><span class=\"n\">finite_dimensional</span> <span class=\"n\">K</span> <span class=\"n\">V</span><span class=\"o\">]</span> <span class=\"o\">:</span> <span class=\"bp\">∀</span> <span class=\"o\">{</span><span class=\"n\">n</span> <span class=\"o\">:</span> <span class=\"bp\">ℕ</span><span class=\"o\">}</span> <span class=\"o\">{</span><span class=\"n\">x</span> <span class=\"o\">:</span> <span class=\"n\">K</span><span class=\"o\">},</span> <span class=\"n\">x</span> <span class=\"bp\">^</span> <span class=\"n\">n</span> <span class=\"bp\">=</span> <span class=\"mi\">1</span> <span class=\"bp\">↔</span> <span class=\"n\">x</span> <span class=\"bp\">^</span> <span class=\"o\">(</span><span class=\"n\">n</span> <span class=\"bp\">+</span> <span class=\"mi\">1</span><span class=\"o\">)</span> <span class=\"err\">∣</span> <span class=\"mi\">1</span> <span class=\"o\">:=</span>\n<span class=\"k\">begin</span>\n  <span class=\"n\">rw</span> <span class=\"o\">[</span><span class=\"err\">←</span> <span class=\"n\">card_units</span> <span class=\"n\">K</span> <span class=\"n\">p</span><span class=\"o\">,</span> <span class=\"err\">←</span> <span class=\"n\">cardinal</span><span class=\"bp\">.</span><span class=\"n\">lift_injective</span> <span class=\"err\">$</span> <span class=\"n\">is_unit_iff_eq_of_dim_eq</span><span class=\"o\">],</span>\n  <span class=\"n\">convert</span> <span class=\"n\">h</span> <span class=\"o\">{</span><span class=\"n\">n</span><span class=\"o\">}</span> <span class=\"o\">{</span><span class=\"n\">k</span> <span class=\"o\">:</span> <span class=\"bp\">ℤ</span><span class=\"o\">}</span> <span class=\"o\">(</span><span class=\"n\">hk</span> <span class=\"o\">:</span> <span class=\"n\">k</span> <span class=\"err\">∣</span> <span class=\"n\">f</span> <span class=\"n\">b</span><span class=\"o\">)</span> <span class=\"o\">(</span><span class=\"n\">hsucc</span> <span class=\"o\">:</span> <span class=\"bp\">¬</span> <span class=\"n\">cardinal</span><span class=\"o\">)</span> <span class=\"o\">:</span> <span class=\"n\">cardinal</span><span class=\"bp\">.</span><span class=\"o\">{</span><span class=\"n\">u</span><span class=\"o\">}</span> <span class=\"n\">k</span> <span class=\"err\">∈</span> <span class=\"n\">cardinal</span><span class=\"bp\">.</span><span class=\"o\">{</span><span class=\"n\">u</span><span class=\"o\">}</span> <span class=\"o\">:=</span>\n    <span class=\"k\">by</span> <span class=\"o\">{</span> <span class=\"n\">ext</span><span class=\"o\">,</span> <span class=\"n\">exact</span> <span class=\"bp\">⟨</span><span class=\"n\">nat</span><span class=\"bp\">.</span><span class=\"n\">find_min_fac</span> <span class=\"n\">hk</span><span class=\"bp\">⟩</span> <span class=\"o\">}</span><span class=\"bp\">⟩</span>\n</code></pre></div>\n\n\n<p>this one also, it looks like they got confused in the middle of the <code>convert</code> and ended up back in the binders of a theorem declaration</p>",
        "id": 207376006,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1597820387
    },
    {
        "content": "<div class=\"codehilite\"><pre><span></span><code><span class=\"c\">/-</span><span class=\"cm\">- Subtraction of a set `α` and `β` are infinite it induces its induced by a new ellowed; or `α` with the natural `y` in `fin n`.</span>\n<span class=\"cm\">-/</span>\n</code></pre></div>\n\n\n<p>Brilliant stuff!</p>",
        "id": 207376072,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1597820411
    },
    {
        "content": "<p>Where did the <code>ellowed</code> come from?</p>",
        "id": 207376084,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1597820429
    },
    {
        "content": "<p>It's generating at character-level</p>",
        "id": 207376091,
        "sender_full_name": "Iocta",
        "timestamp": 1597820446
    },
    {
        "content": "<p>Sure, but still</p>",
        "id": 207376097,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1597820460
    },
    {
        "content": "<p>The most scary thing is that is seems to have learned that a name of a declaration should have nothing to do with the statement. It's becoming like an old-skool mathematician very fast!!</p>",
        "id": 207376204,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1597820561
    },
    {
        "content": "<p>I think it mixed <code>induced by a</code> <code>by a new element</code> <code>are allowed;</code></p>",
        "id": 207376235,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1597820609
    },
    {
        "content": "<p>what was <code>d_model</code> for this instance of minGPT?</p>",
        "id": 207376313,
        "sender_full_name": "Jesse Michael Han",
        "timestamp": 1597820677
    },
    {
        "content": "<p>but the context switching is very impressive</p>",
        "id": 207376319,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1597820685
    },
    {
        "content": "<p>comments are appropriately short and sparse :P</p>",
        "id": 207376340,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1597820714
    },
    {
        "content": "<p>and only precede <code>def</code>s</p>",
        "id": 207376352,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1597820730
    },
    {
        "content": "<p>We should use <code>dum</code> instead of <code>dim</code> more often!</p>",
        "id": 207376468,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1597820827
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"116045\">@Jesse Michael Han</span> 512</p>",
        "id": 207376552,
        "sender_full_name": "Iocta",
        "timestamp": 1597820901
    },
    {
        "content": "<p>Did you read the essay that GPT wrote in response to concerns by some philosophers? In it, GPT claimed that it was good at maths...</p>",
        "id": 207376581,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1597820953
    },
    {
        "content": "<p><a href=\"http://dailynous.com/2020/07/30/philosophers-gpt-3/#gpt3replies\">http://dailynous.com/2020/07/30/philosophers-gpt-3/#gpt3replies</a></p>",
        "id": 207376674,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1597821058
    },
    {
        "content": "<p>impressive, maybe we'll even get compiling proofs with <code>d_model</code> at GPT-3's 12288</p>",
        "id": 207376830,
        "sender_full_name": "Jesse Michael Han",
        "timestamp": 1597821192
    },
    {
        "content": "<blockquote>\n<p>\"Maybe you're just good at abstract reasoning,\" I said.</p>\n<p>\"Maybe,\" it said. \"But I'm not sure I understand abstract reasoning. I'm not sure what it is. It's not just logic. I can do logic. But that's not the same thing. I can do lots of things that are not the same thing. I'm good at math. I can do algebra and calculus. But that's not the same thing. I'm good at English. I can read and write. But that's not the same thing. I'm good at philosophy. But that's not the same thing either. So what is it? I'm good at a lot of things. But I'm not sure what I'm good at. I don't know what abstract reasoning is. I'm good at it, but I don't know what it is.\"</p>\n</blockquote>",
        "id": 207376847,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1597821223
    },
    {
        "content": "<p>Interesting, and the proof style looked very Mario</p>",
        "id": 207378165,
        "sender_full_name": "Minchao Wu",
        "timestamp": 1597822546
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"116045\">Jesse Michael Han</span> <a href=\"#narrow/stream/219941-Machine-Learning.20for.20Theorem.20Proving/topic/GPT/near/207376830\">said</a>:</p>\n<blockquote>\n<p>impressive, maybe we'll even get compiling proofs with <code>d_model</code> at GPT-3's 12288</p>\n</blockquote>\n<p>I think it's also a matter of how much data we have. It's possible that the current mathlib is not enough for it to learn to produce compiling proofs</p>",
        "id": 207378834,
        "sender_full_name": "Minchao Wu",
        "timestamp": 1597823112
    },
    {
        "content": "<p>Completely agreed that the data scarcity will be a challenge here. But we're hopeful that we'll get interesting results despite that. <span class=\"user-mention\" data-user-id=\"321854\">@Auguste Poiroux</span> has been working hard on integrating Lean in our existing infrastructure at OpenAI and we'll soon be running initial experiments to better understand the automated theorem capabilities of GPT-* in the context of Lean <span aria-label=\"+1\" class=\"emoji emoji-1f44d\" role=\"img\" title=\"+1\">:+1:</span></p>",
        "id": 207391949,
        "sender_full_name": "Stanislas Polu",
        "timestamp": 1597833290
    },
    {
        "content": "<p>I presume minGPT has been trained with a simple auto-regressive objective on lean files directly here? We're also looking to post-process lean files to train on a conditional objective aiming to generate one tactic application given a goal stack. This has the main advantage that it enables us to tree search.</p>",
        "id": 207392306,
        "sender_full_name": "Stanislas Polu",
        "timestamp": 1597833562
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"253355\">@Iocta</span>  Very interesting!  <code>minGPT</code> just came out a few days ago, right?  What hardware was this trained on?  Is <code>minGPT</code> easy to play around with (for models with a small number of parameters)?</p>",
        "id": 207403778,
        "sender_full_name": "Jason Rute",
        "timestamp": 1597841970
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"249373\">@Stanislas Polu</span> I very much look forward to seeing your results, both for Lean and for your <a href=\"https://groups.google.com/g/metamath/c/D09W2QVR-_I\">Metamath proof assistant</a>. (Are there any other provers you are working with?)</p>",
        "id": 207407232,
        "sender_full_name": "Jason Rute",
        "timestamp": 1597843769
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"115715\">@Jason Rute</span> we've been focusing lately on Metamath. But we've integrated with Hol-light/Holist and now Lean 3</p>",
        "id": 207407378,
        "sender_full_name": "Stanislas Polu",
        "timestamp": 1597843830
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"249373\">Stanislas Polu</span> <a href=\"#narrow/stream/219941-Machine-Learning.20for.20Theorem.20Proving/topic/GPT/near/207392306\">said</a>:</p>\n<blockquote>\n<p>I presume minGPT has been trained with a simple auto-regressive objective on lean files directly here? We're also looking to post-process lean files to train on a conditional objective aiming to generate one tactic application given a goal stack. This has the main advantage that it enables us to tree search.</p>\n</blockquote>\n<p>That makes a lot of sense to incorporate extra information into an auto-regressive generator.  I agree the goal state is an obvious candidate for tactic proofs (as humans also need that to guide their proof).  Is the idea that you would train on data of the following processed form:</p>\n<div class=\"codehilite\"><pre><span></span><code><span class=\"bp\">&lt;</span><span class=\"n\">previous</span> <span class=\"n\">lean</span> <span class=\"n\">code</span><span class=\"bp\">&gt;</span>\n<span class=\"kn\">theorem</span> <span class=\"n\">foo</span> <span class=\"o\">(</span><span class=\"n\">α</span> <span class=\"o\">:</span> <span class=\"kt\">Type</span><span class=\"o\">)</span> <span class=\"o\">(</span><span class=\"n\">a</span> <span class=\"o\">:</span> <span class=\"n\">α</span><span class=\"o\">)</span> <span class=\"o\">:</span> <span class=\"n\">a</span> <span class=\"bp\">=</span> <span class=\"n\">a</span> <span class=\"o\">:=</span> <span class=\"k\">begin</span>\n<span class=\"bp\">&lt;</span><span class=\"n\">state</span><span class=\"bp\">&gt;</span> <span class=\"bp\">&lt;</span><span class=\"n\">tactic</span><span class=\"bp\">&gt;</span><span class=\"o\">,</span>\n<span class=\"bp\">&lt;</span><span class=\"n\">state</span><span class=\"bp\">&gt;</span> <span class=\"bp\">&lt;</span><span class=\"n\">tactic</span><span class=\"bp\">&gt;</span><span class=\"o\">,</span>\n<span class=\"bp\">&lt;</span><span class=\"n\">state</span><span class=\"bp\">&gt;</span> <span class=\"bp\">&lt;</span><span class=\"n\">tactic</span><span class=\"bp\">&gt;</span>\n<span class=\"kn\">end</span>\n</code></pre></div>\n\n\n<p>where <code>&lt;state&gt;</code> is some encoding of the state at that point, something like <code>[state_start] α : Type, a : α |- a = a [end_state]</code>?  When generating a tactic, then you would have the Lean server insert the states before predicting the tactic command?</p>",
        "id": 207407458,
        "sender_full_name": "Jason Rute",
        "timestamp": 1597843879
    },
    {
        "content": "<p>More simply like <code>GOAL &lt;state&gt; PROOFSTEP &lt;tactic&gt;</code>. We may prefix/condition that maybe by a list of imports. We won't be looking to benchmark against a held-out test split from the mathlib  (which causes a complexities: imports / definition presence or not in Lean; theorem/lemma ordering in both Lean and Metamath) but instead plan to converge towards a cross-system benchmark going form high-school algebra (trivial in Lean, not so much in Metamath) to undergrad math exercise (or \"french engineering school entry exam\" for the ones who are familiar with them) to math competitions!</p>",
        "id": 207434276,
        "sender_full_name": "Stanislas Polu",
        "timestamp": 1597856612
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"115715\">@Jason Rute</span> Yeah it's new. It was trained on a P100. It's simple to tune parameters (though GPU time is constrained by budget).</p>",
        "id": 207444924,
        "sender_full_name": "Iocta",
        "timestamp": 1597862156
    },
    {
        "content": "<p>Update: we're working on training GPT-like models on the <code>goal_state -&gt; tactic</code> task (we're using <span class=\"user-mention\" data-user-id=\"115715\">@Jason Rute</span> extraction methodology (calling the lean-server on every files and recording \"state\" events)). We'll probably fork the VSCode extension to evaluate our model qualitatively. If anybody interested in trying it out when it's ready, we'd love to chat!</p>",
        "id": 207828334,
        "sender_full_name": "Stanislas Polu",
        "timestamp": 1598265294
    },
    {
        "content": "<p>(Also if anybody knows who are the best contacts to discuss the VSCode extension, I'd be super interested <span aria-label=\"thank you\" class=\"emoji emoji-1f64f\" role=\"img\" title=\"thank you\">:thank_you:</span>)</p>",
        "id": 207828451,
        "sender_full_name": "Stanislas Polu",
        "timestamp": 1598265383
    },
    {
        "content": "<p>That's <span class=\"user-mention\" data-user-id=\"110043\">@Gabriel Ebner</span>, <span class=\"user-mention\" data-user-id=\"121918\">@Edward Ayers</span>, <span class=\"user-mention\" data-user-id=\"123965\">@Bryan Gin-ge Chen</span>.</p>",
        "id": 207828479,
        "sender_full_name": "Gabriel Ebner",
        "timestamp": 1598265399
    },
    {
        "content": "<p>Yay! <span class=\"user-mention\" data-user-id=\"110043\">@Gabriel Ebner</span> I presume we'll start with a simple branch that \"barely\" works and we can take it from there</p>",
        "id": 207828508,
        "sender_full_name": "Stanislas Polu",
        "timestamp": 1598265437
    },
    {
        "content": "<p>(if that works for you)</p>",
        "id": 207828527,
        "sender_full_name": "Stanislas Polu",
        "timestamp": 1598265454
    },
    {
        "content": "<p>Sure, feel free to post questions (here or on #general) if you're stuck.</p>",
        "id": 207828593,
        "sender_full_name": "Gabriel Ebner",
        "timestamp": 1598265509
    },
    {
        "content": "<p>Is there a list of Lean resources available online that is more informal and therefore maybe more extensive than the recent <a href=\"https://leanprover-community.github.io/lean_projects.html\">Lean projects</a>? Aslo, how broken is <a href=\"https://github.com/leanprover-community/lean-perfectoid-spaces\">lean-perfectoid-spaces</a>? My intuition is that it is just slightly broken wrt newer versions of Lean but still in pretty good shape (and therefore good to harvest from an ML perspective?)</p>",
        "id": 208675993,
        "sender_full_name": "Stanislas Polu",
        "timestamp": 1598961039
    },
    {
        "content": "<p>I believe the roadmap for <code>lean-perfectoid-spaces</code> is to eventually move everything into mathlib, and parts have already been migrated.<br>\n<span class=\"user-mention\" data-user-id=\"112680\">@Johan Commelin</span> <span class=\"user-mention\" data-user-id=\"110031\">@Patrick Massot</span> <span class=\"user-mention\" data-user-id=\"110038\">@Kevin Buzzard</span></p>",
        "id": 208676399,
        "sender_full_name": "Gabriel Ebner",
        "timestamp": 1598961257
    },
    {
        "content": "<p>It is a <em>very</em> unfortunate side effect of Rob's recent efforts that the perfectoid project seem broken. This isn't true at all.</p>",
        "id": 208676503,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1598961326
    },
    {
        "content": "<p>It is unmaintained, so it won't build with a recent mathlib, but if you download it, it will work with the versions of Lean+mathlib that are indicated in the project <code>leanpkg.toml</code>.</p>",
        "id": 208676605,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1598961380
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"110043\">@Gabriel Ebner</span> thanks! <span class=\"user-mention\" data-user-id=\"110031\">@Patrick Massot</span> <span aria-label=\"+1\" class=\"emoji emoji-1f44d\" role=\"img\" title=\"+1\">:+1:</span> Do you have an estimate of how much was already migrated to mathlib?</p>",
        "id": 208676628,
        "sender_full_name": "Stanislas Polu",
        "timestamp": 1598961396
    },
    {
        "content": "<p>Rob's table is all about compatibility with a handful of random  versions of mathlib, determined by Lean versions. Each time a new version of Lean comes out <em>and</em> mathlib builds with the version for the first time, the preceding mathlib commit becomes a new column in this table.</p>",
        "id": 208676692,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1598961451
    },
    {
        "content": "<p>Makes total sense.</p>",
        "id": 208676786,
        "sender_full_name": "Stanislas Polu",
        "timestamp": 1598961505
    },
    {
        "content": "<p>In principle, everything which is currently inside the perfectoid repo is not in mathlib, but there are some exceptions. However a lot of work from the project was migrated to mathlib and can no longer be seen in our repo (or was never in the repo and directly contributed to mathlib with our project in mind).</p>",
        "id": 208676824,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1598961544
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"110031\">@Patrick Massot</span> fantastic and good to know. thanks a lot!</p>",
        "id": 208677191,
        "sender_full_name": "Stanislas Polu",
        "timestamp": 1598961769
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"249373\">@Stanislas Polu</span> just to comment that the perfectoid project is now compiling with lean 3.4.2 and mathlib branch lean-3.4.2</p>",
        "id": 211591753,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1601367089
    },
    {
        "content": "<p>Thanks! Roger that <span aria-label=\"+1\" class=\"emoji emoji-1f44d\" role=\"img\" title=\"+1\">:+1:</span></p>",
        "id": 211592838,
        "sender_full_name": "Stanislas Polu",
        "timestamp": 1601367801
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"110038\">@Kevin Buzzard</span> <span class=\"user-mention\" data-user-id=\"112680\">@Johan Commelin</span> very curious if you find <a href=\"https://openai.com/research/gpt-4\">https://openai.com/research/gpt-4</a> a little less dumb than previous versions</p>",
        "id": 341857235,
        "sender_full_name": "Daniel Selsam",
        "timestamp": 1678813653
    },
    {
        "content": "<p>also curious if you find Bing Chat (which can read some documents on the fly) a little less wrong on math</p>",
        "id": 341857600,
        "sender_full_name": "Daniel Selsam",
        "timestamp": 1678813728
    },
    {
        "content": "<p>When is this going to be available on <a href=\"https://chat.openai.com/\">https://chat.openai.com/</a> ? I tried signing up for a \"plus\" account just now hoping that it would give me access to the new model, but it does not seem to.</p>",
        "id": 341861437,
        "sender_full_name": "David Renshaw",
        "timestamp": 1678814672
    },
    {
        "content": "<p>I'm probably the wrong person to ask -- I've never used ChatGPT and the only thing I know about it is just the constant stream of \"ha ha look what it did now\" posts which were all over Twitter (and even here) a month or two ago. I guess the thing which concerned me the most about ChatGPT (in terms of doing research math) were the questions of the form \"You're on the Monty Hall show. You open door 1 and it's the car. That's the thing you want. Monty opens door 3 and it's a goat. He then asks you if you want to change. Do you change?\" and ChatGPT confidently just spits out the standard argument saying that you should change (even carefully and correctly explaining the mathematics behind the standard Monty Hall question) without even reading the question properly (and noticing that it is not the standard question). In mathematics you do see changes in the question like this, and just going with the most popular answer to a similar question isn't going to work in those situations.</p>",
        "id": 341871453,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1678817313
    },
    {
        "content": "<p>ah, looks like I have access now. I tried asking:</p>\n<blockquote>\n<p>Can you help me fill in the Lean 3 proof below?<br>\nWhat should go where the <code>sorry</code> is?</p>\n</blockquote>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"kn\">import</span> <span class=\"n\">algebra.big_operators.intervals</span>\n<span class=\"kn\">import</span> <span class=\"n\">algebra.big_operators.ring</span>\n<span class=\"kn\">import</span> <span class=\"n\">data.nat.prime</span>\n<span class=\"kn\">import</span> <span class=\"n\">algebra.associated</span>\n<span class=\"kn\">import</span> <span class=\"n\">data.int.basic</span>\n<span class=\"kn\">import</span> <span class=\"n\">tactic.ring</span>\n\n<span class=\"n\">open_locale</span> <span class=\"n\">big_operators</span>\n\n<span class=\"kd\">lemma</span> <span class=\"n\">sum_range_square_mul_six</span> <span class=\"o\">(</span><span class=\"n\">n</span> <span class=\"o\">:</span> <span class=\"n\">ℕ</span><span class=\"o\">)</span> <span class=\"o\">:</span>\n  <span class=\"o\">(</span><span class=\"bp\">∑</span><span class=\"o\">(</span><span class=\"n\">i</span><span class=\"o\">:</span><span class=\"n\">ℕ</span><span class=\"o\">)</span> <span class=\"k\">in</span> <span class=\"n\">finset.range</span> <span class=\"n\">n</span><span class=\"o\">,</span> <span class=\"o\">(</span><span class=\"n\">i</span><span class=\"bp\">+</span><span class=\"mi\">1</span><span class=\"o\">)</span><span class=\"bp\">^</span><span class=\"mi\">2</span><span class=\"o\">)</span> <span class=\"bp\">*</span> <span class=\"mi\">6</span> <span class=\"bp\">=</span> <span class=\"n\">n</span> <span class=\"bp\">*</span> <span class=\"o\">(</span><span class=\"n\">n</span> <span class=\"bp\">+</span> <span class=\"mi\">1</span><span class=\"o\">)</span> <span class=\"bp\">*</span> <span class=\"o\">(</span><span class=\"mi\">2</span><span class=\"bp\">*</span><span class=\"n\">n</span> <span class=\"bp\">+</span> <span class=\"mi\">1</span><span class=\"o\">)</span> <span class=\"o\">:=</span>\n<span class=\"kd\">begin</span>\n  <span class=\"gr\">sorry</span>\n<span class=\"kd\">end</span>\n</code></pre></div>\n<p>and it said</p>\n<blockquote>\n<p>I can help you complete the Lean 3 proof for the given lemma. Replace the sorry with the following proof:</p>\n</blockquote>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"n\">induction</span> <span class=\"n\">n</span> <span class=\"k\">with</span> <span class=\"n\">n</span> <span class=\"n\">ih</span><span class=\"o\">,</span>\n<span class=\"o\">{</span> <span class=\"n\">simp</span> <span class=\"o\">},</span>\n<span class=\"o\">{</span> <span class=\"n\">rw</span> <span class=\"n\">finset.sum_range_succ</span><span class=\"o\">,</span>\n  <span class=\"n\">rw</span> <span class=\"n\">mul_add</span><span class=\"o\">,</span>\n  <span class=\"n\">rw</span> <span class=\"n\">ih</span><span class=\"o\">,</span>\n  <span class=\"n\">rw</span> <span class=\"n\">nat.succ_eq_add_one</span><span class=\"o\">,</span>\n  <span class=\"n\">rw</span> <span class=\"n\">add_mul</span><span class=\"o\">,</span>\n  <span class=\"n\">rw</span> <span class=\"n\">add_mul</span><span class=\"o\">,</span>\n  <span class=\"n\">rw</span> <span class=\"n\">one_mul</span><span class=\"o\">,</span>\n  <span class=\"n\">rw</span> <span class=\"n\">one_mul</span><span class=\"o\">,</span>\n  <span class=\"n\">rw</span> <span class=\"n\">mul_add</span><span class=\"o\">,</span>\n  <span class=\"n\">rw</span> <span class=\"n\">add_assoc</span><span class=\"o\">,</span>\n  <span class=\"n\">rw</span> <span class=\"n\">add_assoc</span><span class=\"o\">,</span>\n  <span class=\"n\">rw</span> <span class=\"n\">mul_comm</span> <span class=\"n\">_</span> <span class=\"o\">(</span><span class=\"n\">n</span> <span class=\"bp\">+</span> <span class=\"mi\">1</span><span class=\"o\">),</span>\n <span class=\"bp\">...</span> <span class=\"o\">(</span><span class=\"n\">hundreds</span> <span class=\"n\">more</span> <span class=\"n\">similar</span> <span class=\"n\">lines</span> <span class=\"n\">until</span> <span class=\"n\">I</span> <span class=\"n\">killed</span> <span class=\"n\">it</span><span class=\"o\">)</span>\n</code></pre></div>",
        "id": 341901005,
        "sender_full_name": "David Renshaw",
        "timestamp": 1678826981
    },
    {
        "content": "<p>Nice! Does it work?</p>",
        "id": 341901167,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1678827040
    },
    {
        "content": "<p>Oh -- I thought it was finite.</p>",
        "id": 341901189,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1678827050
    },
    {
        "content": "<p>the base case looks good. The inductive step... it kinda got itself stuck.</p>",
        "id": 341901242,
        "sender_full_name": "David Renshaw",
        "timestamp": 1678827068
    },
    {
        "content": "<p><code>finset.sum_range_succ</code> is indeed the main lemma to use here</p>",
        "id": 341901427,
        "sender_full_name": "David Renshaw",
        "timestamp": 1678827125
    },
    {
        "content": "<p>Oh it's not too far off -- <code>rw add_mul</code> instead of <code>rw mul_add</code> would have got it to correctly apply the inductive hypothesis, and then <code>ring</code> would have finished it after <code>rw nat.succ_eq_add_one</code>. Maybe it was reluctant to use a high-powered tactic.</p>",
        "id": 341901648,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1678827202
    },
    {
        "content": "<p>I also tried asking it to fill in a Lean 4 proof of a similar lemma, and it gave me Lean 3 code. (That's maybe not too surprising.)</p>",
        "id": 341902333,
        "sender_full_name": "David Renshaw",
        "timestamp": 1678827432
    },
    {
        "content": "<p>Microsoft <a href=\"https://blogs.bing.com/search/march_2023/Confirmed-the-new-Bing-runs-on-OpenAI%E2%80%99s-GPT-4\">confirmed</a> Bing Chat is using GPT-4, so you've already accessed to GPT-4 if you used new Bing.</p>",
        "id": 341911136,
        "sender_full_name": "Junyan Xu",
        "timestamp": 1678830458
    },
    {
        "content": "<p>And GPT-4 is indeed reported to be a lot better at maths than ChatGPT:<br>\n<a href=\"/user_uploads/3121/hSvAxS6-FR6DHZY1FNaQlAZF/image.png\">image.png</a><br>\n<a href=\"/user_uploads/3121/gN89L25rnIaZfH4y8IrWgrgj/image.png\">image.png</a><br>\n<a href=\"/user_uploads/3121/jNOAn2C47F3YBWISTUc1VMOj/image.png\">image.png</a> <br>\n<a href=\"/user_uploads/3121/IbkGWZ4AwO33RfaM93sfLfj0/image.png\">image.png</a><br>\n<a href=\"/user_uploads/3121/5r0Gdg-PtHeMf36Th-GleX3B/image.png\">image.png</a></p>\n<div class=\"message_inline_image\"><a href=\"/user_uploads/3121/hSvAxS6-FR6DHZY1FNaQlAZF/image.png\" title=\"image.png\"><img src=\"/user_uploads/3121/hSvAxS6-FR6DHZY1FNaQlAZF/image.png\"></a></div><div class=\"message_inline_image\"><a href=\"/user_uploads/3121/gN89L25rnIaZfH4y8IrWgrgj/image.png\" title=\"image.png\"><img src=\"/user_uploads/3121/gN89L25rnIaZfH4y8IrWgrgj/image.png\"></a></div><div class=\"message_inline_image\"><a href=\"/user_uploads/3121/jNOAn2C47F3YBWISTUc1VMOj/image.png\" title=\"image.png\"><img src=\"/user_uploads/3121/jNOAn2C47F3YBWISTUc1VMOj/image.png\"></a></div><div class=\"message_inline_image\"><a href=\"/user_uploads/3121/IbkGWZ4AwO33RfaM93sfLfj0/image.png\" title=\"image.png\"><img src=\"/user_uploads/3121/IbkGWZ4AwO33RfaM93sfLfj0/image.png\"></a></div><div class=\"message_inline_image\"><a href=\"/user_uploads/3121/5r0Gdg-PtHeMf36Th-GleX3B/image.png\" title=\"image.png\"><img src=\"/user_uploads/3121/5r0Gdg-PtHeMf36Th-GleX3B/image.png\"></a></div>",
        "id": 341911270,
        "sender_full_name": "Junyan Xu",
        "timestamp": 1678830504
    },
    {
        "content": "<p>In January 30, ChatGPT's maths ability was improved according to <a href=\"https://help.openai.com/en/articles/6825453-chatgpt-release-notes\">changelog</a>. Not sure whether the current version is v2, v3, or v4.</p>",
        "id": 341911422,
        "sender_full_name": "Junyan Xu",
        "timestamp": 1678830591
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"243791\">@David Renshaw</span> Hard for people to do it in one shot as well! It proved it on my first attempt, with informal planning and Lean interaction. After the initial prompt, I just blindly pasted in the result from the Lean Web Editor after each step suggested by the model. This process can be trivially automated.</p>\n<blockquote>\n<p>Me</p>\n</blockquote>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"kn\">import</span> <span class=\"n\">algebra.big_operators.intervals</span>\n<span class=\"kn\">import</span> <span class=\"n\">algebra.big_operators.ring</span>\n<span class=\"kn\">import</span> <span class=\"n\">data.nat.prime</span>\n<span class=\"kn\">import</span> <span class=\"n\">algebra.associated</span>\n<span class=\"kn\">import</span> <span class=\"n\">data.int.basic</span>\n<span class=\"kn\">import</span> <span class=\"n\">tactic.ring</span>\n\n<span class=\"n\">open_locale</span> <span class=\"n\">big_operators</span>\n\n<span class=\"kd\">lemma</span> <span class=\"n\">sum_range_square_mul_six</span> <span class=\"o\">(</span><span class=\"n\">n</span> <span class=\"o\">:</span> <span class=\"n\">ℕ</span><span class=\"o\">)</span> <span class=\"o\">:</span>\n  <span class=\"o\">(</span><span class=\"bp\">∑</span><span class=\"o\">(</span><span class=\"n\">i</span><span class=\"o\">:</span><span class=\"n\">ℕ</span><span class=\"o\">)</span> <span class=\"k\">in</span> <span class=\"n\">finset.range</span> <span class=\"n\">n</span><span class=\"o\">,</span> <span class=\"o\">(</span><span class=\"n\">i</span><span class=\"bp\">+</span><span class=\"mi\">1</span><span class=\"o\">)</span><span class=\"bp\">^</span><span class=\"mi\">2</span><span class=\"o\">)</span> <span class=\"bp\">*</span> <span class=\"mi\">6</span> <span class=\"bp\">=</span> <span class=\"n\">n</span> <span class=\"bp\">*</span> <span class=\"o\">(</span><span class=\"n\">n</span> <span class=\"bp\">+</span> <span class=\"mi\">1</span><span class=\"o\">)</span> <span class=\"bp\">*</span> <span class=\"o\">(</span><span class=\"mi\">2</span><span class=\"bp\">*</span><span class=\"n\">n</span> <span class=\"bp\">+</span> <span class=\"mi\">1</span><span class=\"o\">)</span> <span class=\"o\">:=</span>\n<span class=\"kd\">begin</span>\n  <span class=\"gr\">sorry</span>\n<span class=\"kd\">end</span>\n</code></pre></div>\n<p>Here is the current goal:</p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"n\">n</span> <span class=\"o\">:</span> <span class=\"n\">ℕ</span>\n<span class=\"bp\">⊢</span> <span class=\"o\">(</span><span class=\"bp\">∑</span> <span class=\"o\">(</span><span class=\"n\">i</span> <span class=\"o\">:</span> <span class=\"n\">ℕ</span><span class=\"o\">)</span> <span class=\"k\">in</span> <span class=\"n\">finset.range</span> <span class=\"n\">n</span><span class=\"o\">,</span> <span class=\"o\">(</span><span class=\"n\">i</span> <span class=\"bp\">+</span> <span class=\"mi\">1</span><span class=\"o\">)</span> <span class=\"bp\">^</span> <span class=\"mi\">2</span><span class=\"o\">)</span> <span class=\"bp\">*</span> <span class=\"mi\">6</span> <span class=\"bp\">=</span> <span class=\"n\">n</span> <span class=\"bp\">*</span> <span class=\"o\">(</span><span class=\"n\">n</span> <span class=\"bp\">+</span> <span class=\"mi\">1</span><span class=\"o\">)</span> <span class=\"bp\">*</span> <span class=\"o\">(</span><span class=\"mi\">2</span> <span class=\"bp\">*</span> <span class=\"n\">n</span> <span class=\"bp\">+</span> <span class=\"mi\">1</span><span class=\"o\">)</span>\n</code></pre></div>\n<ol>\n<li>Please write out a plan for proceeding, in English (with LaTeX).</li>\n<li>Please suggest the next tactic step to try next.</li>\n</ol>\n<blockquote>\n<p>Model</p>\n</blockquote>\n<ol>\n<li>Plan:</li>\n</ol>\n<p>We will prove the given lemma by induction on <code>n</code>. The steps are as follows:</p>\n<p>a. Base Case: Show that the equality holds for n = 0.<br>\n      We have LHS = (∑(i:ℕ) in finset.range 0, (i+1)^2) * 6, which should be equal to RHS = 0 * (0 + 1) * (2*0 + 1).</p>\n<p>b. Inductive Step: Assume the equality holds for n = k, and prove that it holds for n = k + 1.<br>\n      We have LHS(k+1) = (∑(i:ℕ) in finset.range (k+1), (i+1)^2) * 6 and RHS(k+1) = (k+1) * ((k+1) + 1) * (2*(k+1) + 1).</p>\n<p>We will use the inductive hypothesis that LHS(k) = RHS(k) and express LHS(k+1) using LHS(k). Then, we will simplify the expression and show that it is equal to RHS(k+1).</p>\n<ol start=\"2\">\n<li>Next tactic step:</li>\n</ol>\n<p>Since we are using induction, let's start with the <code>induction n with k ih</code> tactic. This will introduce the base case and the inductive step.</p>\n<blockquote>\n<p>Me</p>\n</blockquote>\n<p>2 goals<br>\ncase <a href=\"http://nat.zero\">nat.zero</a><br>\n⊢ (∑ (i : ℕ) in finset.range 0, (i + 1) ^ 2) * 6 = 0 * (0 + 1) * (2 * 0 + 1)</p>\n<p>case nat.succ<br>\nk : ℕ,<br>\nih : (∑ (i : ℕ) in finset.range k, (i + 1) ^ 2) * 6 = k * (k + 1) * (2 * k + 1)<br>\n⊢ (∑ (i : ℕ) in finset.range k.succ, (i + 1) ^ 2) * 6 = k.succ * (k.succ + 1) * (2 * k.succ + 1)</p>\n<blockquote>\n<p>Model</p>\n</blockquote>\n<p>Now we have two goals, one for the base case and one for the inductive step. We will handle them one by one.</p>\n<p>Base Case:</p>\n<p>We want to show that (∑ (i : ℕ) in finset.range 0, (i + 1) ^ 2) * 6 = 0 * (0 + 1) * (2 * 0 + 1). The sum over an empty range is 0, so the left-hand side is 0 * 6 = 0. The right-hand side is also 0, so the equality holds for the base case. </p>\n<p>Next tactic step for the base case: <code>simp</code></p>\n<p>Inductive Step:</p>\n<p>We are given the inductive hypothesis <code>ih</code> and want to show that the equality holds for k.succ. We will first rewrite the sum over the range <code>k.succ</code> in terms of the sum over the range <code>k</code>. Then, we will use the inductive hypothesis to replace the sum over the range <code>k</code> and simplify the resulting expression.</p>\n<p>Next tactic step for the inductive step: <code>rw finset.sum_range_succ</code></p>\n<blockquote>\n<p>Me</p>\n</blockquote>\n<p>case nat.succ<br>\nk : ℕ,<br>\nih : (∑ (i : ℕ) in finset.range k, (i + 1) ^ 2) * 6 = k * (k + 1) * (2 * k + 1)<br>\n⊢ (∑ (x : ℕ) in finset.range k, (x + 1) ^ 2 + (k + 1) ^ 2) * 6 = k.succ * (k.succ + 1) * (2 * k.succ + 1)</p>\n<blockquote>\n<p>Model</p>\n</blockquote>\n<p>Now the goal for the inductive step has been rewritten in terms of the sum over the range <code>k</code>. Next, we will use the inductive hypothesis <code>ih</code> to replace the sum over the range <code>k</code> and simplify the resulting expression.</p>\n<p>Next tactic step for the inductive step: <code>rw ih</code></p>\n<blockquote>\n<p>Me </p>\n</blockquote>\n<p>rewrite tactic failed, did not find instance of the pattern in the target expression<br>\n  (∑ (i : ℕ) in finset.range k, (i + 1) ^ 2) * 6<br>\nstate:<br>\ncase nat.succ<br>\nk : ℕ,<br>\nih : (∑ (i : ℕ) in finset.range k, (i + 1) ^ 2) * 6 = k * (k + 1) * (2 * k + 1)<br>\n⊢ (∑ (x : ℕ) in finset.range k, (x + 1) ^ 2 + (k + 1) ^ 2) * 6 = k.succ * (k.succ + 1) * (2 * k.succ + 1)</p>\n<blockquote>\n<p>Model</p>\n</blockquote>\n<p>Apologies for the confusion. We need to rewrite the goal in a way that separates the inductive hypothesis term from the rest.</p>\n<p>Next tactic step for the inductive step: <code>simp only [mul_add, add_mul]</code></p>\n<blockquote>\n<p>Me</p>\n</blockquote>\n<p>case nat.succ<br>\nk : ℕ,<br>\nih : (∑ (i : ℕ) in finset.range k, (i + 1) ^ 2) * 6 = k * (k + 1) * (2 * k + 1)<br>\n⊢ (∑ (x : ℕ) in finset.range k, (x + 1) ^ 2) * 6 + (k + 1) ^ 2 * 6 =<br>\n    k.succ * k.succ * (2 * k.succ) + k.succ * k.succ * 1 + (k.succ * 1 * (2 * k.succ) + k.succ * 1 * 1)</p>\n<blockquote>\n<p>Model</p>\n</blockquote>\n<p>Now the goal for the inductive step has been rewritten so that the inductive hypothesis term is separated from the rest. Next, we will use the inductive hypothesis <code>ih</code> to replace the sum over the range <code>k</code>.</p>\n<p>Next tactic step for the inductive step: <code>rw ih</code></p>\n<blockquote>\n<p>Me</p>\n</blockquote>\n<p>case nat.succ<br>\nk : ℕ,<br>\nih : (∑ (i : ℕ) in finset.range k, (i + 1) ^ 2) * 6 = k * (k + 1) * (2 * k + 1)<br>\n⊢ k * (k + 1) * (2 * k + 1) + (k + 1) ^ 2 * 6 =<br>\n    k.succ * k.succ * (2 * k.succ) + k.succ * k.succ * 1 + (k.succ * 1 * (2 * k.succ) + k.succ * 1 * 1)</p>\n<blockquote>\n<p>Model</p>\n</blockquote>\n<p>Now that we have substituted the inductive hypothesis, we will simplify the expressions and show that both sides of the equation are equal.</p>\n<p>Next tactic step for the inductive step: <code>simp [nat.succ_eq_add_one, mul_add, add_mul]</code></p>\n<blockquote>\n<p>Me</p>\n</blockquote>\n<p>case nat.succ<br>\nk : ℕ,<br>\nih : (∑ (i : ℕ) in finset.range k, (i + 1) ^ 2) * 6 = k * (k + 1) * (2 * k + 1)<br>\n⊢ k * k * (2 * k) + k * k + (k * (2 * k) + k) + (k + 1) ^ 2 * 6 =<br>\n    k * k * (2 * k) + k * k * 2 + (k * (2 * k) + k * 2) + (k * (2 * k) + k * 2 + (2 * k + 2)) + (k * k + k + (k + 1)) +<br>\n      (k * (2 * k) + k * 2 + (2 * k + 2) + (k + 1))</p>\n<blockquote>\n<p>Model</p>\n</blockquote>\n<p>Now both sides of the equation are expanded. We will continue simplifying and combining like terms to show that the equality holds.</p>\n<p>Next tactic step for the inductive step: <code>ring</code></p>\n<blockquote>\n<p>Me</p>\n</blockquote>\n<p>No goals.</p>",
        "id": 341914198,
        "sender_full_name": "Daniel Selsam",
        "timestamp": 1678831767
    },
    {
        "content": "<p>It would be interesting to see how well the automated version of this loop (with some reasonable limit on resources) does on a range of tasks like mathlib lemmas (or IMO problems...).</p>",
        "id": 341914901,
        "sender_full_name": "Michael Stoll",
        "timestamp": 1678832069
    },
    {
        "content": "<p>Yeah this \"many shot\" approach seems to be far more successful. What Michael said!</p>",
        "id": 341920850,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1678834690
    },
    {
        "content": "<p>Hi, I wonder whether anyone has tried it on data that GPT-4 has not seen? IMHO, <code>sum_range_square_mul_six</code> seens quite standard that GPT-4 may have seen such Lean proof (guess it is in mathlib?), or at least human language proof (\"what is the formula of sum of squares\"). Also curious whether anyone tried its performance on MiniF2F and/or other dataset in this field.</p>",
        "id": 341927685,
        "sender_full_name": "fzyzcjy",
        "timestamp": 1678837064
    },
    {
        "content": "<p>You can make PRs to <a href=\"https://github.com/openai/eval\">https://github.com/openai/eval</a>; it seems MiniF2F and ProofNet are not there.</p>",
        "id": 341928192,
        "sender_full_name": "Junyan Xu",
        "timestamp": 1678837403
    },
    {
        "content": "<p>\"hardware correctness\" and \"software correctness\" are apparently a thing in the training of GPT-4. I'd expect they are using unit tests rather than formalization though? <a href=\"https://openai.com/contributions/gpt-4\">https://openai.com/contributions/gpt-4</a></p>\n<p>There's also \"Training run babysitting\" :) and \"Code capability\"</p>",
        "id": 341933480,
        "sender_full_name": "Junyan Xu",
        "timestamp": 1678840233
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"224323\">Junyan Xu</span> <a href=\"#narrow/stream/219941-Machine-Learning-for-Theorem-Proving/topic/GPT/near/341928192\">said</a>:</p>\n<blockquote>\n<p>You can make PRs to <a href=\"https://github.com/openai/eval\">https://github.com/openai/eval</a>; it seems MiniF2F and ProofNet are not there.</p>\n</blockquote>\n<p>We don't know if MiniF2F and Proofnet are in the training set or not tho</p>",
        "id": 342464717,
        "sender_full_name": "Sid",
        "timestamp": 1679024038
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"246665\">Sid</span> <a href=\"#narrow/stream/219941-Machine-Learning-for-Theorem-Proving/topic/GPT/near/342464717\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"224323\">Junyan Xu</span> <a href=\"#narrow/stream/219941-Machine-Learning-for-Theorem-Proving/topic/GPT/near/341928192\">said</a>:</p>\n<blockquote>\n<p>You can make PRs to <a href=\"https://github.com/openai/eval\">https://github.com/openai/eval</a>; it seems MiniF2F and ProofNet are not there.</p>\n</blockquote>\n<p>We don't know if MiniF2F and Proofnet are in the training set or not tho</p>\n</blockquote>\n<p>proofnet definitely isn't in the training set, since gpt-4's knowledge cutoff is 2021.</p>",
        "id": 342629742,
        "sender_full_name": "Zhangir Azerbayev",
        "timestamp": 1679075221
    },
    {
        "content": "<p>Do we know that? Do we even know that what they claim in the paper is true?</p>\n<p>It's so different to maths where everything is like \"we proved this, here's the proof, you can all see it\"</p>",
        "id": 342646217,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1679080006
    },
    {
        "content": "<p>All I feel like I really know is that they didn't train it on things which haven't appeared yet</p>",
        "id": 342646640,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1679080133
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110038\">Kevin Buzzard</span> <a href=\"#narrow/stream/219941-Machine-Learning-for-Theorem-Proving/topic/GPT/near/342646640\">said</a>:</p>\n<blockquote>\n<p>All I feel like I really know is that they didn't train it on things which haven't appeared yet</p>\n</blockquote>\n<p>I wouldn't assume that either ... j/k :)</p>",
        "id": 342647866,
        "sender_full_name": "Daniel Selsam",
        "timestamp": 1679080546
    },
    {
        "content": "<p>I'd be curious to see a GPT4 auto-porter tool that constructs a prompt with the current file up to the cursor along with the matching lean 3 code, and then tries an iterative approach like <a href=\"#narrow/stream/219941-Machine-Learning-for-Theorem-Proving/topic/GPT/near/341914198\">above</a> but extended to work for all text (not just tactics). things it repeatedly misses could be accumulated into tips/hints and added to the original prompt</p>",
        "id": 342651463,
        "sender_full_name": "Daniel Selsam",
        "timestamp": 1679081804
    },
    {
        "content": "<p>I think that if the autoporter was a disaster then this could be a really innovative save, but it seems to me that Mario et al (Gabriel?) have written an excellent autoporter, and often when things don't work it's because there were actually changes between lean 3 and lean 4 which we are now learning how to code around. It would still be an interesting experiment though. Perhaps a better fit would be porting Coq code to Lean code though? Because this is probably too hard for an autoporter to do in some sense. However would the issue there be a lack of training data?</p>",
        "id": 342653637,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1679082643
    },
    {
        "content": "<p>Oops, I haven't been following the autoporter work and I am glad to hear it is working so well. Then I'll just throw out the more general: I think there is major untapped potential in building all sorts of tools that wrap GPT4 subroutines in various ways. It can do so much zero/few shot that I wouldn't worry too much about lack of training data.</p>",
        "id": 342661926,
        "sender_full_name": "Daniel Selsam",
        "timestamp": 1679085813
    },
    {
        "content": "<p>^ especially if you can give it interactive feedback, e.g. tactic states + error messages</p>",
        "id": 342663201,
        "sender_full_name": "Daniel Selsam",
        "timestamp": 1679086252
    },
    {
        "content": "<p>It is also easier than ever to write VSCode plugins since GPT4 can do most of the work for you</p>",
        "id": 342664961,
        "sender_full_name": "Daniel Selsam",
        "timestamp": 1679086980
    },
    {
        "content": "<p>I tried asking ChatGPT-4 for help on a different lemma (this time in Lean 4) just now:</p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"kn\">import</span> <span class=\"n\">Mathlib.Data.Real.Basic</span>\n<span class=\"kn\">import</span> <span class=\"n\">Mathlib.Tactic.LibrarySearch</span>\n<span class=\"kn\">import</span> <span class=\"n\">Mathlib.Tactic.Linarith</span>\n<span class=\"kn\">import</span> <span class=\"n\">Mathlib.Tactic.Ring</span>\n<span class=\"kn\">import</span> <span class=\"n\">Mathlib.Tactic.FieldSimp</span>\n\n<span class=\"kd\">theorem</span> <span class=\"n\">lemma1</span> <span class=\"o\">{</span><span class=\"n\">a</span> <span class=\"n\">b</span> <span class=\"n\">c</span> <span class=\"n\">d</span> <span class=\"o\">:</span> <span class=\"n\">ℝ</span><span class=\"o\">}</span> <span class=\"o\">(</span><span class=\"n\">ha</span> <span class=\"o\">:</span> <span class=\"mi\">0</span> <span class=\"bp\">&lt;</span> <span class=\"n\">a</span><span class=\"o\">)</span> <span class=\"o\">(</span><span class=\"n\">hb</span> <span class=\"o\">:</span> <span class=\"mi\">0</span> <span class=\"bp\">&lt;</span> <span class=\"n\">b</span><span class=\"o\">)</span>\n    <span class=\"o\">(</span><span class=\"n\">h</span> <span class=\"o\">:</span> <span class=\"n\">a</span> <span class=\"bp\">*</span> <span class=\"n\">c</span> <span class=\"bp\">&gt;</span> <span class=\"n\">b</span> <span class=\"bp\">*</span> <span class=\"n\">d</span><span class=\"o\">)</span> <span class=\"o\">:</span> <span class=\"o\">(</span><span class=\"mi\">1</span> <span class=\"bp\">/</span> <span class=\"n\">b</span><span class=\"o\">)</span> <span class=\"bp\">*</span> <span class=\"n\">c</span> <span class=\"bp\">&gt;</span> <span class=\"o\">(</span><span class=\"mi\">1</span><span class=\"bp\">/</span><span class=\"n\">a</span><span class=\"o\">)</span> <span class=\"bp\">*</span> <span class=\"n\">d</span> <span class=\"o\">:=</span> <span class=\"kd\">by</span> <span class=\"gr\">sorry</span>\n</code></pre></div>\n<p>ChatGPT's high-level idea was good, but it kept getting little details wrong, e.g. multiplying on both sides rather than dividing, or using plausible-sounding but non-existent mathlib lemmas.</p>\n<p>After a few somewhat frustrating back-and-forths with ChatGPT, I finished the proof myself and pushed it here:<br>\n<a href=\"https://github.com/dwrensha/math-puzzles-in-lean4/commit/68d6eedd1f487e4ab50ff6c5f018649ce8a7e36e\">https://github.com/dwrensha/math-puzzles-in-lean4/commit/68d6eedd1f487e4ab50ff6c5f018649ce8a7e36e</a></p>\n<p>I consider the new proof to be an improvement on the old one.</p>",
        "id": 342672339,
        "sender_full_name": "David Renshaw",
        "timestamp": 1679090689
    },
    {
        "content": "<p>Is it <code>field_simps; nlinarith</code>?</p>",
        "id": 342680679,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1679094482
    },
    {
        "content": "<p>BTW <code>&gt;</code> considered harmful</p>",
        "id": 342680751,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1679094509
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"243791\">@David Renshaw</span> if you post the transcript I might be able to suggest prompting/interaction tricks</p>",
        "id": 342682315,
        "sender_full_name": "Daniel Selsam",
        "timestamp": 1679095402
    },
    {
        "content": "<p>is there an easy way to export a transcript from the chat interface?</p>",
        "id": 342683550,
        "sender_full_name": "David Renshaw",
        "timestamp": 1679096247
    },
    {
        "content": "<p>I'll copy/paste into a text file and fix it up a bit...</p>",
        "id": 342683561,
        "sender_full_name": "David Renshaw",
        "timestamp": 1679096261
    },
    {
        "content": "<p><a href=\"/user_uploads/3121/Wbk9OeHStPGEWKSQwCQXAi6-/chatgpt-transcript.txt\">chatgpt-transcript.txt</a></p>",
        "id": 342683706,
        "sender_full_name": "David Renshaw",
        "timestamp": 1679096390
    },
    {
        "content": "<p><code>field_simp; nlinarith</code> gives me: <code>linarith failed to find a contradiction</code></p>",
        "id": 342683999,
        "sender_full_name": "David Renshaw",
        "timestamp": 1679096590
    },
    {
        "content": "<p>which is more than I expected ( I thought it would just say something about <code>nlinarith</code> not be implemented in Lean 4 yet.)</p>",
        "id": 342684025,
        "sender_full_name": "David Renshaw",
        "timestamp": 1679096615
    },
    {
        "content": "<p>The trick with these things is the interaction, it seems to me. I'm still only an amateur in this field but is that what they call \"fewshot\"? Some seem to interpret this as \"humans and computers interacting to get better results\" but I always look at it as \"human which knows the answer already telling AI various hints in order to increase the score on their tests so they can say it got 75% rather than 25% because they cheated\"</p>",
        "id": 342684105,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1679096653
    },
    {
        "content": "<p>Having said that it really does seem to help the AI (perhaps unsurprisingly, given that the human is in practice giving out parts of the answer)</p>",
        "id": 342684323,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1679096808
    },
    {
        "content": "<p><code>div_lt_div_of_lt_of_pos</code> is what I was referring to when I said \"plausible-sounding but non-existent mathlib lemmas\"</p>",
        "id": 342684410,
        "sender_full_name": "David Renshaw",
        "timestamp": 1679096879
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"243791\">David Renshaw</span> <a href=\"#narrow/stream/219941-Machine-Learning-for-Theorem-Proving/topic/GPT/near/342683706\">said</a>:</p>\n<blockquote>\n<p><a href=\"/user_uploads/3121/Wbk9OeHStPGEWKSQwCQXAi6-/chatgpt-transcript.txt\">chatgpt-transcript.txt</a></p>\n</blockquote>\n<p>thanks, very interesting! a few notes:</p>\n<ul>\n<li>it is wasting tokens stating the full prefix each time -- ideally you would only be communicating deltas like in my example above</li>\n<li>since lean 4 appears much less on the web than lean 3 (especially when GPT-4 was actually trained), it will probably be extra helpful to put a bunch of example lean4 proofs above the current one in the context. I think the 500 lines above the current spot in the current file would be a good place to start</li>\n<li>consider telling it about other actions it can take, i.e. asking if it wants to pretty print with different settings, search the library for a pattern, etc.</li>\n</ul>",
        "id": 342684493,
        "sender_full_name": "Daniel Selsam",
        "timestamp": 1679096929
    },
    {
        "content": "<p>Conversely I think very highly of those sorts of errors (hallucinating lemmas). I regard them as evidence that we should be actually writing the lemmas and putting them into mathlib</p>",
        "id": 342684518,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1679096960
    },
    {
        "content": "<p>free form convos are great to get started and build intuition, but I would aim for an automatable workflow with a clear protocol for filling in the user messages</p>",
        "id": 342684545,
        "sender_full_name": "Daniel Selsam",
        "timestamp": 1679096987
    },
    {
        "content": "<p>I saw one of the systems suggest <code>[is_foo X]</code> at one point where the correct mathlib would have been just <code>[foo X]</code> and I'm thinking \"yeah but actually it has a point here, we're being inconsistent and it's spotted what we should have called it\"</p>",
        "id": 342684737,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1679097116
    },
    {
        "content": "<p>The machines really are helping us there</p>",
        "id": 342684805,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1679097149
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110038\">Kevin Buzzard</span> <a href=\"#narrow/stream/219941-Machine-Learning-for-Theorem-Proving/topic/GPT/near/342684105\">said</a>:</p>\n<blockquote>\n<p>but is that what they call \"fewshot\"? </p>\n</blockquote>\n<p>Suppose you have a question <code>Q</code> and you want it to give an answer <code>A</code>. \"Few-shot\" prompting refers to formatting the prompt as:</p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"n\">Q</span><span class=\"o\">:</span> <span class=\"bp\">&lt;</span><span class=\"n\">Q1</span><span class=\"bp\">&gt;</span>\n<span class=\"n\">A</span><span class=\"o\">:</span> <span class=\"bp\">&lt;</span><span class=\"n\">A1</span><span class=\"bp\">&gt;</span>\n<span class=\"bp\">...</span>\n<span class=\"n\">Q</span><span class=\"o\">:</span> <span class=\"bp\">&lt;</span><span class=\"n\">Qn</span><span class=\"bp\">&gt;</span>\n<span class=\"n\">A</span><span class=\"o\">:</span> <span class=\"bp\">&lt;</span><span class=\"n\">An</span><span class=\"bp\">&gt;</span>\n<span class=\"n\">Q</span><span class=\"o\">:</span> <span class=\"bp\">&lt;</span><span class=\"n\">Q</span><span class=\"bp\">&gt;</span>\n<span class=\"n\">A</span><span class=\"o\">:</span>\n</code></pre></div>\n<p>It originated as a way of communicating the instruction/goal to the system, but even when an instruction can suffice, including examples in the context often makes it much better, especially on non-standard domains.</p>",
        "id": 342684836,
        "sender_full_name": "Daniel Selsam",
        "timestamp": 1679097178
    },
    {
        "content": "<p>Including the text above the current point in the file also gives it extra information about what imports there are, what declarations are in scope, namespaces open, etc.</p>",
        "id": 342684931,
        "sender_full_name": "Daniel Selsam",
        "timestamp": 1679097249
    },
    {
        "content": "<p>Oh so you don't actually ask the question until you've done the prep? It's not \"ask the question and then keep explaining what the system did wrong until the system gets it right and then you give it a point and say it got it right^* {footnote: we used fewshot}\"?</p>",
        "id": 342684968,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1679097284
    },
    {
        "content": "<p>That was my interpretation of that weasel word</p>",
        "id": 342685003,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1679097314
    },
    {
        "content": "<p>I was trying to understand the comments about the AMC12 results in the GPT4 paper and at the end of it I was totally bewildered about what was actually going on</p>",
        "id": 342685089,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1679097382
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110038\">Kevin Buzzard</span> <a href=\"#narrow/stream/219941-Machine-Learning-for-Theorem-Proving/topic/GPT/near/342684968\">said</a>:</p>\n<blockquote>\n<p>Oh so you don't actually ask the question until you've done the prep? It's not \"ask the question and then keep explaining what the system did wrong until the system gets it right and then you give it a point and say it got it right^* {footnote: we used fewshot}\"?</p>\n</blockquote>\n<p>I don't think I am parsing this correctly, but the short answer is that we are still in the prompting Dark Ages and there is very little in the way of best practices. Also, best practices would change every GPT version (IIRC few-shot prompting didn't even work at all until GPT-3) -- who knows what suddenly works now!</p>",
        "id": 342685093,
        "sender_full_name": "Daniel Selsam",
        "timestamp": 1679097386
    },
    {
        "content": "<p>The paper seemed to say \"we asked the question and then the system wrote some stuff and then we decided which of the multiple choice answers it had chosen\" and my jaw hit the floor</p>",
        "id": 342685134,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1679097434
    },
    {
        "content": "<p>So if the system just wrote loads of waffle implying that the answer was both A and C then the graders could just decide that probably it meant the correct answer</p>",
        "id": 342685187,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1679097481
    },
    {
        "content": "<p>You might also find amusing my chess game against GPT-4 from last night: <a href=\"/user_uploads/3121/STEzKzMtWca41YDCyjPOkzCW/chatgpt-chess-transcript.txt\">chatgpt-chess-transcript.txt</a> . It made no illegal moves, and even almost tricked me into a stalemate. And I'm not entirely sure that it was playing at its full strength (I was the first to blunder).</p>",
        "id": 342685262,
        "sender_full_name": "David Renshaw",
        "timestamp": 1679097532
    },
    {
        "content": "<p>Oh interesting; I'd heard that GPT3 just cheated at chess</p>",
        "id": 342685283,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1679097560
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110038\">Kevin Buzzard</span> <a href=\"#narrow/stream/219941-Machine-Learning-for-Theorem-Proving/topic/GPT/near/342685134\">said</a>:</p>\n<blockquote>\n<p>The paper seemed to say \"we asked the question and then the system wrote some stuff and then we decided which of the multiple choice answers it had chosen\" and my jaw hit the floor</p>\n</blockquote>\n<p>I don't know what you are referring to -- do you recall the page number?</p>",
        "id": 342685289,
        "sender_full_name": "Daniel Selsam",
        "timestamp": 1679097568
    },
    {
        "content": "<p>It was the description of how they had graded the AMC12 paper</p>",
        "id": 342685331,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1679097600
    },
    {
        "content": "<p>I'm on mobile right now, I'll dig it up later</p>",
        "id": 342685416,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1679097612
    },
    {
        "content": "<p>I'm sort of fussy about the small print and I think it's generally established that the paper is in places light on details of how things actually work</p>",
        "id": 342685479,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1679097658
    },
    {
        "content": "<p>For example I'd like to see the complete input and output of the session at the end of which it was decided that GPT4 had scored 40% on AMC12 or whatever the figure was</p>",
        "id": 342685600,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1679097724
    },
    {
        "content": "<p>Rather than \"the engineers at openai said that it scored 40% based on its responses\"</p>",
        "id": 342685634,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1679097756
    },
    {
        "content": "<p>Oh maybe you are referring to</p>\n<blockquote>\n<p>For most exam runs, we extract the model’s letter choice directly from the explanation</p>\n</blockquote>\n<p>IIUC this just means there is some simple script that e.g. looks for <code>(a)</code>, <code>(b)</code>, <code>(c)</code>, <code>(d)</code> and returns the last one that appears in the solution.</p>",
        "id": 342685649,
        "sender_full_name": "Daniel Selsam",
        "timestamp": 1679097764
    },
    {
        "content": "<p>I think that this is just because I'm from a very different community where you're not allowed to say \"I did this and the proof is on a piece of paper in my office\" in publications</p>",
        "id": 342685705,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1679097816
    },
    {
        "content": "<p>I can't comment on what you understand, but my understanding of the sentence is that I'm not being told the whole story</p>",
        "id": 342685787,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1679097850
    },
    {
        "content": "<p>And this would not be solved by openai showing <em>one</em> example of a solution and how it was graded because then they can just choose a totally unambiguous success</p>",
        "id": 342685844,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1679097905
    },
    {
        "content": "<p>I don't know if everything is there yet, but IIUC the plan is to do this with <a href=\"https://github.com/openai/evals/tree/main\">https://github.com/openai/evals/tree/main</a> plus, the model is openly available and anyone can check scores in principle, and also see how robust the model is to rewording</p>",
        "id": 342685862,
        "sender_full_name": "Daniel Selsam",
        "timestamp": 1679097921
    },
    {
        "content": "<p>I'd like to see the entire run and then grade it impartially</p>",
        "id": 342685865,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1679097924
    },
    {
        "content": "<p>I'd also like to see evidence that the script which did the grading was written before the system was given the exam (if indeed that's what happened)</p>",
        "id": 342685948,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1679097966
    },
    {
        "content": "<p>I'm not expecting to see any of this though because computer scientists seem to have no interest in the individual datum of a solution</p>",
        "id": 342685986,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1679098004
    },
    {
        "content": "<p>They always work with large data sets and report outcomes of calculations they did on the datasets</p>",
        "id": 342686040,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1679098039
    },
    {
        "content": "<p>There are two issues here. Firstly, the correct way to do statistics is to completely design the experiment before you actually run it, eg you have to fix the methodology by which the system is going to be graded before the system gets to see the data. It is really really common across all of experimental science that this rule is broken</p>",
        "id": 342686185,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1679098111
    },
    {
        "content": "<p>I ran gpt4 on proofnet and it managed to correctly formalize 29% of theorems few-shot, compared to 13% for codex. The qualitative difference feels huge--there were a good number of instances where the gpt4 formalization matched the human-written reference character-by-character, which almost never happened with codex. </p>\n<p>I'll try other prompting tricks like chain-of-thought and retrieval as soon as I can. Gpt4 seems to really want to do CoT, so much so that it sometimes starts planning out its formalizations in NL even though I have 12 few-shot examples that tell it not to. These methods should improve over the 29% by a good margin. </p>\n<p>If I can get lean-gym working, I'll also try pasting in error messages and automating the proving process from earlier in the thread.</p>",
        "id": 342686289,
        "sender_full_name": "Zhangir Azerbayev",
        "timestamp": 1679098189
    },
    {
        "content": "<p>I've seen evidence of medics analysing drug trials where they just click every statistics test on the software they're using until they find the test which gives them the result which their funders want to see</p>",
        "id": 342686307,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1679098199
    },
    {
        "content": "<p>And secondly I think that looking at the individual data is important rather than the overall percentages. Yang Hui He gave a talk at Imperial and was saying stuff like \"our system correctly predicts the dimension of 70% of these cohomology groups\" and I said \"were 70% of the cohomology groups zero by any chance?\" and his response could be translated as \"I have absolutely no idea, I never looked at the data and don't even have access to it, a post-doc did that bit\"</p>",
        "id": 342686629,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1679098387
    },
    {
        "content": "<p>I can write a system which tells you with high accuracy whether you're straight or gay given only a picture of your knee (assuming a random sample of population), and I don't know a thing about AI.</p>",
        "id": 342686778,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1679098471
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"110038\">@Kevin Buzzard</span> I share your concern about evals in general -- a big motivation for the IMO-GC was to prevent the kind of soft-cheating that was common in ML at the time -- but this model is available to the world, and anyone can eval it on whatever data (past or future) with whatever methodology they want. As for the cohomology groups analogy, I don't think this applies to well-known tests such as AMC where the score is a-priori interpretable.</p>",
        "id": 342686883,
        "sender_full_name": "Daniel Selsam",
        "timestamp": 1679098545
    },
    {
        "content": "<p>I look at these claims in the openAI paper and I'm full of questions about what's actually going on and I find it frustrating that I can't see more details</p>",
        "id": 342686892,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1679098554
    },
    {
        "content": "<p>Individual data for my proofnet gpt4 run: <a href=\"https://github.com/zhangir-azerbayev/ProofNet/tree/gpt4/eval/results/gpt4_12shot_formalize\">https://github.com/zhangir-azerbayev/ProofNet/tree/gpt4/eval/results/gpt4_12shot_formalize</a></p>",
        "id": 342686971,
        "sender_full_name": "Zhangir Azerbayev",
        "timestamp": 1679098585
    },
    {
        "content": "<p>Zhangir still an UG so hasn't been corrupted by the tech company smoke and mirrors yet ;-)</p>",
        "id": 342687088,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1679098672
    },
    {
        "content": "<p>The only evals I still completely trust are ones on data that was created after the model's training set was scraped. ML researchers will try to decontaminate the training set using fuzzy matching, but who knows if that actually works. For all we know there might be some random reddit thread where people have discussed step-by-step solutions for superGLUE problems.</p>",
        "id": 342687877,
        "sender_full_name": "Zhangir Azerbayev",
        "timestamp": 1679099168
    },
    {
        "content": "<p>And I think we can trust industry labs when they say the model was trained only on data up to some date. If it wasn't people would quickly discover the model knows a bunch of really specific facts about things that happened after the knowledge cutoff.</p>",
        "id": 342688071,
        "sender_full_name": "Zhangir Azerbayev",
        "timestamp": 1679099300
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"284997\">Zhangir Azerbayev</span> <a href=\"#narrow/stream/219941-Machine-Learning-for-Theorem-Proving/topic/GPT/near/342688071\">said</a>:</p>\n<blockquote>\n<p>And I think we can trust industry labs when they say the model was trained only on data up to some date. If it wasn't people would quickly discover the model knows a bunch of really specific facts about things that happened after the knowledge cutoff.</p>\n</blockquote>\n<p>Trust, but read footnote 10 :) and then continue to pay attention to minor version numbers</p>",
        "id": 342688171,
        "sender_full_name": "Daniel Selsam",
        "timestamp": 1679099387
    },
    {
        "content": "<p>Daniel has just pointed out to me offline that actually instead of moaning that I can't see what they did, I could literally just go and do it again myself, and I think that this rather negates a lot of my complaints above.</p>",
        "id": 342688470,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1679099538
    },
    {
        "content": "<p>(note that this was definitely not the case in some of my case studies above)</p>",
        "id": 342688512,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1679099580
    },
    {
        "content": "<p>Yes -- given the openness of our API, any number we report that is significantly misleading will <em>obviously</em> be discovered by the Internet in short order, and so we are strongly incentivized not to over-claim. Though of course, mistakes (and subtle contamination) do happen.</p>",
        "id": 342688753,
        "sender_full_name": "Daniel Selsam",
        "timestamp": 1679099725
    },
    {
        "content": "<p>So I guess the issue which isn't resolved by this observation is \"what if you actually trained on the data\" ;-) Maybe worth doing AMC12 2023 the moment it comes out?</p>",
        "id": 342688904,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1679099802
    },
    {
        "content": "<p>But thanks, you've pointed out what was probably quite an obvious point to you but given that I've never actually used GPT3 or 4 at all, hadn't really clicked for me.</p>",
        "id": 342689010,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1679099878
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"284997\">Zhangir Azerbayev</span> <a href=\"#narrow/stream/219941-Machine-Learning-for-Theorem-Proving/topic/GPT/near/342687877\">said</a>:</p>\n<blockquote>\n<p>The only evals I still completely trust are ones on data that was created after the model's training set was scraped. ML researchers will try to decontaminate the training set using fuzzy matching, but who knows if that actually works. For all we know there might be some random reddit thread where people have discussed step-by-step solutions for superGLUE problems.</p>\n</blockquote>\n<p>agreed 100%. full decontamination is ill-posed and impossible -- a problem could appear on some obscure blog in base64 representation of a polish translation :)</p>",
        "id": 342689539,
        "sender_full_name": "Daniel Selsam",
        "timestamp": 1679100186
    },
    {
        "content": "<p>It's even worse -- the committee setting AMC12 problems has an extremely hard job and are inevitably going to be reusing ideas (either implicitly or explicitly). This is one of the reasons why I think AI proving a hard conjecture that humans can't do is currently science fiction -- here there's strong evidence that the sum total of human knowledge available on the internet is not good enough without injection of new ideas. With Wiles' proof of FLT for example you can really point your fingers to where the innovations are.</p>",
        "id": 342690136,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1679100573
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110038\">Kevin Buzzard</span> <a href=\"#narrow/stream/219941-Machine-Learning-for-Theorem-Proving/topic/GPT/near/342690136\">said</a>:</p>\n<blockquote>\n<p>here there's strong evidence that the sum total of human knowledge available on the internet is not good enough without injection of new ideas.</p>\n</blockquote>\n<p>FWIW I am not so sure this is the best way to think about it. The sum total of human knowledge includes accumulated wisdom about effective processes for slowly solving hard new problems. It might be possible to employ that knowledge with a lot of compute/search to tackle big challenges. \"Let's think step by step\" on steroids.</p>",
        "id": 342690783,
        "sender_full_name": "Daniel Selsam",
        "timestamp": 1679100902
    },
    {
        "content": "<p>Right, and this is where I really feel that I don't understand the capabilities of these systems. Every great maths theorem was proved by humans who were inspired by what they knew and somehow took things one crucial step further.</p>",
        "id": 342691763,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1679101499
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110038\">Kevin Buzzard</span> <a href=\"#narrow/stream/219941-Machine-Learning-for-Theorem-Proving/topic/GPT/near/342691763\">said</a>:</p>\n<blockquote>\n<p>Right, and this is where I really feel that I don't understand the capabilities of these systems.</p>\n</blockquote>\n<p>You are in good company :)</p>",
        "id": 342692351,
        "sender_full_name": "Daniel Selsam",
        "timestamp": 1679101819
    },
    {
        "content": "<p>Hi, casual observer here: I think the effective processes for slowly solving hard new problems could still be unique to humans. GPT learned most of the \"fast\" stuff. Here the meaning of fast and slow is analogous to Thinking, Fast and Slow.</p>",
        "id": 342692638,
        "sender_full_name": "Jonathan Yan",
        "timestamp": 1679102035
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"443213\">Jonathan Yan</span> <a href=\"#narrow/stream/219941-Machine-Learning-for-Theorem-Proving/topic/GPT/near/342692638\">said</a>:</p>\n<blockquote>\n<p>Hi, casual observer here: I think the effective processes for slowly solving hard new problems could still be unique to humans. GPT learned most of the \"fast\" stuff. Here the meaning of fast and slow is analogous to Thinking, Fast and Slow.</p>\n</blockquote>\n<p>I think \"Let's think by step by step\" has basically already disproved this, but I would be curious to hear any falsifiable hypotheses based on this framing.</p>",
        "id": 342825428,
        "sender_full_name": "Daniel Selsam",
        "timestamp": 1679164232
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"443213\">@Jonathan Yan</span>  While I agree with the fast and slow framing and that GPT (and other similar neural models) tend to the fast side, there are lots of ways to also introduce slowness into these models.  Chain of thought prompting (e.g. \"let's think step by step\") is one way.  It slows the model down by making it consume more tokens before giving an answer (and it also induces a rudimentary form of recurrence into a model which is otherwise not very recurrent).  Feedback loops, like in Daniel's example above, are another way.  Neural-guided search trees like in Alpha Zero (which are common in many neural theorem proving models) are a third way.  Finally, reinforcement learning is a fourth way to introduce slowness into these models.  So I don't think it is unique to humans, but I think a big part of future AI research is going to be how to effectively incorporate slowness into these otherwise fast models.</p>",
        "id": 342842555,
        "sender_full_name": "Jason Rute",
        "timestamp": 1679175886
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"230999\">@Daniel Selsam</span> My hypothesis is that in 5 years, the best models are going to have a decidedly recognizable \"slow\" mechanism, and that if removed the models will perform much worse on tasks which require reasoning.  That might already be true with things like chain of thought prompting (which I've already claimed are an example of slow thinking), but I think it will be more recognizable (and powerful) in 5 years.</p>",
        "id": 342843245,
        "sender_full_name": "Jason Rute",
        "timestamp": 1679176473
    },
    {
        "content": "<p>I agree with <span class=\"user-mention\" data-user-id=\"115715\">@Jason Rute</span> 's response to <span class=\"user-mention\" data-user-id=\"230999\">@Daniel Selsam</span> , ie concrete examples of the \"slow\" mechanism including the CoT trick, and that a more powerful slow system will improve performance substantially. Thanks!</p>",
        "id": 342880814,
        "sender_full_name": "Jonathan Yan",
        "timestamp": 1679205274
    },
    {
        "content": "<p>More precisely, my intuition is that the \"fast\" (F) system is simply one forward pass of a trained LLM, producing one token. A basic GPT system is running this F with a simple slow (S) mechanism: run until the end. And CoT is human adding \"step by step\" to this S.</p>\n<p>Re \"uniqueness\", I was referring to the unique <em>effectiveness</em> of the human S that magically produces highly-intelligent behavior when applied to the human F, which is less knowledgeable and has a much smaller context window than the machine F.</p>",
        "id": 342881696,
        "sender_full_name": "Jonathan Yan",
        "timestamp": 1679205997
    },
    {
        "content": "<p>Note that the human S has the ability to train the human F on the fly: notice a new concept in exploratory thoughts, recognize that the concept is helpful, do some practice to internalize it (in a matter of days), then build on this new intuition for new thoughts. Mathematicians are extremely good at this while machines still have a long way to go.</p>",
        "id": 342882275,
        "sender_full_name": "Jonathan Yan",
        "timestamp": 1679206472
    },
    {
        "content": "<p>Regarding training data contamination: I've had the impression with the previous releases of Chatgpt that it sometimes knew about big news that happened after its official knowledge cutoff, probably because of users asking it about these and because RLHF training continued on the new interaction samples. <span class=\"user-mention\" data-user-id=\"230999\">@Daniel Selsam</span> do you know more on how this?</p>",
        "id": 342924461,
        "sender_full_name": "Fabian Glöckle",
        "timestamp": 1679228242
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"210057\">Fabian Glöckle</span> <a href=\"#narrow/stream/219941-Machine-Learning-for-Theorem-Proving/topic/GPT/near/342924461\">said</a>:</p>\n<blockquote>\n<p>Regarding training data contamination: I've had the impression with the previous releases of Chatgpt that it sometimes knew about big news that happened after its official knowledge cutoff, probably because of users asking it about these and because RLHF training continued on the new interaction samples. <span class=\"user-mention silent\" data-user-id=\"230999\">Daniel Selsam</span> do you know more on how this?</p>\n</blockquote>\n<p>AFAIK those cutoffs are to set expectations, not a contamination guarantee. Some analogue of footnote 10 applies.</p>",
        "id": 343178920,
        "sender_full_name": "Daniel Selsam",
        "timestamp": 1679332276
    },
    {
        "content": "<p>I see, thank you!</p>",
        "id": 343194914,
        "sender_full_name": "Fabian Glöckle",
        "timestamp": 1679336345
    },
    {
        "content": "<p>I've just had an epic chat session with ChatGPT-3.5, mostly trying to act as a robotic interface between ChatGPT and Lean. That is, my job is to carry proposed code from ChatGPT back to Lean, and error messages or goal states back to ChatGPT.</p>\n<p>I'm not sure whether to characterise it as promising or not.</p>\n<ul>\n<li>It's sure trying hard.</li>\n<li>It's getting mixed up between Lean 3 and Lean 4 syntax a lot</li>\n<li>Even though I tried to ask it to work one line at a time, occasionally it gets complicated ideas, and the \"just report the error messages\" feedback loop isn't enough to suppress these once they happen.</li>\n<li>This is only ChatGPT-3.5, not ChatGPT-4.</li>\n</ul>",
        "id": 343321944,
        "sender_full_name": "Scott Morrison",
        "timestamp": 1679392684
    },
    {
        "content": "<p>Giant transcript follows:</p>\n<hr>\n<p>I'm trying to prove a mathematical statement in the Lean 4 theorem prover, and would like your help suggesting the next step. Please note that I'm working in the newer Lean 4, rather than Lean 3, and the syntax is slightly different. It's okay if you want to give an informal explanation of your idea for the next step. Most importantly, I want you to repeat back the code I'm giving you, with one more proof step before the 'sorry'. Don't try to complete the whole proof immediately, because in a moment I'll use the Lean goal state to give you feedback about how your first suggestion works. The proof I have at the moment is:</p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"kd\">@[simp]</span>\n<span class=\"kd\">theorem</span> <span class=\"n\">getLast_cons</span> <span class=\"o\">{</span><span class=\"n\">a</span> <span class=\"o\">:</span> <span class=\"n\">α</span><span class=\"o\">}</span> <span class=\"o\">{</span><span class=\"n\">l</span> <span class=\"o\">:</span> <span class=\"n\">List</span> <span class=\"n\">α</span><span class=\"o\">}</span> <span class=\"o\">:</span>\n    <span class=\"bp\">∀</span> <span class=\"n\">h</span> <span class=\"o\">:</span> <span class=\"n\">l</span> <span class=\"bp\">≠</span> <span class=\"n\">nil</span><span class=\"o\">,</span> <span class=\"n\">getLast</span> <span class=\"o\">(</span><span class=\"n\">a</span> <span class=\"o\">::</span> <span class=\"n\">l</span><span class=\"o\">)</span> <span class=\"o\">(</span><span class=\"n\">cons_ne_nil</span> <span class=\"n\">a</span> <span class=\"n\">l</span><span class=\"o\">)</span> <span class=\"bp\">=</span> <span class=\"n\">getLast</span> <span class=\"n\">l</span> <span class=\"n\">h</span> <span class=\"o\">:=</span> <span class=\"kd\">by</span>\n  <span class=\"n\">induction</span> <span class=\"n\">l</span> <span class=\"bp\">&lt;;&gt;</span> <span class=\"n\">intros</span>\n  <span class=\"gr\">sorry</span>\n</code></pre></div>\n<hr>\n<p>Based on the provided code, it seems like you're trying to prove a lemma called getLast_cons. This lemma states that for any non-empty list l and element a, the last element of the list a :: l (which is just l with a added to the front) is the same as the last element of l itself.</p>\n<p>To prove this lemma, you've started an induction on the list l, which means you need to consider two cases: the base case when l is empty, and the inductive case when l is non-empty.</p>\n<p>For the base case, you need to show that getLast (a :: nil) _ is equal to getLast nil _, where _ is a proof of the fact that nil is not equal to nil (since you're assuming that l is non-empty). This is impossible to prove, so you can use the cases tactic to show that the assumption h : l ≠ nil is false when l is nil. Here's the modified code:</p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"kd\">@[simp]</span>\n<span class=\"kd\">theorem</span> <span class=\"n\">getLast_cons</span> <span class=\"o\">{</span><span class=\"n\">a</span> <span class=\"o\">:</span> <span class=\"n\">α</span><span class=\"o\">}</span> <span class=\"o\">{</span><span class=\"n\">l</span> <span class=\"o\">:</span> <span class=\"n\">List</span> <span class=\"n\">α</span><span class=\"o\">}</span> <span class=\"o\">:</span>\n    <span class=\"bp\">∀</span> <span class=\"n\">h</span> <span class=\"o\">:</span> <span class=\"n\">l</span> <span class=\"bp\">≠</span> <span class=\"n\">nil</span><span class=\"o\">,</span> <span class=\"n\">getLast</span> <span class=\"o\">(</span><span class=\"n\">a</span> <span class=\"o\">::</span> <span class=\"n\">l</span><span class=\"o\">)</span> <span class=\"o\">(</span><span class=\"n\">cons_ne_nil</span> <span class=\"n\">a</span> <span class=\"n\">l</span><span class=\"o\">)</span> <span class=\"bp\">=</span> <span class=\"n\">getLast</span> <span class=\"n\">l</span> <span class=\"n\">h</span> <span class=\"o\">:=</span> <span class=\"kd\">by</span>\n  <span class=\"n\">induction</span> <span class=\"n\">l</span> <span class=\"k\">with</span> <span class=\"n\">hd</span> <span class=\"n\">tl</span> <span class=\"n\">hl</span>\n  <span class=\"n\">case</span> <span class=\"n\">nil</span>\n  <span class=\"o\">{</span> <span class=\"n\">intro</span> <span class=\"n\">h</span><span class=\"o\">,</span> <span class=\"n\">cases</span> <span class=\"n\">h</span> <span class=\"o\">}</span>\n  <span class=\"gr\">sorry</span>\n</code></pre></div>\n<p>This code pattern-matches on the list l using the with keyword and introduces the variables hd and tl to refer to the head and tail of the list, respectively. In the nil case, you use the intro tactic to introduce the assumption h and the cases tactic to show that it's false. Note that you don't need the ;&lt; notation here because there's only one case to consider.</p>\n<hr>\n<p>When I tried your suggestion, it gave an error on the line <code>induction l with hd tl hl</code>, specifically on the token <code>hd</code>, saying \"unknown tactic\". Remember this is in Lean 4, and the syntax is different from the syntax in Lean 3.</p>\n<hr>\n<p>My apologies for the confusion. In Lean 4, you can pattern-match on the list l using the match keyword instead of with. Here's the modified code that should work:</p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"kd\">@[simp]</span>\n<span class=\"kd\">theorem</span> <span class=\"n\">getLast_cons</span> <span class=\"o\">{</span><span class=\"n\">a</span> <span class=\"o\">:</span> <span class=\"n\">α</span><span class=\"o\">}</span> <span class=\"o\">{</span><span class=\"n\">l</span> <span class=\"o\">:</span> <span class=\"n\">List</span> <span class=\"n\">α</span><span class=\"o\">}</span> <span class=\"o\">:</span>\n    <span class=\"bp\">∀</span> <span class=\"n\">h</span> <span class=\"o\">:</span> <span class=\"n\">l</span> <span class=\"bp\">≠</span> <span class=\"n\">nil</span><span class=\"o\">,</span> <span class=\"n\">getLast</span> <span class=\"o\">(</span><span class=\"n\">a</span> <span class=\"o\">::</span> <span class=\"n\">l</span><span class=\"o\">)</span> <span class=\"o\">(</span><span class=\"n\">cons_ne_nil</span> <span class=\"n\">a</span> <span class=\"n\">l</span><span class=\"o\">)</span> <span class=\"bp\">=</span> <span class=\"n\">getLast</span> <span class=\"n\">l</span> <span class=\"n\">h</span> <span class=\"o\">:=</span> <span class=\"kd\">by</span>\n  <span class=\"k\">match</span> <span class=\"n\">l</span> <span class=\"k\">with</span>\n  <span class=\"bp\">|</span> <span class=\"n\">nil</span> <span class=\"bp\">=&gt;</span> <span class=\"n\">intro</span> <span class=\"n\">h</span><span class=\"bp\">;</span> <span class=\"n\">cases</span> <span class=\"n\">h</span>\n  <span class=\"bp\">|</span> <span class=\"n\">hd</span> <span class=\"o\">::</span> <span class=\"n\">tl</span> <span class=\"bp\">=&gt;</span> <span class=\"n\">intro</span> <span class=\"n\">h</span><span class=\"bp\">;</span> <span class=\"gr\">sorry</span>\n  <span class=\"kd\">end</span>\n</code></pre></div>\n<p>The match keyword is followed by the object being matched, which in this case is the list l. Then, you use the | symbol to separate the different cases to consider. In the first case, when l is nil, you use the =&gt; symbol to specify the tactics to run, which are to introduce the assumption h and then use the cases tactic to show that h is impossible. In the second case, when l is of the form hd :: tl, you again introduce the assumption h and then leave the proof for now with the sorry placeholder.</p>\n<hr>\n<p>When I try your code</p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"kd\">@[simp]</span>\n<span class=\"kd\">theorem</span> <span class=\"n\">getLast_cons</span> <span class=\"o\">{</span><span class=\"n\">a</span> <span class=\"o\">:</span> <span class=\"n\">α</span><span class=\"o\">}</span> <span class=\"o\">{</span><span class=\"n\">l</span> <span class=\"o\">:</span> <span class=\"n\">List</span> <span class=\"n\">α</span><span class=\"o\">}</span> <span class=\"o\">:</span>\n    <span class=\"bp\">∀</span> <span class=\"n\">h</span> <span class=\"o\">:</span> <span class=\"n\">l</span> <span class=\"bp\">≠</span> <span class=\"n\">nil</span><span class=\"o\">,</span> <span class=\"n\">getLast</span> <span class=\"o\">(</span><span class=\"n\">a</span> <span class=\"o\">::</span> <span class=\"n\">l</span><span class=\"o\">)</span> <span class=\"o\">(</span><span class=\"n\">cons_ne_nil</span> <span class=\"n\">a</span> <span class=\"n\">l</span><span class=\"o\">)</span> <span class=\"bp\">=</span> <span class=\"n\">getLast</span> <span class=\"n\">l</span> <span class=\"n\">h</span> <span class=\"o\">:=</span> <span class=\"kd\">by</span>\n  <span class=\"k\">match</span> <span class=\"n\">l</span> <span class=\"k\">with</span>\n  <span class=\"bp\">|</span> <span class=\"n\">nil</span> <span class=\"bp\">=&gt;</span> <span class=\"n\">intro</span> <span class=\"n\">h</span><span class=\"bp\">;</span> <span class=\"n\">cases</span> <span class=\"n\">h</span>\n  <span class=\"bp\">|</span> <span class=\"n\">hd</span> <span class=\"o\">::</span> <span class=\"n\">tl</span> <span class=\"bp\">=&gt;</span> <span class=\"n\">intro</span> <span class=\"n\">h</span><span class=\"bp\">;</span> <span class=\"gr\">sorry</span>\n  <span class=\"kd\">end</span>\n</code></pre></div>\n<p>Lean 4 gives an error on the line <code>| nil =&gt; intro h; cases h</code>, specifically on the token <code>cases</code>, saying <code>tactic 'induction' failed, major premise type is not an inductive type [] = [] → False</code>.</p>\n<hr>\n<p>I apologize for my previous response. The error is due to the fact that you are using cases h on a hypothesis that asserts the non-emptiness of the list l. Instead, you should use cases l to split l into the cases of [] and h :: t, and then perform the necessary steps in each case. Here is the corrected code:</p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"kd\">@[simp]</span>\n<span class=\"kd\">theorem</span> <span class=\"n\">getLast_cons</span> <span class=\"o\">{</span><span class=\"n\">a</span> <span class=\"o\">:</span> <span class=\"n\">α</span><span class=\"o\">}</span> <span class=\"o\">{</span><span class=\"n\">l</span> <span class=\"o\">:</span> <span class=\"n\">List</span> <span class=\"n\">α</span><span class=\"o\">}</span> <span class=\"o\">:</span>\n    <span class=\"bp\">∀</span> <span class=\"n\">h</span> <span class=\"o\">:</span> <span class=\"n\">l</span> <span class=\"bp\">≠</span> <span class=\"n\">nil</span><span class=\"o\">,</span> <span class=\"n\">getLast</span> <span class=\"o\">(</span><span class=\"n\">a</span> <span class=\"o\">::</span> <span class=\"n\">l</span><span class=\"o\">)</span> <span class=\"o\">(</span><span class=\"n\">cons_ne_nil</span> <span class=\"n\">a</span> <span class=\"n\">l</span><span class=\"o\">)</span> <span class=\"bp\">=</span> <span class=\"n\">getLast</span> <span class=\"n\">l</span> <span class=\"n\">h</span> <span class=\"o\">:=</span> <span class=\"kd\">by</span>\n  <span class=\"n\">cases</span> <span class=\"n\">l</span> <span class=\"k\">with</span> <span class=\"n\">hd</span> <span class=\"n\">tl</span>\n  <span class=\"o\">{</span> <span class=\"n\">intro</span> <span class=\"n\">h</span><span class=\"o\">,</span> <span class=\"n\">contradiction</span> <span class=\"o\">},</span>\n  <span class=\"o\">{</span> <span class=\"n\">intro</span> <span class=\"n\">h</span><span class=\"o\">,</span> <span class=\"gr\">sorry</span> <span class=\"o\">}</span>\n</code></pre></div>\n<p>This code uses cases l to split l into the cases of [] and hd :: tl. In the first case, h is a proof of the false statement [] ≠ nil, so you can use the contradiction tactic to complete the proof. In the second case, h is a proof of the statement hd :: tl ≠ nil, so you can use sorry as a placeholder for the rest of the proof.</p>\n<hr>\n<p>When I try your code</p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"kd\">@[simp]</span>\n<span class=\"kd\">theorem</span> <span class=\"n\">getLast_cons</span> <span class=\"o\">{</span><span class=\"n\">a</span> <span class=\"o\">:</span> <span class=\"n\">α</span><span class=\"o\">}</span> <span class=\"o\">{</span><span class=\"n\">l</span> <span class=\"o\">:</span> <span class=\"n\">List</span> <span class=\"n\">α</span><span class=\"o\">}</span> <span class=\"o\">:</span>\n    <span class=\"bp\">∀</span> <span class=\"n\">h</span> <span class=\"o\">:</span> <span class=\"n\">l</span> <span class=\"bp\">≠</span> <span class=\"n\">nil</span><span class=\"o\">,</span> <span class=\"n\">getLast</span> <span class=\"o\">(</span><span class=\"n\">a</span> <span class=\"o\">::</span> <span class=\"n\">l</span><span class=\"o\">)</span> <span class=\"o\">(</span><span class=\"n\">cons_ne_nil</span> <span class=\"n\">a</span> <span class=\"n\">l</span><span class=\"o\">)</span> <span class=\"bp\">=</span> <span class=\"n\">getLast</span> <span class=\"n\">l</span> <span class=\"n\">h</span> <span class=\"o\">:=</span> <span class=\"kd\">by</span>\n  <span class=\"n\">cases</span> <span class=\"n\">l</span> <span class=\"k\">with</span> <span class=\"n\">hd</span> <span class=\"n\">tl</span>\n  <span class=\"o\">{</span> <span class=\"n\">intro</span> <span class=\"n\">h</span><span class=\"o\">,</span> <span class=\"n\">contradiction</span> <span class=\"o\">},</span>\n  <span class=\"o\">{</span> <span class=\"n\">intro</span> <span class=\"n\">h</span><span class=\"o\">,</span> <span class=\"gr\">sorry</span> <span class=\"o\">}</span>\n</code></pre></div>\n<p>Lean 4 gives an error on the line <code>cases l with hd tl</code>, specifically on the token <code>hd</code>, saying <code>unknown tactic</code>.</p>\n<hr>\n<p>I apologize for the mistake. In Lean 4, you can use the cases tactic to perform case analysis on an inductive type. However, List is a parameterized type, so you need to provide the relevant information to the cases tactic. Here is the corrected code:</p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"kd\">@[simp]</span>\n<span class=\"kd\">theorem</span> <span class=\"n\">getLast_cons</span> <span class=\"o\">{</span><span class=\"n\">a</span> <span class=\"o\">:</span> <span class=\"n\">α</span><span class=\"o\">}</span> <span class=\"o\">{</span><span class=\"n\">l</span> <span class=\"o\">:</span> <span class=\"n\">List</span> <span class=\"n\">α</span><span class=\"o\">}</span> <span class=\"o\">:</span>\n    <span class=\"bp\">∀</span> <span class=\"n\">h</span> <span class=\"o\">:</span> <span class=\"n\">l</span> <span class=\"bp\">≠</span> <span class=\"n\">nil</span><span class=\"o\">,</span> <span class=\"n\">getLast</span> <span class=\"o\">(</span><span class=\"n\">a</span> <span class=\"o\">::</span> <span class=\"n\">l</span><span class=\"o\">)</span> <span class=\"o\">(</span><span class=\"n\">cons_ne_nil</span> <span class=\"n\">a</span> <span class=\"n\">l</span><span class=\"o\">)</span> <span class=\"bp\">=</span> <span class=\"n\">getLast</span> <span class=\"n\">l</span> <span class=\"n\">h</span> <span class=\"o\">:=</span> <span class=\"kd\">by</span>\n  <span class=\"n\">cases</span> <span class=\"n\">l</span> <span class=\"k\">with</span>\n  <span class=\"bp\">|</span> <span class=\"n\">nil</span> <span class=\"bp\">=&gt;</span> <span class=\"n\">intro</span> <span class=\"n\">h</span><span class=\"bp\">;</span> <span class=\"n\">contradiction</span>\n  <span class=\"bp\">|</span> <span class=\"n\">hd</span> <span class=\"o\">::</span> <span class=\"n\">tl</span> <span class=\"bp\">=&gt;</span> <span class=\"n\">intro</span> <span class=\"n\">h</span><span class=\"bp\">;</span> <span class=\"gr\">sorry</span>\n</code></pre></div>\n<p>In this code, I have replaced the curly braces in cases l with hd tl with the | symbol to match the new Lean 4 syntax. Additionally, since List is a parameterized type, you need to use the pipe (|) to introduce variables for its parameters. In this case, since List has one parameter α, you don't need to provide any variables.</p>\n<p>Now the first case of l = nil uses contradiction to immediately close the goal. The second case of l = hd :: tl leaves the proof for now with sorry.</p>\n<hr>\n<p>When I try your code</p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"kd\">@[simp]</span>\n<span class=\"kd\">theorem</span> <span class=\"n\">getLast_cons</span> <span class=\"o\">{</span><span class=\"n\">a</span> <span class=\"o\">:</span> <span class=\"n\">α</span><span class=\"o\">}</span> <span class=\"o\">{</span><span class=\"n\">l</span> <span class=\"o\">:</span> <span class=\"n\">List</span> <span class=\"n\">α</span><span class=\"o\">}</span> <span class=\"o\">:</span>\n    <span class=\"bp\">∀</span> <span class=\"n\">h</span> <span class=\"o\">:</span> <span class=\"n\">l</span> <span class=\"bp\">≠</span> <span class=\"n\">nil</span><span class=\"o\">,</span> <span class=\"n\">getLast</span> <span class=\"o\">(</span><span class=\"n\">a</span> <span class=\"o\">::</span> <span class=\"n\">l</span><span class=\"o\">)</span> <span class=\"o\">(</span><span class=\"n\">cons_ne_nil</span> <span class=\"n\">a</span> <span class=\"n\">l</span><span class=\"o\">)</span> <span class=\"bp\">=</span> <span class=\"n\">getLast</span> <span class=\"n\">l</span> <span class=\"n\">h</span> <span class=\"o\">:=</span> <span class=\"kd\">by</span>\n  <span class=\"n\">cases</span> <span class=\"n\">l</span> <span class=\"k\">with</span>\n  <span class=\"bp\">|</span> <span class=\"n\">nil</span> <span class=\"bp\">=&gt;</span> <span class=\"n\">intro</span> <span class=\"n\">h</span><span class=\"bp\">;</span> <span class=\"n\">contradiction</span>\n  <span class=\"bp\">|</span> <span class=\"n\">hd</span> <span class=\"o\">::</span> <span class=\"n\">tl</span> <span class=\"bp\">=&gt;</span> <span class=\"n\">intro</span> <span class=\"n\">h</span><span class=\"bp\">;</span> <span class=\"gr\">sorry</span>\n</code></pre></div>\n<p>Lean 4 gives an error on the line <code>  | hd :: tl =&gt; intro h; sorry</code>, specifically on the token <code>::</code>, saying <code>expected '=&gt;'</code>.</p>\n<hr>\n<p>I apologize for the mistake. The issue is that :: is a special symbol in Lean, and it cannot be used as an identifier in the cases tactic. Instead, you can use the backtick symbol () to surround ::` and treat it as an identifier. Here is the corrected code:</p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"kd\">@[simp]</span>\n<span class=\"kd\">theorem</span> <span class=\"n\">getLast_cons</span> <span class=\"o\">{</span><span class=\"n\">a</span> <span class=\"o\">:</span> <span class=\"n\">α</span><span class=\"o\">}</span> <span class=\"o\">{</span><span class=\"n\">l</span> <span class=\"o\">:</span> <span class=\"n\">List</span> <span class=\"n\">α</span><span class=\"o\">}</span> <span class=\"o\">:</span>\n    <span class=\"bp\">∀</span> <span class=\"n\">h</span> <span class=\"o\">:</span> <span class=\"n\">l</span> <span class=\"bp\">≠</span> <span class=\"n\">nil</span><span class=\"o\">,</span> <span class=\"n\">getLast</span> <span class=\"o\">(</span><span class=\"n\">a</span> <span class=\"o\">::</span> <span class=\"n\">l</span><span class=\"o\">)</span> <span class=\"o\">(</span><span class=\"n\">cons_ne_nil</span> <span class=\"n\">a</span> <span class=\"n\">l</span><span class=\"o\">)</span> <span class=\"bp\">=</span> <span class=\"n\">getLast</span> <span class=\"n\">l</span> <span class=\"n\">h</span> <span class=\"o\">:=</span> <span class=\"kd\">by</span>\n  <span class=\"n\">cases</span> <span class=\"n\">l</span> <span class=\"k\">with</span>\n  <span class=\"bp\">|</span> <span class=\"n\">nil</span> <span class=\"bp\">=&gt;</span> <span class=\"n\">intro</span> <span class=\"n\">h</span><span class=\"bp\">;</span> <span class=\"n\">contradiction</span>\n  <span class=\"bp\">|</span> <span class=\"bp\">`</span><span class=\"o\">(</span><span class=\"n\">_</span><span class=\"o\">,</span> <span class=\"n\">_</span><span class=\"o\">)</span> <span class=\"bp\">=&gt;</span> <span class=\"n\">intro</span> <span class=\"n\">h</span><span class=\"bp\">;</span> <span class=\"gr\">sorry</span>\n</code></pre></div>\n<p>In this code, I have replaced :: with the backtick symbol to treat it as an identifier. The (_, _) notation is used to match any pair, which is what :: is in Lean. Now, the first case of l = nil uses contradiction to immediately close the goal. The second case of l = hd :: tl leaves the proof for now with sorry.</p>\n<hr>\n<p>When I try your code</p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"kd\">@[simp]</span>\n<span class=\"kd\">theorem</span> <span class=\"n\">getLast_cons</span> <span class=\"o\">{</span><span class=\"n\">a</span> <span class=\"o\">:</span> <span class=\"n\">α</span><span class=\"o\">}</span> <span class=\"o\">{</span><span class=\"n\">l</span> <span class=\"o\">:</span> <span class=\"n\">List</span> <span class=\"n\">α</span><span class=\"o\">}</span> <span class=\"o\">:</span>\n    <span class=\"bp\">∀</span> <span class=\"n\">h</span> <span class=\"o\">:</span> <span class=\"n\">l</span> <span class=\"bp\">≠</span> <span class=\"n\">nil</span><span class=\"o\">,</span> <span class=\"n\">getLast</span> <span class=\"o\">(</span><span class=\"n\">a</span> <span class=\"o\">::</span> <span class=\"n\">l</span><span class=\"o\">)</span> <span class=\"o\">(</span><span class=\"n\">cons_ne_nil</span> <span class=\"n\">a</span> <span class=\"n\">l</span><span class=\"o\">)</span> <span class=\"bp\">=</span> <span class=\"n\">getLast</span> <span class=\"n\">l</span> <span class=\"n\">h</span> <span class=\"o\">:=</span> <span class=\"kd\">by</span>\n  <span class=\"n\">cases</span> <span class=\"n\">l</span> <span class=\"k\">with</span>\n  <span class=\"bp\">|</span> <span class=\"n\">nil</span> <span class=\"bp\">=&gt;</span> <span class=\"n\">intro</span> <span class=\"n\">h</span><span class=\"bp\">;</span> <span class=\"n\">contradiction</span>\n  <span class=\"bp\">|</span> <span class=\"bp\">`</span><span class=\"o\">(</span><span class=\"n\">_</span><span class=\"o\">,</span> <span class=\"n\">_</span><span class=\"o\">)</span> <span class=\"bp\">=&gt;</span> <span class=\"n\">intro</span> <span class=\"n\">h</span><span class=\"bp\">;</span> <span class=\"gr\">sorry</span>\n</code></pre></div>\n<p>Lean 4 gives on error on the line <code>  | </code>(_, _) =&gt; intro h; sorry<code>, specifically on the token ```, saying </code>expected '_' or identifier`.</p>\n<hr>\n<p>I apologize for the mistake. The issue is that Lean does not recognize the syntax I used to match the cons cell pattern. Here is an updated version of the code that should work:</p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"kd\">@[simp]</span>\n<span class=\"kd\">theorem</span> <span class=\"n\">getLast_cons</span> <span class=\"o\">{</span><span class=\"n\">a</span> <span class=\"o\">:</span> <span class=\"n\">α</span><span class=\"o\">}</span> <span class=\"o\">{</span><span class=\"n\">l</span> <span class=\"o\">:</span> <span class=\"n\">List</span> <span class=\"n\">α</span><span class=\"o\">}</span> <span class=\"o\">:</span>\n    <span class=\"bp\">∀</span> <span class=\"n\">h</span> <span class=\"o\">:</span> <span class=\"n\">l</span> <span class=\"bp\">≠</span> <span class=\"n\">nil</span><span class=\"o\">,</span> <span class=\"n\">getLast</span> <span class=\"o\">(</span><span class=\"n\">a</span> <span class=\"o\">::</span> <span class=\"n\">l</span><span class=\"o\">)</span> <span class=\"o\">(</span><span class=\"n\">cons_ne_nil</span> <span class=\"n\">a</span> <span class=\"n\">l</span><span class=\"o\">)</span> <span class=\"bp\">=</span> <span class=\"n\">getLast</span> <span class=\"n\">l</span> <span class=\"n\">h</span> <span class=\"o\">:=</span> <span class=\"kd\">by</span>\n  <span class=\"n\">cases</span> <span class=\"n\">l</span> <span class=\"k\">with</span>\n  <span class=\"bp\">|</span> <span class=\"n\">nil</span> <span class=\"bp\">=&gt;</span> <span class=\"n\">intro</span> <span class=\"n\">h</span><span class=\"bp\">;</span> <span class=\"n\">contradiction</span>\n  <span class=\"bp\">|</span> <span class=\"n\">List.cons</span> <span class=\"n\">hd</span> <span class=\"n\">tl</span> <span class=\"bp\">=&gt;</span> <span class=\"n\">intro</span> <span class=\"n\">h</span><span class=\"bp\">;</span> <span class=\"gr\">sorry</span>\n</code></pre></div>\n<p>In this version of the code, I have used List.cons to match the cons cell pattern. Now, the first case of l = nil uses contradiction to immediately close the goal. The second case of l = hd :: tl leaves the proof for now with sorry.</p>\n<hr>\n<p>When I try your code</p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"kd\">@[simp]</span>\n<span class=\"kd\">theorem</span> <span class=\"n\">getLast_cons</span> <span class=\"o\">{</span><span class=\"n\">a</span> <span class=\"o\">:</span> <span class=\"n\">α</span><span class=\"o\">}</span> <span class=\"o\">{</span><span class=\"n\">l</span> <span class=\"o\">:</span> <span class=\"n\">List</span> <span class=\"n\">α</span><span class=\"o\">}</span> <span class=\"o\">:</span>\n    <span class=\"bp\">∀</span> <span class=\"n\">h</span> <span class=\"o\">:</span> <span class=\"n\">l</span> <span class=\"bp\">≠</span> <span class=\"n\">nil</span><span class=\"o\">,</span> <span class=\"n\">getLast</span> <span class=\"o\">(</span><span class=\"n\">a</span> <span class=\"o\">::</span> <span class=\"n\">l</span><span class=\"o\">)</span> <span class=\"o\">(</span><span class=\"n\">cons_ne_nil</span> <span class=\"n\">a</span> <span class=\"n\">l</span><span class=\"o\">)</span> <span class=\"bp\">=</span> <span class=\"n\">getLast</span> <span class=\"n\">l</span> <span class=\"n\">h</span> <span class=\"o\">:=</span> <span class=\"kd\">by</span>\n  <span class=\"n\">cases</span> <span class=\"n\">l</span> <span class=\"k\">with</span>\n  <span class=\"bp\">|</span> <span class=\"n\">nil</span> <span class=\"bp\">=&gt;</span> <span class=\"n\">intro</span> <span class=\"n\">h</span><span class=\"bp\">;</span> <span class=\"n\">contradiction</span>\n  <span class=\"bp\">|</span> <span class=\"n\">List.cons</span> <span class=\"n\">hd</span> <span class=\"n\">tl</span> <span class=\"bp\">=&gt;</span> <span class=\"n\">intro</span> <span class=\"n\">h</span><span class=\"bp\">;</span> <span class=\"gr\">sorry</span>\n</code></pre></div>\n<p>Lean 4 gives on error on the entire line <code>  | List.cons hd tl =&gt; intro h; sorry</code>, saying <code>invalid alternative name 'List.cons'</code>.</p>\n<hr>\n<p>I apologize for the mistake. It seems like Lean 4 does not recognize the List.cons notation. Here is an updated version of the code that should work:</p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"kd\">@[simp]</span>\n<span class=\"kd\">theorem</span> <span class=\"n\">getLast_cons</span> <span class=\"o\">{</span><span class=\"n\">a</span> <span class=\"o\">:</span> <span class=\"n\">α</span><span class=\"o\">}</span> <span class=\"o\">{</span><span class=\"n\">l</span> <span class=\"o\">:</span> <span class=\"n\">List</span> <span class=\"n\">α</span><span class=\"o\">}</span> <span class=\"o\">:</span>\n    <span class=\"bp\">∀</span> <span class=\"n\">h</span> <span class=\"o\">:</span> <span class=\"n\">l</span> <span class=\"bp\">≠</span> <span class=\"n\">nil</span><span class=\"o\">,</span> <span class=\"n\">getLast</span> <span class=\"o\">(</span><span class=\"n\">a</span> <span class=\"o\">::</span> <span class=\"n\">l</span><span class=\"o\">)</span> <span class=\"o\">(</span><span class=\"n\">cons_ne_nil</span> <span class=\"n\">a</span> <span class=\"n\">l</span><span class=\"o\">)</span> <span class=\"bp\">=</span> <span class=\"n\">getLast</span> <span class=\"n\">l</span> <span class=\"n\">h</span> <span class=\"o\">:=</span> <span class=\"kd\">by</span>\n  <span class=\"n\">cases</span> <span class=\"n\">l</span> <span class=\"k\">with</span>\n  <span class=\"bp\">|</span> <span class=\"n\">nil</span> <span class=\"bp\">=&gt;</span> <span class=\"n\">intro</span> <span class=\"n\">h</span><span class=\"bp\">;</span> <span class=\"n\">contradiction</span>\n  <span class=\"bp\">|</span> <span class=\"n\">hd</span> <span class=\"o\">::</span> <span class=\"n\">tl</span> <span class=\"bp\">=&gt;</span> <span class=\"n\">intro</span> <span class=\"n\">h</span><span class=\"bp\">;</span> <span class=\"gr\">sorry</span>\n</code></pre></div>\n<p>In this version of the code, I have used hd :: tl to match the cons cell pattern. Now, the first case of l = nil uses contradiction to immediately close the goal. The second case of l = hd :: tl leaves the proof for now with sorry.</p>\n<hr>\n<p>Okay, that still produces an error, so I'm going to help you out. The correct syntax here is</p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"kd\">@[simp]</span>\n<span class=\"kd\">theorem</span> <span class=\"n\">getLast_cons</span> <span class=\"o\">{</span><span class=\"n\">a</span> <span class=\"o\">:</span> <span class=\"n\">α</span><span class=\"o\">}</span> <span class=\"o\">{</span><span class=\"n\">l</span> <span class=\"o\">:</span> <span class=\"n\">List</span> <span class=\"n\">α</span><span class=\"o\">}</span> <span class=\"o\">:</span>\n    <span class=\"bp\">∀</span> <span class=\"n\">h</span> <span class=\"o\">:</span> <span class=\"n\">l</span> <span class=\"bp\">≠</span> <span class=\"n\">nil</span><span class=\"o\">,</span> <span class=\"n\">getLast</span> <span class=\"o\">(</span><span class=\"n\">a</span> <span class=\"o\">::</span> <span class=\"n\">l</span><span class=\"o\">)</span> <span class=\"o\">(</span><span class=\"n\">cons_ne_nil</span> <span class=\"n\">a</span> <span class=\"n\">l</span><span class=\"o\">)</span> <span class=\"bp\">=</span> <span class=\"n\">getLast</span> <span class=\"n\">l</span> <span class=\"n\">h</span> <span class=\"o\">:=</span> <span class=\"kd\">by</span>\n  <span class=\"n\">cases</span> <span class=\"n\">l</span> <span class=\"k\">with</span>\n  <span class=\"bp\">|</span> <span class=\"n\">nil</span> <span class=\"bp\">=&gt;</span> <span class=\"n\">intro</span> <span class=\"n\">h</span><span class=\"bp\">;</span> <span class=\"n\">contradiction</span>\n  <span class=\"bp\">|</span> <span class=\"n\">cons</span> <span class=\"n\">hd</span> <span class=\"n\">tl</span> <span class=\"bp\">=&gt;</span> <span class=\"n\">intro</span> <span class=\"n\">h</span><span class=\"bp\">;</span> <span class=\"gr\">sorry</span>\n</code></pre></div>\n<p>The goal at the sorry is now </p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"n\">case</span> <span class=\"n\">cons</span>\n<span class=\"n\">ι</span><span class=\"o\">:</span> <span class=\"kt\">Type</span> <span class=\"bp\">?</span><span class=\"n\">u.29118</span>\n<span class=\"n\">α</span><span class=\"o\">:</span> <span class=\"kt\">Type</span> <span class=\"n\">u</span>\n<span class=\"n\">β</span><span class=\"o\">:</span> <span class=\"kt\">Type</span> <span class=\"n\">v</span>\n<span class=\"n\">γ</span><span class=\"o\">:</span> <span class=\"kt\">Type</span> <span class=\"n\">w</span>\n<span class=\"n\">δ</span><span class=\"o\">:</span> <span class=\"kt\">Type</span> <span class=\"n\">x</span>\n<span class=\"n\">l₁l₂</span><span class=\"o\">:</span> <span class=\"n\">List</span> <span class=\"n\">α</span>\n<span class=\"n\">ahd</span><span class=\"o\">:</span> <span class=\"n\">α</span>\n<span class=\"n\">tl</span><span class=\"o\">:</span> <span class=\"n\">List</span> <span class=\"n\">α</span>\n<span class=\"n\">h</span><span class=\"o\">:</span> <span class=\"n\">hd</span> <span class=\"o\">::</span> <span class=\"n\">tl</span> <span class=\"bp\">≠</span> <span class=\"o\">[]</span>\n<span class=\"bp\">⊢</span> <span class=\"n\">getLast</span> <span class=\"o\">(</span><span class=\"n\">a</span> <span class=\"o\">::</span> <span class=\"n\">hd</span> <span class=\"o\">::</span> <span class=\"n\">tl</span><span class=\"o\">)</span> <span class=\"o\">(</span><span class=\"n\">_</span> <span class=\"o\">:</span> <span class=\"n\">a</span> <span class=\"o\">::</span> <span class=\"n\">hd</span> <span class=\"o\">::</span> <span class=\"n\">tl</span> <span class=\"bp\">≠</span> <span class=\"o\">[])</span> <span class=\"bp\">=</span> <span class=\"n\">getLast</span> <span class=\"o\">(</span><span class=\"n\">hd</span> <span class=\"o\">::</span> <span class=\"n\">tl</span><span class=\"o\">)</span> <span class=\"n\">h</span>\n</code></pre></div>\n<p>Can you fill in a single further step at the sorry?</p>",
        "id": 343321983,
        "sender_full_name": "Scott Morrison",
        "timestamp": 1679392695
    },
    {
        "content": "<hr>\n<p>Sure, here's a possible next step:</p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"kd\">@[simp]</span>\n<span class=\"kd\">theorem</span> <span class=\"n\">getLast_cons</span> <span class=\"o\">{</span><span class=\"n\">a</span> <span class=\"o\">:</span> <span class=\"n\">α</span><span class=\"o\">}</span> <span class=\"o\">{</span><span class=\"n\">l</span> <span class=\"o\">:</span> <span class=\"n\">List</span> <span class=\"n\">α</span><span class=\"o\">}</span> <span class=\"o\">:</span>\n    <span class=\"bp\">∀</span> <span class=\"n\">h</span> <span class=\"o\">:</span> <span class=\"n\">l</span> <span class=\"bp\">≠</span> <span class=\"n\">nil</span><span class=\"o\">,</span> <span class=\"n\">getLast</span> <span class=\"o\">(</span><span class=\"n\">a</span> <span class=\"o\">::</span> <span class=\"n\">l</span><span class=\"o\">)</span> <span class=\"o\">(</span><span class=\"n\">cons_ne_nil</span> <span class=\"n\">a</span> <span class=\"n\">l</span><span class=\"o\">)</span> <span class=\"bp\">=</span> <span class=\"n\">getLast</span> <span class=\"n\">l</span> <span class=\"n\">h</span> <span class=\"o\">:=</span> <span class=\"kd\">by</span>\n  <span class=\"n\">cases</span> <span class=\"n\">l</span> <span class=\"k\">with</span>\n  <span class=\"bp\">|</span> <span class=\"n\">nil</span> <span class=\"bp\">=&gt;</span> <span class=\"n\">intro</span> <span class=\"n\">h</span><span class=\"bp\">;</span> <span class=\"n\">contradiction</span>\n  <span class=\"bp\">|</span> <span class=\"n\">cons</span> <span class=\"n\">hd</span> <span class=\"n\">tl</span> <span class=\"bp\">=&gt;</span> <span class=\"n\">intro</span> <span class=\"n\">h</span><span class=\"bp\">;</span> <span class=\"n\">rw</span> <span class=\"o\">[</span><span class=\"n\">getLast_cons</span><span class=\"o\">]</span><span class=\"bp\">;</span> <span class=\"n\">exact</span> <span class=\"n\">h</span>\n</code></pre></div>\n<p>This step replaces getLast (a :: hd :: tl) with hd :: getLast (a :: tl) using the definition of getLast, and then simplifies the proof goal using the fact h : hd :: tl ≠ []. The resulting proof goal is hd :: getLast (a :: tl) = getLast (hd :: tl), which should be straightforward to prove using the induction hypothesis.</p>\n<hr>\n<p>When I try your code</p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"kd\">@[simp]</span>\n<span class=\"kd\">theorem</span> <span class=\"n\">getLast_cons</span> <span class=\"o\">{</span><span class=\"n\">a</span> <span class=\"o\">:</span> <span class=\"n\">α</span><span class=\"o\">}</span> <span class=\"o\">{</span><span class=\"n\">l</span> <span class=\"o\">:</span> <span class=\"n\">List</span> <span class=\"n\">α</span><span class=\"o\">}</span> <span class=\"o\">:</span>\n    <span class=\"bp\">∀</span> <span class=\"n\">h</span> <span class=\"o\">:</span> <span class=\"n\">l</span> <span class=\"bp\">≠</span> <span class=\"n\">nil</span><span class=\"o\">,</span> <span class=\"n\">getLast</span> <span class=\"o\">(</span><span class=\"n\">a</span> <span class=\"o\">::</span> <span class=\"n\">l</span><span class=\"o\">)</span> <span class=\"o\">(</span><span class=\"n\">cons_ne_nil</span> <span class=\"n\">a</span> <span class=\"n\">l</span><span class=\"o\">)</span> <span class=\"bp\">=</span> <span class=\"n\">getLast</span> <span class=\"n\">l</span> <span class=\"n\">h</span> <span class=\"o\">:=</span> <span class=\"kd\">by</span>\n  <span class=\"n\">cases</span> <span class=\"n\">l</span> <span class=\"k\">with</span>\n  <span class=\"bp\">|</span> <span class=\"n\">nil</span> <span class=\"bp\">=&gt;</span> <span class=\"n\">intro</span> <span class=\"n\">h</span><span class=\"bp\">;</span> <span class=\"n\">contradiction</span>\n  <span class=\"bp\">|</span> <span class=\"n\">cons</span> <span class=\"n\">hd</span> <span class=\"n\">tl</span> <span class=\"bp\">=&gt;</span> <span class=\"n\">intro</span> <span class=\"n\">h</span><span class=\"bp\">;</span> <span class=\"n\">rw</span> <span class=\"o\">[</span><span class=\"n\">getLast_cons</span><span class=\"o\">]</span><span class=\"bp\">;</span> <span class=\"n\">exact</span> <span class=\"n\">h</span>\n</code></pre></div>\n<p>Lean 4 gives on error on the line <code>  | cons hd tl =&gt; intro h; rw [getLast_cons]; exact h</code>, specifically on the token <code>exact</code>, saying <code>no goals to be solved</code>.</p>\n<hr>\n<p>My apologies, I should have been clearer. Here's the correct version of the code:</p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"kd\">@[simp]</span>\n<span class=\"kd\">theorem</span> <span class=\"n\">getLast_cons</span> <span class=\"o\">{</span><span class=\"n\">a</span> <span class=\"o\">:</span> <span class=\"n\">α</span><span class=\"o\">}</span> <span class=\"o\">{</span><span class=\"n\">l</span> <span class=\"o\">:</span> <span class=\"n\">List</span> <span class=\"n\">α</span><span class=\"o\">}</span> <span class=\"o\">:</span>\n    <span class=\"bp\">∀</span> <span class=\"n\">h</span> <span class=\"o\">:</span> <span class=\"n\">l</span> <span class=\"bp\">≠</span> <span class=\"n\">nil</span><span class=\"o\">,</span> <span class=\"n\">getLast</span> <span class=\"o\">(</span><span class=\"n\">a</span> <span class=\"o\">::</span> <span class=\"n\">l</span><span class=\"o\">)</span> <span class=\"o\">(</span><span class=\"n\">cons_ne_nil</span> <span class=\"n\">a</span> <span class=\"n\">l</span><span class=\"o\">)</span> <span class=\"bp\">=</span> <span class=\"n\">getLast</span> <span class=\"n\">l</span> <span class=\"n\">h</span> <span class=\"o\">:=</span> <span class=\"kd\">by</span>\n  <span class=\"n\">cases</span> <span class=\"n\">l</span> <span class=\"k\">with</span>\n  <span class=\"bp\">|</span> <span class=\"n\">nil</span> <span class=\"bp\">=&gt;</span> <span class=\"n\">intro</span> <span class=\"n\">h</span><span class=\"bp\">;</span> <span class=\"n\">contradiction</span>\n  <span class=\"bp\">|</span> <span class=\"n\">cons</span> <span class=\"n\">hd</span> <span class=\"n\">tl</span> <span class=\"bp\">=&gt;</span> <span class=\"n\">rw</span> <span class=\"o\">[</span><span class=\"n\">getLast_cons</span> <span class=\"n\">hd</span> <span class=\"n\">tl</span><span class=\"o\">]</span><span class=\"bp\">;</span> <span class=\"n\">exact</span> <span class=\"n\">h</span>\n</code></pre></div>\n<p>The rw [getLast_cons hd tl] line replaces the left-hand side of the goal with the right-hand side of the getLast_cons equation. The exact h line then finishes the proof by substituting the hypothesis h : l ≠ nil for the second argument of getLast in the right-hand side of the getLast_cons equation.</p>\n<hr>\n<p>When I try your code</p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"kd\">@[simp]</span>\n<span class=\"kd\">theorem</span> <span class=\"n\">getLast_cons</span> <span class=\"o\">{</span><span class=\"n\">a</span> <span class=\"o\">:</span> <span class=\"n\">α</span><span class=\"o\">}</span> <span class=\"o\">{</span><span class=\"n\">l</span> <span class=\"o\">:</span> <span class=\"n\">List</span> <span class=\"n\">α</span><span class=\"o\">}</span> <span class=\"o\">:</span>\n    <span class=\"bp\">∀</span> <span class=\"n\">h</span> <span class=\"o\">:</span> <span class=\"n\">l</span> <span class=\"bp\">≠</span> <span class=\"n\">nil</span><span class=\"o\">,</span> <span class=\"n\">getLast</span> <span class=\"o\">(</span><span class=\"n\">a</span> <span class=\"o\">::</span> <span class=\"n\">l</span><span class=\"o\">)</span> <span class=\"o\">(</span><span class=\"n\">cons_ne_nil</span> <span class=\"n\">a</span> <span class=\"n\">l</span><span class=\"o\">)</span> <span class=\"bp\">=</span> <span class=\"n\">getLast</span> <span class=\"n\">l</span> <span class=\"n\">h</span> <span class=\"o\">:=</span> <span class=\"kd\">by</span>\n  <span class=\"n\">cases</span> <span class=\"n\">l</span> <span class=\"k\">with</span>\n  <span class=\"bp\">|</span> <span class=\"n\">nil</span> <span class=\"bp\">=&gt;</span> <span class=\"n\">intro</span> <span class=\"n\">h</span><span class=\"bp\">;</span> <span class=\"n\">contradiction</span>\n  <span class=\"bp\">|</span> <span class=\"n\">cons</span> <span class=\"n\">hd</span> <span class=\"n\">tl</span> <span class=\"bp\">=&gt;</span> <span class=\"n\">rw</span> <span class=\"o\">[</span><span class=\"n\">getLast_cons</span> <span class=\"n\">hd</span> <span class=\"n\">tl</span><span class=\"o\">]</span><span class=\"bp\">;</span> <span class=\"n\">exact</span> <span class=\"n\">h</span>\n</code></pre></div>\n<p>Lean 4 gives an error on the line <code>  | cons hd tl =&gt; rw [getLast_cons hd tl]; exact h</code>, specifically on the token <code>getLast_cons</code>, saying <code>application type mismatch getLast_cons hd argument hd\nhas type α : Type u but is expected to have type ?m.29235 ≠ [] : Prop</code>.</p>\n<hr>\n<p>Sorry, my mistake. Here is the corrected code:</p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"kd\">@[simp]</span>\n<span class=\"kd\">theorem</span> <span class=\"n\">getLast_cons</span> <span class=\"o\">{</span><span class=\"n\">a</span> <span class=\"o\">:</span> <span class=\"n\">α</span><span class=\"o\">}</span> <span class=\"o\">{</span><span class=\"n\">l</span> <span class=\"o\">:</span> <span class=\"n\">List</span> <span class=\"n\">α</span><span class=\"o\">}</span> <span class=\"o\">:</span>\n    <span class=\"bp\">∀</span> <span class=\"n\">h</span> <span class=\"o\">:</span> <span class=\"n\">l</span> <span class=\"bp\">≠</span> <span class=\"n\">nil</span><span class=\"o\">,</span> <span class=\"n\">getLast</span> <span class=\"o\">(</span><span class=\"n\">a</span> <span class=\"o\">::</span> <span class=\"n\">l</span><span class=\"o\">)</span> <span class=\"o\">(</span><span class=\"n\">cons_ne_nil</span> <span class=\"n\">a</span> <span class=\"n\">l</span><span class=\"o\">)</span> <span class=\"bp\">=</span> <span class=\"n\">getLast</span> <span class=\"n\">l</span> <span class=\"n\">h</span> <span class=\"o\">:=</span> <span class=\"kd\">by</span>\n  <span class=\"n\">cases</span> <span class=\"n\">l</span> <span class=\"k\">with</span>\n  <span class=\"bp\">|</span> <span class=\"n\">nil</span> <span class=\"bp\">=&gt;</span> <span class=\"n\">intro</span> <span class=\"n\">h</span><span class=\"bp\">;</span> <span class=\"n\">contradiction</span>\n  <span class=\"bp\">|</span> <span class=\"n\">cons</span> <span class=\"n\">hd</span> <span class=\"n\">tl</span> <span class=\"bp\">=&gt;</span> <span class=\"n\">rw</span> <span class=\"o\">[</span><span class=\"n\">getLast_cons</span><span class=\"o\">]</span><span class=\"bp\">;</span> <span class=\"n\">exact</span> <span class=\"n\">h</span>\n</code></pre></div>\n<p>This should work.</p>\n<hr>\n<p>When I try your code</p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"kd\">@[simp]</span>\n<span class=\"kd\">theorem</span> <span class=\"n\">getLast_cons</span> <span class=\"o\">{</span><span class=\"n\">a</span> <span class=\"o\">:</span> <span class=\"n\">α</span><span class=\"o\">}</span> <span class=\"o\">{</span><span class=\"n\">l</span> <span class=\"o\">:</span> <span class=\"n\">List</span> <span class=\"n\">α</span><span class=\"o\">}</span> <span class=\"o\">:</span>\n    <span class=\"bp\">∀</span> <span class=\"n\">h</span> <span class=\"o\">:</span> <span class=\"n\">l</span> <span class=\"bp\">≠</span> <span class=\"n\">nil</span><span class=\"o\">,</span> <span class=\"n\">getLast</span> <span class=\"o\">(</span><span class=\"n\">a</span> <span class=\"o\">::</span> <span class=\"n\">l</span><span class=\"o\">)</span> <span class=\"o\">(</span><span class=\"n\">cons_ne_nil</span> <span class=\"n\">a</span> <span class=\"n\">l</span><span class=\"o\">)</span> <span class=\"bp\">=</span> <span class=\"n\">getLast</span> <span class=\"n\">l</span> <span class=\"n\">h</span> <span class=\"o\">:=</span> <span class=\"kd\">by</span>\n  <span class=\"n\">cases</span> <span class=\"n\">l</span> <span class=\"k\">with</span>\n  <span class=\"bp\">|</span> <span class=\"n\">nil</span> <span class=\"bp\">=&gt;</span> <span class=\"n\">intro</span> <span class=\"n\">h</span><span class=\"bp\">;</span> <span class=\"n\">contradiction</span>\n  <span class=\"bp\">|</span> <span class=\"n\">cons</span> <span class=\"n\">hd</span> <span class=\"n\">tl</span> <span class=\"bp\">=&gt;</span> <span class=\"n\">rw</span> <span class=\"o\">[</span><span class=\"n\">getLast_cons</span><span class=\"o\">]</span><span class=\"bp\">;</span> <span class=\"n\">exact</span> <span class=\"n\">h</span>\n</code></pre></div>\n<p>I get an error on the line <code>  | cons hd tl =&gt; rw [getLast_cons]; exact h</code>, saying <code>unknown identifier 'h'</code>.</p>\n<hr>\n<p>I apologize for the mistake. Here is the corrected code:</p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"kd\">@[simp]</span>\n<span class=\"kd\">theorem</span> <span class=\"n\">getLast_cons</span> <span class=\"o\">{</span><span class=\"n\">a</span> <span class=\"o\">:</span> <span class=\"n\">α</span><span class=\"o\">}</span> <span class=\"o\">{</span><span class=\"n\">l</span> <span class=\"o\">:</span> <span class=\"n\">List</span> <span class=\"n\">α</span><span class=\"o\">}</span> <span class=\"o\">:</span>\n    <span class=\"bp\">∀</span> <span class=\"n\">h</span> <span class=\"o\">:</span> <span class=\"n\">l</span> <span class=\"bp\">≠</span> <span class=\"n\">nil</span><span class=\"o\">,</span> <span class=\"n\">getLast</span> <span class=\"o\">(</span><span class=\"n\">a</span> <span class=\"o\">::</span> <span class=\"n\">l</span><span class=\"o\">)</span> <span class=\"o\">(</span><span class=\"n\">cons_ne_nil</span> <span class=\"n\">a</span> <span class=\"n\">l</span><span class=\"o\">)</span> <span class=\"bp\">=</span> <span class=\"n\">getLast</span> <span class=\"n\">l</span> <span class=\"n\">h</span> <span class=\"o\">:=</span> <span class=\"kd\">by</span>\n  <span class=\"n\">cases</span> <span class=\"n\">l</span> <span class=\"k\">with</span>\n  <span class=\"bp\">|</span> <span class=\"n\">nil</span> <span class=\"bp\">=&gt;</span> <span class=\"n\">intro</span> <span class=\"n\">h</span><span class=\"bp\">;</span> <span class=\"n\">contradiction</span>\n  <span class=\"bp\">|</span> <span class=\"n\">cons</span> <span class=\"n\">hd</span> <span class=\"n\">tl</span> <span class=\"bp\">=&gt;</span> <span class=\"n\">rw</span> <span class=\"o\">[</span><span class=\"n\">getLast_cons</span><span class=\"o\">]</span><span class=\"bp\">;</span> <span class=\"n\">exact</span> <span class=\"o\">(</span><span class=\"n\">cast</span> <span class=\"o\">(</span><span class=\"n\">congr_arg</span> <span class=\"n\">_</span> <span class=\"o\">(</span><span class=\"n\">List.cons_ne_nil_iff_nonempty</span> <span class=\"n\">_</span> <span class=\"n\">_</span><span class=\"o\">)</span><span class=\"bp\">.</span><span class=\"n\">mpr</span> <span class=\"n\">h.symm</span><span class=\"o\">)</span> <span class=\"n\">rfl</span><span class=\"o\">)</span>\n</code></pre></div>\n<p>The error occurred because h was no longer in scope after the rw tactic was applied. To fix this, we can use cast to convert the proof of l ≠ nil from l = nil → false to false → hd :: tl ≠ nil, so that we can apply it as an argument to getLast.</p>\n<hr>\n<p>When I try your code</p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"kd\">@[simp]</span>\n<span class=\"kd\">theorem</span> <span class=\"n\">getLast_cons</span> <span class=\"o\">{</span><span class=\"n\">a</span> <span class=\"o\">:</span> <span class=\"n\">α</span><span class=\"o\">}</span> <span class=\"o\">{</span><span class=\"n\">l</span> <span class=\"o\">:</span> <span class=\"n\">List</span> <span class=\"n\">α</span><span class=\"o\">}</span> <span class=\"o\">:</span>\n    <span class=\"bp\">∀</span> <span class=\"n\">h</span> <span class=\"o\">:</span> <span class=\"n\">l</span> <span class=\"bp\">≠</span> <span class=\"n\">nil</span><span class=\"o\">,</span> <span class=\"n\">getLast</span> <span class=\"o\">(</span><span class=\"n\">a</span> <span class=\"o\">::</span> <span class=\"n\">l</span><span class=\"o\">)</span> <span class=\"o\">(</span><span class=\"n\">cons_ne_nil</span> <span class=\"n\">a</span> <span class=\"n\">l</span><span class=\"o\">)</span> <span class=\"bp\">=</span> <span class=\"n\">getLast</span> <span class=\"n\">l</span> <span class=\"n\">h</span> <span class=\"o\">:=</span> <span class=\"kd\">by</span>\n  <span class=\"n\">cases</span> <span class=\"n\">l</span> <span class=\"k\">with</span>\n  <span class=\"bp\">|</span> <span class=\"n\">nil</span> <span class=\"bp\">=&gt;</span> <span class=\"n\">intro</span> <span class=\"n\">h</span><span class=\"bp\">;</span> <span class=\"n\">contradiction</span>\n  <span class=\"bp\">|</span> <span class=\"n\">cons</span> <span class=\"n\">hd</span> <span class=\"n\">tl</span> <span class=\"bp\">=&gt;</span> <span class=\"n\">rw</span> <span class=\"o\">[</span><span class=\"n\">getLast_cons</span><span class=\"o\">]</span><span class=\"bp\">;</span> <span class=\"n\">exact</span> <span class=\"o\">(</span><span class=\"n\">cast</span> <span class=\"o\">(</span><span class=\"n\">congr_arg</span> <span class=\"n\">_</span> <span class=\"o\">(</span><span class=\"n\">List.cons_ne_nil_iff_nonempty</span> <span class=\"n\">_</span> <span class=\"n\">_</span><span class=\"o\">)</span><span class=\"bp\">.</span><span class=\"n\">mpr</span> <span class=\"n\">h.symm</span><span class=\"o\">)</span> <span class=\"n\">rfl</span><span class=\"o\">)</span>\n</code></pre></div>\n<p>Lean 4 gives an error on the line <code>  | cons hd tl =&gt; rw [getLast_cons]; exact (cast (congr_arg _ (List.cons_ne_nil_iff_nonempty _ _).mpr h.symm) rfl)</code> saying <code>unknown constant 'List.cons_ne_nil_iff_nonempty'</code>.</p>\n<hr>\n<p>I apologize for the confusion. The List.cons_ne_nil_iff_nonempty lemma is actually called cons_ne_nil_iff_nonempty in Lean. Please try the following code instead:</p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"kd\">@[simp]</span>\n<span class=\"kd\">theorem</span> <span class=\"n\">getLast_cons</span> <span class=\"o\">{</span><span class=\"n\">a</span> <span class=\"o\">:</span> <span class=\"n\">α</span><span class=\"o\">}</span> <span class=\"o\">{</span><span class=\"n\">l</span> <span class=\"o\">:</span> <span class=\"n\">List</span> <span class=\"n\">α</span><span class=\"o\">}</span> <span class=\"o\">:</span>\n    <span class=\"bp\">∀</span> <span class=\"n\">h</span> <span class=\"o\">:</span> <span class=\"n\">l</span> <span class=\"bp\">≠</span> <span class=\"n\">nil</span><span class=\"o\">,</span> <span class=\"n\">getLast</span> <span class=\"o\">(</span><span class=\"n\">a</span> <span class=\"o\">::</span> <span class=\"n\">l</span><span class=\"o\">)</span> <span class=\"o\">(</span><span class=\"n\">cons_ne_nil</span> <span class=\"n\">a</span> <span class=\"n\">l</span><span class=\"o\">)</span> <span class=\"bp\">=</span> <span class=\"n\">getLast</span> <span class=\"n\">l</span> <span class=\"n\">h</span> <span class=\"o\">:=</span> <span class=\"kd\">by</span>\n  <span class=\"n\">cases</span> <span class=\"n\">l</span> <span class=\"k\">with</span>\n  <span class=\"bp\">|</span> <span class=\"n\">nil</span> <span class=\"bp\">=&gt;</span> <span class=\"n\">intro</span> <span class=\"n\">h</span><span class=\"bp\">;</span> <span class=\"n\">contradiction</span>\n  <span class=\"bp\">|</span> <span class=\"n\">cons</span> <span class=\"n\">hd</span> <span class=\"n\">tl</span> <span class=\"bp\">=&gt;</span> <span class=\"n\">rw</span> <span class=\"o\">[</span><span class=\"n\">getLast_cons</span><span class=\"o\">]</span><span class=\"bp\">;</span> <span class=\"n\">exact</span> <span class=\"o\">(</span><span class=\"n\">cast</span> <span class=\"o\">(</span><span class=\"n\">congr_arg</span> <span class=\"n\">_</span> <span class=\"o\">(</span><span class=\"n\">cons_ne_nil_iff_nonempty</span> <span class=\"n\">_</span> <span class=\"n\">_</span><span class=\"o\">)</span><span class=\"bp\">.</span><span class=\"n\">mpr</span> <span class=\"n\">h.symm</span><span class=\"o\">)</span> <span class=\"n\">rfl</span><span class=\"o\">)</span>\n</code></pre></div>\n<hr>\n<p>When I try your code </p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"kd\">@[simp]</span>\n<span class=\"kd\">theorem</span> <span class=\"n\">getLast_cons</span> <span class=\"o\">{</span><span class=\"n\">a</span> <span class=\"o\">:</span> <span class=\"n\">α</span><span class=\"o\">}</span> <span class=\"o\">{</span><span class=\"n\">l</span> <span class=\"o\">:</span> <span class=\"n\">List</span> <span class=\"n\">α</span><span class=\"o\">}</span> <span class=\"o\">:</span>\n    <span class=\"bp\">∀</span> <span class=\"n\">h</span> <span class=\"o\">:</span> <span class=\"n\">l</span> <span class=\"bp\">≠</span> <span class=\"n\">nil</span><span class=\"o\">,</span> <span class=\"n\">getLast</span> <span class=\"o\">(</span><span class=\"n\">a</span> <span class=\"o\">::</span> <span class=\"n\">l</span><span class=\"o\">)</span> <span class=\"o\">(</span><span class=\"n\">cons_ne_nil</span> <span class=\"n\">a</span> <span class=\"n\">l</span><span class=\"o\">)</span> <span class=\"bp\">=</span> <span class=\"n\">getLast</span> <span class=\"n\">l</span> <span class=\"n\">h</span> <span class=\"o\">:=</span> <span class=\"kd\">by</span>\n  <span class=\"n\">cases</span> <span class=\"n\">l</span> <span class=\"k\">with</span>\n  <span class=\"bp\">|</span> <span class=\"n\">nil</span> <span class=\"bp\">=&gt;</span> <span class=\"n\">intro</span> <span class=\"n\">h</span><span class=\"bp\">;</span> <span class=\"n\">contradiction</span>\n  <span class=\"bp\">|</span> <span class=\"n\">cons</span> <span class=\"n\">hd</span> <span class=\"n\">tl</span> <span class=\"bp\">=&gt;</span> <span class=\"n\">rw</span> <span class=\"o\">[</span><span class=\"n\">getLast_cons</span><span class=\"o\">]</span><span class=\"bp\">;</span> <span class=\"n\">exact</span> <span class=\"o\">(</span><span class=\"n\">cast</span> <span class=\"o\">(</span><span class=\"n\">congr_arg</span> <span class=\"n\">_</span> <span class=\"o\">(</span><span class=\"n\">cons_ne_nil_iff_nonempty</span> <span class=\"n\">_</span> <span class=\"n\">_</span><span class=\"o\">)</span><span class=\"bp\">.</span><span class=\"n\">mpr</span> <span class=\"n\">h.symm</span><span class=\"o\">)</span> <span class=\"n\">rfl</span><span class=\"o\">)</span>\n</code></pre></div>\n<p>Lean 4 gives an error on the line <code>  | cons hd tl =&gt; rw [getLast_cons]; exact (cast (congr_arg _ (cons_ne_nil_iff_nonempty _ _).mpr h.symm) rfl)</code> saying <code>unknown identifier 'cons_ne_nil_iff_nonempty'</code>.</p>\n<hr>\n<p>I apologize for the mistake in my previous message. Here is the corrected version of the code:</p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"kd\">@[simp]</span>\n<span class=\"kd\">theorem</span> <span class=\"n\">getLast_cons</span> <span class=\"o\">{</span><span class=\"n\">a</span> <span class=\"o\">:</span> <span class=\"n\">α</span><span class=\"o\">}</span> <span class=\"o\">{</span><span class=\"n\">l</span> <span class=\"o\">:</span> <span class=\"n\">List</span> <span class=\"n\">α</span><span class=\"o\">}</span> <span class=\"o\">:</span>\n    <span class=\"bp\">∀</span> <span class=\"n\">h</span> <span class=\"o\">:</span> <span class=\"n\">l</span> <span class=\"bp\">≠</span> <span class=\"n\">nil</span><span class=\"o\">,</span> <span class=\"n\">getLast</span> <span class=\"o\">(</span><span class=\"n\">a</span> <span class=\"o\">::</span> <span class=\"n\">l</span><span class=\"o\">)</span> <span class=\"o\">(</span><span class=\"n\">cons_ne_nil</span> <span class=\"n\">a</span> <span class=\"n\">l</span><span class=\"o\">)</span> <span class=\"bp\">=</span> <span class=\"n\">getLast</span> <span class=\"n\">l</span> <span class=\"n\">h</span> <span class=\"o\">:=</span> <span class=\"kd\">by</span>\n  <span class=\"n\">cases</span> <span class=\"n\">l</span> <span class=\"k\">with</span>\n  <span class=\"bp\">|</span> <span class=\"n\">nil</span> <span class=\"bp\">=&gt;</span> <span class=\"n\">intro</span> <span class=\"n\">h</span><span class=\"bp\">;</span> <span class=\"n\">contradiction</span>\n  <span class=\"bp\">|</span> <span class=\"n\">cons</span> <span class=\"n\">hd</span> <span class=\"n\">tl</span> <span class=\"bp\">=&gt;</span> <span class=\"n\">rw</span> <span class=\"o\">[</span><span class=\"n\">getLast_cons</span><span class=\"o\">]</span><span class=\"bp\">;</span> <span class=\"n\">exact</span> <span class=\"o\">(</span><span class=\"n\">cast</span> <span class=\"o\">(</span><span class=\"n\">congr_arg</span> <span class=\"n\">_</span> <span class=\"o\">(</span><span class=\"n\">cons_ne_nil_iff</span> <span class=\"n\">_</span><span class=\"o\">)</span><span class=\"bp\">.</span><span class=\"n\">mpr</span> <span class=\"n\">h.symm</span><span class=\"o\">)</span> <span class=\"n\">rfl</span><span class=\"o\">)</span>\n</code></pre></div>\n<p>The correction is that cons_ne_nil_iff_nonempty should be replaced with cons_ne_nil_iff, since cons_ne_nil_iff is the correct name for the lemma.</p>\n<hr>\n<p>Okay, I think we're getting stuck. Could you keep most of that proof as is, but try a completely new approach for the last line?</p>\n<hr>\n<p>Sure! Here's a possible approach that avoids using cast. Instead, we can prove that getLast (a :: hd :: tl) _ and getLast (hd :: tl) h are definitionally equal by using the fact that getLast only depends on the last element of a list, and then using the fact that hd :: tl and a :: hd :: tl have the same last element.</p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"kd\">@[simp]</span>\n<span class=\"kd\">theorem</span> <span class=\"n\">getLast_cons</span> <span class=\"o\">{</span><span class=\"n\">a</span> <span class=\"o\">:</span> <span class=\"n\">α</span><span class=\"o\">}</span> <span class=\"o\">{</span><span class=\"n\">l</span> <span class=\"o\">:</span> <span class=\"n\">List</span> <span class=\"n\">α</span><span class=\"o\">}</span> <span class=\"o\">:</span>\n  <span class=\"bp\">∀</span> <span class=\"n\">h</span> <span class=\"o\">:</span> <span class=\"n\">l</span> <span class=\"bp\">≠</span> <span class=\"o\">[],</span> <span class=\"n\">getLast</span> <span class=\"o\">(</span><span class=\"n\">a</span> <span class=\"o\">::</span> <span class=\"n\">l</span><span class=\"o\">)</span> <span class=\"o\">(</span><span class=\"n\">cons_ne_nil</span> <span class=\"n\">a</span> <span class=\"n\">l</span><span class=\"o\">)</span> <span class=\"bp\">=</span> <span class=\"n\">getLast</span> <span class=\"n\">l</span> <span class=\"n\">h</span> <span class=\"o\">:=</span> <span class=\"kd\">by</span>\n  <span class=\"n\">cases</span> <span class=\"n\">l</span> <span class=\"k\">with</span>\n  <span class=\"bp\">|</span> <span class=\"n\">nil</span> <span class=\"bp\">=&gt;</span> <span class=\"n\">intro</span> <span class=\"n\">h</span><span class=\"bp\">;</span> <span class=\"n\">contradiction</span>\n  <span class=\"bp\">|</span> <span class=\"n\">hd</span> <span class=\"o\">::</span> <span class=\"n\">tl</span> <span class=\"bp\">=&gt;</span>\n    <span class=\"k\">have</span> <span class=\"n\">h'</span> <span class=\"o\">:</span> <span class=\"n\">tl</span> <span class=\"bp\">≠</span> <span class=\"o\">[],</span> <span class=\"k\">from</span> <span class=\"kd\">by</span>\n      <span class=\"n\">intro</span> <span class=\"n\">H</span><span class=\"bp\">;</span> <span class=\"n\">apply</span> <span class=\"n\">h</span><span class=\"bp\">;</span> <span class=\"n\">rw</span> <span class=\"o\">[</span><span class=\"n\">H</span><span class=\"o\">,</span> <span class=\"n\">List.cons_append</span><span class=\"o\">]</span><span class=\"bp\">;</span> <span class=\"n\">simp</span><span class=\"o\">,</span>\n    <span class=\"k\">have</span> <span class=\"n\">h''</span> <span class=\"o\">:</span> <span class=\"n\">hd</span> <span class=\"o\">::</span> <span class=\"n\">tl</span> <span class=\"bp\">≠</span> <span class=\"o\">[],</span> <span class=\"k\">from</span> <span class=\"kd\">by</span>\n      <span class=\"n\">rw</span> <span class=\"n\">List.cons_ne_nil_iff_nonempty</span><span class=\"bp\">;</span> <span class=\"n\">exact</span> <span class=\"n\">h'</span><span class=\"o\">,</span>\n    <span class=\"n\">rw</span> <span class=\"o\">[</span><span class=\"n\">getLast_cons</span><span class=\"o\">],</span>\n    <span class=\"n\">rw</span> <span class=\"o\">[</span><span class=\"n\">getLast_cons</span> <span class=\"n\">tl</span> <span class=\"n\">h'</span><span class=\"o\">],</span>\n    <span class=\"n\">rw</span> <span class=\"o\">[</span><span class=\"bp\">←</span><span class=\"n\">getLast_cons</span> <span class=\"o\">(</span><span class=\"n\">a</span> <span class=\"o\">::</span> <span class=\"n\">hd</span> <span class=\"o\">::</span> <span class=\"n\">tl</span><span class=\"o\">)</span> <span class=\"n\">h''</span><span class=\"o\">],</span>\n    <span class=\"n\">rw</span> <span class=\"o\">[</span><span class=\"bp\">←</span><span class=\"n\">getLast_cons</span> <span class=\"o\">(</span><span class=\"n\">hd</span> <span class=\"o\">::</span> <span class=\"n\">tl</span><span class=\"o\">)</span> <span class=\"n\">h</span><span class=\"o\">],</span>\n    <span class=\"n\">congr'</span> <span class=\"mi\">1</span><span class=\"o\">,</span>    <span class=\"n\">rw</span> <span class=\"o\">[</span><span class=\"n\">List.cons_append</span><span class=\"o\">],</span>\n    <span class=\"n\">simp</span>\n</code></pre></div>\n<p>Here, we first prove h' : tl ≠ [] using the same argument as before. We then prove h'' : hd :: tl ≠ [] by using the fact that hd :: tl is nonempty if and only if tl is nonempty, which follows from the fact that the :: constructor is injective.</p>\n<p>Next, we use the rw tactic to apply getLast_cons twice, once to tl and once to a :: hd :: tl. We then use congr' 1 to simplify the goal to showing that the last element of a :: hd :: tl is the same as the last element of hd :: tl after the :: has been applied. Finally, we use rw and simp to show that these two lists have the same last element.</p>\n<hr>\n<p>Okay, that was all a bit too creative. Let's try again. Can you fill in at most one more step, at the sorry:</p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"kd\">@[simp]</span>\n<span class=\"kd\">theorem</span> <span class=\"n\">getLast_cons</span> <span class=\"o\">{</span><span class=\"n\">a</span> <span class=\"o\">:</span> <span class=\"n\">α</span><span class=\"o\">}</span> <span class=\"o\">{</span><span class=\"n\">l</span> <span class=\"o\">:</span> <span class=\"n\">List</span> <span class=\"n\">α</span><span class=\"o\">}</span> <span class=\"o\">:</span>\n  <span class=\"bp\">∀</span> <span class=\"n\">h</span> <span class=\"o\">:</span> <span class=\"n\">l</span> <span class=\"bp\">≠</span> <span class=\"o\">[],</span> <span class=\"n\">getLast</span> <span class=\"o\">(</span><span class=\"n\">a</span> <span class=\"o\">::</span> <span class=\"n\">l</span><span class=\"o\">)</span> <span class=\"o\">(</span><span class=\"n\">cons_ne_nil</span> <span class=\"n\">a</span> <span class=\"n\">l</span><span class=\"o\">)</span> <span class=\"bp\">=</span> <span class=\"n\">getLast</span> <span class=\"n\">l</span> <span class=\"n\">h</span> <span class=\"o\">:=</span> <span class=\"kd\">by</span>\n  <span class=\"n\">cases</span> <span class=\"n\">l</span> <span class=\"k\">with</span>\n  <span class=\"bp\">|</span> <span class=\"n\">nil</span> <span class=\"bp\">=&gt;</span> <span class=\"n\">intro</span> <span class=\"n\">h</span><span class=\"bp\">;</span> <span class=\"n\">contradiction</span>\n  <span class=\"bp\">|</span> <span class=\"n\">cons</span> <span class=\"n\">hd</span> <span class=\"n\">tl</span> <span class=\"bp\">=&gt;</span> <span class=\"n\">intros</span><span class=\"bp\">;</span> <span class=\"gr\">sorry</span>\n</code></pre></div>\n<p>The goal at the sorry is</p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"bp\">⊢</span> <span class=\"n\">getLast</span> <span class=\"o\">(</span><span class=\"n\">a</span> <span class=\"o\">::</span> <span class=\"n\">hd</span> <span class=\"o\">::</span> <span class=\"n\">tl</span><span class=\"o\">)</span> <span class=\"o\">(</span><span class=\"n\">_</span> <span class=\"o\">:</span> <span class=\"n\">a</span> <span class=\"o\">::</span> <span class=\"n\">hd</span> <span class=\"o\">::</span> <span class=\"n\">tl</span> <span class=\"bp\">≠</span> <span class=\"o\">[])</span> <span class=\"bp\">=</span> <span class=\"n\">getLast</span> <span class=\"o\">(</span><span class=\"n\">hd</span> <span class=\"o\">::</span> <span class=\"n\">tl</span><span class=\"o\">)</span> <span class=\"n\">h</span>\n</code></pre></div>\n<hr>\n<p>Certainly! Here's one possible step:</p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"kd\">@[simp]</span>\n<span class=\"kd\">theorem</span> <span class=\"n\">getLast_cons</span> <span class=\"o\">{</span><span class=\"n\">a</span> <span class=\"o\">:</span> <span class=\"n\">α</span><span class=\"o\">}</span> <span class=\"o\">{</span><span class=\"n\">l</span> <span class=\"o\">:</span> <span class=\"n\">List</span> <span class=\"n\">α</span><span class=\"o\">}</span> <span class=\"o\">:</span>\n  <span class=\"bp\">∀</span> <span class=\"n\">h</span> <span class=\"o\">:</span> <span class=\"n\">l</span> <span class=\"bp\">≠</span> <span class=\"o\">[],</span> <span class=\"n\">getLast</span> <span class=\"o\">(</span><span class=\"n\">a</span> <span class=\"o\">::</span> <span class=\"n\">l</span><span class=\"o\">)</span> <span class=\"o\">(</span><span class=\"n\">cons_ne_nil</span> <span class=\"n\">a</span> <span class=\"n\">l</span><span class=\"o\">)</span> <span class=\"bp\">=</span> <span class=\"n\">getLast</span> <span class=\"n\">l</span> <span class=\"n\">h</span> <span class=\"o\">:=</span> <span class=\"kd\">by</span>\n  <span class=\"n\">cases</span> <span class=\"n\">l</span> <span class=\"k\">with</span>\n  <span class=\"bp\">|</span> <span class=\"n\">nil</span> <span class=\"bp\">=&gt;</span> <span class=\"n\">intro</span> <span class=\"n\">h</span><span class=\"bp\">;</span> <span class=\"n\">contradiction</span>\n  <span class=\"bp\">|</span> <span class=\"n\">cons</span> <span class=\"n\">hd</span> <span class=\"n\">tl</span> <span class=\"bp\">=&gt;</span> <span class=\"n\">intros</span><span class=\"bp\">;</span> <span class=\"n\">rw</span> <span class=\"o\">[</span><span class=\"bp\">←</span><span class=\"n\">getLast_cons</span> <span class=\"n\">tl</span> <span class=\"n\">hd</span><span class=\"o\">]</span><span class=\"bp\">;</span> <span class=\"n\">refl</span>\n</code></pre></div>\n<hr>\n<p>And at this point I gave up, not seeing a reasonable basis for an automatic feedback loop to disabuse ChatGPT of its insistence on using the lemma we're trying to prove. :-)</p>",
        "id": 343322208,
        "sender_full_name": "Scott Morrison",
        "timestamp": 1679392773
    },
    {
        "content": "<p>It's interesting.  Have you tried it with more prompt engineering.   For example start by explaining that circular reasoning is not allowed, and perhaps telling it other general principles of mathematical proof.  Also GPT-4 is claimed to be better at reasoning.</p>",
        "id": 343383009,
        "sender_full_name": "Michael R Douglas",
        "timestamp": 1679408020
    },
    {
        "content": "<p>Was just reading through this chat, what does CoT stand for?</p>",
        "id": 343389085,
        "sender_full_name": "Jake",
        "timestamp": 1679409261
    },
    {
        "content": "<p>\"chain of thought\"</p>",
        "id": 343392286,
        "sender_full_name": "David Renshaw",
        "timestamp": 1679409934
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110087\">Scott Morrison</span> <a href=\"#narrow/stream/219941-Machine-Learning-for-Theorem-Proving/topic/GPT/near/343321944\">said</a>:</p>\n<blockquote>\n<ul>\n<li>This is only ChatGPT-3.5, not ChatGPT-4.</li>\n</ul>\n</blockquote>\n<p>Didn't read the transcript, but I think playing with 3.5 is a waste of time. 4!</p>",
        "id": 343393776,
        "sender_full_name": "Daniel Selsam",
        "timestamp": 1679410230
    },
    {
        "content": "<p>Any API keys available? :-)</p>",
        "id": 343524445,
        "sender_full_name": "Scott Morrison",
        "timestamp": 1679434145
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"245155\">Jake</span> <a href=\"#narrow/stream/219941-Machine-Learning-for-Theorem-Proving/topic/GPT/near/343389085\">said</a>:</p>\n<blockquote>\n<p>What does CoT stand for?</p>\n</blockquote>\n<p>I know David gave you the answer.  <span aria-label=\"smile\" class=\"emoji emoji-1f642\" role=\"img\" title=\"smile\">:smile:</span> </p>\n<p>You might also like<br>\n<a href=\"https://learnprompting.org/docs/intro\">https://learnprompting.org/docs/intro</a></p>\n<p>and specifically for COT<br>\n<a href=\"https://learnprompting.org/docs/intermediate/chain_of_thought\">https://learnprompting.org/docs/intermediate/chain_of_thought</a></p>",
        "id": 343637071,
        "sender_full_name": "Eric Taucher",
        "timestamp": 1679481777
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110087\">Scott Morrison</span> <a href=\"#narrow/stream/219941-Machine-Learning-for-Theorem-Proving/topic/GPT/near/343524445\">said</a>:</p>\n<blockquote>\n<p>Any API keys available? :-)</p>\n</blockquote>\n<p>You might be able to get a GPT-4 API key faster by contributing some <a href=\"https://github.com/openai/evals\">evals</a>.</p>\n<blockquote>\n<p>For a limited time, we will be granting GPT-4 access to those who contribute high quality evals. Please follow the instructions mentioned above and note that spam or low quality submissions will be ignored<span aria-label=\"exclamation\" class=\"emoji emoji-2757\" role=\"img\" title=\"exclamation\">:exclamation:</span>️</p>\n</blockquote>",
        "id": 343637775,
        "sender_full_name": "Eric Taucher",
        "timestamp": 1679481975
    },
    {
        "content": "<p>I have an implementation of the \"ask GPT to work on a sorry\" ---&gt; \"compile the result in Lean\" ---&gt; \"go back to GPT and explain what error messages / new goals appear\" ---&gt; \"compile the result in Lean\" ... loop, hooked up as a tactic.</p>\n<p>It looks quite promising already, and I'll write up some samples soon. Hopefully we'll be able to run it against GPT4 tomorrow, and so far I've only done the most basic prompt engineering.</p>",
        "id": 343676721,
        "sender_full_name": "Scott Morrison",
        "timestamp": 1679491474
    },
    {
        "content": "<p>Is your code public? I want to play with it!</p>",
        "id": 343677615,
        "sender_full_name": "David Renshaw",
        "timestamp": 1679491676
    },
    {
        "content": "<p>I got the API keys last week when pretending to do some research with large language models to see if they could be useful to formalize mathematics from plain english. No idea if the proof of the irrationality of square root of 2 in lean which GPT-4 gave to me is correct. At least when I translated the code back into plain english it was right. Although GPT-4 is now a better mathematician than my undergraduate students it still makes stupid mistakes. Thus a feedback loop for GPT-4 would be quite useful. I hope the image input is soon available. No more hand grading of mathematical undergraduate papers...</p>",
        "id": 343700633,
        "sender_full_name": "Gerald Höhn",
        "timestamp": 1679496615
    },
    {
        "content": "<p>Are you saying that you want hand over the grading of undergrad papers to a system that still makes stupid mistakes?</p>",
        "id": 343704985,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1679497516
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"112680\">Johan Commelin</span> <a href=\"#narrow/stream/219941-Machine-Learning-for-Theorem-Proving/topic/GPT/near/343704985\">said</a>:</p>\n<blockquote>\n<p>Are you saying that you want hand over the grading of undergrad papers to a system that still makes stupid mistakes?</p>\n</blockquote>\n<p>My university is already doing this <span aria-label=\"man facepalming\" class=\"emoji emoji-1f926-200d-2642\" role=\"img\" title=\"man facepalming\">:man_facepalming:</span></p>",
        "id": 343707187,
        "sender_full_name": "Adam Topaz",
        "timestamp": 1679497972
    },
    {
        "content": "<blockquote>\n<p>Are you saying that you want hand over the grading of undergrad papers to a system that still makes stupid mistakes?</p>\n</blockquote>\n<p>I can understand your doubt. But one has to compare it with the quality of graders paid minimum wage. But as said, I am interested in a feedback loop so that GPT-4 can be sure its reasoning is correct.</p>",
        "id": 343707689,
        "sender_full_name": "Gerald Höhn",
        "timestamp": 1679498089
    },
    {
        "content": "<p>tangentially related (assuming folks heard about the fact that the old codex was being shut down): <a href=\"https://github.blog/2023-03-22-github-copilot-x-the-ai-powered-developer-experience/\">https://github.blog/2023-03-22-github-copilot-x-the-ai-powered-developer-experience/</a></p>",
        "id": 343728988,
        "sender_full_name": "Adam Topaz",
        "timestamp": 1679502787
    },
    {
        "content": "<p>In France we solved that graders problem a long time ago. There isn't any money to pay people to grade. Professors do it for free.</p>",
        "id": 343736493,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1679504625
    },
    {
        "content": "<p>Better than GPT-4?</p>",
        "id": 343736709,
        "sender_full_name": "Matthew Ballard",
        "timestamp": 1679504669
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"110087\">@Scott Morrison</span> Just curious-- how are you accessing the OpenAI api with lean4?</p>",
        "id": 343786836,
        "sender_full_name": "Adam Topaz",
        "timestamp": 1679519645
    },
    {
        "content": "<p>curl</p>",
        "id": 343786877,
        "sender_full_name": "Scott Morrison",
        "timestamp": 1679519663
    },
    {
        "content": "<p>and some structures <code>deriving ToJson, FromJson</code>.</p>",
        "id": 343786937,
        "sender_full_name": "Scott Morrison",
        "timestamp": 1679519692
    },
    {
        "content": "<p>Talking to it is pretty trivial.</p>",
        "id": 343786953,
        "sender_full_name": "Scott Morrison",
        "timestamp": 1679519700
    },
    {
        "content": "<p>Ah ok</p>",
        "id": 343787016,
        "sender_full_name": "Adam Topaz",
        "timestamp": 1679519713
    },
    {
        "content": "<p>The fun stuff is compiling what it returns, so we can sensibly ask follow up questions. But Lean is awesome? I hadn't tried \"running Lean from Lean\" until yesterday, but it works beautifully, and you get as much information back as you like.</p>",
        "id": 343787208,
        "sender_full_name": "Scott Morrison",
        "timestamp": 1679519773
    },
    {
        "content": "<p>The fact that you can write a tactic that wakes up in a file, reads the source code, makes some modifications to it, runs it in a virtual Lean session, and can retrieve from it the <code>MVarId</code>s from sorries that file, check their types, etc, is pretty wild.</p>",
        "id": 343787694,
        "sender_full_name": "Scott Morrison",
        "timestamp": 1679519925
    },
    {
        "content": "<p>Now I'm really curious to see this code, not just because of the AI stuff, but just for the metaprogramming!</p>",
        "id": 343789787,
        "sender_full_name": "Adam Topaz",
        "timestamp": 1679520708
    },
    {
        "content": "<p>First refactor almost there :-)</p>",
        "id": 343790374,
        "sender_full_name": "Scott Morrison",
        "timestamp": 1679520960
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110087\">Scott Morrison</span> <a href=\"#narrow/stream/219941-Machine-Learning-for-Theorem-Proving/topic/GPT/near/343787694\">said</a>:</p>\n<blockquote>\n<p>The fact that you can write a tactic that wakes up in a file, reads the source code, makes some modifications to it, runs it in a virtual Lean session, and can retrieve from it the <code>MVarId</code>s from sorries that file, check their types, etc, is pretty wild.</p>\n</blockquote>\n<p>That sounds pretty awesome.  I’d love to see the code. When you are ready to share.</p>",
        "id": 343798476,
        "sender_full_name": "Jason Rute",
        "timestamp": 1679524754
    },
    {
        "content": "<p>FYI I just saw that Microsoft wrote a paper assessing GPT-4, with an entire section on its mathematical abilities <a href=\"https://arxiv.org/abs/2303.12712\">https://arxiv.org/abs/2303.12712</a></p>",
        "id": 343814640,
        "sender_full_name": "Daniel Selsam",
        "timestamp": 1679536411
    },
    {
        "content": "<p>The maths section is full of interesting stuff, but look at the \"tool use\" section!</p>",
        "id": 343816501,
        "sender_full_name": "Scott Morrison",
        "timestamp": 1679537892
    },
    {
        "content": "<p><span aria-label=\"mind blown\" class=\"emoji emoji-1f92f\" role=\"img\" title=\"mind blown\">:mind_blown:</span>, GPT-4 drawing a map, after exploring a world in a text adventure game. Fig 5.8</p>",
        "id": 343816759,
        "sender_full_name": "Scott Morrison",
        "timestamp": 1679538146
    },
    {
        "content": "<p>In another text adventure, after GPT-4 fails to cook a meal (attempting to look for a frying pan in the bedroom), the authors admit they couldn't solve it either without reading the source code. They fail to mention if they tried showing GPT-4 the source code. :-)</p>",
        "id": 343816914,
        "sender_full_name": "Scott Morrison",
        "timestamp": 1679538312
    },
    {
        "content": "<p>I think one thing that the discussions above show and the section on mathematics in this paper show is that we need better errors in lean/mathlib.</p>",
        "id": 343817801,
        "sender_full_name": "Adam Topaz",
        "timestamp": 1679539299
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"230999\">Daniel Selsam</span> <a href=\"#narrow/stream/219941-Machine-Learning-for-Theorem-Proving/topic/GPT/near/343814640\">said</a>:</p>\n<blockquote>\n<p>FYI I just saw that Microsoft wrote a paper assessing GPT-4, with an entire section on its mathematical abilities <a href=\"https://arxiv.org/abs/2303.12712\">https://arxiv.org/abs/2303.12712</a></p>\n</blockquote>\n<p>The inevitable HN discussion: <a href=\"https://news.ycombinator.com/item?id=35269590\">https://news.ycombinator.com/item?id=35269590</a></p>",
        "id": 343823749,
        "sender_full_name": "Adam Topaz",
        "timestamp": 1679542671
    },
    {
        "content": "<blockquote>\n<p>[...] First, the training data of the model mainly consists of questions and their solutions, but it does not capture the wording that expresses the thinking process which leads to the solution of a math problem, in which one makes guesses, encounters errors, verifies and examines which parts of the solution are correct, backtracks, etc. In other words, since the training data is essentially a linear exposition of the solution, a model trained on this data has no incentive to engage in an “inner dialogue” where it revisits and critically evaluates its own suggestions and calculations.</p>\n</blockquote>\n<p>This is of course not a new realization, but it does underscore that the kind of feedback loop that Scott is now building could maybe potentially (hopefully, etc...) massively improve the model.</p>",
        "id": 343876579,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1679554935
    },
    {
        "content": "<p>When I was a kid in the early 80s, chess computers had just become viable. 20 years previously computers were the size of large rooms and made of valves, but because of the silicon revolution they could now be made to fit snugly under a chessboard and, with the addition of some magnets and a screen (screen technology was already good enough to make small visible LCD screens) you could have a machine that you could play chess against in your own home. One could argue that this was a result of decades of spectacular progress in engineering. The only problem was that these chess computers were absolutely lousy at chess. They would never throw away pieces or accidentally let themselves get bank rank checkmated in 1, and they could beat rabbits by simply taking all their pieces and then overwhelming them, but on a reasonably hard setting they were still no match for an average club player, and if you put them on the hardest setting then they typically took hours to make a move. Down my chess club the kids loved them, and the experts showed no interest in them because they had nothing to teach the experts. 15 years later, thanks to IBM (who were at that time a powerhouse in the computing world) who decided to throw a ton of money at the problem, they were beating grandmasters, and since then we've never looked back.</p>\n<p>I feel like we're in the \"early 80s\" phase right now with these large language models, and that is why I am super-uninterested in them right now. I certainly go around giving talks where I extol their virtues, and show a slide where they're solving 50% of the easiest IMO problem ever in Lean and claim that this is a breakthrough (which it is!). But at the end of the day GPT4 getting a half-decent mark in AMC 12, a multiple choice exam meant for schoolkids, is something which can simultaneously be regarded as an amazing achievement and something which indicates that there is still an essentially infinite amount of work still to be done before they are going to be doing research maths, which is why I am still bewildered by the claims of Szegedy et al that this is going to happen by 2029. Right now they can beat rabbits at maths and that's it. Beating rabbits is a major achievement but undergraduates can easily do this too.</p>\n<p>I've just looked at the MS paper and it's still the case that the mathematics is very ropey. The system makes errors, and in most of life the occasional error is fine but in mathematics one single error is unacceptable. This is one reason why I am concerned about the idea of pushing natural language proofs as opposed to generating Lean proofs, where there is no debate about whether an argument is correct. As is so often the case I feel like the researchers over-hype what they're seeing -- this is a continual problem I have with this community. For example in arguably the hardest math problem they give the system (p40, a modified IMO problem) I have several issues with their presentation. Firstly we have this perennial problem that they have to tell the system the answer -- I cannot complain too much about that because just the same would be true in a formal approach. Secondly they don't state the actual problem (which is <a href=\"https://artofproblemsolving.com/wiki/index.php/2022_IMO_Problems/Problem_2\">this</a> -- they have made substantial changes to it. Firstly they have cleared denominators, and secondly they've added the smoothness hypothesis which makes the question a lot easier (and is crucially used in the proof) -- major changes have been made (as well as telling the machine the solution). So this is <em>very much</em> a \"watered down IMO problem\" -- one reason the original question is hard is precisely because you cannot use the \"wiggle\" argument which smoothness gives you. Also, the researchers write that the GPT4 produces a \"correct proof\". This is not really the case -- this is not a 7/7 solution. For example the line \"let <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msup><mi>y</mi><mo>∗</mo></msup></mrow><annotation encoding=\"application/x-tex\">y^*</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8831em;vertical-align:-0.1944em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">y</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6887em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mbin mtight\">∗</span></span></span></span></span></span></span></span></span></span></span> be the unique positive solution of <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>g</mi><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo><mo>+</mo><mi>g</mi><mo stretchy=\"false\">(</mo><mi>y</mi><mo stretchy=\"false\">)</mo><mo>=</mo><mn>2</mn><mi>x</mi><mi>y</mi></mrow><annotation encoding=\"application/x-tex\">g(x)+g(y)=2xy</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">g</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">x</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">g</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">y</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.8389em;vertical-align:-0.1944em;\"></span><span class=\"mord\">2</span><span class=\"mord mathnormal\">x</span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">y</span></span></span></span>\" -- there is no justification in the given proof that such a <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msup><mi>y</mi><mo>∗</mo></msup></mrow><annotation encoding=\"application/x-tex\">y^*</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8831em;vertical-align:-0.1944em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">y</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6887em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mbin mtight\">∗</span></span></span></span></span></span></span></span></span></span></span> exists and yet the researchers don't pick up on this, even praising the machine's step here. I'm taking at least one mark off here. The next step is also not at all clearly written -- it took me a minute to figure out what was being said. Of course, like so much human-produced mathematics, things can be fixed up. With a Lean proof there would be no such ambiguities. For me the ambiguities are very worrying because this is exactly what doesn't scale when it comes to mathematics (indeed, this is what drew me into ITPs in the first place). If we have computers producing natural language which purports to be a proof of the Riemann Hypothesis but looks like Mochizuki's proof of the ABC conjecture -- with an essential ambiguity in -- what then?</p>\n<p>Now will it take 15 years, like the chess machines, to solve these problems? Nobody knows. Maybe it will be 5 -- maybe it will be 50. But even though these things have come a very long way these examples indicate that there is still a hugely long way to go when it comes to mathematics. Maybe the next step is getting them to pass an undergraduate degree (which again is not going to impress a lot of the experts because undergraduates can do that -- but it's perhaps a step in the right direction?). I am reminded of the theorem prover story : for decades ITPs have been able to solve undergraduate mathematics problems with human assistance, and for decades most experts were not remotely impressed by this. Clearly there have been breakthroughs -- but we are stil several breakthroughs away from my understanding of Szegedy's dream.</p>",
        "id": 343915858,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1679563961
    },
    {
        "content": "<p>Many people (including myself) feel that the best hope is a combination of LLMs for <em>intuitive</em> stuff: making auxiliary constructions (many useless, some useful), suggesting intermediate lemmas (again many useless/false), suggesting what results to use etc. Actual proving can be done by rule-based automation, experimentation to avoid wasting time on false \"lemmas\" etc.</p>",
        "id": 343934563,
        "sender_full_name": "Siddhartha Gadgil",
        "timestamp": 1679567951
    },
    {
        "content": "<p>Of course the proof of the pudding lies in the eating, and so far there isn't even a pudding.</p>",
        "id": 343934696,
        "sender_full_name": "Siddhartha Gadgil",
        "timestamp": 1679567989
    },
    {
        "content": "<p>Incidentally, Szegedi, Josef Urban and others have used deep learning for premise selection together with powerful First-order logic solvers to make the best systems for \"TPTP\" kind of problems (simpler ones). So likely enough the 10 year bet is based on thinking in terms of hybrid systems.</p>",
        "id": 343937392,
        "sender_full_name": "Siddhartha Gadgil",
        "timestamp": 1679568547
    },
    {
        "content": "<p>One metric I like to track is the number of words it takes domain experts to explain how dumb each new GPT is. It seems to grow exponentially. They are almost always correct about the particular version they are critiquing, but I think sometimes they do miss the forest for the trees. The salient context is that there is a no-breakthrough-required knob to keep turning, and turning, and turning.</p>",
        "id": 344043165,
        "sender_full_name": "Daniel Selsam",
        "timestamp": 1679590928
    },
    {
        "content": "<p>That's a great observation :-)</p>",
        "id": 344044596,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1679591209
    },
    {
        "content": "<p>FYI</p>\n<p><a href=\"https://community.openai.com/t/chatgpt-plugins-are-here/115731\">ChatGPT plugins are here!</a> - Currently requires signing up for a wait list.</p>\n<p><strong>EDIT</strong></p>\n<p><a href=\"https://writings.stephenwolfram.com/2023/03/chatgpt-gets-its-wolfram-superpowers/\">ChatGPT Gets Its “Wolfram Superpowers”!</a></p>",
        "id": 344059601,
        "sender_full_name": "Eric Taucher",
        "timestamp": 1679593899
    },
    {
        "content": "<p>love the wolfram integration!</p>",
        "id": 344059871,
        "sender_full_name": "Daniel Selsam",
        "timestamp": 1679593982
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"479359\">Michael Stoll</span> <a href=\"#narrow/stream/219941-Machine-Learning-for-Theorem-Proving/topic/GPT/near/341914901\">said</a>:</p>\n<blockquote>\n<p>It would be interesting to see how well the automated version of this loop (with some reasonable limit on resources) does on a range of tasks like mathlib lemmas (or IMO problems...).</p>\n</blockquote>\n<p>Regarding IMO problems, we are resticted to 2022 since it is not in its training data. It could do (without any loop) a simplified version of one problem (<a href=\"https://github.com/leanprover-community/mathlib/pull/2\">#2</a>). See page 40 of <a href=\"https://arxiv.org/pdf/2303.12712.pdf\">https://arxiv.org/pdf/2303.12712.pdf</a></p>\n<p>P.S.: I overlooked that someone already posted the link to the paper somewhat above.</p>",
        "id": 344067311,
        "sender_full_name": "Gerald Höhn",
        "timestamp": 1679595967
    },
    {
        "content": "<p>wasn't the IMO in July and the model from December?</p>",
        "id": 344097548,
        "sender_full_name": "Fabian Glöckle",
        "timestamp": 1679604325
    },
    {
        "content": "<p>The modified question only bears a passing resemblance to the original question anyway. Continuity and smoothness are not in the original question (indeed they are not on the IMO syllabus), so the near-solution generated to the watered-down problem will probably not have been inspired by any web solution</p>",
        "id": 344106631,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1679607495
    },
    {
        "content": "<p>Yes, thanks, I saw your message this morning. Just mentioned because it means that you cannot evaluate GPT4 on IMO2022.</p>",
        "id": 344107435,
        "sender_full_name": "Fabian Glöckle",
        "timestamp": 1679607780
    },
    {
        "content": "<p>It depends what you mean by \"evaluate\", but for the most extreme sense, you can only evaluate an LLM on an IMO on the day of that IMO!</p>",
        "id": 344107920,
        "sender_full_name": "Scott Morrison",
        "timestamp": 1679607968
    },
    {
        "content": "<p>It would be interesting to see how GPT-4 does on IMO2023</p>",
        "id": 344108583,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1679608301
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110038\">Kevin Buzzard</span> <a href=\"#narrow/stream/219941-Machine-Learning-for-Theorem-Proving/topic/GPT/near/344108583\">said</a>:</p>\n<blockquote>\n<p>It would be interesting to see how GPT-4 does on IMO2023</p>\n</blockquote>\n<p>I view GPT as a <em>meta</em>-system -- almost more like a programming language than a program -- and might rephrase as: it would be interesting to see how various GPT-powered programs do on IMO 2023.</p>",
        "id": 344113169,
        "sender_full_name": "Daniel Selsam",
        "timestamp": 1679610142
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110038\">Kevin Buzzard</span> <a href=\"#narrow/stream/219941-Machine-Learning-for-Theorem-Proving/topic/GPT/near/344106631\">said</a>:</p>\n<blockquote>\n<p>The modified question only bears a passing resemblance to the original question anyway. Continuity and smoothness are not in the original question (indeed they are not on the IMO syllabus), so the near-solution generated to the watered-down problem will probably not have been inspired by any web solution</p>\n</blockquote>\n<p>I played a little around with the temperature and asked GPT-4 for an educated guess for the function g(x) in the modified problem (without mentioning the answer g(x)=x^2). In one of five tries it guessed the correct anwer. Remember one has 90 minutes time for an IMO problem and one prompt takes about a minute (and $0.10).</p>\n<p>One more paper today: <a href=\"https://arxiv.org/abs/2303.10130\">https://arxiv.org/abs/2303.10130</a><br>\nOn page 15 the models predict that Mathematicians are one of the most exposed profession on the Labor Market .<br>\nUndergraduate programs in Mathematics will soon be shut down in most places. Maybe or maybe not.</p>",
        "id": 344139528,
        "sender_full_name": "Gerald Höhn",
        "timestamp": 1679623582
    },
    {
        "content": "<p>Given that these things are currently as good as bad undergraduates, who already exist in great numbers, I think we'd have to see some remarkable improvements. OTOH I got into theorem proving precisely because I thought it would be nice to have an early retirement</p>",
        "id": 344180457,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1679643471
    },
    {
        "content": "<p>Kevin, we still have some time before retirement: <br>\n<a href=\"/user_uploads/3121/wOUlqNGQszEz1QGpZhg-n40l/Screenshot-2023-03-24-at-06-52-34-ChatGPT.png\">Screenshot-2023-03-24-at-06-52-34-ChatGPT.png</a></p>\n<div class=\"message_inline_image\"><a href=\"/user_uploads/3121/wOUlqNGQszEz1QGpZhg-n40l/Screenshot-2023-03-24-at-06-52-34-ChatGPT.png\" title=\"Screenshot-2023-03-24-at-06-52-34-ChatGPT.png\"><img src=\"/user_uploads/3121/wOUlqNGQszEz1QGpZhg-n40l/Screenshot-2023-03-24-at-06-52-34-ChatGPT.png\"></a></div>",
        "id": 344255243,
        "sender_full_name": "Adam Topaz",
        "timestamp": 1679662390
    },
    {
        "content": "<p>I actually did a similar thing on the last homework for my NT class, asking them to identify all the errors made by GPT in a similar proof.</p>",
        "id": 344255680,
        "sender_full_name": "Adam Topaz",
        "timestamp": 1679662499
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"243562\">Adam Topaz</span> <a href=\"#narrow/stream/219941-Machine-Learning-for-Theorem-Proving/topic/GPT/near/344255680\">said</a>:</p>\n<blockquote>\n<p>I actually did a similar thing on the last homework for my NT class, asking them to identify all the errors made by GPT in a similar proof.</p>\n</blockquote>\n<p>This is a great exercise!</p>",
        "id": 344256564,
        "sender_full_name": "Matthew Ballard",
        "timestamp": 1679662715
    },
    {
        "content": "<p>OTOH, this interaction has me genuinely impressed: </p>\n<p>Me: I will give you some mathematical constructions, written using LaTeX code. Please translate them into Lean4 code.</p>\n<p>Let $C$ be the collection of tuples $(A,B,e)$ where $A$ and $B$ are commutative rings and $e : A^\\times \\to B^\\times$ is a morphism of abelian groups. Here, for a commutative ring $A$, $A^\\times$ denotes the unit group of $A$. Consider $C$ as a category where morphisms $(A,B,e) \\to (A',B',e')$ consist of pairs $(f,g)$ where $f : A \\to A'$ and $g : B \\to B'$ are morphisms of rings, such that for all $a \\in A^\\times$, one has $e'(f(a)) = g(e(a))$.</p>\n<p>Write $CRing$ for the category of commutative rings and $F : C \\to CRing$ the functor sending $(A,B,e)$ to $A$ on objects and $(f,g)$ to $f$ on morphisms.</p>\n<p>ChatGPT(w/ GPT4):<br>\nTo translate the given mathematical constructions into Lean4 code, we'll first need to define the necessary structures and classes, such as CommRing, UnitGroup, and Morphism. Then, we'll define the category C and the functor F. Here's the code:</p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"kn\">import</span> <span class=\"n\">algebra.category.CommRing</span>\n<span class=\"kn\">import</span> <span class=\"n\">algebra.group.units</span>\n<span class=\"kn\">import</span> <span class=\"n\">category_theory.functor</span>\n\n<span class=\"n\">open_locale</span> <span class=\"n\">classical</span>\n\n<span class=\"kd\">universes</span> <span class=\"n\">u</span> <span class=\"n\">v</span>\n\n<span class=\"kd\">variables</span> <span class=\"o\">(</span><span class=\"n\">A</span> <span class=\"o\">:</span> <span class=\"kt\">Type</span> <span class=\"n\">u</span><span class=\"o\">)</span> <span class=\"o\">(</span><span class=\"n\">B</span> <span class=\"o\">:</span> <span class=\"kt\">Type</span> <span class=\"n\">v</span><span class=\"o\">)</span> <span class=\"o\">[</span><span class=\"n\">comm_ring</span> <span class=\"n\">A</span><span class=\"o\">]</span> <span class=\"o\">[</span><span class=\"n\">comm_ring</span> <span class=\"n\">B</span><span class=\"o\">]</span>\n\n<span class=\"kd\">def</span> <span class=\"n\">UnitGroup</span> <span class=\"o\">(</span><span class=\"n\">R</span> <span class=\"o\">:</span> <span class=\"kt\">Type</span><span class=\"bp\">*</span><span class=\"o\">)</span> <span class=\"o\">[</span><span class=\"n\">comm_ring</span> <span class=\"n\">R</span><span class=\"o\">]</span> <span class=\"o\">:=</span> <span class=\"n\">units</span> <span class=\"n\">R</span>\n\n<span class=\"kd\">structure</span> <span class=\"n\">Morphism</span> <span class=\"o\">:=</span>\n<span class=\"o\">(</span><span class=\"n\">map</span> <span class=\"o\">:</span> <span class=\"n\">UnitGroup</span> <span class=\"n\">A</span> <span class=\"bp\">→</span> <span class=\"n\">UnitGroup</span> <span class=\"n\">B</span><span class=\"o\">)</span>\n<span class=\"o\">(</span><span class=\"n\">is_group_hom</span> <span class=\"o\">:</span> <span class=\"n\">is_group_hom</span> <span class=\"n\">map</span><span class=\"o\">)</span>\n\n<span class=\"kd\">structure</span> <span class=\"n\">CRingTriple</span> <span class=\"o\">:=</span>\n<span class=\"o\">(</span><span class=\"n\">A</span> <span class=\"o\">:</span> <span class=\"n\">CommRing.</span><span class=\"o\">{</span><span class=\"n\">u</span><span class=\"o\">})</span>\n<span class=\"o\">(</span><span class=\"n\">B</span> <span class=\"o\">:</span> <span class=\"n\">CommRing.</span><span class=\"o\">{</span><span class=\"n\">v</span><span class=\"o\">})</span>\n<span class=\"o\">(</span><span class=\"n\">e</span> <span class=\"o\">:</span> <span class=\"n\">Morphism</span> <span class=\"n\">A</span> <span class=\"n\">B</span><span class=\"o\">)</span>\n\n<span class=\"kd\">variable</span> <span class=\"o\">{</span><span class=\"n\">A</span><span class=\"o\">}</span>\n\n<span class=\"kd\">structure</span> <span class=\"n\">CRingTripleMorphism</span> <span class=\"o\">(</span><span class=\"n\">C₁</span> <span class=\"n\">C₂</span> <span class=\"o\">:</span> <span class=\"n\">CRingTriple</span><span class=\"o\">)</span> <span class=\"o\">:=</span>\n<span class=\"o\">(</span><span class=\"n\">f</span> <span class=\"o\">:</span> <span class=\"n\">C₁.A</span> <span class=\"bp\">⟶</span> <span class=\"n\">C₂.A</span><span class=\"o\">)</span>\n<span class=\"o\">(</span><span class=\"n\">g</span> <span class=\"o\">:</span> <span class=\"n\">C₁.B</span> <span class=\"bp\">⟶</span> <span class=\"n\">C₂.B</span><span class=\"o\">)</span>\n<span class=\"o\">(</span><span class=\"n\">commutes</span> <span class=\"o\">:</span> <span class=\"bp\">∀</span> <span class=\"n\">a</span> <span class=\"o\">:</span> <span class=\"n\">UnitGroup</span> <span class=\"n\">C₁.A</span><span class=\"o\">,</span> <span class=\"n\">C₂.e.map</span> <span class=\"o\">(</span><span class=\"n\">C₁.e.map</span> <span class=\"n\">a</span><span class=\"o\">)</span> <span class=\"bp\">=</span> <span class=\"n\">g</span> <span class=\"o\">(</span><span class=\"n\">C₁.e.map</span> <span class=\"n\">a</span><span class=\"o\">))</span>\n\n<span class=\"kd\">instance</span> <span class=\"n\">CRingTriple_category</span> <span class=\"o\">:</span> <span class=\"n\">category_theory.category</span> <span class=\"n\">CRingTriple</span> <span class=\"o\">:=</span>\n<span class=\"o\">{</span> <span class=\"n\">hom</span> <span class=\"o\">:=</span> <span class=\"n\">CRingTripleMorphism</span><span class=\"o\">,</span>\n  <span class=\"n\">id</span> <span class=\"o\">:=</span> <span class=\"bp\">λ</span> <span class=\"n\">X</span><span class=\"o\">,</span> <span class=\"o\">⟨</span><span class=\"mi\">𝟙</span> <span class=\"n\">_</span><span class=\"o\">,</span> <span class=\"mi\">𝟙</span> <span class=\"n\">_</span><span class=\"o\">,</span> <span class=\"bp\">λ</span> <span class=\"n\">a</span><span class=\"o\">,</span> <span class=\"n\">rfl</span><span class=\"o\">⟩,</span>\n  <span class=\"n\">comp</span> <span class=\"o\">:=</span> <span class=\"bp\">λ</span> <span class=\"n\">X</span> <span class=\"n\">Y</span> <span class=\"n\">Z</span> <span class=\"n\">f</span> <span class=\"n\">g</span><span class=\"o\">,</span> <span class=\"o\">⟨</span><span class=\"n\">f.f</span> <span class=\"bp\">≫</span> <span class=\"n\">g.f</span><span class=\"o\">,</span> <span class=\"n\">f.g</span> <span class=\"bp\">≫</span> <span class=\"n\">g.g</span><span class=\"o\">,</span> <span class=\"bp\">λ</span> <span class=\"n\">a</span><span class=\"o\">,</span> <span class=\"kd\">by</span> <span class=\"n\">rw</span> <span class=\"o\">[</span><span class=\"bp\">←</span><span class=\"n\">g.commutes</span><span class=\"o\">,</span> <span class=\"bp\">←</span><span class=\"n\">f.commutes</span><span class=\"o\">,</span> <span class=\"n\">category_theory.types_comp</span><span class=\"o\">]⟩</span> <span class=\"o\">}</span>\n\n<span class=\"kd\">def</span> <span class=\"n\">F</span> <span class=\"o\">:</span> <span class=\"n\">CRingTriple</span> <span class=\"bp\">⥤</span> <span class=\"n\">CommRing</span> <span class=\"o\">:=</span>\n<span class=\"o\">{</span> <span class=\"n\">obj</span> <span class=\"o\">:=</span> <span class=\"bp\">λ</span> <span class=\"n\">X</span><span class=\"o\">,</span> <span class=\"n\">X.A</span><span class=\"o\">,</span>\n  <span class=\"n\">map</span> <span class=\"o\">:=</span> <span class=\"bp\">λ</span> <span class=\"n\">X</span> <span class=\"n\">Y</span> <span class=\"n\">f</span><span class=\"o\">,</span> <span class=\"n\">f.f</span><span class=\"o\">,</span>\n  <span class=\"n\">map_id'</span> <span class=\"o\">:=</span> <span class=\"bp\">λ</span> <span class=\"n\">X</span><span class=\"o\">,</span> <span class=\"n\">rfl</span><span class=\"o\">,</span>\n  <span class=\"n\">map_comp'</span> <span class=\"o\">:=</span> <span class=\"bp\">λ</span> <span class=\"n\">X</span> <span class=\"n\">Y</span> <span class=\"n\">Z</span> <span class=\"n\">f</span> <span class=\"n\">g</span><span class=\"o\">,</span> <span class=\"n\">rfl</span> <span class=\"o\">}</span>\n</code></pre></div>\n<p>This Lean4 code defines the category C as CRingTriple_category and the functor F as described in the problem statement.</p>",
        "id": 344364118,
        "sender_full_name": "Adam Topaz",
        "timestamp": 1679690475
    },
    {
        "content": "<p>It's not correct, but it's a close approximation</p>",
        "id": 344364190,
        "sender_full_name": "Adam Topaz",
        "timestamp": 1679690507
    },
    {
        "content": "<p>The funny thing is that it seems to have learned that the autoparam'ed fields <code>comp_id</code> etc. in the category instance can usually be dropped, and it has omitted them in <code>CRingTriple_category</code>.</p>",
        "id": 344364420,
        "sender_full_name": "Adam Topaz",
        "timestamp": 1679690604
    },
    {
        "content": "<p>I don't know if this is an argument for or against dropping these fields from mathlib.</p>",
        "id": 344364448,
        "sender_full_name": "Adam Topaz",
        "timestamp": 1679690622
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110087\">Scott Morrison</span> <a href=\"#narrow/stream/219941-Machine-Learning-for-Theorem-Proving/topic/GPT/near/343787208\">said</a>:</p>\n<blockquote>\n<p>The fun stuff is compiling what it returns, so we can sensibly ask follow up questions. But Lean is awesome? I hadn't tried \"running Lean from Lean\" until yesterday, but it works beautifully, and you get as much information back as you like.</p>\n</blockquote>\n<p>Do you have any suggestions on resources for learning \"running Lean from Lean\"?</p>",
        "id": 344500983,
        "sender_full_name": "Jake",
        "timestamp": 1679754773
    },
    {
        "content": "<p>Perhaps I am a harsh grader, but I would give GPT-4 much less than 7/7 on that vastly simplified IMO problem.</p>\n<p>Quite aside from the fact that this \"simplified version\" is quite easy (you don't even need the continuity assumption; you just need x²+y^2&gt;=2xy, nothing else), the fact is that the \"proof\" that GPT-4 provides is incomplete *unless you provide the missing step yourself, which is... x^2+y^2&gt;=2x y*. Only if you read that into the lines (in the antepenultimate step) does this become a (verbose) proof.</p>\n<p>This is impressive nevertheless, but more in the line of \"an AI tricked someone into believing it was a beautiful woman with a crush on him and imperfect English\".</p>\n<p>(I do admit I am impressed by the fact that GPT-4 manage to apply and explain continuity correctly (if pointlessly).)</p>",
        "id": 344559957,
        "sender_full_name": "Harald Helfgott",
        "timestamp": 1679782573
    },
    {
        "content": "<p>I suggest that if people wish to evaluate GPT-based systems (or any other AI producing informal answers from informal problem statements) on IMO problems, then as well as the evaluations being more credible if they're based on the actual problem statements rather than simplified versions, and more credible if a commitment to do such an evaluation (and publish the results) with details of the evaluation protocol is declared in public before the IMO in question to avoid publication bias, they would also be more credible if the declared protocol involves a coordinator on the problem in question at the IMO in question doing the evaluation using the mark scheme actually used at the IMO, rather than someone unfamiliar with how the problem was marked doing their own evaluation.</p>\n<p>Although such an evaluation protocol has the disadvantage (compared to evaluation of formal proofs, possibly produced by a system that first produces an informal proof then autoformalizes it) that the mark schemes aren't public (I tend to think they should be, though I guess a majority of leaders at the IMO would disagree), given the various criticisms I've seen of how limited the published information is regarding the design and training of GPT-4 I suspect that inability to reproduce things entirely from public information might not be a major concern to some people producing AIs.</p>",
        "id": 344563055,
        "sender_full_name": "Joseph Myers",
        "timestamp": 1679784547
    },
    {
        "content": "<p>I came here to post the same thing. Specifically <a href=\"https://arxiv.org/pdf/2303.12712.pdf#page=26\">on page 26</a> it shows how GPT4 can be used to help you type up Latex much faster, and the maths section is page <a href=\"https://arxiv.org/pdf/2303.12712.pdf#page=30\">30</a>-41  , and appendix on page <a href=\"https://arxiv.org/pdf/2303.12712.pdf#page=122\">122</a>-140  </p>\n<p>IMO The most exciting offering GPT4 can bring to Lean is: Self Healing code - setting up a loop where an LLM proposes something, gets an error, evaluates the error message, then suggest refinements, repeatedly, until no more errors. At minimum it will make error-free code. Who knows if it'll be useful. But if it's good enough to get 90% of the way there, set up a script to run 'n' number of attempts ('n' limited by how much money you're willing to spend on API calls) and you'll likely get some neat results. Basically automating the Computational Approach to maths that Stephen Wolfram describes in the \"All Possible Theorems\" section of <a href=\"https://writings.stephenwolfram.com/2020/09/the-empirical-metamathematics-of-euclid-and-beyond/\">this</a> article.</p>\n<p>A working example of Self Healing code already working in Python can be found <a href=\"https://github.com/biobootloader/wolverine\">here</a>, and a high-level discussion of the general design properties such a system should have is <a href=\"https://www.cognitect.com/blog/2016/12/9/works-on-my-machine-self-healing-code-with-clojurespec-1\">summarised here (from 2016!)</a>.</p>\n<p>I might as well dump all my other GPT related top tips while I'm at it:<br>\n<a href=\"https://chrome.google.com/webstore/detail/superpower-chatgpt/amhmeenmapldpjdedekalnfifgnpfnkc\">This ChatGPT Chrome extension</a> gives useful features, and an extremely high value newsletter: </p>\n<p>Former Harvard CS prof predicts that will be how AI changes writing code. Humans will specify what the code should do, the AI will write the code, humans will test and check it. <a href=\"https://youtu.be/mj0pW9_ckug?t=308\">Very good talk</a>, highly recommend.</p>\n<div class=\"youtube-video message_inline_image\"><a data-id=\"mj0pW9_ckug\" href=\"https://youtu.be/mj0pW9_ckug?t=308\"><img src=\"https://uploads.zulipusercontent.net/ee9cafae203eb99882aeb861ff133c0e416916de/68747470733a2f2f692e7974696d672e636f6d2f76692f6d6a307057395f636b75672f64656661756c742e6a7067\"></a></div><p>Big <span aria-label=\"raised hands\" class=\"emoji emoji-1f64c\" role=\"img\" title=\"raised hands\">:raised_hands:</span> I've been watching this space since IIRC 2019, and I hope what I've shared can bring some useful ideas.</p>",
        "id": 344759266,
        "sender_full_name": "Jay T",
        "timestamp": 1679892813
    },
    {
        "content": "<blockquote>\n<p>At minimum it will make error-free code</p>\n</blockquote>\n<p>At minimum it will go into an infinite loop without finding any error free code. Based on the above discussion this seems to be the case often with ChatGPT</p>",
        "id": 344759889,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1679893163
    },
    {
        "content": "<blockquote>\n<p>at minimum it will make error free code</p>\n</blockquote>\n<p>At minimum it will get stuck trying to make error free code -- oh sorry Mario got there first.</p>",
        "id": 344788611,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1679903929
    },
    {
        "content": "<p>If you ask a current system a hard question (eg \"prove a tricky theorem that is not in mathlib because we didn't get around to it yet\") then the chances of it making error free code are going to be vanishingly small, otherwise this community would have heard about it by now.</p>",
        "id": 344789077,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1679904099
    },
    {
        "content": "<p>It’s not here yet. But if you want to learn about recent work in this direction, see: <a href=\"https://arxiv.org/abs/2303.04910v2\">https://arxiv.org/abs/2303.04910v2</a></p>",
        "id": 344802549,
        "sender_full_name": "Albert Jiang",
        "timestamp": 1679907647
    },
    {
        "content": "<p>Proof repair is very useful in the program verification domain, and IMHO less useful in research level mathematics.</p>",
        "id": 344802751,
        "sender_full_name": "Albert Jiang",
        "timestamp": 1679907720
    },
    {
        "content": "<p>It’s a very new method. I’m very excited to see what it will evolve into 5 years from now.</p>",
        "id": 344803018,
        "sender_full_name": "Albert Jiang",
        "timestamp": 1679907803
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"258175\">Albert Jiang</span> <a href=\"#narrow/stream/219941-Machine-Learning-for-Theorem-Proving/topic/GPT/near/344803018\">said</a>:</p>\n<blockquote>\n<p>It’s a very new method. I’m very excited to see what it will evolve into 5 years from now.</p>\n</blockquote>\n<p>That's my impression about proof repair as well. It is just beginning to pick up steam according to people I know in this field.</p>",
        "id": 344911991,
        "sender_full_name": "Shreyas Srinivas",
        "timestamp": 1679934036
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"258175\">Albert Jiang</span> <a href=\"#narrow/stream/219941-Machine-Learning-for-Theorem-Proving/topic/GPT/near/344802751\">said</a>:</p>\n<blockquote>\n<p>Proof repair is very useful in the program verification domain, and IMHO less useful in research level mathematics.</p>\n</blockquote>\n<p>I wonder if that's just because people are mostly mechanizing existing mathematics, i.e. not primarily making new things. I'd imagine proof repair is important in a context where the definitions and theorems are changing over time, albeit mildly. This currently happens more often in program verification, but I could imagine in a couple of years when the tools and the corpus of formalized mathematics allow it, if research mathematics starts happening in theorem provers, then proof repair would probably also be important there, don't you think?</p>",
        "id": 345307663,
        "sender_full_name": "Andrés Goens",
        "timestamp": 1680072481
    },
    {
        "content": "<p>proof repair is a very common thing in mathlib maintenance</p>",
        "id": 345310253,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1680073366
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"315434\">Andrés Goens</span> <a href=\"#narrow/stream/219941-Machine-Learning-for-Theorem-Proving/topic/GPT/near/345307663\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"258175\">Albert Jiang</span> <a href=\"#narrow/stream/219941-Machine-Learning-for-Theorem-Proving/topic/GPT/near/344802751\">said</a>:</p>\n<blockquote>\n<p>Proof repair is very useful in the program verification domain, and IMHO less useful in research level mathematics.</p>\n</blockquote>\n<p>I wonder if that's just because people are mostly mechanizing existing mathematics, i.e. not primarily making new things. I'd imagine proof repair is important in a context where the definitions and theorems are changing over time, albeit mildly. This currently happens more often in program verification, but I could imagine in a couple of years when the tools and the corpus of formalized mathematics allow it, if research mathematics starts happening in theorem provers, then proof repair would probably also be important there, don't you think?</p>\n</blockquote>\n<p>Agreed. In addition, in a nice world with well developed proof repair, porting mathlib theorems would be much more automated.</p>",
        "id": 345338141,
        "sender_full_name": "Shreyas Srinivas",
        "timestamp": 1680080905
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110049\">Mario Carneiro</span> <a href=\"#narrow/stream/219941-Machine-Learning-for-Theorem-Proving/topic/GPT/near/345310253\">said</a>:</p>\n<blockquote>\n<p>proof repair is a very common thing in mathlib maintenance</p>\n</blockquote>\n<p>Ah i didn’t know this. That’s great! Any chance you can point me to where this is done?</p>",
        "id": 345367347,
        "sender_full_name": "Albert Jiang",
        "timestamp": 1680088552
    },
    {
        "content": "<p>I mean just look at any recent mathlib refactor (well, I suppose those are less common of late...). Anything that touches 30+ files will almost certainly have been created by changing some basic files and then going into a dialogue with CI to hunt down all the proofs that broke and make appropriate changes to fix them</p>",
        "id": 345370711,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1680089471
    },
    {
        "content": "<p>My experience with proof repair is that usually the pain is having to wait for CI to make it through all of mathlib, rather than actually having difficulty fixing the proofs themselves. In many case, having a deterministic tool (eg to perform renames or change argument explicitness) would be more helpful than an AI assistant.</p>",
        "id": 345372213,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1680089829
    },
    {
        "content": "<p>It would be very nice if there was data on this incremental process. Baldur's proof repair is trained with <code>(theorem_statement, candidate_proof, error_message) -&gt; ground_truth_proof</code> because the incremental procedure of<br>\n<code>(theorem_statement, candidate_proof, error_message) -&gt; candidate_proof_2</code><br>\n<code>(theorem_statement, candidate_proof_2, error_message_2) -&gt; candidate_proof_3</code><br>\n...<br>\n<code>(theorem_statement, candidate_proof_n, error_message_n) -&gt; ground_truth_proof</code><br>\nis not recorded anywhere, so we would have to send the language model into an MCTS-like search loop and retrain it on the sucessful sequences</p>",
        "id": 345373082,
        "sender_full_name": "Fabian Glöckle",
        "timestamp": 1680090017
    },
    {
        "content": "<p>A teaser:</p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"sd\">/-- The length of the concatenation of two lists is the sum of the lengths of the lists. -/</span>\n<span class=\"kd\">theorem</span> <span class=\"n\">length_append</span> <span class=\"o\">:</span> <span class=\"gr\">sorry</span> <span class=\"o\">:=</span> <span class=\"kd\">by</span> <span class=\"n\">sagredo</span>\n</code></pre></div>\n<p>produces</p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"sd\">/-- The length of the concatenation of two lists is the sum of the lengths of the lists. -/</span>\n<span class=\"kd\">theorem</span> <span class=\"n\">length_append</span> <span class=\"o\">(</span><span class=\"n\">xs</span> <span class=\"n\">ys</span> <span class=\"o\">:</span> <span class=\"n\">List</span> <span class=\"n\">α</span><span class=\"o\">)</span> <span class=\"o\">:</span> <span class=\"n\">List.length</span> <span class=\"o\">(</span><span class=\"n\">xs</span> <span class=\"bp\">++</span> <span class=\"n\">ys</span><span class=\"o\">)</span> <span class=\"bp\">=</span> <span class=\"n\">List.length</span> <span class=\"n\">xs</span> <span class=\"bp\">+</span> <span class=\"n\">List.length</span> <span class=\"n\">ys</span> <span class=\"o\">:=</span> <span class=\"kd\">by</span>\n  <span class=\"n\">induction</span> <span class=\"n\">xs</span> <span class=\"k\">with</span>\n  <span class=\"bp\">|</span> <span class=\"n\">nil</span> <span class=\"bp\">=&gt;</span> <span class=\"n\">rw</span> <span class=\"o\">[</span><span class=\"n\">List.nil_append</span><span class=\"o\">,</span> <span class=\"n\">List.length_nil</span><span class=\"o\">,</span> <span class=\"n\">Nat.zero_add</span><span class=\"o\">]</span>\n  <span class=\"bp\">|</span> <span class=\"n\">cons</span> <span class=\"n\">x</span> <span class=\"n\">xs'</span> <span class=\"n\">ih</span> <span class=\"bp\">=&gt;</span> <span class=\"n\">rw</span> <span class=\"o\">[</span><span class=\"n\">List.cons_append</span><span class=\"o\">,</span> <span class=\"n\">List.length_cons</span><span class=\"o\">,</span> <span class=\"n\">List.length_cons</span><span class=\"o\">,</span> <span class=\"n\">ih</span><span class=\"o\">]</span><span class=\"bp\">;</span> <span class=\"n\">rw</span> <span class=\"o\">[</span><span class=\"n\">Nat.succ_add</span><span class=\"o\">]</span>\n</code></pre></div>",
        "id": 345519499,
        "sender_full_name": "Scott Morrison",
        "timestamp": 1680125566
    },
    {
        "content": "<p><a href=\"https://en.wikipedia.org/wiki/Giovanni_Francesco_Sagredo\">https://en.wikipedia.org/wiki/Giovanni_Francesco_Sagredo</a> ?</p>",
        "id": 345519895,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1680125739
    },
    {
        "content": "<p>With current prompting, sagredo takes 5 exchanges (completely automatic) between GPT and Lean before producing this result. Hence it is not fast!</p>",
        "id": 345519906,
        "sender_full_name": "Scott Morrison",
        "timestamp": 1680125747
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"284997\">@Zhangir Azerbayev</span> has been helping with the prompting design, and building good test cases. I don't think it's at all ready for prime time, but I'll try to post some of the actual dialogues behind these results soon. It needs a GPT4 API key to run, so don't expect wide deployment right away. :-)</p>",
        "id": 345520319,
        "sender_full_name": "Scott Morrison",
        "timestamp": 1680125924
    },
    {
        "content": "<p>Doesn't Isabelle/HOL's <code>sledgehammer</code> also take an age?</p>\n<p>When my PhD thesis hit 50 pages, I used to start TeX running on it and then go and make a cup of tea.</p>",
        "id": 345520569,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1680126054
    },
    {
        "content": "<p>So it writes the type of the function as well?!?</p>",
        "id": 345521052,
        "sender_full_name": "Adam Topaz",
        "timestamp": 1680126276
    },
    {
        "content": "<p>Yes. If you write a natural language outline of the proof in a comment before calling <code>sagredo</code> it also tries to follow your script. (At least, sometimes. Sometimes it does really dumb stuff, too. :-)</p>",
        "id": 345521182,
        "sender_full_name": "Scott Morrison",
        "timestamp": 1680126338
    },
    {
        "content": "<p>It still really struggles with Lean 4 syntax, and a lot of our prompting is helping it with that. Hopefully this will get much better once there is a training run that includes mathlib4.</p>",
        "id": 345521282,
        "sender_full_name": "Scott Morrison",
        "timestamp": 1680126375
    },
    {
        "content": "<p>right, but that's expected, I guess, since gpt4's data was limited to some time in 2021 IIRC</p>",
        "id": 345521338,
        "sender_full_name": "Adam Topaz",
        "timestamp": 1680126404
    },
    {
        "content": "<p>I've heard rumors that they're already training gpt5, but I don't know whether to trust them...</p>",
        "id": 345521417,
        "sender_full_name": "Adam Topaz",
        "timestamp": 1680126454
    },
    {
        "content": "<p>It also gets frustrated when it can't find the right lemma name. I just had an amusing one where it couldn't find the lemma for <code>List.range 0 = []</code>. Maybe we should teach it how to call <code>library_search</code>!</p>",
        "id": 345521437,
        "sender_full_name": "Scott Morrison",
        "timestamp": 1680126469
    },
    {
        "content": "<p>I mean, how could they not be training GPT5? As various people have said, there is a just a knob to turn to keep making it better at this point.</p>",
        "id": 345521557,
        "sender_full_name": "Scott Morrison",
        "timestamp": 1680126511
    },
    {
        "content": "<p>I guess so.</p>",
        "id": 345521586,
        "sender_full_name": "Adam Topaz",
        "timestamp": 1680126522
    },
    {
        "content": "<p>At some point they will probably also allow us to fine-tune gpt4, which would certainly help.</p>",
        "id": 345521619,
        "sender_full_name": "Adam Topaz",
        "timestamp": 1680126536
    },
    {
        "content": "<p>Anyway, this looks really really cool! I look forward to playing with it :)</p>",
        "id": 345521735,
        "sender_full_name": "Adam Topaz",
        "timestamp": 1680126589
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110087\">Scott Morrison</span> <a href=\"#narrow/stream/219941-Machine-Learning-for-Theorem-Proving/topic/GPT/near/345521557\">said</a>:</p>\n<blockquote>\n<p>I mean, how could they not be training GPT5? As various people have said, there is a just a knob to turn to keep making it better at this point.</p>\n</blockquote>\n<div class=\"message_inline_image\"><a href=\"https://media0.giphy.com/media/3o6EhWZRnnQNI3gg9y/giphy.gif?cid=c623cb35sg751g009qsnk460mu9f5bauwcansnstv1kzr7kr&amp;rid=giphy.gif&amp;ct=g\"><img src=\"https://uploads.zulipusercontent.net/ae69945509e617e0ee5e6c2efae56ccb49e5c3a9/68747470733a2f2f6d65646961302e67697068792e636f6d2f6d656469612f336f364568575a526e6e514e4933676739792f67697068792e6769663f6369643d633632336362333573673735316730303971736e6b3436306d753966356261757763616e736e737476316b7a72376b72267269643d67697068792e6769662663743d67\"></a></div>",
        "id": 345522238,
        "sender_full_name": "Adam Topaz",
        "timestamp": 1680126834
    },
    {
        "content": "<p>Have you thought about just asking it for lean 3 code and running mathport (or a bespoke mini 3-&gt;4 translator) on the output? If  simple syntax changes is whats throwing it off so much it might not be as ridiculous as it sounds.</p>",
        "id": 345522612,
        "sender_full_name": "Alex J. Best",
        "timestamp": 1680127007
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110087\">Scott Morrison</span> <a href=\"#narrow/stream/219941-Machine-Learning-for-Theorem-Proving/topic/GPT/near/345521437\">said</a>:</p>\n<blockquote>\n<p>It also gets frustrated when it can't find the right lemma name. I just had an amusing one where it couldn't find the lemma for <code>List.range 0 = []</code>. Maybe we should teach it how to call <code>library_search</code>!</p>\n</blockquote>\n<p>The best way to deal with this problem is likely to use openai's embeddings (not sure if they'll be good enough) or to train a lightweight premise selection model, in the spirit of <a href=\"https://arxiv.org/abs/2303.04488\">magnushammer</a>. Magnushammer works quite well for Isabelle and is only 86M parameters, so you can train it with academic resources and run it on cpu.</p>",
        "id": 345522654,
        "sender_full_name": "Zhangir Azerbayev",
        "timestamp": 1680127029
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"127136\">Alex J. Best</span> <a href=\"#narrow/stream/219941-Machine-Learning-for-Theorem-Proving/topic/GPT/near/345522612\">said</a>:</p>\n<blockquote>\n<p>Have you thought about just asking it for lean 3 code and running mathport (or a bespoke mini 3-&gt;4 translator) on the output? If  simple syntax changes is whats throwing it off so much it might not be as ridiculous as it sounds.</p>\n</blockquote>\n<p>Wouldn't we also need a lean4 -&gt; lean3 converter for the prompt itself?</p>",
        "id": 345522858,
        "sender_full_name": "Adam Topaz",
        "timestamp": 1680127112
    },
    {
        "content": "<p>The prompt in Scotts example is the same in lean 3 and lean 4 at least (just a docstring and function name) which is probably part of the issue</p>",
        "id": 345522976,
        "sender_full_name": "Alex J. Best",
        "timestamp": 1680127181
    },
    {
        "content": "<p>sure, but that's not always going to be the case.</p>",
        "id": 345523002,
        "sender_full_name": "Adam Topaz",
        "timestamp": 1680127197
    },
    {
        "content": "<p>I think the syntax problems for Lean4 are pretty solvable. Zhangir's prompting is already a massive improvement over my initial attempt, and we can certainly do more. And this problem will just go away over time. Our whole code is pretty simple and pure Lean 4, and at this point I would hate to have the hacky overhead of interacting with Lean 3 and/or mathport.</p>",
        "id": 345524754,
        "sender_full_name": "Scott Morrison",
        "timestamp": 1680128073
    },
    {
        "content": "<p>Nice work! We have a GPT4 API key, would love to give it a try.</p>",
        "id": 345536572,
        "sender_full_name": "Tyler Josephson ⚛️",
        "timestamp": 1680135608
    },
    {
        "content": "<p>William Stein <a href=\"https://groups.google.com/g/sage-support/c/Fybdtxbui0Y/m/hGAJr9pdAwAJ\">talks</a> about deployment of ChatGPT in the sage-support mailing list:</p>\n<blockquote>\n<p>I added this \"Help me fix this...\" feature to cocalc jupyter notebooks a week ago, and it's been extremely popular with 1000+ uses a day. It's exactly the sort of thing that ChatGPT can be very helpful with, given that Sage typical outputs a massive scary stacktrace when anything goes wrong, and it's just a lot of mental effort to untangle it, especially given the preparser. ChatGPT is far from perfect, but it doesn't mind expending a lot of effort. People also often get stuck and very frustrated with Sage due to silly little things, e.g., accidentally capitalizing a function name, and chatgpt instantly points out such things.</p>\n</blockquote>",
        "id": 346100456,
        "sender_full_name": "Junyan Xu",
        "timestamp": 1680321065
    },
    {
        "content": "<p>Just want to say. ChatGPT is a great tool for those familiar with LEAN(or any other language), but it can be potentially harmful for newcomers at times. In this sense, Zulip is much better than ChatGPT.<br>\n<a href=\"/user_uploads/3121/n_ADxTH6EbRYTSgQH83sAjK2/chat-shot-13.png\">chat-shot.png</a></p>\n<div class=\"message_inline_image\"><a href=\"/user_uploads/3121/n_ADxTH6EbRYTSgQH83sAjK2/chat-shot-13.png\" title=\"chat-shot.png\"><img src=\"/user_uploads/3121/n_ADxTH6EbRYTSgQH83sAjK2/chat-shot-13.png\"></a></div>",
        "id": 347141931,
        "sender_full_name": "RexWang",
        "timestamp": 1680700812
    },
    {
        "content": "<p>The mix of correct and completely false information is really striking. Trusting this thing would indeed be very harmful.</p>",
        "id": 347151992,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1680702672
    },
    {
        "content": "<p>obviously, there is a much lower false-information rate when GPT is augmented with web search <a href=\"/user_uploads/3121/x8Lp5BRxNiWwfv6rjWx9FE3o/Screenshot-2023-04-05-at-10.43.50-AM.png\">Screenshot-2023-04-05-at-10.43.50-AM.png</a></p>\n<div class=\"message_inline_image\"><a href=\"/user_uploads/3121/x8Lp5BRxNiWwfv6rjWx9FE3o/Screenshot-2023-04-05-at-10.43.50-AM.png\" title=\"Screenshot-2023-04-05-at-10.43.50-AM.png\"><img src=\"/user_uploads/3121/x8Lp5BRxNiWwfv6rjWx9FE3o/Screenshot-2023-04-05-at-10.43.50-AM.png\"></a></div>",
        "id": 347218024,
        "sender_full_name": "Daniel Selsam",
        "timestamp": 1680716705
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110031\">Patrick Massot</span> <a href=\"#narrow/stream/219941-Machine-Learning-for-Theorem-Proving/topic/GPT/near/347151992\">said</a>:</p>\n<blockquote>\n<p>The mix of correct and completely false information is really striking. Trusting this thing would indeed be very harmful.</p>\n</blockquote>\n<p>StackOverFlow banned answers from ChatGPT precisely because its answers are plausible, nearly-correct but often wrong, and hard to get corrected by experts at scale. <a href=\"https://www.theverge.com/2022/12/5/23493932/chatgpt-ai-generated-answers-temporarily-banned-stack-overflow-llms-dangers\">https://www.theverge.com/2022/12/5/23493932/chatgpt-ai-generated-answers-temporarily-banned-stack-overflow-llms-dangers</a></p>",
        "id": 347431920,
        "sender_full_name": "Tyler Josephson ⚛️",
        "timestamp": 1680790532
    },
    {
        "content": "<p>I would like to know more about the information available at <a href=\"http://irs.gov\">irs.gov</a></p>",
        "id": 347440013,
        "sender_full_name": "Reid Barton",
        "timestamp": 1680792022
    },
    {
        "content": "<p>MathOverflow also has such a ban I believe, but it's more because ChatGPT still generates obvious nonsense in that context.</p>",
        "id": 347440157,
        "sender_full_name": "Reid Barton",
        "timestamp": 1680792054
    },
    {
        "content": "<p>I can reproduce the conversation and the <a href=\"https://www.irs.gov/businesses/small-businesses-self-employed/whats-the-difference-between-a-levy-and-a-lien\">irs.gov link</a> is about the difference between Levy and Lien, so it looks like some kind of fuzzy match (the word \"Lean\" doesn't appear). <a href=\"http://irs.gov\">irs.gov</a> doesn't actually appear in the first several pages of results when I search \"difference between Lean3 and Lean4\" on Bing, but the first result from \"difference between Lean3 and Lean4 <a href=\"http://irs.gov\">irs.gov</a>\" is indeed about Lien.</p>",
        "id": 348090493,
        "sender_full_name": "Junyan Xu",
        "timestamp": 1681073142
    },
    {
        "content": "<p>There have already been a few ongoing-agent-on-top-of-GPT projects (e.g. <a href=\"https://github.com/Torantulino/Auto-GPT\">https://github.com/Torantulino/Auto-GPT</a>). I think Lean provides an interesting environment for this kind of system since the kernel preempts many common \"going off-the-rails\" failure modes and might permit systematic progress over long time horizons. It would be cool to see a GPT-agent interacting with Lean server directly (without VSCode) in the context of (say) a Mathlib fork, web/arXiv search, and occasional Q/As on Zulip, etc., perhaps with a very grand goal such as \"formalize all existing mathematical knowledge in Lean\".</p>",
        "id": 348288670,
        "sender_full_name": "Daniel Selsam",
        "timestamp": 1681154646
    },
    {
        "content": "<p>/me <em>looks suspiciously at the other users here</em><br>\nhow many of you are, already, GPT agents?</p>",
        "id": 348290991,
        "sender_full_name": "David Renshaw",
        "timestamp": 1681155572
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"230999\">Daniel Selsam</span> <a href=\"#narrow/stream/219941-Machine-Learning-for-Theorem-Proving/topic/GPT/near/348288670\">said</a>:</p>\n<blockquote>\n<p>There have already been a few ongoing-agent-on-top-of-GPT projects (e.g. <a href=\"https://github.com/Torantulino/Auto-GPT\">https://github.com/Torantulino/Auto-GPT</a>). I think Lean provides an interesting environment for this kind of system since the kernel preempts many common \"going off-the-rails\" failure modes and might permit systematic progress over long time horizons. It would be cool to see a GPT-agent interacting with Lean server directly (without VSCode) in the context of (say) a Mathlib fork, web/arXiv search, and occasional Q/As on Zulip, etc., perhaps with a very grand goal such as \"formalize all existing mathematical knowledge in Lean\".</p>\n</blockquote>\n<p>Yeah I also just posted similar ideas <a href=\"#narrow/stream/219941-Machine-Learning-for-Theorem-Proving/topic/sagredo/near/348247558\">in the sagredo thread</a>.</p>\n<p>By the way, do maintainers think it's a good idea to enroll all leanprover(-community) repos into the <a href=\"https://githubnext.com/projects/copilot-for-pull-requests\">Copilot for PRs</a> waitlist? Apparently I myself could enroll them, but if it's generally agree it's a good idea (I can't see any downsides), <del>and if every member enrolls them, then we might be able to get access faster</del>. I'm now in the <a href=\"https://githubnext.com/projects/copilot-for-docs\">Copilot for docs</a> waitlist, but I think it's probably not specific to any repo.</p>",
        "id": 348344632,
        "sender_full_name": "Junyan Xu",
        "timestamp": 1681184110
    },
    {
        "content": "<p>I think this would be fine. Presumably at some point copilot would want money.</p>",
        "id": 348375349,
        "sender_full_name": "Scott Morrison",
        "timestamp": 1681197626
    },
    {
        "content": "<p>I just requested installing the copilot4prs GitHub App on all leanprover-community repos (I can't actually do anything with leanprover repos), and it requests the following privileges that probably need a maintainer to approve. Once it's approved I think we will be in the waitlist.<br>\n<a href=\"/user_uploads/3121/yzcBPozAFakOlebU7PoNoSiI/image.png\">image.png</a></p>\n<div class=\"message_inline_image\"><a href=\"/user_uploads/3121/yzcBPozAFakOlebU7PoNoSiI/image.png\" title=\"image.png\"><img src=\"/user_uploads/3121/yzcBPozAFakOlebU7PoNoSiI/image.png\"></a></div>",
        "id": 348379378,
        "sender_full_name": "Junyan Xu",
        "timestamp": 1681198724
    },
    {
        "content": "<p>(deleted)</p>",
        "id": 348389917,
        "sender_full_name": "Siddhartha Gadgil",
        "timestamp": 1681201395
    }
]