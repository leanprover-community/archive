[
    {
        "content": "<p><a href=\"https://english.elpais.com/science-tech/2025-06-24/spanish-mathematician-javier-gomez-serrano-and-google-deepmind-team-up-to-solve-the-navier-stokes-million-dollar-problem.html?outputType=amp\">https://english.elpais.com/science-tech/2025-06-24/spanish-mathematician-javier-gomez-serrano-and-google-deepmind-team-up-to-solve-the-navier-stokes-million-dollar-problem.html?outputType=amp</a></p>",
        "id": 525993519,
        "sender_full_name": "Anh Nguyễn",
        "timestamp": 1750981646
    },
    {
        "content": "<p>I'll believe it when I see it. Why don't they tackle some less researched problems first like invariant subspace problem before diving into this one?</p>",
        "id": 525993833,
        "sender_full_name": "Leni Aniva",
        "timestamp": 1750981877
    },
    {
        "content": "<p>They said that they have been working 3 years now for that problems</p>",
        "id": 525997804,
        "sender_full_name": "Anh Nguyễn",
        "timestamp": 1750985350
    },
    {
        "content": "<p>Seems to indicate some specialized AI method unless they pivoted to more general LLM usage.</p>",
        "id": 525998682,
        "sender_full_name": "Justin Asher",
        "timestamp": 1750986242
    },
    {
        "content": "<p>In the article they mentioned the use of neural theorem prover</p>",
        "id": 525999032,
        "sender_full_name": "Anh Nguyễn",
        "timestamp": 1750986567
    },
    {
        "content": "<p>No, the article does not mention neural theorem provers</p>",
        "id": 525999705,
        "sender_full_name": "Thomas Zhu",
        "timestamp": 1750987300
    },
    {
        "content": "<p>Sorry, not in that article but in other article</p>",
        "id": 526004537,
        "sender_full_name": "Anh Nguyễn",
        "timestamp": 1750992152
    },
    {
        "content": "<p>Reference?</p>",
        "id": 526004929,
        "sender_full_name": "Justin Asher",
        "timestamp": 1750992569
    },
    {
        "content": "<p>In searching for <code>neural theorem provers</code> did not find it but did find</p>\n<p>Machine Learning in PDE: Discovering New, Unstable Solutions By <a href=\"https://www.carmin.tv/en/speakers/javier-gomez-serrano\">Javier Gómez-Serrano</a> (May 2025) (<a href=\"https://www.carmin.tv/en/video/machine-learning-in-pde-discovering-new-unstable-solutions\">Video Lecture</a>)</p>\n<p>The lecture notes the use of </p>\n<ul>\n<li><a href=\"https://deepmind.google/discover/blog/alphaevolve-a-gemini-powered-coding-agent-for-designing-advanced-algorithms/\">AlphaEvolve</a></li>\n<li>Physics-Informed Neural Networks (PINN) (<a href=\"https://faculty.sites.iastate.edu/hliu/files/inline-files/PINN_RPK_2019_1.pdf\">pdf</a>)</li>\n</ul>\n<p>Deep Learning Poised to ‘Blow Up’ Famed Fluid Equations (April 2022) (<a href=\"https://www.quantamagazine.org/deep-learning-poised-to-blow-up-famed-fluid-equations-20220412/\">Quanta Magazine</a>)</p>",
        "id": 526024226,
        "sender_full_name": "Eric Taucher",
        "timestamp": 1751008081
    },
    {
        "content": "<p>ArXiv list for <a href=\"https://arxiv.org/search/math?searchtype=author&amp;query=G%C3%B3mez-Serrano,+J\">Gómez-Serrano, J</a></p>",
        "id": 526042449,
        "sender_full_name": "Eric Taucher",
        "timestamp": 1751015327
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"631691\">Thomas Zhu</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/DeepMind.20and.20Navier.20Stokes/near/525999705\">said</a>:</p>\n<blockquote>\n<p>No, the article does not mention neural theorem provers</p>\n</blockquote>\n<p><code>neural theorem provers</code> is a real term, was not sure myself so checked.</p>\n<p>Deciding What Game to Play, What Mathematics Problem to Solve By <a href=\"https://www.carmin.tv/en/speakers/katie-collins\">Katie Collins</a> (May 2025) (<a href=\"https://www.carmin.tv/en/collections/mathematics-for-an-by-large-language-models-2025-edition/video/deciding-what-game-to-play-what-mathematics-problem-to-solve\">Video Lecture</a>)</p>\n<p>The intro page shows the paper:</p>\n<p>HyperTree Proof Search for Neural Theorem Proving (<a href=\"https://arxiv.org/pdf/2205.11491\">pdf</a>)</p>\n<p>That paper references a paper with one of the authors being <span class=\"user-mention\" data-user-id=\"115715\">@Jason Rute</span>  </p>\n<p>Proof Artifact Co-Training For Theorem Proving With Language Models (<a href=\"https://arxiv.org/pdf/2102.06203\">pdf</a>)</p>\n<blockquote>\n<p>We instrument Lean with a neural theorem prover driven by a Transformer language model and show that PACT improves theorem proving success rate on a held-out suite of test theorems from 32% to 48%.</p>\n</blockquote>",
        "id": 526052102,
        "sender_full_name": "Eric Taucher",
        "timestamp": 1751019005
    },
    {
        "content": "<p>Gowers also gave a talk in this conference (<a href=\"https://www.carmin.tv/en/collections/mathematics-for-an-by-large-language-models-2025-edition\">Mathematics for an by Large Language Models – 2025 Edition</a>) at IHES</p>",
        "id": 526053318,
        "sender_full_name": "Junyan Xu",
        "timestamp": 1751019476
    },
    {
        "content": "<p>My impression from the first article is that the idea is to use something like AlphaEvolve to find initial conditions which empirically seem to blow up in simulations and then probably use those as data to understand the problem well enough to give a rigorous proof.  They say that this mathematician did something like this (using his own custom problem-specific machine learning tool) for Euler’s equations, but only after someone else already showed they blow up.</p>",
        "id": 526062928,
        "sender_full_name": "Jason Rute",
        "timestamp": 1751023307
    },
    {
        "content": "<p>Also, if people aren’t aware, Terence Tao (about a decade ago) proposed a different approach to showing NS blows up. The idea is to construct a self replicating machine (von Neumann machine) out of ideal fluid. That machine would make a smaller copy of itself and then transfer all its energy into that copy.  Doing this recursively it would lead to a singularity.  While I don’t know if anyone has followed up on that approach, if they did, Lean might be quite useful in bookkeeping all the components of this machine and keeping track of the error bounds.</p>",
        "id": 526064603,
        "sender_full_name": "Jason Rute",
        "timestamp": 1751024005
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"115715\">Jason Rute</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/DeepMind.20and.20Navier.20Stokes/near/526064603\">said</a>:</p>\n<blockquote>\n<p>Terence Tao (about a decade ago) proposed a different approach to showing NS blows up.</p>\n</blockquote>\n<p><a href=\"https://arxiv.org/pdf/1402.0290\">https://arxiv.org/pdf/1402.0290</a></p>\n<p><a href=\"https://www.quantamagazine.org/a-fluid-new-path-in-grand-math-challenge-20140224/\">https://www.quantamagazine.org/a-fluid-new-path-in-grand-math-challenge-20140224/</a></p>\n<p><a href=\"https://gilkalai.wordpress.com/2014/02/07/navier-stokes-fluid-computers/\">https://gilkalai.wordpress.com/2014/02/07/navier-stokes-fluid-computers/</a></p>\n<p><a href=\"https://terrytao.wordpress.com/2014/02/04/finite-time-blowup-for-an-averaged-three-dimensional-navier-stokes-equation/\">https://terrytao.wordpress.com/2014/02/04/finite-time-blowup-for-an-averaged-three-dimensional-navier-stokes-equation/</a></p>",
        "id": 526081397,
        "sender_full_name": "Eric Taucher",
        "timestamp": 1751030186
    },
    {
        "content": "<p>And <a href=\"https://m.youtube.com/watch?v=uGVMrFf_V0I\">https://m.youtube.com/watch?v=uGVMrFf_V0I</a></p>\n<div class=\"youtube-video message_inline_image\"><a data-id=\"uGVMrFf_V0I\" href=\"https://m.youtube.com/watch?v=uGVMrFf_V0I\"><img src=\"https://uploads.zulipusercontent.net/d0257b580e617ece03aae22995fc4dbc615a2f4c/68747470733a2f2f692e7974696d672e636f6d2f76692f7547564d7246665f5630492f6d7164656661756c742e6a7067\"></a></div>",
        "id": 526081791,
        "sender_full_name": "Jason Rute",
        "timestamp": 1751030320
    },
    {
        "content": "<p>They just posted <a href=\"https://deepmind.google/discover/blog/discovering-new-solutions-to-century-old-problems-in-fluid-dynamics/\">https://deepmind.google/discover/blog/discovering-new-solutions-to-century-old-problems-in-fluid-dynamics/</a></p>",
        "id": 540329034,
        "sender_full_name": "Junyan Xu",
        "timestamp": 1758233117
    },
    {
        "content": "<p>Direct link to arXiv paper: <a href=\"https://arxiv.org/abs/2509.14185\">https://arxiv.org/abs/2509.14185</a> <br>\nI thought the formatting was weird when I saw this earlier. I noticed at least one author with a <a href=\"http://google.com\">google.com</a> email address, but it didn't click it was DeepMind.</p>",
        "id": 540350324,
        "sender_full_name": "David Michael Roberts",
        "timestamp": 1758239938
    },
    {
        "content": "<p>There is certainly some language that feels very much \"not mathematician-speak\" in it, like \"unstable singularities are exceptionally elusive; they require initial conditions tuned with infinite precision\" Here's the abstract:</p>\n<blockquote>\n<p>Whether singularities can form in  fluids remains a foundational unanswered question in mathematics. This  phenomenon occurs when solutions to governing equations, such as the 3D  Euler equations, develop infinite gradients from smooth initial  conditions. Historically, numerical approaches have primarily identified  stable singularities. However, these are not expected to exist for key  open problems, such as the boundary-free Euler and Navier-Stokes cases,  where unstable singularities are hypothesized to play a crucial role.  Here, we present the first systematic discovery of new families of unstable singularities. A stable singularity is a robust outcome,  forming even if the initial state is slightly perturbed. In contrast,  unstable singularities are exceptionally elusive; they require initial conditions tuned with infinite precision, being in a state of  instability whereby infinitesimal perturbations immediately divert the  solution from its blow-up trajectory. In particular, we present multiple new, unstable self-similar solutions for the incompressible porous  media equation and the 3D Euler equation with boundary, revealing a  simple empirical asymptotic formula relating the blow-up rate to the  order of instability. Our approach combines curated machine learning architectures and training schemes with a high-precision Gauss-Newton  optimizer, achieving accuracies that significantly surpass previous work across all discovered solutions. For specific solutions, we reach near double-float machine precision, attaining a level of accuracy  constrained only by the round-off errors of the GPU hardware. This level  of precision meets the requirements for rigorous mathematical  validation via computer-assisted proofs. This work provides a new playbook for exploring the complex landscape of nonlinear partial differential equations (PDEs) and tackling long-standing challenges in mathematical physics.</p>\n</blockquote>\n<p>The self-similarity of the solutions as mentioned in this makes me suspect something closer to what Tao was thinking of, as noted in an earlier comment in the thread.</p>",
        "id": 540350583,
        "sender_full_name": "David Michael Roberts",
        "timestamp": 1758240110
    },
    {
        "content": "<p>That exceptionally elusive line made sense to me, especially in the context of numerical simulations and experimental mathematics.</p>",
        "id": 540382975,
        "sender_full_name": "Jason Rute",
        "timestamp": 1758263991
    },
    {
        "content": "<p>(Not that I’ve read the paper or know much about fluid differential equations.)</p>",
        "id": 540383037,
        "sender_full_name": "Jason Rute",
        "timestamp": 1758264022
    },
    {
        "content": "<p>The paper feels like it was written for people interested in the ML aspects of automated discovery and computer verification - which is entirely reasonable, coming from GDM. I hope (expect?) there will be a follow-up paper focusing on the solutions and the topology/configuration of the actual instabilities themselves.</p>",
        "id": 540472365,
        "sender_full_name": "Alex Meiburg",
        "timestamp": 1758292740
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"366057\">Eric Taucher</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/DeepMind.20and.20Navier.20Stokes/near/526024226\">said</a>:</p>\n<blockquote>\n<p>The lecture notes the use of </p>\n<ul>\n<li><a href=\"https://deepmind.google/discover/blog/alphaevolve-a-gemini-powered-coding-agent-for-designing-advanced-algorithms/\">AlphaEvolve</a></li>\n<li>Physics-Informed Neural Networks (PINN) (<a href=\"https://faculty.sites.iastate.edu/hliu/files/inline-files/PINN_RPK_2019_1.pdf\">pdf</a>)</li>\n</ul>\n<p>Deep Learning Poised to ‘Blow Up’ Famed Fluid Equations (April 2022) (<a href=\"https://www.quantamagazine.org/deep-learning-poised-to-blow-up-famed-fluid-equations-20220412/\">Quanta Magazine</a>)</p>\n</blockquote>\n<p><a href=\"/user_uploads/3121/a2LU0GKXjfhBksIgN34LuVSn/image.png\">image.png</a></p>\n<div class=\"message_inline_image\"><a href=\"/user_uploads/3121/a2LU0GKXjfhBksIgN34LuVSn/image.png\" title=\"image.png\"><img data-original-content-type=\"image/png\" data-original-dimensions=\"852x697\" src=\"/user_uploads/thumbnail/3121/a2LU0GKXjfhBksIgN34LuVSn/image.png/840x560.webp\"></a></div><p>The paper said \"We use small neural networks with thousands to tens of thousands of parameters\"</p>\n<p>\"This (nearly) fully automated scheme, implemented using the open-source library kfac-jax56, allows us to rapidly iterate on modeling choices without expensive hyperparameter sweeps. In Figure 4 we demonstrate the efficacy of this optimizer, which is able to discover solutions with maximum residuals of O(10−8 ) within 50k iterations (≈ 3 A100 GPU hours), compared to standard optimization techniques.\"</p>\n<p>this is something i haven't seen too often.  Quite a step change improvement:</p>\n<p><a href=\"/user_uploads/3121/HD3kP76SfOpkasyWHjpZ0kMf/image.png\">image.png</a></p>\n<div class=\"message_inline_image\"><a href=\"/user_uploads/3121/HD3kP76SfOpkasyWHjpZ0kMf/image.png\" title=\"image.png\"><img data-original-content-type=\"image/png\" data-original-dimensions=\"810x277\" src=\"/user_uploads/thumbnail/3121/HD3kP76SfOpkasyWHjpZ0kMf/image.png/840x560.webp\"></a></div><p>They cite this for the Gauss-Newton choice: <a href=\"https://arxiv.org/pdf/2402.10680\">https://arxiv.org/pdf/2402.10680</a></p>",
        "id": 541123575,
        "sender_full_name": "Deleted User 968128",
        "timestamp": 1758674245
    }
]