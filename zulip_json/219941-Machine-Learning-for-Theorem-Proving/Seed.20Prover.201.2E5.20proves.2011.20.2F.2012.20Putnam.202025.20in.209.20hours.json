[
    {
        "content": "<p>Link to announcement: <a class=\"stream-topic\" data-stream-id=\"113486\" href=\"/#narrow/channel/113486-announce/topic/Seed.20Prover.201.2E5.20proves.2011.20.2F.2012.20Putnam.202025.20in.209.20hours/with/564627635\">#announce &gt; Seed Prover 1.5 proves 11 / 12 Putnam 2025 in 9 hours</a></p>",
        "id": 564628322,
        "sender_full_name": "Zeyu Zheng",
        "timestamp": 1766126519
    },
    {
        "content": "<p><a href=\"/user_uploads/3121/t3jb5Hg2Re7f7lk7ll4m0gNs/Screenshot-from-2025-12-19-09-37-16.png\">Screenshot from 2025-12-19 09-37-16.png</a></p>\n<div class=\"message_inline_image\"><a href=\"/user_uploads/3121/t3jb5Hg2Re7f7lk7ll4m0gNs/Screenshot-from-2025-12-19-09-37-16.png\" title=\"Screenshot from 2025-12-19 09-37-16.png\"><img data-original-content-type=\"image/png\" data-original-dimensions=\"1292x266\" src=\"/user_uploads/thumbnail/3121/t3jb5Hg2Re7f7lk7ll4m0gNs/Screenshot-from-2025-12-19-09-37-16.png/840x560.webp\"></a></div><p>The last sentence in this quote (from p9) is a reminder to the mathematicians in this community here that there is still plenty of work to do. I think that we are just about at the point where I can state the main result of my PhD thesis using only things in mathlib but we're still a long way from being able to state the main intermediate results involved in the proof, and this thesis was written 30 years ago; things will only have gotten worse since then.</p>",
        "id": 564654274,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1766137265
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"890706\">@Zeyu Zheng</span> I did not find the model on Hugging Face. Do you provide it somewhere else ?</p>",
        "id": 564704864,
        "sender_full_name": "Bas Spitters",
        "timestamp": 1766153554
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"259452\">Bas Spitters</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Seed.20Prover.201.2E5.20proves.2011.20.2F.2012.20Putnam.202025.20in.209.20hours/near/564704864\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"890706\">Zeyu Zheng</span> I did not find the model on Hugging Face. Do you provide it somewhere else ?</p>\n</blockquote>\n<p>This is not an open sourced model</p>",
        "id": 564721019,
        "sender_full_name": "Zheng Yuan",
        "timestamp": 1766157800
    },
    {
        "content": "<p>Some general observations / questions prompted by this report:</p>",
        "id": 564725827,
        "sender_full_name": "Joseph Myers",
        "timestamp": 1766159093
    },
    {
        "content": "<p>At the current level of AI results on PutnamBench, I wonder whether AIs <em>failing</em> to solve a particular problem is a signal that there might well be a misformalization of that problem making it harder or impossible to solve. I don't know if there's public information on which PutnamBench problems have not been solved by any AI (or more generally, on which problems were solved by which AIs), but have the PutnamBench maintainers used information on the problems not solved by AIs to search for misformalized statements there?</p>",
        "id": 564726222,
        "sender_full_name": "Joseph Myers",
        "timestamp": 1766159208
    },
    {
        "content": "<p>Taking 16.5 hours to solve IMO 2025 P1 certainly suggests <em>something</em> about the difficulty of some kinds of combinatorics problems in Lean, whether in general or specifically for AIs. I'm not sure exactly what the lessons are to take there (and in particular, whether there are things to do better in Lean and mathlib to make such formalizations easier), but it does seem that combinatorics is a key area of difficulty for AIs on competition-type problems at present. (Though I note that three of the five IMO 2025 problems for which a solution is reported in this report have a time to solve greater than the 4.5 hours available each day to a human contestant for all three of that paper's problems.)</p>\n<p>Similarly, CombiBench results are given with a note \"However, we discovered significant formalization issues within this dataset. We list the performance here for reference.\". It's true that early CombiBench versions had major issues, as discussed here on Zulip, and the report doesn't seem to say which CombiBench commit was used. Were the significant issues found reported to the CombiBench maintainers and have they now been fixed, or are they in addition to the many issues that were fixed fairly early? Given current strengths and weaknesses of AIs in solving competition problems, we could do with good ways to assess their abilities in combinatorics, whether or not CombiBench itself is useful as such a benchmark.</p>",
        "id": 564728027,
        "sender_full_name": "Joseph Myers",
        "timestamp": 1766159720
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"890706\">@Zeyu Zheng</span>  Can you provide more info on how the system utilized \"Python as a tool\"?</p>\n<ul>\n<li>What type of problems did the system use it for?</li>\n<li>What subproblems did the system use it for?</li>\n<li>How was the Python tool presented/described to the system?</li>\n<li>...</li>\n</ul>\n<p>The article didn't provide much detail on this topic.</p>",
        "id": 564730184,
        "sender_full_name": "Kelly Davis",
        "timestamp": 1766160271
    },
    {
        "content": "<p>The stated IMO 2025 results say \"(P2 is solved by Seed-Geometry)\", which I understand as meaning it's not actually a Lean solution at all and not directly comparable with anything solving in Lean.</p>\n<p>Now, it's perfectly reasonable in principle for an AI to call out to tools where helpful, whether those tools are Lean, Python, a SAT solver, a computer algebra system or a geometry solver. But to be relevant to Lean solving, a geometry solver should only be used as part of generating a Lean solution to the whole problem, stated in Lean using mathlib definitions and with the AI responsible for doing all translations to and from the format needed by the geometry solver.</p>\n<p>And in modern AI, general (scalable) methods are expected to work better in the long run than special-casing things based on detailed human knowledge of a given kind of problem (the \"bitter lesson\"). So given an AI goal of contributing usefully to mathematics in general, I think the natural challenge for elementary Euclidean geometry is to get general methods to the point where they can tackle such problems without needing a custom geometry solver (unless the AI notices for itself the use of such a solver and also writes the solver itself without human intervention) - not because such a solver is bad, but because there are very many niche areas of mathematics that might sometimes benefit from custom solvers but where AI can't reasonably always expect solvers to be available (unless it writes them itself as needed) or to have huge amounts of training material on how to use them if they are available.</p>\n<p>I.e., rather than thinking of Euclidean geometry as \"this is outside the modern mathematical mainstream, deal with the competition problems as a special case\", think of it as one of many examples of a niche mathematical area with little formal material available (but much more informal material available for training), where the ability to tackle such problems by general methods should be equally applicable to other niche areas of mathematics. Of course this means not just the AIs attempting to solve the problems in Lean by general methods - it means the AIs looking for more generally applicable lemmas and doing their own PRs of those to mathlib in mathlib-suitable form, just as is needed in any area of mathematics where you can expect that a nontrivial formalization will show up lots of missing lemmas in mathlib.</p>",
        "id": 564730901,
        "sender_full_name": "Joseph Myers",
        "timestamp": 1766160456
    },
    {
        "content": "<p>Oh yeah -- writing something that can translate these geometry tool proofs into Lean would be awesome! There is always a mismatch in my talks when AlphaProof says things like \"we solved 4/6 problems on the 2024 IMO\" and I say \"AlphaProof solved 3/6 problems on the 2024 IMO in Lean\" and it's because of the AlphaGeometry proof, but thanks to Joseph's sterling efforts we are now pretty much at the point where Lean can understand statements and proofs of many IMO geometry problems, so why not make such a system?</p>",
        "id": 564732362,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1766160850
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110038\">Kevin Buzzard</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Seed.20Prover.201.2E5.20proves.2011.20.2F.2012.20Putnam.202025.20in.209.20hours/near/564732362\">said</a>:</p>\n<blockquote>\n<p>Oh yeah -- writing something that can translate these geometry tool proofs into Lean would be awesome! There is always a mismatch in my talks when AlphaProof says things like \"we solved 4/6 problems on the 2024 IMO\" and I say \"AlphaProof solved 3/6 problems on the 2024 IMO in Lean\" and it's because of the AlphaGeometry proof, but thanks to Joseph's sterling efforts we are now pretty much at the point where Lean can understand statements and proofs of many IMO geometry problems, so why not make such a system?</p>\n</blockquote>\n<p>I think the problem is, although the proof given by AlphaGeometry is rigorous in some sense, it's certainly not a very concrete proof that you can formalize in Mathlib. To be more precise, the proof of AlphaGeometry actually gives the result \"if the geometric relationship of the points (e.g. A, B are on the same side of line CD) is the same as the internally generated graph (which is numerically computed), then the result holds\". But proofs generated by these formal systems don't really address the problem of geometric relationship, despite the fact that their deductions (e.g. angle chasing) might be highly reliant on the specific geometric relationships.</p>",
        "id": 564735298,
        "sender_full_name": "Wang Jingting",
        "timestamp": 1766161668
    },
    {
        "content": "<p>I don't think proving \"same side\" and \"same sign\" properties should be any harder for an AI than any of the other gaps you have to fill in when going from an informal proof to a formal one. (You could no doubt write a custom solver that attempts to do so - or a custom Lean tactic. But a reasonable challenge for AIs is to do as much as possible <em>without</em> hardcoding custom solvers for particular parts of mathematics, just using general methods that could apply elsewhere in mathematics, indeed without needing a custom geometry solver at all.)</p>",
        "id": 564749723,
        "sender_full_name": "Joseph Myers",
        "timestamp": 1766166633
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"266253\">Joseph Myers</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Seed.20Prover.201.2E5.20proves.2011.20.2F.2012.20Putnam.202025.20in.209.20hours/near/564726222\">said</a>:</p>\n<blockquote>\n<p>At the current level of AI results on PutnamBench, I wonder whether AIs <em>failing</em> to solve a particular problem is a signal that there might well be a misformalization of that problem making it harder or impossible to solve. I don't know if there's public information on which PutnamBench problems have not been solved by any AI (or more generally, on which problems were solved by which AIs), but have the PutnamBench maintainers used information on the problems not solved by AIs to search for misformalized statements there?</p>\n</blockquote>\n<p>We have an autoformalizer judger using LLM which states some misformalized in Putnam and combibench (both latest commit). But this is a model judger, we don’t use many human efforts to double check it. For combi problem, I think the model are not familiar with them enough since creating many high-quality combi training data is really hard, it’s easy to misformalize the problem. Also I think there is some api issues for combi question in mathlib.</p>",
        "id": 564785374,
        "sender_full_name": "Zheng Yuan",
        "timestamp": 1766184653
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"900292\">Kelly Davis</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Seed.20Prover.201.2E5.20proves.2011.20.2F.2012.20Putnam.202025.20in.209.20hours/near/564730184\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"890706\">Zeyu Zheng</span>  Can you provide more info on how the system utilized \"Python as a tool\"?</p>\n<ul>\n<li>What type of problems did the system use it for?</li>\n<li>What subproblems did the system use it for?</li>\n<li>How was the Python tool presented/described to the system?</li>\n<li>...</li>\n</ul>\n<p>The article didn't provide much detail on this topic.</p>\n</blockquote>\n<p>I think the system using Python not too much, it mainly use it to ensure some correctness of calculations. Python tool is described as a simply function which you input a python code and the tool response is the final print result.</p>",
        "id": 564785542,
        "sender_full_name": "Zheng Yuan",
        "timestamp": 1766184787
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"686407\">Zheng Yuan</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Seed.20Prover.201.2E5.20proves.2011.20.2F.2012.20Putnam.202025.20in.209.20hours/near/564785542\">said</a>:</p>\n<blockquote>\n<p>I think the system using Python not too much, it mainly use it to ensure some correctness of calculations. Python tool is described as a simply function which you input a python code and the tool response is the final print result.</p>\n</blockquote>\n<p>Thanks for the response. However, it still leaves me with a few questions:</p>\n<ul>\n<li>Lean 4 ensures correctness of calculations. So I'm not sure exactly what you mean when you say it is mainly used \"to ensure some correctness of calculations\".</li>\n<li>Generally, in what type of calculations is it used? (For example, is it used for geometry questions, combinatoric questions....)</li>\n<li>Can you give a bit more detail beyond the tool being described as \"simply function which you input a python code and the tool response is the final print result\". Traditionally such tools are described to the system by a prompt indicating to the system how the tool is to be called, the parameters it takes, what it returns... something like</li>\n</ul>\n<div class=\"codehilite\" data-code-language=\"Markdown\"><pre><span></span><code><span class=\"gu\">## Tools Available</span>\n\n<span class=\"gu\">### movie_showtime_db(movie_name, date, time_preference, theater_location)</span>\nSearch for available movie showtimes at theaters.\n\n<span class=\"gs\">**How to call it:**</span>\n``python\n<span class=\"gh\"># Basic - just movie name (required)</span>\nmovie_showtime_db(\"Interstellar\")\n\n<span class=\"gh\"># With date filter</span>\nmovie_showtime_db(\"Interstellar\", date=\"2025-10-15\")\n\n<span class=\"gh\"># With time preference</span>\nmovie_showtime_db(\"Interstellar\", time_preference=\"evening\")\n\n<span class=\"gh\"># With theater location</span>\nmovie_showtime_db(\"Interstellar\", theater_location=\"downtown\")\n\n<span class=\"gh\"># With multiple filters</span>\nmovie_showtime_db(\"Interstellar\", date=\"2025-10-15\", time_preference=\"evening\")\n``\n\n<span class=\"gs\">**Parameters:**</span>\n<span class=\"k\">-</span><span class=\"w\"> </span><span class=\"sb\">`movie_name`</span> (required): Name of the movie (case-insensitive)\n<span class=\"k\">-</span><span class=\"w\"> </span><span class=\"sb\">`date`</span> (optional): Specific date in YYYY-MM-DD format\n<span class=\"k\">-</span><span class=\"w\"> </span><span class=\"sb\">`time_preference`</span> (optional): \"morning\", \"afternoon\", \"evening\", or \"late\"\n<span class=\"k\">-</span><span class=\"w\"> </span><span class=\"sb\">`theater_location`</span> (optional): Theater area like \"downtown\", \"mall\", \"northside\"\n\n<span class=\"gs\">**Returns:**</span> List of showtimes with theater info, times, dates, available seats, and pricing.\n...\n</code></pre></div>\n<p>As you can see, the description in the prompt of a tool can give strong priors to the system as to how the tool can/should be used.</p>\n<p>So in the case of Seed Prover 1.5 such a prompt could be used to steer the system to use Python for, say, combinatoric questions, geometric questions... Thus, my curiosity on how the Python tool was presented/described to the system.</p>",
        "id": 564807914,
        "sender_full_name": "Kelly Davis",
        "timestamp": 1766213477
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"900292\">Kelly Davis</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Seed.20Prover.201.2E5.20proves.2011.20.2F.2012.20Putnam.202025.20in.209.20hours/near/564807914\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"686407\">Zheng Yuan</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Seed.20Prover.201.2E5.20proves.2011.20.2F.2012.20Putnam.202025.20in.209.20hours/near/564785542\">said</a>:</p>\n<blockquote>\n<p>I think the system using Python not too much, it mainly use it to ensure some correctness of calculations. Python tool is described as a simply function which you input a python code and the tool response is the final print result.</p>\n</blockquote>\n<p>Thanks for the response. However, it still leaves me with a few questions:</p>\n<ul>\n<li>Lean 4 ensures correctness of calculations. So I'm not sure exactly what you mean when you say it is mainly used \"to ensure some correctness of calculations\".</li>\n<li>Generally, in what type of calculations is it used? (For example, is it used for geometry questions, combinatoric questions....)</li>\n<li>Can you give a bit more detail beyond the tool being described as \"simply function which you input a python code and the tool response is the final print result\". Traditionally such tools are described to the system by a prompt indicating to the system how the tool is to be called, the parameters it takes, what it returns... something like</li>\n</ul>\n<div class=\"codehilite\" data-code-language=\"Markdown\"><pre><span></span><code><span class=\"gu\">## Tools Available</span>\n\n<span class=\"gu\">### movie_showtime_db(movie_name, date, time_preference, theater_location)</span>\nSearch for available movie showtimes at theaters.\n\n<span class=\"gs\">**How to call it:**</span>\n``python\n<span class=\"gh\"># Basic - just movie name (required)</span>\nmovie_showtime_db(\"Interstellar\")\n\n<span class=\"gh\"># With date filter</span>\nmovie_showtime_db(\"Interstellar\", date=\"2025-10-15\")\n\n<span class=\"gh\"># With time preference</span>\nmovie_showtime_db(\"Interstellar\", time_preference=\"evening\")\n\n<span class=\"gh\"># With theater location</span>\nmovie_showtime_db(\"Interstellar\", theater_location=\"downtown\")\n\n<span class=\"gh\"># With multiple filters</span>\nmovie_showtime_db(\"Interstellar\", date=\"2025-10-15\", time_preference=\"evening\")\n``\n\n<span class=\"gs\">**Parameters:**</span>\n<span class=\"k\">-</span><span class=\"w\"> </span><span class=\"sb\">`movie_name`</span> (required): Name of the movie (case-insensitive)\n<span class=\"k\">-</span><span class=\"w\"> </span><span class=\"sb\">`date`</span> (optional): Specific date in YYYY-MM-DD format\n<span class=\"k\">-</span><span class=\"w\"> </span><span class=\"sb\">`time_preference`</span> (optional): \"morning\", \"afternoon\", \"evening\", or \"late\"\n<span class=\"k\">-</span><span class=\"w\"> </span><span class=\"sb\">`theater_location`</span> (optional): Theater area like \"downtown\", \"mall\", \"northside\"\n\n<span class=\"gs\">**Returns:**</span> List of showtimes with theater info, times, dates, available seats, and pricing.\n...\n</code></pre></div>\n<p>As you can see, the description in the prompt of a tool can give strong priors to the system as to how the tool can/should be used.</p>\n<p>So in the case of Seed Prover 1.5 such a prompt could be used to steer the system to use Python for, say, combinatoric questions, geometric questions... Thus, my curiosity on how the Python tool was presented/described to the system.</p>\n</blockquote>\n<p>The system is prompted to use python like sympy, numpy, … and some other python calculations tools</p>",
        "id": 564812232,
        "sender_full_name": "Zheng Yuan",
        "timestamp": 1766218728
    },
    {
        "content": "<p>My guess would be to perform some basic (for humans) mathematical calculations or solving systems of equations, similar to what students would write on scratch paper during the Putnam. For example, I definitely wouldn't trust my LLM to solve a system of linear equations and would rather offload that to NumPy or SymPy.</p>",
        "id": 564911524,
        "sender_full_name": "Gavin Zhao",
        "timestamp": 1766345794
    },
    {
        "content": "<p>By calculations I meant numerical calculations.</p>",
        "id": 564911551,
        "sender_full_name": "Gavin Zhao",
        "timestamp": 1766345821
    },
    {
        "content": "<p>Or even doing integration. Since tools like Symbolab already exist that can integrate or differentiate deterministically and mechanically, I think it is quite reasonable to offload those parts to an external system or use them as an external checker to prevent hallucinations when doing complex calculations.</p>",
        "id": 564911775,
        "sender_full_name": "Gavin Zhao",
        "timestamp": 1766346005
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"766285\">@Gavin Zhao</span> I agree with all your speculations. I hold the exact same views. </p>\n<p>However, I wanted detailed confirmation from the paper's authors, e.g. the prompt or section of the prompt describing the Python tool to the system. This level of detail is lacking in the paper.</p>",
        "id": 564939034,
        "sender_full_name": "Kelly Davis",
        "timestamp": 1766382664
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"900292\">Kelly Davis</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Seed.20Prover.201.2E5.20proves.2011.20.2F.2012.20Putnam.202025.20in.209.20hours/near/564939034\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"766285\">Gavin Zhao</span> I agree with all your speculations. I hold the exact same views. </p>\n<p>However, I wanted detailed confirmation from the paper's authors, e.g. the prompt or section of the prompt describing the Python tool to the system. This level of detail is lacking in the paper.</p>\n</blockquote>\n<p>{\"type\": \"function\", \"name\": \"run_python\", \"description\": \"Executes Python code in a Jupyter notebook cell. All variables defined in previous executions are preserved and accessible in subsequent executions. This allows you to build on previous calculations and define functions that can be used later.\"}</p>",
        "id": 564940953,
        "sender_full_name": "Zheng Yuan",
        "timestamp": 1766384226
    },
    {
        "content": "<p>Congrats! Are there any plans to allow outside access to these math-proof models in the next year?</p>",
        "id": 564991383,
        "sender_full_name": "Andy Jiang",
        "timestamp": 1766405661
    },
    {
        "content": "<p>I'm interested in knowing, \"a long way\" is about how long in terms of time? And has recent AI progress look promising to reduce that time significantly?</p>",
        "id": 565347756,
        "sender_full_name": "Xiyu Zhai",
        "timestamp": 1766646827
    }
]