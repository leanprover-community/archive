[
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"938385\">Yong Lin</span> <a href=\"#narrow/channel/113486-announce/topic/Goedel-Prover-V2.3A.20A.20new.20SOTA.20model.20for.20theorem.20proving/near/529049919\">said</a>:</p>\n<blockquote>\n<p>The Goedel team is happy to annouce our open sourced SOTA model Goedel-Prover-V2.</p>\n<p>Our flagship model, Goedel-Prover-V2-32B, achieves the new SOTA...</p>\n</blockquote>\n<p>All in 32B! Impressive! <span aria-label=\"clap\" class=\"emoji emoji-1f44f\" role=\"img\" title=\"clap\">:clap:</span></p>\n<p>Are there plans for an arXiv paper?</p>",
        "id": 529053214,
        "sender_full_name": "Kelly Davis",
        "timestamp": 1752670478
    },
    {
        "content": "<p><a href=\"#narrow/channel/113488-general/topic/Discussion.3A.20Goedel-Prover-V2.3A.20A.20new.20SOTA.20model/near/529053214\">A message</a> was moved here from <a class=\"stream-topic\" data-stream-id=\"113486\" href=\"/#narrow/channel/113486-announce/topic/Goedel-Prover-V2.3A.20A.20new.20SOTA.20model.20for.20theorem.20proving/with/529049919\">#announce &gt; Goedel-Prover-V2: A new SOTA model for theorem proving</a> by <span class=\"user-mention silent\" data-user-id=\"306577\">Matthew Ballard</span>.</p>",
        "id": 529054234,
        "sender_full_name": "Notification Bot",
        "timestamp": 1752670759
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"900292\">Kelly Davis</span> <a href=\"#narrow/channel/113486-announce/topic/Goedel-Prover-V2.3A.20A.20new.20SOTA.20model.20for.20theorem.20proving/near/529053214\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"938385\">Yong Lin</span> <a href=\"#narrow/channel/113486-announce/topic/Goedel-Prover-V2.3A.20A.20new.20SOTA.20model.20for.20theorem.20proving/near/529049919\">said</a>:</p>\n<blockquote>\n<p>The Goedel team is happy to annouce our open sourced SOTA model Goedel-Prover-V2.</p>\n<p>Our flagship model, Goedel-Prover-V2-32B, achieves the new SOTA...</p>\n</blockquote>\n<p>All in 32B! Impressive! <span aria-label=\"clap\" class=\"emoji emoji-1f44f\" role=\"img\" title=\"clap\">:clap:</span></p>\n<p>Are there plans for an arXiv paper?</p>\n</blockquote>\n<p>Arxiv paper is coming in 2-3 weeks.</p>",
        "id": 529054245,
        "sender_full_name": "Yong Lin",
        "timestamp": 1752670762
    },
    {
        "content": "<p><a href=\"#narrow/channel/113488-general/topic/Discussion.3A.20Goedel-Prover-V2.3A.20A.20new.20SOTA.20model/near/529054245\">A message</a> was moved here from <a class=\"stream-topic\" data-stream-id=\"113486\" href=\"/#narrow/channel/113486-announce/topic/Goedel-Prover-V2.3A.20A.20new.20SOTA.20model.20for.20theorem.20proving/with/529054236\">#announce &gt; Goedel-Prover-V2: A new SOTA model for theorem proving</a> by <span class=\"user-mention silent\" data-user-id=\"306577\">Matthew Ballard</span>.</p>",
        "id": 529054412,
        "sender_full_name": "Notification Bot",
        "timestamp": 1752670805
    },
    {
        "content": "<p>Should we move the discussion to <a class=\"stream\" data-stream-id=\"219941\" href=\"/#narrow/channel/219941-Machine-Learning-for-Theorem-Proving\">#Machine Learning for Theorem Proving</a> ?</p>",
        "id": 529060792,
        "sender_full_name": "Kaiyu Yang",
        "timestamp": 1752672665
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"584504\">Kaiyu Yang</span> <a href=\"#narrow/channel/113488-general/topic/Discussion.3A.20Goedel-Prover-V2.3A.20A.20new.20SOTA.20model/near/529060792\">said</a>:</p>\n<blockquote>\n<p>Should we move the discussion to <a class=\"stream\" data-stream-id=\"219941\" href=\"/#narrow/channel/219941-Machine-Learning-for-Theorem-Proving\">#Machine Learning for Theorem Proving</a> ?</p>\n</blockquote>\n<p>Yes. It seems a more appropriate home.</p>",
        "id": 529062235,
        "sender_full_name": "Kelly Davis",
        "timestamp": 1752673052
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"306577\">@Matthew Ballard</span>  Could you please help us move the discussion? Thanks!</p>",
        "id": 529071963,
        "sender_full_name": "Kaiyu Yang",
        "timestamp": 1752675810
    },
    {
        "content": "<p>This topic was moved here from <a class=\"stream-topic\" data-stream-id=\"113488\" href=\"/#narrow/channel/113488-general/topic/Discussion.3A.20Goedel-Prover-V2.3A.20A.20new.20SOTA.20model\">#general &gt; Discussion: Goedel-Prover-V2: A new SOTA model</a> by <span class=\"user-mention silent\" data-user-id=\"306577\">Matthew Ballard</span>.</p>",
        "id": 529073829,
        "sender_full_name": "Notification Bot",
        "timestamp": 1752676282
    },
    {
        "content": "<p>question : Does Pass@32 mean you collected the best of 32 attempts for each theorem?</p>",
        "id": 529077534,
        "sender_full_name": "Shreyas Srinivas",
        "timestamp": 1752677283
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"466334\">Shreyas Srinivas</span> <a href=\"#narrow/stream/219941-Machine-Learning-for-Theorem-Proving/topic/Discussion.3A.20Goedel-Prover-V2.3A.20A.20new.20SOTA.20model/near/529077534\">said</a>:</p>\n<blockquote>\n<p>question : Does Pass@32 mean you collected the best of 32 attempts for each theorem?</p>\n</blockquote>\n<p>I think it is more like generating 32 attempts and see if any one of them pass</p>",
        "id": 529087341,
        "sender_full_name": "Anh Nguyễn",
        "timestamp": 1752680062
    },
    {
        "content": "<p>I'm trying to run Goedel-Prover-V2 on my laptop (with no GPU) and I'm always getting the error</p>\n<div class=\"codehilite\" data-code-language=\"Lean4\"><pre><span></span><code><span class=\"n\">SafetensorError</span><span class=\"o\">:</span><span class=\"w\"> </span><span class=\"n\">File</span><span class=\"w\"> </span><span class=\"n\">does</span><span class=\"w\"> </span><span class=\"n\">not</span><span class=\"w\"> </span><span class=\"n\">contain</span><span class=\"w\"> </span><span class=\"n\">tensor</span><span class=\"w\"> </span><span class=\"n\">model</span><span class=\"bp\">.</span><span class=\"n\">layers</span><span class=\"bp\">.</span><span class=\"m\">19</span><span class=\"bp\">.</span><span class=\"n\">input_layernorm</span><span class=\"bp\">.</span><span class=\"n\">weight</span>\n</code></pre></div>\n<p>(or similar). How do I fix this?</p>\n<p>I want to see whether the new model can prove IMO 1997 Q3 (<a href=\"https://github.com/leanprover-community/mathlib4/pull/27159\">#27159</a>), which is not in the training dataset, and if so what the generated output is</p>",
        "id": 529191145,
        "sender_full_name": "Jeremy Tan",
        "timestamp": 1752717935
    },
    {
        "content": "<p>I've tried it on Colab and I get the same error</p>",
        "id": 529191507,
        "sender_full_name": "Jeremy Tan",
        "timestamp": 1752718262
    },
    {
        "content": "<p>This looks very promising! I'm particularly curious about the \"Verifier-Guided Self-Correction\" part and what this means about using this model most effectively. For example, the way I tell Claude Code to write Lean code is:</p>\n<ol>\n<li>Write some Lean code.</li>\n<li>Run the Lean compiler to make sure it compiles.</li>\n<li>If it doesn't compile, read the error message (including context and goal) and come up with a fix. Go back to step 2.</li>\n</ol>\n<p>Is Goedel optimized to be used in a similar way? Or are you just doing this feedback loop in training?</p>",
        "id": 529198274,
        "sender_full_name": "Gavin Zhao",
        "timestamp": 1752724561
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"598052\">Jeremy Tan</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Discussion.3A.20Goedel-Prover-V2.3A.20A.20new.20SOTA.20model/near/529191145\">said</a>:</p>\n<blockquote>\n<p>I'm trying to run Goedel-Prover-V2 on my laptop (with no GPU) and I'm always getting the error</p>\n<div class=\"codehilite\" data-code-language=\"Lean4\"><pre><span></span><code><span class=\"n\">SafetensorError</span><span class=\"o\">:</span><span class=\"w\"> </span><span class=\"n\">File</span><span class=\"w\"> </span><span class=\"n\">does</span><span class=\"w\"> </span><span class=\"n\">not</span><span class=\"w\"> </span><span class=\"n\">contain</span><span class=\"w\"> </span><span class=\"n\">tensor</span><span class=\"w\"> </span><span class=\"n\">model</span><span class=\"bp\">.</span><span class=\"n\">layers</span><span class=\"bp\">.</span><span class=\"m\">19</span><span class=\"bp\">.</span><span class=\"n\">input_layernorm</span><span class=\"bp\">.</span><span class=\"n\">weight</span>\n</code></pre></div>\n<p>(or similar). How do I fix this?</p>\n<p>I want to see whether the new model can prove IMO 1997 Q3 (<a href=\"https://github.com/leanprover-community/mathlib4/pull/27159\">#27159</a>), which is not in the training dataset, and if so what the generated output is</p>\n</blockquote>\n<p>Can you provide the exact steps to reproduce the error (including code and commands you run)?</p>",
        "id": 529391883,
        "sender_full_name": "Kaiyu Yang",
        "timestamp": 1752815827
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"766285\">Gavin Zhao</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Discussion.3A.20Goedel-Prover-V2.3A.20A.20new.20SOTA.20model/near/529198274\">said</a>:</p>\n<blockquote>\n<p>This looks very promising! I'm particularly curious about the \"Verifier-Guided Self-Correction\" part and what this means about using this model most effectively. For example, the way I tell Claude Code to write Lean code is:</p>\n<ol>\n<li>Write some Lean code.</li>\n<li>Run the Lean compiler to make sure it compiles.</li>\n<li>If it doesn't compile, read the error message (including context and goal) and come up with a fix. Go back to step 2.</li>\n</ol>\n<p>Is Goedel optimized to be used in a similar way? Or are you just doing this feedback loop in training?</p>\n</blockquote>\n<p>Something like that at a high level (only in inference). More details will be available in the paper to be released.</p>",
        "id": 529391982,
        "sender_full_name": "Kaiyu Yang",
        "timestamp": 1752815919
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"584504\">Kaiyu Yang</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Discussion.3A.20Goedel-Prover-V2.3A.20A.20new.20SOTA.20model/near/529391883\">said</a>:</p>\n<blockquote>\n<p>Can you provide the exact steps to reproduce the error (including code and commands you run)?</p>\n</blockquote>\n<ol>\n<li><code>mkdir goedel; cd goedel</code> in any convenient location.</li>\n<li><code>python3 -m venv .venv</code> to create the virtual environment, then <code>source .venv/bin/activate</code> to activate it.</li>\n<li><code>python3 -m pip install transformers torch accelerate</code> to install the dependencies</li>\n<li>For now I am just using the sample script <a href=\"https://huggingface.co/Goedel-LM/Goedel-Prover-V2-32B#5-quick-start\">provided on the HuggingFace page</a> as a sanity check. Copy that script and paste it as <code>prover.py</code> in <code>goedel</code>.</li>\n<li>Run the script – it takes quite a while to download the tensors (naturally), and then at the line</li>\n</ol>\n<div class=\"codehilite\" data-code-language=\"Lean4\"><pre><span></span><code><span class=\"n\">outputs</span><span class=\"w\"> </span><span class=\"bp\">=</span><span class=\"w\"> </span><span class=\"n\">model</span><span class=\"bp\">.</span><span class=\"n\">generate</span><span class=\"o\">(</span><span class=\"n\">inputs</span><span class=\"o\">,</span><span class=\"w\"> </span><span class=\"n\">max_new_tokens</span><span class=\"bp\">=</span><span class=\"mi\">32768</span><span class=\"o\">)</span>\n</code></pre></div>\n<p>the error I mentioned is thrown.</p>",
        "id": 529398232,
        "sender_full_name": "Jeremy Tan",
        "timestamp": 1752819919
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"874606\">Anh Nguyễn</span> <a href=\"#narrow/stream/219941-Machine-Learning-for-Theorem-Proving/topic/Discussion.3A.20Goedel-Prover-V2.3A.20A.20new.20SOTA.20model/near/529087341\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"466334\">Shreyas Srinivas</span> <a href=\"#narrow/stream/219941-Machine-Learning-for-Theorem-Proving/topic/Discussion.3A.20Goedel-Prover-V2.3A.20A.20new.20SOTA.20model/near/529077534\">said</a>:</p>\n<blockquote>\n<p>question : Does Pass@32 mean you collected the best of 32 attempts for each theorem?</p>\n</blockquote>\n<p>I think it is more like generating 32 attempts and see if any one of them pass</p>\n</blockquote>\n<p>So in principle it is possible that the model succeeds on problem X in round n and not in round (n + 1), but it would still count as a success in the statistics right?</p>",
        "id": 529438758,
        "sender_full_name": "Shreyas Srinivas",
        "timestamp": 1752836087
    },
    {
        "content": "<p>Are these passes parallel or sequential?</p>",
        "id": 529441505,
        "sender_full_name": "Shreyas Srinivas",
        "timestamp": 1752837132
    },
    {
        "content": "<p>this model sent a shiver down my spine</p>",
        "id": 529461858,
        "sender_full_name": "Ping J",
        "timestamp": 1752844853
    },
    {
        "content": "<p>never felt this way since gpt4</p>",
        "id": 529461899,
        "sender_full_name": "Ping J",
        "timestamp": 1752844867
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"466334\">Shreyas Srinivas</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Discussion.3A.20Goedel-Prover-V2.3A.20A.20new.20SOTA.20model/near/529441505\">said</a>:</p>\n<blockquote>\n<p>Are these passes parallel or sequential?</p>\n</blockquote>\n<p>i guess parallel, where each containing 3 self-correct iterations</p>",
        "id": 529462034,
        "sender_full_name": "Ping J",
        "timestamp": 1752844913
    },
    {
        "content": "<p>Is self-correction the same is Proof repair(the Curry-Howard equivalent of Program repair)?<br>\nE.g. the work by Talia Ringer <a href=\"https://homes.cs.washington.edu/~djg/theses/ringer_dissertation.pdf\">https://homes.cs.washington.edu/~djg/theses/ringer_dissertation.pdf</a></p>",
        "id": 529469266,
        "sender_full_name": "Bas Spitters",
        "timestamp": 1752847417
    },
    {
        "content": "<p>The model doesn't always have an accurate model of how Lean works. When Lean provides the compiler errors the model can then fix the code.</p>",
        "id": 529486145,
        "sender_full_name": "(deleted)",
        "timestamp": 1752853333
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"466334\">Shreyas Srinivas</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Discussion.3A.20Goedel-Prover-V2.3A.20A.20new.20SOTA.20model/near/529077534\">said</a>:</p>\n<blockquote>\n<p>question : Does Pass@32 mean you collected the best of 32 attempts for each theorem?</p>\n</blockquote>\n<p>Pass@32 means that the prover tries 32 times for a theorem, and as long as one is verified by lean then we count it as correct.</p>",
        "id": 529618728,
        "sender_full_name": "Shange Tang",
        "timestamp": 1752968689
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"785507\">Your full name</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Discussion.3A.20Goedel-Prover-V2.3A.20A.20new.20SOTA.20model/near/529462034\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"466334\">Shreyas Srinivas</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Discussion.3A.20Goedel-Prover-V2.3A.20A.20new.20SOTA.20model/near/529441505\">said</a>:</p>\n<blockquote>\n<p>Are these passes parallel or sequential?</p>\n</blockquote>\n<p>i guess parallel, where each containing 3 self-correct iterations</p>\n</blockquote>\n<p>Yes, our model do the passes in parallel. And each pass contains an initial attempt of writing the entire proof + two rounds of self correction given the lean feedback. The process ended when a correct proof is found at any stage (or two rounds of self corrections still fail to find the proof)</p>",
        "id": 529619011,
        "sender_full_name": "Shange Tang",
        "timestamp": 1752969133
    },
    {
        "content": "<p>Hi! Our inference framework supports multiple rounds of modification and allows for multiple corrections for a single error.<br>\nWhen we report \"pass@32 with self-correction,\" it means that we first perform inference 32 times. If none of the outputs are correct, we then apply a single correction to each error individually. If there are still no correct outputs, we continue from the previous attempts and apply another round of corrections. All of this is done within a 40k context length, which means that some errors cannot be sequentially corrected twice.</p>",
        "id": 529620028,
        "sender_full_name": "Bohan Lyu",
        "timestamp": 1752970613
    },
    {
        "content": "<p>What Lean and mathlib version is this trained on?</p>",
        "id": 529873611,
        "sender_full_name": "(deleted)",
        "timestamp": 1753098472
    },
    {
        "content": "<p>I plan to run this model</p>",
        "id": 529873717,
        "sender_full_name": "(deleted)",
        "timestamp": 1753098513
    },
    {
        "content": "<p>i thought this takes the cake until i saw <a href=\"https://deepmind.google/discover/blog/advanced-version-of-gemini-with-deep-think-officially-achieves-gold-medal-standard-at-the-international-mathematical-olympiad/\">https://deepmind.google/discover/blog/advanced-version-of-gemini-with-deep-think-officially-achieves-gold-medal-standard-at-the-international-mathematical-olympiad/</a>     ... i wonder what post-AGI society will be like... i don't want to live on mars....</p>",
        "id": 529932365,
        "sender_full_name": "Ping J",
        "timestamp": 1753118045
    },
    {
        "content": "<p>While a pro-AI person, I don't think speculating about a post-AGI society is very welcome on this Zulip instance</p>",
        "id": 529934501,
        "sender_full_name": "(deleted)",
        "timestamp": 1753118674
    },
    {
        "content": "<p>Especially when it's off topic for this thread</p>",
        "id": 529934611,
        "sender_full_name": "(deleted)",
        "timestamp": 1753118719
    },
    {
        "content": "<p>i just noticed <a href=\"https://www.gemini.com/\">https://www.gemini.com/</a> is not owned by Google lol.   (i know completely off topic but where else can community members chitchat w</p>",
        "id": 529940104,
        "sender_full_name": "Ping J",
        "timestamp": 1753120500
    },
    {
        "content": "<p>Please take chitchat to the Lean Discord <a href=\"https://discord.com/invite/WZ9bs9UCvx\">https://discord.com/invite/WZ9bs9UCvx</a></p>",
        "id": 529946832,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1753122929
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"598052\">Jeremy Tan</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Discussion.3A.20Goedel-Prover-V2.3A.20A.20new.20SOTA.20model/near/529398232\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"584504\">Kaiyu Yang</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Discussion.3A.20Goedel-Prover-V2.3A.20A.20new.20SOTA.20model/near/529391883\">said</a>:</p>\n<blockquote>\n<p>Can you provide the exact steps to reproduce the error (including code and commands you run)?</p>\n</blockquote>\n<ol>\n<li><code>mkdir goedel; cd goedel</code> in any convenient location.</li>\n<li><code>python3 -m venv .venv</code> to create the virtual environment, then <code>source .venv/bin/activate</code> to activate it.</li>\n<li><code>python3 -m pip install transformers torch accelerate</code> to install the dependencies</li>\n<li>For now I am just using the sample script <a href=\"https://huggingface.co/Goedel-LM/Goedel-Prover-V2-32B#5-quick-start\">provided on the HuggingFace page</a> as a sanity check. Copy that script and paste it as <code>prover.py</code> in <code>goedel</code>.</li>\n<li>Run the script – it takes quite a while to download the tensors (naturally), and then at the line</li>\n</ol>\n<div class=\"codehilite\" data-code-language=\"Lean4\"><pre><span></span><code><span class=\"n\">outputs</span><span class=\"w\"> </span><span class=\"bp\">=</span><span class=\"w\"> </span><span class=\"n\">model</span><span class=\"bp\">.</span><span class=\"n\">generate</span><span class=\"o\">(</span><span class=\"n\">inputs</span><span class=\"o\">,</span><span class=\"w\"> </span><span class=\"n\">max_new_tokens</span><span class=\"bp\">=</span><span class=\"mi\">32768</span><span class=\"o\">)</span>\n</code></pre></div>\n<p>the error I mentioned is thrown.</p>\n</blockquote>\n<p><span class=\"user-mention\" data-user-id=\"598052\">@Jeremy Tan</span>  We just released a GitHub repo (<a href=\"https://github.com/Goedel-LM/Goedel-Prover-V2\">https://github.com/Goedel-LM/Goedel-Prover-V2</a>), and the best way to get help is opening an issue there.</p>",
        "id": 529987810,
        "sender_full_name": "Kaiyu Yang",
        "timestamp": 1753148402
    },
    {
        "content": "<p>Ok. Looks like all Chinese firms use this exact ancient Lean and Mathlib version.</p>",
        "id": 529989866,
        "sender_full_name": "(deleted)",
        "timestamp": 1753150280
    },
    {
        "content": "<p>I'm also working for a Chinese firm too, so that's... compatibility!</p>",
        "id": 529989937,
        "sender_full_name": "(deleted)",
        "timestamp": 1753150340
    },
    {
        "content": "<p>Any chance this model gets supported by inference providers in the future?</p>",
        "id": 529989965,
        "sender_full_name": "(deleted)",
        "timestamp": 1753150371
    },
    {
        "content": "<p>Oh I'm not seeing a recommended prompt</p>",
        "id": 529990538,
        "sender_full_name": "(deleted)",
        "timestamp": 1753150868
    },
    {
        "content": "<p>Found the prompt. <a href=\"https://github.com/Goedel-LM/Goedel-Prover-V2/blob/main/src/utils.py#L339\">https://github.com/Goedel-LM/Goedel-Prover-V2/blob/main/src/utils.py#L339</a></p>",
        "id": 529990644,
        "sender_full_name": "(deleted)",
        "timestamp": 1753150967
    },
    {
        "content": "<p>To line 377.</p>",
        "id": 529990658,
        "sender_full_name": "(deleted)",
        "timestamp": 1753150982
    },
    {
        "content": "<p>I hope RL doesn't remove its ability to follow human provided proof sketches</p>",
        "id": 529990730,
        "sender_full_name": "(deleted)",
        "timestamp": 1753151036
    },
    {
        "content": "<p>Wonder how much time/money it would take to re-train models like this with more recent Lean+Mathlib versions <span aria-label=\"eyes\" class=\"emoji emoji-1f440\" role=\"img\" title=\"eyes\">:eyes:</span></p>",
        "id": 529992818,
        "sender_full_name": "Gavin Zhao",
        "timestamp": 1753152968
    },
    {
        "content": "<p>The paper seems to have been released here: <a href=\"https://arxiv.org/abs/2508.03613\">https://arxiv.org/abs/2508.03613</a></p>",
        "id": 533027004,
        "sender_full_name": "Pawan sasanka ammanamanchi",
        "timestamp": 1754457859
    },
    {
        "content": "<p>Hello. I used Goedel Prover v2 to prove theorems in this list: <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/AlphaGeometry.20doesn't.20have.20a.20secure.20foundation/near/532238675\">https://leanprover.zulipchat.com/#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/AlphaGeometry.20doesn't.20have.20a.20secure.20foundation/near/532238675</a></p>\n<p>I found that even when the theorem statements are expanded into real numbers, Goedel Prover v2 still struggles with them, except the easiest theorems.</p>\n<p>I used ollama on Google Colab to run this model: <a href=\"https://ollama.com/alessandrorumampuk/Goedel-Prover-V2:32b\">https://ollama.com/alessandrorumampuk/Goedel-Prover-V2:32b</a></p>\n<p>It could be possible that the version on ollama is not optimized, but I found that even when running the official inference code, the performance on my set of theorems is still poor.</p>\n<p>Therefore, I believe that good benchmarking could be important in making strong AI models. I feel MiniF2F performance isn't representative of the model's strength in other high school math problems.</p>",
        "id": 536581354,
        "sender_full_name": "(deleted)",
        "timestamp": 1756379179
    },
    {
        "content": "<p><a href=\"/user_uploads/3121/lkCGYmcLY6W9-wo8NScmGqMJ/Screenshot_20250830_182202_com_android_chrome_SameTaskWebApkActivity.jpg\">Screenshot_20250830_182202_com_android_chrome_SameTaskWebApkActivity.jpg</a></p>\n<div class=\"message_inline_image\"><a href=\"/user_uploads/3121/lkCGYmcLY6W9-wo8NScmGqMJ/Screenshot_20250830_182202_com_android_chrome_SameTaskWebApkActivity.jpg\" title=\"Screenshot_20250830_182202_com_android_chrome_SameTaskWebApkActivity.jpg\"><img data-original-content-type=\"image/jpeg\" data-original-dimensions=\"1080x2412\" src=\"/user_uploads/thumbnail/3121/lkCGYmcLY6W9-wo8NScmGqMJ/Screenshot_20250830_182202_com_android_chrome_SameTaskWebApkActivity.jpg/840x560.webp\"></a></div><p>Very disastrous looping behavior here.</p>",
        "id": 536907748,
        "sender_full_name": "(deleted)",
        "timestamp": 1756553065
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"511228\">Huỳnh Trần Khanh</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Discussion.3A.20Goedel-Prover-V2.3A.20A.20new.20SOTA.20model/near/536581354\">said</a>:</p>\n<blockquote>\n<p>I found that even when the theorem statements are expanded into real numbers, Goedel Prover v2 still struggles with them...</p>\n</blockquote>\n<p>Which theorems, as stated in PastedText.txt, failed?</p>",
        "id": 538691746,
        "sender_full_name": "Kelly Davis",
        "timestamp": 1757520833
    },
    {
        "content": "<p>Many. But try u31 first. Goedel Prover v2 fails on u31.</p>",
        "id": 538693952,
        "sender_full_name": "(deleted)",
        "timestamp": 1757521517
    },
    {
        "content": "<p>In fact, Goedel Prover v2 rarely succeeds.</p>",
        "id": 538694038,
        "sender_full_name": "(deleted)",
        "timestamp": 1757521553
    },
    {
        "content": "<p>Thank you for looking into this.</p>",
        "id": 538694084,
        "sender_full_name": "(deleted)",
        "timestamp": 1757521567
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"938385\">@Yong Lin</span> Hi! Do you have any infomation on how long it took your models to generate a proof on average (both 8B and 32B)?<br>\nI am looking for a baseline to compare with my setup</p>",
        "id": 560594536,
        "sender_full_name": "Alessandro Sosso",
        "timestamp": 1764249307
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"938385\">@Yong Lin</span> <span class=\"user-mention\" data-user-id=\"877583\">@Yong Lin</span> Thanks for the nice work on Goedel. Are there plans on supporting recent versions of lean ?</p>",
        "id": 562948739,
        "sender_full_name": "Bas Spitters",
        "timestamp": 1765371575
    }
]