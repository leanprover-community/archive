[
    {
        "content": "<p>I had this idea yesterday and I wonder if anyone has tried it before. Instead of trying to write Lean code, an AI agent would try to create terms of <a href=\"https://github.com/leanprover/lean4/blob/1e9864363f605ff842a659aefbdab5e20b9f0044/src/Lean/Expr.lean#L301\"><code>Lean.Expr</code></a> directly. This approach would be more easily plugged to Lean 4, as a meta program. I wonder if this path would be promising.</p>",
        "id": 515379677,
        "sender_full_name": "Arthur Paulino",
        "timestamp": 1746040288
    },
    {
        "content": "<p>I had a similar idea a little while ago, but realized that the most convenient interface for an agent to interact with is still the tactic system, but with a restricted set of tactics (intro, apply and refine, primarily)</p>",
        "id": 515383418,
        "sender_full_name": "Adam Topaz",
        "timestamp": 1746041518
    },
    {
        "content": "<p>It depends on what you mean by \"convenient\". Operating with <code>Lean.Expr</code> directly is very convenient too as it doesn't need to leave <code>MetaM</code> and avoids overheads related to parsing. In RL algorithms, the cycle cost is very important. That is, the cost of checking whether a new proof term attempt works or not.</p>",
        "id": 515386982,
        "sender_full_name": "Arthur Paulino",
        "timestamp": 1746042821
    },
    {
        "content": "<p>The main problem, however, is in the feedback the human would receive. Instead of a series of tactics, it would be some seriously ugly proof term. My thinking is that it's a tradeoff that favors the machine over the human in the loop</p>",
        "id": 515387306,
        "sender_full_name": "Arthur Paulino",
        "timestamp": 1746042948
    },
    {
        "content": "<p>I think trying to build an <code>Expr</code> for a <code>rw</code> tactic is rather an ordeal</p>",
        "id": 515399920,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1746047480
    },
    {
        "content": "<p>For instance, look at how large the proof term for the following is:</p>\n<div class=\"codehilite\" data-code-language=\"Lean4\"><pre><span></span><code><span class=\"kn\">import</span><span class=\"w\"> </span><span class=\"n\">Mathlib</span>\n\n<span class=\"kn\">open</span><span class=\"w\"> </span><span class=\"kn\">scoped</span><span class=\"w\"> </span><span class=\"n\">TensorProduct</span>\n\n<span class=\"c1\">-- to show the full proof term</span>\n<span class=\"kn\">set_option</span><span class=\"w\"> </span><span class=\"n\">pp</span><span class=\"bp\">.</span><span class=\"n\">all</span><span class=\"w\"> </span><span class=\"n\">true</span>\n\n<span class=\"kn\">set_option</span><span class=\"w\"> </span><span class=\"n\">pp</span><span class=\"bp\">.</span><span class=\"n\">all</span><span class=\"w\"> </span><span class=\"n\">true</span>\n<span class=\"bp\">#</span><span class=\"n\">check</span><span class=\"w\"> </span><span class=\"n\">add_comm</span><span class=\"w\"> </span><span class=\"o\">(</span><span class=\"mi\">1</span><span class=\"w\"> </span><span class=\"o\">:</span><span class=\"w\"> </span><span class=\"n\">ℤ</span><span class=\"w\"> </span><span class=\"bp\">⊗</span><span class=\"o\">[</span><span class=\"n\">ℤ</span><span class=\"o\">]</span><span class=\"w\"> </span><span class=\"n\">ℤ</span><span class=\"w\"> </span><span class=\"bp\">⊗</span><span class=\"o\">[</span><span class=\"n\">ℤ</span><span class=\"o\">]</span><span class=\"w\"> </span><span class=\"n\">ℤ</span><span class=\"o\">)</span><span class=\"w\"> </span><span class=\"mi\">0</span>\n</code></pre></div>",
        "id": 515400439,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1746047697
    },
    {
        "content": "<p>oh god</p>",
        "id": 515400581,
        "sender_full_name": "Aaron Liu",
        "timestamp": 1746047761
    },
    {
        "content": "<p>Giving up typeclass search and the elaborator is giving up some very carefully tuned algorithms written by humans, and asking your agent to learn those at the same time as learning formalizing mathematics</p>",
        "id": 515401054,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1746047956
    },
    {
        "content": "<p>(and also to memorize all the instance names which are explicitly not part of any backwards compatibility guarantee)</p>",
        "id": 515401110,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1746047983
    },
    {
        "content": "<p>If not <code>Lean.Expr</code>, then maybe <code>Syntax</code>.<br>\nIt's more constrained than pure text and still more easily pluggable via metaprogramming</p>",
        "id": 515474211,
        "sender_full_name": "Arthur Paulino",
        "timestamp": 1746091462
    },
    {
        "content": "<p>Technically speaking <code>Lean.Expr</code> is also Lean code.</p>\n<p>I've a system that can do this. I don't think we should give up the elaboration system.</p>\n<p>Also it would be a huge pain to use this mechanism to build up any non-trivial proof. Just <code>#print</code> some random theorem in mathlib to see this.</p>",
        "id": 516043007,
        "sender_full_name": "Leni Aniva",
        "timestamp": 1746375125
    },
    {
        "content": "<p>If you have a system that incrementally builds an expression, then its basically just tactics, and we're back in square one.</p>",
        "id": 516043914,
        "sender_full_name": "Leni Aniva",
        "timestamp": 1746375773
    },
    {
        "content": "<p>cant you just stop the elaboration depth after a certain point</p>",
        "id": 516047970,
        "sender_full_name": "Frederick Pu",
        "timestamp": 1746378676
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"676310\">Frederick Pu</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Building.20up.20Lean.2EExpr's/near/516047970\">said</a>:</p>\n<blockquote>\n<p>cant you just stop the elaboration depth after a certain point</p>\n</blockquote>\n<p>What do you mean by this?</p>",
        "id": 516053331,
        "sender_full_name": "Leni Aniva",
        "timestamp": 1746382214
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"451983\">Arthur Paulino</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Building.20up.20Lean.2EExpr's/near/515474211\">said</a>:</p>\n<blockquote>\n<p>If not <code>Lean.Expr</code>, then maybe <code>Syntax</code>.</p>\n</blockquote>\n<p>This is a very reasonable thing to do in principle, though compared to generating raw text it is much harder to benefit from existing LLM training.</p>",
        "id": 516058003,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1746385450
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"599027\">Leni Aniva</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Building.20up.20Lean.2EExpr's/near/516053331\">said</a>:</p>\n<blockquote>\n<p>Frederick Pu <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Building.20up.20Lean.2EExpr's/near/516047970\">said</a>:</p>\n</blockquote>\n<p>I meant don't unfold function and typeclass definitions.</p>",
        "id": 516069254,
        "sender_full_name": "Frederick Pu",
        "timestamp": 1746393459
    },
    {
        "content": "<p>They're not being unfolded, they're just normally implicit, but they're still in the <code>Lean.Expr</code>.</p>",
        "id": 516069736,
        "sender_full_name": "Aaron Liu",
        "timestamp": 1746393814
    }
]