[
    {
        "content": "<p>I ran some simple experiments that may be of interest to folks here: <a href=\"https://docs.google.com/document/d/1Dr2FFZMqpPWuhCBRi0nSg_Ji6US_Xm_aGJvQx_5Z2Cc\">https://docs.google.com/document/d/1Dr2FFZMqpPWuhCBRi0nSg_Ji6US_Xm_aGJvQx_5Z2Cc</a></p>\n<p>Cross-posted to Coq discourse: <a href=\"https://coq.discourse.group/t/chatgpt-can-help-translate-between-coq-and-lean/2203\">https://coq.discourse.group/t/chatgpt-can-help-translate-between-coq-and-lean/2203</a></p>\n<p>Here's a summary:</p>\n<p>Making high-quality proof libraries takes a ton of work. It would be a shame to duplicate all that work for each ITP language, or to get locked out of using a specific ITP because it doesn't have the right libraries. Cheap library reuse across languages would reduce the burden of language silos.</p>\n<p>For instance, software verification in Lean could benefit from Coq's advanced libraries for software, while Coq could benefit from Lean's math libraries. Having equivalent proofs implemented in different ITPs also provides clear benchmarks for comparing research results across ITPs.</p>\n<p>I ran some simple experiments on using ChatGPT-4 as an assistant to iteratively write and translate between Coq and Lean 4 definitions (not proofs).</p>\n<p>These experiments found that ChatGPT significantly reduced the work to (a) write a toy ISA model and example assembly programs in Coq (~400 SLOC), (b) translate these to Lean, (c) compare the Coq vs. Lean programs for semantic differences, and (d) port a Coq bugfix to Lean as an incremental patch. The most surprising result was that ChatGPT accurately detected minor semantic differences between two implementations, one in Coq and the other in Lean, and could patch the Lean code to match the Coq code.</p>\n<p>—</p>\n<p>Is this direction interesting to folks here?</p>",
        "id": 421298188,
        "sender_full_name": "Daniel Windham",
        "timestamp": 1707847685
    },
    {
        "content": "<p>As a practical tool, yes it is interesting.  I’d be interested in if others feel the same way, and if it is as easy to go one direction or the other.  (I think ChatGPT often gets Lean 3 and 4 mixed up so I bet it is better having Lean as a source language instead of a target language.)</p>",
        "id": 421315742,
        "sender_full_name": "Jason Rute",
        "timestamp": 1707854284
    },
    {
        "content": "<p>As a research direction, I’ve often wondered about translating between ITPs and their libraries.  We can do it the logical way through shallow embeddings, and the probabilistic way though machine learning, but can we combine the two approaches?  If one could show a method which accurately and idiomatically translates large chunks from one ITP language to another <em>including the proofs</em>, I think that would be really exciting, especially since proofs can be automatically checked and we can have some guarantees the translation is correct.</p>",
        "id": 421315757,
        "sender_full_name": "Jason Rute",
        "timestamp": 1707854286
    },
    {
        "content": "<p>(But I’m not sure how interesting of a paper it would be to say that ChatGPT is a good assistant for translating the non-proof code.  I don’t find this surprising anymore.  Useful, yes: surprising, not so much.)</p>",
        "id": 421315984,
        "sender_full_name": "Jason Rute",
        "timestamp": 1707854384
    },
    {
        "content": "<p>Although I guess translating say all of Isabelle’s AFP or Coq’s MathComp to Lean automatically (even without the proofs) would provide a lot of interesting training and testing data for automated theorem proving in the same ways that natural-to-formal auto-formalization papers like ProofNet did.</p>",
        "id": 421317081,
        "sender_full_name": "Jason Rute",
        "timestamp": 1707854792
    },
    {
        "content": "<p>Isn't the issue here that the idiomatic way to do things in two different languages might be very different? So you translate from one prover to another and you may get a bunch of unidiomatic code which is hard to use.</p>",
        "id": 421317719,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1707855038
    },
    {
        "content": "<p>I was also about to say I know someone who is really interested in this direction of translating between Lean and Coq.  His name is (looks up name in recent messages) <span class=\"user-mention\" data-user-id=\"662442\">@Daniel Windham</span> <span aria-label=\"laughter tears\" class=\"emoji emoji-1f602\" role=\"img\" title=\"laughter tears\">:laughter_tears:</span>.</p>",
        "id": 421317723,
        "sender_full_name": "Jason Rute",
        "timestamp": 1707855040
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"110038\">@Kevin Buzzard</span> I think <span class=\"user-mention\" data-user-id=\"662442\">@Daniel Windham</span> is saying that the ChatGPT translation is very idiomatic.</p>",
        "id": 421317867,
        "sender_full_name": "Jason Rute",
        "timestamp": 1707855111
    },
    {
        "content": "<p>…and correct also, right?</p>",
        "id": 421317987,
        "sender_full_name": "Jason Rute",
        "timestamp": 1707855148
    },
    {
        "content": "<p>I think it would be good to see some side-by-side examples.</p>",
        "id": 421318049,
        "sender_full_name": "Jason Rute",
        "timestamp": 1707855187
    },
    {
        "content": "<blockquote>\n<p>I think ChatGPT often gets Lean 3 and 4 mixed up so I bet it is better having Lean as a source language instead of a target language.</p>\n</blockquote>\n<p>In my experience GPT-4 has been reasonably good at Lean 4 now that the training cutoff date is April 2023. There were a couple syntax mistakes it kept making but they were things I could fix with find/replace, and they weren't Lean 3 vs 4 issues.<br>\n .</p>\n<blockquote>\n<p>I was also about to say I know someone who is really interested in this direction of translating between Lean and Coq.</p>\n</blockquote>\n<p>Ha! Yes... this was that project.<br>\n .</p>\n<blockquote>\n<p>Isn't the issue here that the idiomatic way to do things in two different languages might be very different? </p>\n</blockquote>\n<blockquote>\n<p>I think it would be good to see some side-by-side examples.</p>\n</blockquote>\n<p>I'm pretty new to ITPs so I'm not the right person to assess what's idiomatic to Coq or Lean. The experiment I ran was equivalent to \"Say we want a software engineer to start developing verified software. Can tools like ChatGPT get them to deliver value with just weeks of training?\" So it's not a good experiment for studying \"idiomatic\".</p>\n<p>Here are the final programs <a href=\"https://github.com/atlas-computing-org/CoqLeanTranslation/blob/main/CoqLeanTranslation/Coq/ToyISA.v\">in Coq</a> and <a href=\"https://github.com/atlas-computing-org/CoqLeanTranslation/blob/main/CoqLeanTranslation/Lean/ToyISA-GPT4.lean\">in Lean</a>.</p>",
        "id": 421319081,
        "sender_full_name": "Daniel Windham",
        "timestamp": 1707855628
    },
    {
        "content": "<p>But yes - my takeaway was that the translation was correct, including in iterative workflows where it's important to translate incremental changes that align to existing definitions.</p>",
        "id": 421320315,
        "sender_full_name": "Daniel Windham",
        "timestamp": 1707856107
    },
    {
        "content": "<p>Could these approach help to make the code in PudnamBench more idiomatic?</p>",
        "id": 453675507,
        "sender_full_name": "Bas Spitters",
        "timestamp": 1721822739
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"259452\">@Bas Spitters</span> it depends on the gaps, but it would be fast for someone familiar with the PutnamBench problems to try. I'm happy to pair with them if that's of interest. If someone spends more than half an hour on trying this out, they should spend the first half-hour customizing the chatbot to query PutnamBench's existing resources.</p>\n<p>I'd expect this approach to be helpful for:</p>\n<ul>\n<li>Code style refactors that involve common or easy-to-describe syntactic patterns</li>\n<li>Improving names and naming consistency</li>\n<li>Translating problem formalizations from one language to another when the user can point out theorems in the target language that match the source language's dependencies</li>\n</ul>\n<p>I'd expect it to not help when:</p>\n<ul>\n<li>Improvements wouldn't be valuable enough to justify manual review the results</li>\n<li>The logical structure of a formalization needs to be rethought based on the available lemmas or language features</li>\n</ul>\n<p>(Sorry for the very delayed reply.)</p>",
        "id": 457109678,
        "sender_full_name": "Daniel Windham",
        "timestamp": 1723037274
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"644040\">@George Tsoukalas</span> is this relevant for you?</p>",
        "id": 462359539,
        "sender_full_name": "Bas Spitters",
        "timestamp": 1723646273
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"259452\">Bas Spitters</span> <a href=\"#narrow/stream/219941-Machine-Learning-for-Theorem-Proving/topic/ChatGPT.20can.20help.20translate.20between.20Coq.C2.A0and.20Lean/near/462359539\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"644040\">George Tsoukalas</span> is this relevant for you?</p>\n</blockquote>\n<p>I agree with Daniel about when I'd expect it to help. I'd also be curious to know if ChatGPT or any of the big LLMs could reliably catch subtle mistakes in the formalizations - we did not run any experiment like this. I'd be supportive of any efforts to look into this further. However, for the Coq formalizations we are currently revising, we are still planning on doing them manually because it helps build experience in our group, even if it takes longer. Though if there were modifications needed based on simple syntactic changes, I could see this kind of automated fixing to be very useful, especially from a maintenance perspective.</p>",
        "id": 462362661,
        "sender_full_name": "George Tsoukalas",
        "timestamp": 1723647257
    },
    {
        "content": "<blockquote>\n<p>Making high-quality proof libraries takes a ton of work. It would be a shame to duplicate all that work for each ITP language, or to get locked out of using a specific ITP because it doesn't have the right libraries. Cheap library reuse across languages would reduce the burden of language silos.</p>\n</blockquote>\n<p><strong>An idea from CAS:  wrapper for ITPs?</strong> Since the translation works could become overwhelming as libraries grow.</p>\n<p>There are many CAS languages, such as Mathematica, Maple, SymPy, GAP, and more. SageMath builds on top of them and access their combined power through a common interface. One can perform computations on a group in GAP and then transfer the result to Maple for further processing, as long as <strong>we know we're dealing with the same abstract objects.</strong></p>\n<p>However, the concept of \"the same objects\" carries more weight in ITPs. Could there be a standard or a wrapper that allows the conversion of proof objects (definitions and propositions) between different ITPs? If we know <strong>the objects are equivalent</strong>, we could transfer them to another ITP and use its lemmas seamlessly.</p>\n<p>It would also be fascinating to explore interactions between ITPs and CAS. CAS excels in computation, while ITPs specialize in proving; the two could complement each other effectively. Currently, LLMs can interface with both, but perhaps this is not the most natural solution. Could there be a more organic integration?</p>\n<p>Related papers just found: <a href=\"https://robertylewis.com/leanmm/lean_mm.pdf\">A Bi-Directional Extensible Interface Between Lean and Mathematica</a>.</p>",
        "id": 470255640,
        "sender_full_name": "RexWang",
        "timestamp": 1726366898
    },
    {
        "content": "<p>One possibility is importing Lean into Coq: <a href=\"https://coq.discourse.group/t/alpha-announcement-coq-is-a-lean-typechecker/581/5\">https://coq.discourse.group/t/alpha-announcement-coq-is-a-lean-typechecker/581/5</a></p>",
        "id": 470334273,
        "sender_full_name": "Bas Spitters",
        "timestamp": 1726406079
    },
    {
        "content": "<p>The people working on Dedukti have worked on <a href=\"https://inria.hal.science/hal-01592243/document\">proof exchange between provers</a> for some time now. If I remember correctly, they are also working on interfacing with Lean. They also know that a big obstacle is maintainability of the approach after it has been completed, and have plans to tackle it.</p>",
        "id": 470543245,
        "sender_full_name": "Jonathan Julian Huerta y Munive",
        "timestamp": 1726482584
    },
    {
        "content": "<p>For LLM purposes, I think low-level translations between proof systems are useless, and high-level (source-to-source) translations a la mathport qualify as \"synthetic data\". They are no good for learning how to write idiomatic code</p>",
        "id": 470597825,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1726492129
    }
]