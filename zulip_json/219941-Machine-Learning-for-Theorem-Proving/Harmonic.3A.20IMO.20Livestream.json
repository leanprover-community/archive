[
    {
        "content": "<p>Harmonic is announcing their IMO results, incl. their Lean proofs: <a href=\"https://x.com/i/broadcasts/1BdGYqEkOYyGX\">https://x.com/i/broadcasts/1BdGYqEkOYyGX</a></p>",
        "id": 531472433,
        "sender_full_name": "Alex Meiburg",
        "timestamp": 1753741262
    },
    {
        "content": "<p>and from the QR code: <a href=\"https://github.com/harmonic-ai/IMO2025/\">https://github.com/harmonic-ai/IMO2025/</a></p>",
        "id": 531472557,
        "sender_full_name": "Alex Meiburg",
        "timestamp": 1753741326
    },
    {
        "content": "<p>Do I understand correctly that the problems were presented to the AI in easy mode, with the answer included? That's what the video seemed to be saying, showing a file including the answer (like the <code>StatementOnly</code> files in the repository) and saying that was what was given to the AI.</p>",
        "id": 531483076,
        "sender_full_name": "Joseph Myers",
        "timestamp": 1753747070
    },
    {
        "content": "<p>I'll also ask more or less the same questions I put to ByteDance: (a) Could you add the formal statement of P6 that the AI didn't solve to the repository? (b) What if anything did you do to attempt to coordinate with other AIs on having a single common version of the problems in Lean? (c) Was there a particular reason for preparing your own Lean statements rather than having the IMO provide them?</p>",
        "id": 531483758,
        "sender_full_name": "Joseph Myers",
        "timestamp": 1753747442
    },
    {
        "content": "<p>And since people have discussed testing formal-to-formal AIs on formal-conjectures, and both Terry Tao and I (and Simon Frieder) have commented on issues of disclosing test methodology as well as what better methodology for evaluating mathematical AIs in future might look like: can you commit that, if you do solve an unsolved problem with AI, you will also disclose, at the same time as the solution to that problem, details of all the other problems the AI attempted without solving?</p>",
        "id": 531484329,
        "sender_full_name": "Joseph Myers",
        "timestamp": 1753747757
    },
    {
        "content": "<p>Thank you also for waiting a reasonable time after the IMO for the announcement. As I remarked to the other coordinators, I'm not convinced that the AI companies rushing to announce understand that much of the IMO community is travelling all over the world immediately after the IMO, and are largely out of contact while travelling and so not in a good position to respond to media requests for comment at that time - an issue I predicted in this channel before the IMO.</p>",
        "id": 531485468,
        "sender_full_name": "Joseph Myers",
        "timestamp": 1753748467
    },
    {
        "content": "<p>One thing I am curious about is that each automated Lean theorem prover seems to have super long solutions. Does anyone know how much more efficiently a good Lean proof writer could write these solutions if given the informal versions? Or are they fundamentally long solutions to write in Lean? Both ByteDance and Harmonic have this feature.</p>\n<p>Last year, AlphaProof seemed to have much more efficient solutions. For reference, Harmonic's solution of P1 2025 is 96k characters, whereas DeepMind AlphaProof's informal proof of P1 2024 was only 6.4k characters. Harmonic's also have a decent number of \"have\" claims, like ByteDance and Morph. Am I missing something?</p>",
        "id": 531489300,
        "sender_full_name": "Justin Asher",
        "timestamp": 1753750849
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"266253\">Joseph Myers</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Harmonic.3A.20IMO.20Livestream/near/531484329\">said</a>:</p>\n<blockquote>\n<p>And since people have discussed testing formal-to-formal AIs on formal-conjectures, and both Terry Tao and I (and Simon Frieder) have commented on issues of disclosing test methodology as well as what better methodology for evaluating mathematical AIs in future might look like: can you commit that, if you do solve an unsolved problem with AI, you will also disclose, at the same time as the solution to that problem, details of all the other problems the AI attempted without solving?</p>\n</blockquote>\n<p>Not that my opinion matters, but I find this a strange requirement to impose on the companies. I don't see much value in this except to lower the impressiveness of any achievement. I would consider it, in an anthropomorphized way, like asking a mathematician after a talk, \"yes but what about all the questions you failed to solve?\"</p>",
        "id": 531489523,
        "sender_full_name": "Andy Jiang",
        "timestamp": 1753750993
    },
    {
        "content": "<p>When the explicit goal of your company is mathematical superintelligence, identifying the rate of successes and failures at solving problems, so that human mathematicians can compare it to their own experience, is extremely relevant to evaluating whether such a goal has been achieved.</p>",
        "id": 531490545,
        "sender_full_name": "Joseph Myers",
        "timestamp": 1753751655
    },
    {
        "content": "<p>Or: being part of the scientific community means disclosing scientifically relevant information about your experimental results, in a way that avoids publication bias. There's a strong argument that it would be <em>unethical</em> to make claims about the abilities of an AI on unsolved problems without disclosing failures as well as successes. Note that the IMO announcement included failing to solve P6, not just succeeding on other problems.</p>",
        "id": 531491069,
        "sender_full_name": "Joseph Myers",
        "timestamp": 1753751959
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"266253\">Joseph Myers</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Harmonic.3A.20IMO.20Livestream/near/531490545\">said</a>:</p>\n<blockquote>\n<p>When the explicit goal of your company is mathematical superintelligence, identifying the rate of successes and failures at solving problems, so that human mathematicians can compare it to their own experience, is extremely relevant to evaluating whether such a goal has been achieved.</p>\n</blockquote>\n<p>This I generally agree with. Although it's unclear what it means to \"compare with their own experience\" on a list of unsolved questions as presumably the experience is \"I can't solve any otherwise I would've shortened the list\". I think I just assume by default that if they claim one of the formal problems, say of formal-conjectures, that they probably attempted all of them plus whatever else they could've formalized at least for a little while (to figure out what the system is making most progress on). So in that sense I guess there's a case to be made if they only tried it on like 3 problems, disclosing this would boost their claims.</p>",
        "id": 531491964,
        "sender_full_name": "Andy Jiang",
        "timestamp": 1753752509
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"780541\">Justin Asher</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Harmonic.3A.20IMO.20Livestream/near/531489300\">said</a>:</p>\n<blockquote>\n<p>Last year, AlphaProof seemed to have much more efficient solutions. For reference, Harmonic's solution of P1 2025 is 96k characters, whereas DeepMind AlphaProof's informal proof of P1 2024 was only 6.4k characters. Harmonic's are also plagued by \"have\" claims like ByteDance and Morph. Am I missing something?</p>\n</blockquote>\n<p><code>have</code> claims may not be a bad thing to structure proofs. Although at least idiomatic mathlib style would prefer lots of lemmas each with a short proof in place of long proofs of single lemmas (with the consequence that internal comments within proofs are rarely needed because you can tell the key ideas by looking at what lemmas are used).</p>\n<p>These long proofs feel a lot more readable than AlphaProof's solutions last year. Also, cleaning up and golfing a formal proof ought to be a lot easier for an AI to do than finding the proof in the first place.</p>",
        "id": 531492904,
        "sender_full_name": "Joseph Myers",
        "timestamp": 1753753143
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"662620\">Andy Jiang</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Harmonic.3A.20IMO.20Livestream/near/531491964\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"266253\">Joseph Myers</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Harmonic.3A.20IMO.20Livestream/near/531490545\">said</a>:</p>\n<blockquote>\n<p>When the explicit goal of your company is mathematical superintelligence, identifying the rate of successes and failures at solving problems, so that human mathematicians can compare it to their own experience, is extremely relevant to evaluating whether such a goal has been achieved.</p>\n</blockquote>\n<p>This I generally agree with. Although it's unclear what it means to \"compare with their own experience\" on a list of unsolved questions as presumably the experience is \"I can't solve any otherwise I would've shortened the list\". I think I just assume by default that if they claim one of the formal problems, say of formal-conjectures, that they probably attempted all of them plus whatever else they could've formalized at least for a little while (to figure out what the system is making most progress on). So in that sense I guess there's a case to be made if they only tried it on like 3 problems, disclosing this would boost their claims.</p>\n</blockquote>\n<p>Well, it would be comparing with experience on different problems (the rate at which they, or their PhD students, had solved problems attempted, adjusted for perceived difficulty); not an exact science given different difficulty levels. And the choice of spending a lot of compute on a few problems or less compute on lots of problems is a basic part of the experimental design that ought to be disclosed.</p>",
        "id": 531493352,
        "sender_full_name": "Joseph Myers",
        "timestamp": 1753753453
    },
    {
        "content": "<p>I agree that AlphaProof can be hard to read and debug. </p>\n<p>If you look <a href=\"https://github.com/dwrensha/compfiles/tree/main/Compfiles\">here</a>, you can find some previous formalizations of IMO problems and their solutions in Lean. I ran a script and found that the longest IMO solution from there is 47k characters, so 96k is definitely more than what would be expected (P5 is also 98k).</p>\n<p>And yes, there are not too many unnecessary have claims in Harmonic's solutions, albeit I have noticed an excess in other systems since they are trying to get compiler feedback and mimic the natural language proofs.</p>",
        "id": 531495305,
        "sender_full_name": "Justin Asher",
        "timestamp": 1753754652
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"780541\">Justin Asher</span> <a href=\"#narrow/stream/219941-Machine-Learning-for-Theorem-Proving/topic/Harmonic.3A.20IMO.20Livestream/near/531495305\">said</a>:</p>\n<blockquote>\n<p>I agree that AlphaProof can be hard to read and debug. </p>\n<p>If you look <a href=\"https://github.com/dwrensha/compfiles/tree/main/Compfiles\">here</a>, you can find some previous formalizations of IMO problems and their solutions in Lean. I ran a script and found that the longest IMO solution from there is 47k characters, so 96k is definitely more than what would be expected (P5 is also 98k).</p>\n<p>And yes, there are not too many unnecessary have claims in Harmonic's solutions, albeit I have noticed an excess in other systems since they are trying to get compiler feedback and mimic the natural language proofs.</p>\n</blockquote>\n<p>Isn't there possible selection bias on what people formalized?</p>",
        "id": 531495996,
        "sender_full_name": "Andy Jiang",
        "timestamp": 1753755104
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"662620\">Andy Jiang</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Harmonic.3A.20IMO.20Livestream/near/531495996\">said</a>:</p>\n<blockquote>\n<p>Isn't there possible selection bias on what people formalized?</p>\n</blockquote>\n<p>That's fair. I am still curious how much more optimally the proofs can be formalized for practical purposes. For instance, at one point, their system writes a single line that contains</p>\n<p>exact âŸ¨ d1, âŸ¨ <a href=\"http://Nat.mem_properDivisors.mp\">Nat.mem_properDivisors.mp</a> ( Finset.mem_sort ( Î± := â„• ) ( fun x1 x2 =&gt; x2 â‰¤ x1 ) |&gt;.1 ( by rw [ x ] ; simp ( config := { decide := Bool.true } ) ) ) |&gt;.1, <a href=\"http://Nat.mem_properDivisors.mp\">Nat.mem_properDivisors.mp</a> ( Finset.mem_sort ( Î± := â„• ) ( fun x1 x2 =&gt; x2 â‰¤ x1 ) |&gt;.1 ( by rw [ x ] ; simp ( config := { decide := Bool.true } ) ) ) |&gt;.2 âŸ©, d2, âŸ¨ <a href=\"http://Nat.mem_properDivisors.mp\">Nat.mem_properDivisors.mp</a> ( Finset.mem_sort ( Î± := â„• ) ( fun x1 x2 =&gt; x2 â‰¤ x1 ) |&gt;.1 ( by rw [ x ] ; simp ( config := { decide := Bool.true } ) ) ) |&gt;.1, <a href=\"http://Nat.mem_properDivisors.mp\">Nat.mem_properDivisors.mp</a> ( Finset.mem_sort ( Î± := â„• ) ( fun x1 x2 =&gt; x2 â‰¤ x1 ) |&gt;.1 ( by rw [ x ] ; simp ( config := { decide := Bool.true } ) ) ) |&gt;.2 âŸ©, d3, âŸ¨ <a href=\"http://Nat.mem_properDivisors.mp\">Nat.mem_properDivisors.mp</a> ( Finset.mem_sort ( Î± := â„• ) ( fun x1 x2 =&gt; x2 â‰¤ x1 ) |&gt;.1 ( by rw [ x ] ; simp ( config := { decide := Bool.true } ) ) ) |&gt;.1, <a href=\"http://Nat.mem_properDivisors.mp\">Nat.mem_properDivisors.mp</a> ( Finset.mem_sort ( Î± := â„• ) ( fun x1 x2 =&gt; x2 â‰¤ x1 ) |&gt;.1 ( by rw [ x ] ; simp ( config := { decide := Bool.true } ) ) ) |&gt;.2 âŸ©, by linarith, by linarith, rfl âŸ©;</p>\n<p>which seems atypical. Presumably the next generation of models will be better in this regard.</p>",
        "id": 531496901,
        "sender_full_name": "Justin Asher",
        "timestamp": 1753755668
    },
    {
        "content": "<p>These companies are selling a product, one which is (sometimes) billed by the volume of use. If they claim their product can solve X problems, then they had better say the success rate and under what conditions, otherwise they can say they can solve X, but it takes 100 attempts and a bazillion tokens on the biggest clusters, which their customers might like to know before buying the miracle machine.</p>",
        "id": 531504460,
        "sender_full_name": "David Michael Roberts",
        "timestamp": 1753760451
    },
    {
        "content": "<p>Are those <code>exact?</code> supposed to stay in the code, not get replaced by the proofs Lean found?</p>",
        "id": 531524819,
        "sender_full_name": "Martin DvoÅ™Ã¡k",
        "timestamp": 1753771069
    },
    {
        "content": "<p>Should we care that the axiom <code>Lean.ofReduceBool</code> is used by the proof of P3 and both proofs of P4?</p>",
        "id": 531533673,
        "sender_full_name": "Martin DvoÅ™Ã¡k",
        "timestamp": 1753774096
    },
    {
        "content": "<p>I don't know why the CI on GitHub fails, but everything builds fine on my computer.</p>",
        "id": 531535210,
        "sender_full_name": "Martin DvoÅ™Ã¡k",
        "timestamp": 1753774596
    },
    {
        "content": "<p>Can the use of <code>Lean.ofReduceBook</code> be eliminated, or does the proof depend on it in some critical way?</p>",
        "id": 531537622,
        "sender_full_name": "Niels Voss",
        "timestamp": 1753775371
    },
    {
        "content": "<p><code>Lean.ofReduceBool</code> effectively adds an unbounded set of compiler extensions to the trusted codebase. My personal opinion (and feel free to disagree with me on this) is that in an adversarial context, <code>Lean.ofReduceBool</code> should be treated the same way as <code>sorryAx</code>.</p>",
        "id": 531539202,
        "sender_full_name": "Niels Voss",
        "timestamp": 1753775842
    },
    {
        "content": "<p>With that said, if all it takes is replacing <code>native_decide</code> with something like <code>decide</code> or <code>decide +kernel</code> to eliminate <code>Lean.ofReduceBool</code>, then I would consider the original LLM generated solution to be valid, since the manual editing at the end would have been negligible.</p>",
        "id": 531539989,
        "sender_full_name": "Niels Voss",
        "timestamp": 1753776068
    },
    {
        "content": "<p>I did (earlier this morning) review the uses of <code>native_decide</code>. They look correct to me, but I agree with everyone's desire to see this not being used in AI generated proofs.</p>",
        "id": 531547777,
        "sender_full_name": "Kim Morrison",
        "timestamp": 1753778454
    },
    {
        "content": "<p>A scary feature of two of their <code>native_decide</code> calls is that the corresponding <code>#eval</code> calls will generate panics, and they are relying on the default values. True, but ... not reassuring.</p>",
        "id": 531548201,
        "sender_full_name": "Kim Morrison",
        "timestamp": 1753778581
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"417654\">Martin DvoÅ™Ã¡k</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Harmonic.3A.20IMO.20Livestream/near/531524819\">said</a>:</p>\n<blockquote>\n<p>Are those <code>exact?</code> supposed to stay in the code, not get replaced by the proofs Lean found?</p>\n</blockquote>\n<p>Some of the AlphaProof solutions from last year used <code>hint</code> without replacing it by its output.</p>",
        "id": 531568148,
        "sender_full_name": "Joseph Myers",
        "timestamp": 1753783992
    },
    {
        "content": "<p>I want to say that I am really happy that the solutions contain a complete theorem for every problem and that we can see how each  statement was for formalized for the AI to prove.</p>",
        "id": 531573177,
        "sender_full_name": "Martin DvoÅ™Ã¡k",
        "timestamp": 1753785528
    },
    {
        "content": "<p>26 messages were moved from this topic to <a class=\"stream-topic\" data-stream-id=\"219941\" href=\"/#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Guarding.20against.20exploits.20in.20AI.20code/with/531687711\">#Machine Learning for Theorem Proving &gt; Guarding against exploits in AI code</a> by <span class=\"user-mention silent\" data-user-id=\"115715\">Jason Rute</span>.</p>",
        "id": 531687713,
        "sender_full_name": "Notification Bot",
        "timestamp": 1753818696
    },
    {
        "content": "<p>Thanks for the interest in our livestream! I'm Tudor, CEO of Harmonic. Hereâ€™s some thoughts on the points in the thread. If youâ€™re curious about how the system does on a problem of your choice I would encourage just signing up and trying it!Â That will always be the best test, imo... </p>\n<ol>\n<li>The files we shared are just the lean proofs. In this version of Aristotle, a separate system proposed the answer, which is what shows up in the formal statement. The lean prover did not get any information about reasoning, etc, from this system; just the final answer. We donâ€™t have more information to share on how this system works right now.</li>\n<li>On IMO formal statements: there was no official AI competition, so there were no official Lean formal statements. I think the IMO Committee is the right group to organize this next year if they think itâ€™s interesting!Â </li>\n<li><code>native_decide</code> â€“ itâ€™s a very powerful tactic, so weâ€™re not too eager to kill its usage. In fact I think Harmonic may be one of the top bug reporters for issues with it to the FRO <span aria-label=\"grinning\" class=\"emoji emoji-1f600\" role=\"img\" title=\"grinning\">:grinning:</span>. We rarely find correctness issues with it, and quickly report them when we do as well as update Aristotle to avoid them. It is of course totally possible for us to turn off <code>native_decide</code> for any run of our system (with little reduction in performance) should we have an application in mind that requires a smaller trusted code base, we just dont find RL for reasoning to warrant it.</li>\n<li>Formal statement for P6: sure, here you go:</li>\n</ol>\n<div class=\"codehilite\" data-code-language=\"Lean4\"><pre><span></span><code><span class=\"kn\">noncomputable</span><span class=\"w\"> </span><span class=\"kn\">def</span><span class=\"w\"> </span><span class=\"bp\">_</span><span class=\"n\">ANSWER_</span><span class=\"w\"> </span><span class=\"o\">:</span><span class=\"w\"> </span><span class=\"n\">â„•</span><span class=\"w\"> </span><span class=\"o\">:=</span><span class=\"w\"> </span><span class=\"gr\">sorry</span>\n\n<span class=\"c\">/-</span>\n<span class=\"cm\">Consider a 2025Ã—2025 grid of unit squares. Matilda wishes to place on the grid some</span>\n<span class=\"cm\">rectangular tiles, possibly of different sizes, such that each side of every tile lies on a grid line and</span>\n<span class=\"cm\">every unit square is covered by at most one tile.</span>\n<span class=\"cm\">Determine the minimum number of tiles Matilda needs to place so that each row and each column</span>\n<span class=\"cm\">of the grid has exactly one unit square that is not covered by any tile.</span>\n<span class=\"cm\">-/</span>\n<span class=\"kn\">theorem</span><span class=\"w\"> </span><span class=\"n\">problem_IMO_2025_P6</span>\n<span class=\"w\">    </span><span class=\"o\">(</span><span class=\"n\">GoodCover</span><span class=\"w\"> </span><span class=\"o\">:</span><span class=\"w\"> </span><span class=\"n\">Set</span><span class=\"w\"> </span><span class=\"o\">(</span><span class=\"n\">Finset</span><span class=\"w\"> </span><span class=\"o\">(</span><span class=\"n\">NonemptyInterval</span><span class=\"w\"> </span><span class=\"o\">(</span><span class=\"n\">Fin</span><span class=\"w\"> </span><span class=\"mi\">2025</span><span class=\"w\"> </span><span class=\"bp\">Ã—</span><span class=\"w\"> </span><span class=\"n\">Fin</span><span class=\"w\"> </span><span class=\"mi\">2025</span><span class=\"o\">))))</span>\n<span class=\"w\">    </span><span class=\"o\">(</span><span class=\"n\">hGoodCover</span><span class=\"w\"> </span><span class=\"o\">:</span><span class=\"w\"> </span><span class=\"bp\">âˆ€</span><span class=\"w\"> </span><span class=\"n\">S</span><span class=\"o\">,</span><span class=\"w\"> </span><span class=\"n\">S</span><span class=\"w\"> </span><span class=\"bp\">âˆˆ</span><span class=\"w\"> </span><span class=\"n\">GoodCover</span><span class=\"w\"> </span><span class=\"bp\">â†”</span>\n<span class=\"w\">      </span><span class=\"n\">Set</span><span class=\"bp\">.</span><span class=\"n\">PairwiseDisjoint</span><span class=\"w\"> </span><span class=\"n\">S</span><span class=\"bp\">.</span><span class=\"n\">toSet</span><span class=\"w\"> </span><span class=\"n\">SetLike</span><span class=\"bp\">.</span><span class=\"n\">coe</span><span class=\"w\"> </span><span class=\"bp\">âˆ§</span>\n<span class=\"w\">        </span><span class=\"o\">(</span><span class=\"bp\">âˆ€</span><span class=\"w\"> </span><span class=\"n\">i</span><span class=\"o\">,</span><span class=\"w\"> </span><span class=\"bp\">âˆƒ!</span><span class=\"w\"> </span><span class=\"n\">j</span><span class=\"o\">,</span><span class=\"w\"> </span><span class=\"o\">(</span><span class=\"n\">i</span><span class=\"o\">,</span><span class=\"w\"> </span><span class=\"n\">j</span><span class=\"o\">)</span><span class=\"w\"> </span><span class=\"bp\">âˆ‰</span><span class=\"w\"> </span><span class=\"bp\">â‹ƒ</span><span class=\"w\"> </span><span class=\"n\">t</span><span class=\"w\"> </span><span class=\"bp\">âˆˆ</span><span class=\"w\"> </span><span class=\"n\">S</span><span class=\"o\">,</span><span class=\"w\"> </span><span class=\"o\">(</span><span class=\"n\">t</span><span class=\"w\"> </span><span class=\"o\">:</span><span class=\"w\"> </span><span class=\"n\">Set</span><span class=\"w\"> </span><span class=\"o\">(</span><span class=\"n\">Fin</span><span class=\"w\"> </span><span class=\"mi\">2025</span><span class=\"w\"> </span><span class=\"bp\">Ã—</span><span class=\"w\"> </span><span class=\"n\">Fin</span><span class=\"w\"> </span><span class=\"mi\">2025</span><span class=\"o\">)))</span><span class=\"w\"> </span><span class=\"bp\">âˆ§</span>\n<span class=\"w\">        </span><span class=\"o\">(</span><span class=\"bp\">âˆ€</span><span class=\"w\"> </span><span class=\"n\">j</span><span class=\"o\">,</span><span class=\"w\"> </span><span class=\"bp\">âˆƒ!</span><span class=\"w\"> </span><span class=\"n\">i</span><span class=\"o\">,</span><span class=\"w\"> </span><span class=\"o\">(</span><span class=\"n\">i</span><span class=\"o\">,</span><span class=\"w\"> </span><span class=\"n\">j</span><span class=\"o\">)</span><span class=\"w\"> </span><span class=\"bp\">âˆ‰</span><span class=\"w\"> </span><span class=\"bp\">â‹ƒ</span><span class=\"w\"> </span><span class=\"n\">t</span><span class=\"w\"> </span><span class=\"bp\">âˆˆ</span><span class=\"w\"> </span><span class=\"n\">S</span><span class=\"o\">,</span><span class=\"w\"> </span><span class=\"o\">(</span><span class=\"n\">t</span><span class=\"w\"> </span><span class=\"o\">:</span><span class=\"w\"> </span><span class=\"n\">Set</span><span class=\"w\"> </span><span class=\"o\">(</span><span class=\"n\">Fin</span><span class=\"w\"> </span><span class=\"mi\">2025</span><span class=\"w\"> </span><span class=\"bp\">Ã—</span><span class=\"w\"> </span><span class=\"n\">Fin</span><span class=\"w\"> </span><span class=\"mi\">2025</span><span class=\"o\">))))</span><span class=\"w\"> </span><span class=\"o\">:</span>\n<span class=\"w\">    </span><span class=\"n\">IsLeast</span><span class=\"w\"> </span><span class=\"o\">(</span><span class=\"n\">Finset</span><span class=\"bp\">.</span><span class=\"n\">card</span><span class=\"w\"> </span><span class=\"bp\">''</span><span class=\"w\"> </span><span class=\"n\">GoodCover</span><span class=\"o\">)</span><span class=\"w\"> </span><span class=\"bp\">_</span><span class=\"n\">ANSWER_</span><span class=\"w\"> </span><span class=\"o\">:=</span><span class=\"w\"> </span><span class=\"k\">by</span>\n<span class=\"w\">  </span><span class=\"gr\">sorry</span>\n</code></pre></div>",
        "id": 531713832,
        "sender_full_name": "Tudor",
        "timestamp": 1753830422
    },
    {
        "content": "<p>I think if you have a proof using <code>ofReduceBool</code> (via <code>native_decide</code> or otherwise), it thus needs manual review (like Kim did), and if a proof (as opposed to a statement) needs manual review - if the generated olean can't pass through lean4checker because of use of <code>ofReduceBool</code> - its status is that of an <em>informal</em> solution to the problem, not a formally verified solution - anything less than a properly typed term depending only on the three standard axioms might be an informal solution, but not a formally verified one. As noted in the thread split off this one, <code>native_decide</code> is a reasonable tool at intermediate stages in writing a proof, just like <code>sorry</code>; it just shouldn't appear in the final claimed formal proof.</p>",
        "id": 531730431,
        "sender_full_name": "Joseph Myers",
        "timestamp": 1753840717
    },
    {
        "content": "<p>On answers: I suggest putting the same explanation in <a href=\"https://github.com/harmonic-ai/IMO2025/issues/1\">https://github.com/harmonic-ai/IMO2025/issues/1</a> where someone else has asked the same question (or in the repository README, of course).</p>",
        "id": 531730897,
        "sender_full_name": "Joseph Myers",
        "timestamp": 1753840982
    },
    {
        "content": "<p>On shared formal statements: it's true it was emphasized at the IMO that testing models on IMO problems was not a competition of the AIs (and human-oriented thresholds such as that for gold medals are rather arbitrary in scientific terms). What I'm interested in here is <em>scientific evaluation</em> of the capabilities of AIs. As indicated in <a class=\"message-link\" href=\"/#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Seed.20Prover.20Achieves.20Silver-Level.20Score.20at.20IMO.202025/near/530418476\">#Machine Learning for Theorem Proving &gt; Seed Prover Achieves Silver-Level Score at IMO 2025 @ ðŸ’¬</a> where I suggested various ways of doing more nuanced evaluations than \"can AI solve the IMO problems?\", one thing that would be relevant for such evaluations is a common Lean version of the problems. So I made clear on Zulip in advance of the IMO that a common Lean version would be desirable for more comparable data in such an evaluation, and provided my suggested conventions (so challenging anyone disagreeing about the best conventions for such statements to enter into public discussion of their own preferred conventions - of course even with common conventions, different people are still going to come up with different formal statements of the more complicated or combinatorial problems), and I believe the IMO was ready to provide Lean versions if any of the AIs wanted them (at least the Chief Coordinator was asking me about providing such versions at the start of the IMO, a few days before the conclusion was reached that all the AIs only wanted the problems in English).</p>",
        "id": 531732148,
        "sender_full_name": "Joseph Myers",
        "timestamp": 1753841771
    },
    {
        "content": "<p>(I should add that geometry solutions based on a semi-formal domain-specific language and depending on checking diagrams for configuration / angle orientation information, including AlphaGeometry's one last year, also have the status of an informal solution, not a formal one, when you get precise about exactly what counts as a formally verified proof.)</p>",
        "id": 531732606,
        "sender_full_name": "Joseph Myers",
        "timestamp": 1753842047
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110087\">Kim Morrison</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Harmonic.3A.20IMO.20Livestream/near/531548201\">said</a>:</p>\n<blockquote>\n<p>A scary feature of two of their <code>native_decide</code> calls is that the corresponding <code>#eval</code> calls will generate panics, and they are relying on the default values. True, but ... not reassuring.</p>\n</blockquote>\n<p>It also generates panics if you do extract goal on them: taking the first <code>native_decide</code> from their P4 file, and extracting goal gives a panic. It's not hard to reproduce, taking definitions directly from their repo: <a href=\"https://live.lean-lang.org/#codez=JYWwDg9gTgLgBAWQIYwBYBtgCMBQOAmApgGZwDKcAFAHJwBccgqIQCU9T9AvDnHOofOiRQA5oQDOMAApQIYQlAAiwAG7Ax0MZyrUUAOjAy5ilWo1xqzXethUA7XECmRHFvNuvIaInTZ8pautiANoADAC6AIRwANTuIuJShr4mAYEAjBHRsZ4JPsb+GoEATBF4RKQAStpsLGyAWIScbpQUtAy1rAD0Va2uBCRwAMYA+gDWVKMtTKwMjA08lDR6+MlmFlbQ8JT2gCZEzszMgcMAtOnheGiE0IQgcIQAHjBQSP0whPiDqVSoQwDMbEOjv2CcA4cG+rEoqEGUDYHwAPHBKsEpnAADX/UFwIEg350EFYACebgAdigVIRBkR+sAiEA\">https://live.lean-lang.org/#codez=JYWwDg9gTgLgBAWQIYwBYBtgCMBQOAmApgGZwDKcAFAHJwBccgqIQCU9T9AvDnHOofOiRQA5oQDOMAApQIYQlAAiwAG7Ax0MZyrUUAOjAy5ilWo1xqzXethUA7XECmRHFvNuvIaInTZ8pautiANoADAC6AIRwANTuIuJShr4mAYEAjBHRsZ4JPsb+GoEATBF4RKQAStpsLGyAWIScbpQUtAy1rAD0Va2uBCRwAMYA+gDWVKMtTKwMjA08lDR6+MlmFlbQ8JT2gCZEzszMgcMAtOnheGiE0IQgcIQAHjBQSP0whPiDqVSoQwDMbEOjv2CcA4cG+rEoqEGUDYHwAPHBKsEpnAADX/UFwIEg350EFYACebgAdigVIRBkR+sAiEA</a></p>",
        "id": 531736025,
        "sender_full_name": "Bhavik Mehta",
        "timestamp": 1753844281
    },
    {
        "content": "<p>Another two curious points about this repo: </p>\n<ul>\n<li>The statements of theorems don't match, from the Statement and solution lean files.</li>\n<li>The HarmonicLean.lean file only imports one thing on top of mathlib, which means running <code>lake build</code> from the root doesn't actually build or check any of the solutions (and <code>lake exe mk_all</code> fails)</li>\n</ul>",
        "id": 531736307,
        "sender_full_name": "Bhavik Mehta",
        "timestamp": 1753844448
    },
    {
        "content": "<p>The panics are maybe because of the use of <code>[i]!</code>(unsafe list element extraction) in the <em>statement</em>. In my statement in IMOLean I used <code>List.take</code> and <code>List.sum</code>, there are of course other ways of doing things if you want to express the sum of three elements explicitly by their indices, that don't depend on using unsafe definitions in the problem statement. I didn't put anything about avoiding such unsafe definitions in my suggested conventions because it never occurred to me that people would want to use such definitions in problem statements (as opposed to unverified programs) in the first place.</p>",
        "id": 531737359,
        "sender_full_name": "Joseph Myers",
        "timestamp": 1753845129
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"266253\">Joseph Myers</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Harmonic.3A.20IMO.20Livestream/near/531737359\">said</a>:</p>\n<blockquote>\n<p>The panics are maybe because of the use of <code>[i]!</code>(unsafe list element extraction) in the <em>statement</em>.</p>\n</blockquote>\n<p>Yes, it's because of this, but it's also because it's combined with the use of <code>native_decide</code> which performs an evaluation. A proof of this avoiding <code>ofReduceBool</code> would probably go via <a href=\"https://leanprover-community.github.io/mathlib4_docs/find/?pattern=List.getElem%21#doc\">docs#List.getElem!</a>_eq_getElem?_getD, and not have any panics.</p>",
        "id": 531743603,
        "sender_full_name": "Bhavik Mehta",
        "timestamp": 1753848804
    },
    {
        "content": "<p>Speaking as someone that is very interested in the formal verification aspects of Lean, as I am sure harmonic is as well:</p>\n<p>My ideal future is not where everyone stops using <code>native_decide</code>; my ideal future would be when <code>native_decide</code> (or something equally as powerful) becomes safe enough to use, we could trust it enough to let AIs use it without needing manual verification, at least for formal verification tasks. Trusting the compiler is something I could (potentially) live with, but the <a href=\"#narrow/channel/113488-general/topic/Using.20.60native_decide.60.20to.20prove.20False.3F/with/531843397\">known exploits</a> are what is currently making it necessary to manually check <code>native_decide</code> proofs.</p>",
        "id": 531866693,
        "sender_full_name": "GasStationManager",
        "timestamp": 1753887995
    },
    {
        "content": "<p>I expect that any cases of <code>native_decide</code> likely to be of use in mathematical proofs (other than the limited cases of very large computations such as verifying a terabyte-sized SAT certificate) are also ones where a tactic should be able to follow an evaluation procedure that generates a properly typed term, not depending on <code>ofReduceBool</code>, that can be exported from Lean and checked with an external checker.</p>",
        "id": 531909913,
        "sender_full_name": "Joseph Myers",
        "timestamp": 1753902143
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"662620\">Andy Jiang</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Harmonic.3A.20IMO.20Livestream/near/531495996\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"780541\">Justin Asher</span> <a href=\"#narrow/stream/219941-Machine-Learning-for-Theorem-Proving/topic/Harmonic.3A.20IMO.20Livestream/near/531495305\">said</a>:</p>\n<blockquote>\n<p>I agree that AlphaProof can be hard to read and debug. </p>\n<p>If you look <a href=\"https://github.com/dwrensha/compfiles/tree/main/Compfiles\">here</a>, you can find some previous formalizations of IMO problems and their solutions in Lean. I ran a script and found that the longest IMO solution from there is 47k characters, so 96k is definitely more than what would be expected (P5 is also 98k).</p>\n<p>And yes, there are not too many unnecessary have claims in Harmonic's solutions, albeit I have noticed an excess in other systems since they are trying to get compiler feedback and mimic the natural language proofs.</p>\n</blockquote>\n<p>Isn't there possible selection bias on what people formalized?</p>\n</blockquote>\n<p>The two longest IMO solutions in the mathlib archive are mine to IMO 2024 P5 and P3. Since I set out to formalize all six problems from IMO 2024 (still setting up geometrical theory in preparation for doing P4, PR reviews welcome), there's fairly limited scope for selection bias in those particular problems, and I think the distribution in terms of formalization difficulty is probably fairly consistent for the past 20 years or so (maybe perturbed slightly by the adoption of the Smith problem selection protocol in 2013 which ensures that problems 1, 2, 4, 5 include one from each of the four topic areas).</p>\n<p>What is biased there is that (a) those solutions have been golfed in the course of the mathlib review process and (b) since I was aiming for the mathlib archive all along, I was also putting any more generally useful lemmas in mathlib proper, whereas an AI solving a problem that shows up API gaps in mathlib will embed whatever proofs it needs directly in its solution (though hopefully AIs might be able to suggest lemmas for mathlib in future). (I fully expect that human formalizations of 2025 P4 would result in extra API for <code>properDivisors</code> being added to mathlib, for example. We've already had discussions on Zulip of how human formalizations of P1 that work with my geometrically oriented statement that actually uses lines in Euclidean space would result in API being added to support manipulating such objects expressed with concrete coordinates.)</p>",
        "id": 531912117,
        "sender_full_name": "Joseph Myers",
        "timestamp": 1753902902
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"784829\">Tudor</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Harmonic.3A.20IMO.20Livestream/near/531713832\">said</a>:</p>\n<blockquote>\n<p>The files we shared are just the lean proofs. In this version of Aristotle, a separate system proposed the answer, which is what shows up in the formal statement. The lean prover did not get any information about reasoning, etc, from this system; just the final answer. We donâ€™t have more information to share on how this system works right now.</p>\n</blockquote>\n<p>Thanks <span class=\"user-mention\" data-user-id=\"784829\">@Tudor</span> for weighing in here. </p>\n<ol>\n<li>\n<p>Did the separate system generate the full \"statement only\" files, or just propose the numerical answer for humans to use in producing those files?</p>\n</li>\n<li>\n<p>How long did this whole process take: first for the separate system and then for Aristotle to generate the formal proofs?</p>\n</li>\n</ol>",
        "id": 532115789,
        "sender_full_name": "Emily Riehl",
        "timestamp": 1753978333
    },
    {
        "content": "<p>This <code>fast_decide</code> tactic is useful for replacing <code>native_decide</code> when <code>decide</code> and <code>rfl</code> don't work:</p>\n<p><a href=\"https://github.com/girving/interval/blob/main/Interval/Tactic/Decide.lean\">https://github.com/girving/interval/blob/main/Interval/Tactic/Decide.lean</a></p>",
        "id": 532476063,
        "sender_full_name": "Geoffrey Irving",
        "timestamp": 1754158146
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"514145\">@Geoffrey Irving</span> Does it actually help in practice?</p>",
        "id": 532485531,
        "sender_full_name": "Jason Rute",
        "timestamp": 1754166495
    },
    {
        "content": "<p>Yes, I very frequently find cases where it is required, though the <a href=\"https://github.com/girving/interval\">https://github.com/girving/interval</a> repo is very calculation heavy which is why it comes up so much. I'm updating for recently mathlib now, and for some reason need to use it a lot more than I used to.</p>",
        "id": 532485647,
        "sender_full_name": "Geoffrey Irving",
        "timestamp": 1754166594
    },
    {
        "content": "<p>Have you tried harmonics proofs but with your tactic instead of native_decide?  Also if this works so well, why not add it to lean or mathlib, or even replace decide with this faster code?</p>",
        "id": 532485776,
        "sender_full_name": "Jason Rute",
        "timestamp": 1754166702
    },
    {
        "content": "<p>(If I recall correctly, Numina also had a number of native_decide proofs for minif2f that could be tried.)</p>",
        "id": 532485872,
        "sender_full_name": "Jason Rute",
        "timestamp": 1754166788
    },
    {
        "content": "<p>(And I think equational theories has a native_decide proof since decide was am too slow, but I imagine they would have already tried something like this.)</p>",
        "id": 532485987,
        "sender_full_name": "Jason Rute",
        "timestamp": 1754166921
    },
    {
        "content": "<p>Day job mostly blocks me upstreaming stuff, alas (due to lack of time). And no, I haven't tried Harmonic's proofs.</p>",
        "id": 532486043,
        "sender_full_name": "Geoffrey Irving",
        "timestamp": 1754166966
    },
    {
        "content": "<p>How does <code>fast_decide</code> compare to <code>decide +kernel</code>?</p>",
        "id": 532584705,
        "sender_full_name": "Bhavik Mehta",
        "timestamp": 1754244976
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"514145\">Geoffrey Irving</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Harmonic.3A.20IMO.20Livestream/near/532476063\">schrieb</a>:</p>\n<blockquote>\n<p>This <code>fast_decide</code> tactic is useful for replacing <code>native_decide</code> when <code>decide</code> and <code>rfl</code> don't work:</p>\n<p><a href=\"https://github.com/girving/interval/blob/main/Interval/Tactic/Decide.lean\">https://github.com/girving/interval/blob/main/Interval/Tactic/Decide.lean</a></p>\n</blockquote>\n<p>May be subsumed by <code>decide +kernel</code> these days.</p>",
        "id": 532588374,
        "sender_full_name": "Joachim Breitner",
        "timestamp": 1754247486
    },
    {
        "content": "<p>For anyone curious on the stats relevant here:</p>\n<ul>\n<li>There is one native_decide in P3, that checks that <code>padicValNat 2 8 = 3</code>. This doesn't work with any version of <code>decide +kernel</code> or <code>fast_decide</code>, because <code>padicValNat</code> is defined in terms of <code>Nat.find</code>, which is in terms of well-founded recursion, which the kernel cannot reduce.</li>\n<li>In our first proof of P4, we have four native_decide's. One is checking that <code>3 â‰¤ ({1, 2, 3} : Finset Nat).card</code>. This is easily done by <code>decide</code> or even just <code>rfl</code>. The other three all involve <code>Finset.sort</code>, which ultimately is built on (Edit: corrected here) <code>List.mergeSort</code> which uses well-founded recursion and doesn't kernel reduce. So none of these <code>decide</code> tactics work on that, again except for actual native_decide.</li>\n<li>In our second proof of P4, there are 11 native_decide's; 10 are for evaluating <code>padicValNat</code>, and one is for <code>Nat.factorization</code> (which is defined immediately in terms of padicValNat).</li>\n</ul>",
        "id": 532598762,
        "sender_full_name": "Alex Meiburg",
        "timestamp": 1754254683
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"448405\">Alex Meiburg</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Harmonic.3A.20IMO.20Livestream/near/532598762\">said</a>:</p>\n<blockquote>\n<ul>\n<li>In our first proof of P4, we have four native_decide's. One is checking that <code>3 â‰¤ ({1, 2, 3} : Finset Nat).card</code>. This is easily done by <code>decide</code> or even just <code>rfl</code>. The other three all involve <code>Finset.sort</code>, which ultimately is built on <code>Quot.lift</code> and doesn't reduce in the kernel. So none of these <code>decide</code> tactics work on that, again except for actual native_decide.</li>\n</ul>\n</blockquote>\n<p>The problem is probably not <code>Quot.lift</code>, but <a href=\"https://leanprover-community.github.io/mathlib4_docs/find/?pattern=List.mergeSort#doc\">docs#List.mergeSort</a> being defined in terms of well-founded recursion. <code>Quot.lift</code> actually reduces fine most of the time.</p>",
        "id": 532599437,
        "sender_full_name": "Aaron Liu",
        "timestamp": 1754255090
    },
    {
        "content": "<p>oops, you're right! Good catch haha. (and here I was thinking to myself, I thought Quot.lift was ok...? but I'd convinced myself wrong.)</p>",
        "id": 532599995,
        "sender_full_name": "Alex Meiburg",
        "timestamp": 1754255458
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"470149\">Joachim Breitner</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Harmonic.3A.20IMO.20Livestream/near/532588374\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"514145\">Geoffrey Irving</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Harmonic.3A.20IMO.20Livestream/near/532476063\">schrieb</a>:</p>\n<blockquote>\n<p>This <code>fast_decide</code> tactic is useful for replacing <code>native_decide</code> when <code>decide</code> and <code>rfl</code> don't work:</p>\n<p><a href=\"https://github.com/girving/interval/blob/main/Interval/Tactic/Decide.lean\">https://github.com/girving/interval/blob/main/Interval/Tactic/Decide.lean</a></p>\n</blockquote>\n<p>May be subsumed by <code>decide +kernel</code> these days.</p>\n</blockquote>\n<p>Confirmed, all of my <code>fast_decide</code> uses can be replaced by <code>decide +kernel</code>. Neat!</p>",
        "id": 532982309,
        "sender_full_name": "Geoffrey Irving",
        "timestamp": 1754424172
    },
    {
        "content": "<p>how long before aristotle comes out of beta?</p>",
        "id": 533163579,
        "sender_full_name": "Jared green",
        "timestamp": 1754506972
    },
    {
        "content": "<p>Working on it!</p>",
        "id": 533206417,
        "sender_full_name": "Tudor",
        "timestamp": 1754533714
    }
]