[
    {
        "content": "<p>Are there tools / ongoing ML research on :</p>\n<ol>\n<li>Decompiling lean proof terms into succinct and correct tactic proofs. I recall that there is already some LLM stuff on decompiling in other programming languages. The key point is of course for proofs to be succinct and use more powerful tactics like simp, linarith, or ring, rather than just output <code>exact &lt;term&gt;</code></li>\n<li>Translating tactic level proofs from one ITP to another, say Coq to Lean or vice versa.</li>\n</ol>",
        "id": 491172677,
        "sender_full_name": "Shreyas Srinivas",
        "timestamp": 1735475469
    },
    {
        "content": "<p>I think both are good topics, but I know very little work done on either.  As for the first, I don't recall seeing anything.  But I also don't see a lot of direct applications (except for one I'll mention below).  Do you have something in mind?</p>",
        "id": 491231405,
        "sender_full_name": "Jason Rute",
        "timestamp": 1735529290
    },
    {
        "content": "<p>A related topic is just cleaning up proofs like in Improver, <a class=\"stream-topic\" data-stream-id=\"113488\" href=\"/#narrow/channel/113488-general/topic/ImProver.20discussion\">#general &gt; ImProver discussion</a>.  (Actually, one should check if Improver does term proof to tractic translation.)  Also, it's been discussed that if RL agents like AlphaProof give really weird and non-idiomatic proofs, then maybe another AI agent needs to be used to clean them up.</p>",
        "id": 491231408,
        "sender_full_name": "Jason Rute",
        "timestamp": 1735529296
    },
    {
        "content": "<p>As for translation, I've seen it talked about occasionally.  Everything from Lean to Coq (or visa-versa) to just Lean 3 to Lean 4 (when the port was happening).  Somewhat recently, there was a thread about how GPT-4 is good at translating from Lean to Coq.  <a class=\"stream-topic\" data-stream-id=\"219941\" href=\"/#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/ChatGPT.20can.20help.20translate.20between.20Coq.C2.A0and.20Lean\">#Machine Learning for Theorem Proving &gt; ChatGPT can help translate between Coq and Lean</a>.  (I doubt it would be good in the other direction since GPT-4 seems bad at Lean syntax.)  And another one about translating from Adga to TypeScript: <a class=\"stream-topic\" data-stream-id=\"219941\" href=\"/#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Transpiling.20code\">#Machine Learning for Theorem Proving &gt; Transpiling code</a> Also, here are some much older musings of mine on the subject well before ChatGPT came out: <a class=\"stream-topic\" data-stream-id=\"219941\" href=\"/#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Translating.20between.20ITPs.20with.20machine.20learning\">#Machine Learning for Theorem Proving &gt; Translating between ITPs with machine learning</a></p>",
        "id": 491231420,
        "sender_full_name": "Jason Rute",
        "timestamp": 1735529304
    },
    {
        "content": "<p>Also <span class=\"user-mention\" data-user-id=\"110193\">@Cyril Cohen</span> was (or still is?) hiring a postdoc to work on translation between Lean and Coq.  I think the project is to basically automatically translate theorems from Mathlib to math-comp and/or the other direction.  <a class=\"stream-topic\" data-stream-id=\"284757\" href=\"/#narrow/channel/284757-job-postings/topic/Postdoc.3A.20ML.20translation.20between.20formal.20math.20libraries\">#job postings &gt; Postdoc: ML translation between formal math libraries</a></p>",
        "id": 491231422,
        "sender_full_name": "Jason Rute",
        "timestamp": 1735529307
    },
    {
        "content": "<p>One project I have thought about that would be useful and interesting is to combine old-school logical transpilation with ML translation.  The \"old-school\" approach is to find some logical way to translate from one language to the other.  If the source logic is weaker than the target (like Metamath to Lean,  or HOL-Light to Coq)  then it can be fairly easily done (as in <span class=\"user-mention\" data-user-id=\"110049\">@Mario Carneiro</span>'s translation from Metamath to Lean).  There are also systems like Duducki for this sort of work, including the recent <a href=\"https://github.com/Deducteam/coq-hol-light\">translation from HOL-Light to Coq</a>.  But the challenge is in alignment.  You don't want to use the source version of natural numbers.  You want to use the target version.  One can of course manually align (as I think the above projects have done), but I think a very interesting project would be to do automatic alignment with AI.  So (1) automatically find the matching definitions, (2) automatically prove they are isomorphic, (3) automatically translate the statement of one theorem to another along this equivalence, (4) automatically replace the messy theorem statement with a more idiomatic one, (5) translate the proof to one which doesn't use the source definitions and lemmas at all.  Each step is harder than the previous (more or less).  <a href=\"https://www.sciencedirect.com/science/article/pii/S0747717118300348\">Here is an old work on ML alignment of definitions</a> (before neural networks were common here).</p>",
        "id": 491231447,
        "sender_full_name": "Jason Rute",
        "timestamp": 1735529341
    },
    {
        "content": "<p>(And of course natural language to formal \"auto-formalization\" is a hot topic.  In many ways formal to formal should be easier, so if we are making progress on auto-formalization, maybe we are making progress on formal-to-formal translation without even trying.)</p>",
        "id": 491231637,
        "sender_full_name": "Jason Rute",
        "timestamp": 1735529453
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"115715\">Jason Rute</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Questions.20to.20the.20ML.20community/near/491231405\">said</a>:</p>\n<blockquote>\n<p>I think both are good topics, but I know very little work done on either.  As for the first, I don't recall seeing anything.  But I also don't see a lot of direct applications (except for one I'll mention below).  Do you have something in mind?</p>\n</blockquote>\n<p>The motivation is actually point 2. I wondered if we could use the following pipeline for translation : Elaborate lean/coq tactic proof to term =&gt; translate proof terms more systematically to coq/lean <br>\n =&gt; decompile to a succinct tactic proof.</p>\n<p>The nice thing is that of course we don't have to test our decompiler against some artificial semantics, we know whether the decompiler accomplished its job by looking at lake build's output.</p>",
        "id": 491283321,
        "sender_full_name": "Shreyas Srinivas",
        "timestamp": 1735565906
    },
    {
        "content": "<p>A second (far more ambitious) motivation :  I was thinking about the whole interpretability area in ML (and discussing with people who work on it) and I wondered if studying a good network performing these translations would help us study how neural nets deal with proofs and build smaller/more efficient networks, more systematically.</p>",
        "id": 491283519,
        "sender_full_name": "Shreyas Srinivas",
        "timestamp": 1735566031
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"466334\">Shreyas Srinivas</span> <a href=\"#narrow/stream/219941-Machine-Learning-for-Theorem-Proving/topic/Questions.20to.20the.20ML.20community/near/491283321\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"115715\">Jason Rute</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Questions.20to.20the.20ML.20community/near/491231405\">said</a>:</p>\n<blockquote>\n<p>I think both are good topics, but I know very little work done on either.  As for the first, I don't recall seeing anything.  But I also don't see a lot of direct applications (except for one I'll mention below).  Do you have something in mind?</p>\n</blockquote>\n<p>The motivation is actually point 2. I wondered if we could use the following pipeline for translation : Elaborate lean/coq tactic proof to term =&gt; translate proof terms more systematically to coq/lean <br>\n =&gt; decompile to a succinct tactic proof.</p>\n</blockquote>\n<p>Interesting approach (and similar to what I was suggesting above).  I guess you still have to deal with two issues for the second step.  (1) Definitions and lemmas would need to be aligned (and that alignment would be different for different Coq libraries) or left duplicated, and the (2) Lean/Coq foundations are close enough that it might be a bit tricky to translate at the kernel level from one to the other since you can’t have a nice embedding of one logic in the other.  (Wait, I think it is known you can <a href=\"https://github.com/SkySkimmer/coq-lean-import\">translate Lean 3’s kernel into Coq</a>.)</p>",
        "id": 491285366,
        "sender_full_name": "Jason Rute",
        "timestamp": 1735567107
    },
    {
        "content": "<p>to clarify, I think ML can be useful in step 2 as well. When I say \"more systematically\" I mean that the translations could be localised in some sense (one subterm replaced by another)</p>",
        "id": 491285939,
        "sender_full_name": "Shreyas Srinivas",
        "timestamp": 1735567433
    },
    {
        "content": "<p>I think in the lean context, the more useful direction might be Isabelle HOL to Lean, since they apparently have a lot of classical math we don't (this is definitely true for algorithms). In this case the second step might be much more fuzzy</p>",
        "id": 491286067,
        "sender_full_name": "Shreyas Srinivas",
        "timestamp": 1735567502
    },
    {
        "content": "<p>The “problem” with Isabelle is that they also have a lot more very high powered tactics that are used quite frequently, and currently have no equivalent in lean. While the approach you describe might do away with that  issue on the surface, I would hazard a guess that in the chain isabelle tactic -&gt; isabelle proof term -&gt; lean proof term -&gt; lean tactics, when it comes to translating sledgehammer proofs, the last arrow is going to be nearly as hard as just generating the whole proof from scratch. I would expect this to have better luck in Coq, where it’s much more common to have handcrafted proof terms, which are relatively simple, as opposed to the monstrosities generated by SMT solvers. </p>\n<p>Maybe after Duper is up and running in a more stable form direct tactic to tactic translation could become more doable, but of course then you get the annoyance that the simpler logic of Isabelle means rewriting is going to work in situations where it won’t in lean, etc</p>",
        "id": 491380094,
        "sender_full_name": "Luigi Massacci",
        "timestamp": 1735633671
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"466290\">Luigi Massacci</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Questions.20to.20the.20ML.20community/near/491380094\">said</a>:</p>\n<blockquote>\n<p>Maybe after Duper is up and running in a more stable form direct tactic to tactic translation could become more doable, but of course then you get the annoyance that the simpler logic of Isabelle means rewriting is going to work in situations where it won’t in lean, etc</p>\n</blockquote>\n<p>For what it's worth, I suspect that Duper is already in a state where it could reproduce the work done by most <code>metis</code> calls. Aesop might similarly be able to reproduce the work done by most Isabelle <code>auto</code> calls, and although there isn't a stable Lean equivalent for Isabelle's <code>smt</code> calls yet, I believe that <a href=\"https://github.com/ufmg-smite/lean-smt\">lean-smt</a> is working in that direction. So we might be closer to having equivalents to Isabelle's automation than it seems.</p>\n<p>I do agree though that translating problems from Isabelle's logic to \"equivalent\" problems in Lean's logic might result in harder problems depending on how the translation is done.</p>",
        "id": 491400437,
        "sender_full_name": "Josh Clune",
        "timestamp": 1735648880
    },
    {
        "content": "<p>From the utility point of view, even a translator that works for a substantial fraction of Isabelle proofs would be a big step forward.</p>",
        "id": 491400547,
        "sender_full_name": "Shreyas Srinivas",
        "timestamp": 1735648971
    },
    {
        "content": "<p>That being said, I like this problem purely from the point of view of my second motivation, namely to explore interpretation and looking for composable patterns in the model.</p>",
        "id": 491400648,
        "sender_full_name": "Shreyas Srinivas",
        "timestamp": 1735649055
    },
    {
        "content": "<p>From the point of view of mathematics, I think that translating stuff from Isabelle to Lean is a far more inefficient approach than just redoing it in Lean anyway. This is what we did with the prime number theorem, for example, and it's what we're doing with finite-dimensionality of modular forms, and I don't really know of anything else in Isabelle AFP which we'd want in mathlib and which we don't have (although I'm open to being corrected here). But of course translating from Isabelle to Lean is independently an interesting question.</p>",
        "id": 491401097,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1735649415
    },
    {
        "content": "<p>I am looking at TCS stuff that I don't see any point in pushing to mathlib. But I recall someone mentioning  that there is a bunch of stuff with asymptotics that math folks also care about.</p>",
        "id": 491401204,
        "sender_full_name": "Shreyas Srinivas",
        "timestamp": 1735649513
    },
    {
        "content": "<p>From Coq, there is a lot of stuff translating which to lean would be a huge amount of grunt work</p>",
        "id": 491401358,
        "sender_full_name": "Shreyas Srinivas",
        "timestamp": 1735649590
    },
    {
        "content": "<p>This is mostly software verification stuff. Iris and <del>easycrypt</del>(ssprove, thanks Bas Spitters) are the biggest ones, but there are a number of smaller developments as well</p>",
        "id": 491401390,
        "sender_full_name": "Shreyas Srinivas",
        "timestamp": 1735649625
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"662442\">@Daniel Windham</span> might have interest in this discussion.  He was motivated by translating between ITPs.</p>",
        "id": 491403028,
        "sender_full_name": "Jason Rute",
        "timestamp": 1735650847
    },
    {
        "content": "<p>You're right about asmptotics and again my instinct is that it would just be easier to translate them by hand given the volume of material here</p>",
        "id": 491403340,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1735651116
    },
    {
        "content": "<p>Autoformalization between two systems with such different type theories is still a pipe dream and even it becomes a reality then the translations would be very unlikely to be idiomatic and maintainable (in my opinion)</p>",
        "id": 491403594,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1735651330
    },
    {
        "content": "<p>But I'm just saying that I don't see any argument for using these ideas to make mathlib better, I'm certainly not arguing against working on the idea in general. It sounds interesting and difficult (which is good)</p>",
        "id": 491403629,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1735651383
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110038\">Kevin Buzzard</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Questions.20to.20the.20ML.20community/near/491401097\">said</a>:</p>\n<blockquote>\n<p>and I don't really know of anything else in Isabelle AFP which we'd want in mathlib and which we don't have</p>\n</blockquote>\n<p>isn’t all the work of Eberl on complex path integrals in the afp?</p>",
        "id": 491407623,
        "sender_full_name": "Luigi Massacci",
        "timestamp": 1735654493
    },
    {
        "content": "<p>Fundamentally the problem of decompilation to tactics in Lean is a pattern matching problem on expression trees. Given an index of lemmas and some meta patterns describing the \"shape\" of terms generated by tactics, and the input term, the goal is to find subterms which can be successfully replaced by tactics + lemmas. I wonder if some form of recursive pattern matching guided by ML would be practical. I don't know how well neural networks fare at these tasks.</p>",
        "id": 491412351,
        "sender_full_name": "Shreyas Srinivas",
        "timestamp": 1735658121
    },
    {
        "content": "<p>To add to the above, I wouldn't be surprised to learn that there is a deterministic and composable set of tactics (perhaps SSR?) for which this can be accomplished much more easily.</p>",
        "id": 491421662,
        "sender_full_name": "Shreyas Srinivas",
        "timestamp": 1735664330
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"466290\">Luigi Massacci</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Questions.20to.20the.20ML.20community/near/491407623\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"110038\">Kevin Buzzard</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Questions.20to.20the.20ML.20community/near/491401097\">said</a>:</p>\n<blockquote>\n<p>and I don't really know of anything else in Isabelle AFP which we'd want in mathlib and which we don't have</p>\n</blockquote>\n<p>isn’t all the work of Eberl on complex path integrals in the afp?</p>\n</blockquote>\n<p>I talked to Manuel about this quite a bit and he explained to me a more simple approach than what he implemented (which I talked about with David Loeffler), probably that's what we want.</p>",
        "id": 491424442,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1735666187
    },
    {
        "content": "<p>It's hard to see the particular position of this approach in the future suppose that we can just easily do any proofs by human plus reasoning llm plus some autoformalization. Instead of translation between low level languages like Lean, Isabelle, maybe in the ideal world we should maintain a good informal proof and a stable great translator from informal to arbitrary formal language, which is my current project.</p>\n<p>Frankly speaking, I believe the value of many things needs to be carefully reevaluated after we fully utilize the potential of llms. It's easy to underestimate the potential of LLMs, after seeing it can't even reliably do the Lean4 syntax instead of Lean3. But there exist so many ways of composing AI system instead of using just one pass of a single LLM to overcome these superficial problems without even collecting more Lean data.</p>\n<p>Formalization, in my perspective, isn't a particularly intellectually challenging task. I fail to see why this would be a fundamental bottleneck for AI to make progress upon in the coming years.</p>\n<p>Because the rate of AI progressing is so fast, I'm trying to warn people from starting huge projects without evaluating its usefulness if AI just made another leap. AI has this problem of research problems quickly fading away because a new genre of method completely made them obselete.</p>\n<p>The elephant in the room is, what will the best workflow of formalization be like, after we figure out the right way to utilize LLMs? What is definitely not going to be disrupted by LLMs (assuming no significant additional resources are put to buff LLMs)?</p>",
        "id": 491552279,
        "sender_full_name": "Xiyu Zhai",
        "timestamp": 1735789317
    },
    {
        "content": "<ol>\n<li>It is an interesting challenge thanks to the second motivation I described above. Just an interesting problem in its own right. It is worthwhile looking for some combination of GoFAI and modern ML that might be cheaper, more understandable etc.</li>\n<li>AI progress is not easily predictable. The next gen LLM might indeed be slightly better at autoformalisation, but when applied in practice, LLMs seem to be uniformly disappointing so far. Benchmarks not reflecting reality and all that. In the equational theories project for example, where there was a lot of initial expectations around modern AI, the most effective tools turned out to be old fashioned theorem provers; by a wide margin. </li>\n<li>Even if 2 is not an issue, the newer models are behind increasingly expensive paywalls, which are only going to get higher when the VC driven hype is over, and the bills come due.</li>\n</ol>",
        "id": 491598245,
        "sender_full_name": "Shreyas Srinivas",
        "timestamp": 1735818077
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"466334\">Shreyas Srinivas</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Questions.20to.20the.20ML.20community/near/491401390\">said</a>:</p>\n<blockquote>\n<p>This is mostly software verification stuff. Iris and easycrypt are the biggest ones, but there are a number of smaller developments as well</p>\n</blockquote>\n<p>Easycrypt is a standalone tool, so not in Coq. Do you mean <a href=\"https://github.com/SSProve/ssprove\">https://github.com/SSProve/ssprove</a> ?</p>",
        "id": 491601493,
        "sender_full_name": "Bas Spitters",
        "timestamp": 1735819965
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"466120\">Xiyu Zhai</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Questions.20to.20the.20ML.20community/near/491552279\">said</a>:</p>\n<blockquote>\n<p>Formalization, in my perspective, isn't a particularly intellectually challenging task.</p>\n</blockquote>\n<p>I think the fact that formalization is \"just translation\" is a common misconception; many formalizations in mathlib have required lots of careful thought and I believe sometimes even development of new mathematics.</p>",
        "id": 491601513,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1735819984
    },
    {
        "content": "<p>Larry Paulson made a huge effort (semi-)automatically translating HOLlight's real analysis library to Isabelle. This may also be a source of inspiration.</p>",
        "id": 491601790,
        "sender_full_name": "Bas Spitters",
        "timestamp": 1735820148
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"259452\">@Bas Spitters</span> I didn’t realize it was an automatic translation.  I had the impression (I guess wrong) that he mostly did it manually. Are there details on how he did it?  Is assume that the close similarity of systems helped a lot.</p>",
        "id": 491608461,
        "sender_full_name": "Jason Rute",
        "timestamp": 1735823388
    },
    {
        "content": "<p>Here is a post from today by <span class=\"user-mention\" data-user-id=\"255566\">@Philip Zucker</span> on using ChatGPT to translate from Lean to some new theorem prover. <a href=\"https://www.philipzucker.com/cody_sheffer/\">https://www.philipzucker.com/cody_sheffer/</a> It is not clear from the blog if ChatGPT was helpful or not.</p>",
        "id": 491608834,
        "sender_full_name": "Jason Rute",
        "timestamp": 1735823581
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"115715\">@Jason Rute</span> yes, there was less automation than I remembered:<br>\n<a href=\"https://lawrencecpaulson.github.io/2022/09/14/Libraries.html\">https://lawrencecpaulson.github.io/2022/09/14/Libraries.html</a><br>\n<a href=\"https://lawrencecpaulson.github.io/2023/07/12/Metric_spaces.html\">https://lawrencecpaulson.github.io/2023/07/12/Metric_spaces.html</a></p>\n<blockquote>\n<p>Sometimes I was able to port proofs just by eyeballing the HOL Light versions, but often I had to run them in a HOL Light session, occasionally line by line. Sledgehammer did most of the work, and half the time I had no idea what the actual argument was. Well, I don’t really need to know.</p>\n</blockquote>\n<p>However, there is:<br>\n<a href=\"https://members.loria.fr/STourret/papers/isabelle24translation.pdf\">https://members.loria.fr/STourret/papers/isabelle24translation.pdf</a></p>",
        "id": 491611467,
        "sender_full_name": "Bas Spitters",
        "timestamp": 1735825010
    },
    {
        "content": "<p>Nothing very exotic. It was about par for the course of my experience using LLMs. Sometimes it nailed it, but pretty often it needed editting or just be tossed out. Going somewhat interactively lemma by lemma was much better than trying all at once. This was my transcript. <a href=\"https://chatgpt.com/share/6776116b-c4d4-8008-b3d0-d73c401feb05\">https://chatgpt.com/share/6776116b-c4d4-8008-b3d0-d73c401feb05</a> Interested if there is something better I should be doing. One small hope was that knuckledragger being in python removed a barrier to the ML ecosystem, and that Z3 could paper over low level manipulations allowing the LLM to take higher level steps.</p>",
        "id": 491611876,
        "sender_full_name": "Philip Zucker",
        "timestamp": 1735825235
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"310045\">Eric Wieser</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Questions.20to.20the.20ML.20community/near/491601513\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"466120\">Xiyu Zhai</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Questions.20to.20the.20ML.20community/near/491552279\">said</a>:</p>\n<blockquote>\n<p>Formalization, in my perspective, isn't a particularly intellectually challenging task.</p>\n</blockquote>\n<p>I think the fact that formalization is \"just translation\" is a common misconception; many formalizations in mathlib have required lots of careful thought and I believe sometimes even development of new mathematics.</p>\n</blockquote>\n<p>I'm not an expert of formalizing advanced mathematics in any sense. So I just speak up instincts, which represents a random guy outside of typical formalization community but would like to use formalization to make things more rigorous. Feel free to correct me if wrong. I prefer things to be open and corrected than closed and remain unfixed. In my language, this counts as prover-specific fixes. Many have to do with specific prover lacks certain features or just requires a very clean minimal set of axioms (like without axiom of choice). I expect the amount of these new mathematics is finite in a sense. Otherwise, it raises the question whether modern mathematics really has a solid foundation or is waiting for formalization to resolve many potential issues. As Mathlib4 is in its very early stages, I believe these fixes are pretty often. But as things go on, I expect things to be more and more stable and standardized.</p>\n<p>There's two kinds of formalization: formalization of a new branch of mathematics, which no similar field has been formalized; formalization of a piece of mathematics which no consider deep thinking is required. The second kind is what I believe is mostly chore and will be significantly accelerated by AI (not raw LLMs though). If one thinks more about analysis and combinatorics (for finite objects) instead of algebra, the second one is more prominent. I fully understand that the great thing of Lean is that Lean demonstrates the first kind can be solidly solved by provers like Lean.</p>\n<p>Maybe there is other types of formalization. But I'll make things very clear in the future that I refer to the second kind only when I say translation is simple. The first kind is in my eyes the typical kind of fundamentally nontrivial work, which we are very fortunate to be able to work on as we are still very early in terms of autoformalization.</p>\n<p>What would be more beneficial to the whole community, is to less focus on specific tooling, but a focus towards in general far more automatic pipeline.</p>\n<p>Basically the difficulty of translating to formal languages is not something to boast about. The easier the translation is, the better the prover is as a tool to verify correctness. The foundation should be expressive enough to easily express what we need to prove. To convince broader community, the priority is not to show how \"interesting\" formalization is, but to show how \"boring\" and \"trivial\" it can be. The value of formal verification as a mathematical subject and the value of formal verification as a tooling can be contrary to each other. Mathematicians care about how painless it can be to help them check proofs. Engineers care about how it can quickly help iterate designs by reducing bugs. For majority of us outsiders, we mostly care about the functionality of Lean as a tool. Most computer science subjects are like this. Operating systems, programming languages are designed with first priority to be easy to use, rather than challenging to use. I believe if we choose a fixed range of mathematical domains, the difficulty of formalization is finite and will be eventually entirely solved by AI.</p>\n<p>In short, in my amateur opinions, the end goal of the game is writing not a huge library of formalized mathematics. The end goal is creating a truly automatic pipeline with good principles to formalize mathematics, building upon previous experience in translating natural language to formal proofs.</p>",
        "id": 491612605,
        "sender_full_name": "Xiyu Zhai",
        "timestamp": 1735825616
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"259452\">@Bas Spitters</span> : yeah ssprove, sorry, I mix up these crypto framework names sometimes.</p>",
        "id": 491626533,
        "sender_full_name": "Shreyas Srinivas",
        "timestamp": 1735831876
    },
    {
        "content": "<p>Thanks <span class=\"user-mention\" data-user-id=\"115715\">@Jason Rute</span> for the tag. I'm finally catching up after the holiday break. <span class=\"user-mention\" data-user-id=\"241007\">@Jason Gross</span> may soon have a student working on Coq-to-Lean (or similar) proof translations with LLMs. He's interested in this in part as a research question: formal-to-formal proof translation could be a good stepping stone towards LLM-based proof repair and informal-to-formal proof assistance.</p>",
        "id": 492816223,
        "sender_full_name": "Daniel Windham",
        "timestamp": 1736455992
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"241007\">@Jason Gross</span> Can you tell us more about your plans? I know that <span class=\"user-mention\" data-user-id=\"110193\">@Cyril Cohen</span> is also interested in this topic.</p>",
        "id": 492899126,
        "sender_full_name": "Bas Spitters",
        "timestamp": 1736497531
    },
    {
        "content": "<p>We're targeting (semi)automatic LLM translation of software verification from Coq to Lean as a stepping stone to autoformalization of software verification, which itself is a stepping stone to getting o3 (or its successors) to generate the English which is then autoformalized, with the ultimate target being making it massively easier to verify both existing and newly written software.</p>\n<p>For this target, I think it doesn't much matter that the translation is idiomatic except insofar as being non-idiomatic makes it longer/harder to do the proofs and/or to reuse existing results.</p>",
        "id": 493001302,
        "sender_full_name": "Jason Gross",
        "timestamp": 1736532659
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"241007\">@Jason Gross</span> : is this a direct translation from tactic script to tactic script? Or is it like the pipeline I described above?</p>",
        "id": 493001573,
        "sender_full_name": "Shreyas Srinivas",
        "timestamp": 1736532764
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"241007\">@Jason Gross</span> you have o3 access? <span aria-label=\"smile\" class=\"emoji emoji-1f642\" role=\"img\" title=\"smile\">:smile:</span>  But I’m interested to seeing how the project goes.</p>",
        "id": 493008425,
        "sender_full_name": "Jason Rute",
        "timestamp": 1736535432
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"115715\">@Jason Rute</span>  I don't have o3 access (yet), but I imagine by the time we get formal =&gt; formal working, I might have o3 (or equivalent) access / more of the public will have it</p>",
        "id": 493008589,
        "sender_full_name": "Jason Gross",
        "timestamp": 1736535486
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"466334\">@Shreyas Srinivas</span> direct tactic script to tactic script.  Otherwise I don't think it's a very good stepping stone for doing autoformalization.  I'm thinking of possibly using <a href=\"https://github.com/SkySkimmer/coq-lean-import\">https://github.com/SkySkimmer/coq-lean-import</a> as a way of automatically validating the translations (that is, Coq ={LLM}=&gt; Lean ={coq-lean-import}=&gt; Coq should give ~ a coherent isomorphism</p>",
        "id": 493009166,
        "sender_full_name": "Jason Gross",
        "timestamp": 1736535716
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"241007\">@Jason Gross</span> Maybe a more realistic question is about your budget.  I think something like o3 with the hard thinking mode could do an amazing job especially if used in an agent-like framework where it had access to Lean/Coq internals like goal states and error messages.  But that could cost $1000+ per problem.  There is always a cost/benifit trade off with these AI systems.  For example, a lot of agents have switched to use GPt-4o instead of GPT-4 for this very reason.  The real challenge is to find the right tools for the job which balance cost and performance.</p>",
        "id": 493009546,
        "sender_full_name": "Jason Rute",
        "timestamp": 1736535858
    },
    {
        "content": "<p>But knowing the upper bound is also important, so expensive methods have their place.</p>",
        "id": 493009655,
        "sender_full_name": "Jason Rute",
        "timestamp": 1736535907
    },
    {
        "content": "<p>And costs will come down too.</p>",
        "id": 493009828,
        "sender_full_name": "Jason Rute",
        "timestamp": 1736535981
    },
    {
        "content": "<p>Exciting <span class=\"user-mention\" data-user-id=\"241007\">@Jason Gross</span> Yes, I was also thinking that the lean-import could play a role here. As you say, it's unlikely to give an equality, so HoTT or perhaps troqc may be relevant here.</p>",
        "id": 493028808,
        "sender_full_name": "Bas Spitters",
        "timestamp": 1736544824
    },
    {
        "content": "<p>re: o3, my experience with o1 (when I tested it on some Olympiad stuff) is it seemed to be RL-ed so heavily towards “find the answer” that even when I ask it to prove things, it just outputs “find the answer” type reasoning and not proofs. I suspect it doesn’t really know how to prove things at all because there’s no verifier for informal-to-informal to train on.</p>\n<p>Have other people found similar?</p>",
        "id": 493244133,
        "sender_full_name": "llllvvuu",
        "timestamp": 1736734911
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"607118\">@llllvvuu</span> Given how o1 does on the Putnam, I kind of wondered if something like that could be going on.  It is even possible that the reasoning traces are much more robust than the final “proof” would  suggest.  Like you said, it is a lot easier with RL to train it get the answer right than to get an informal proof right (even if internally it is doing something closer to the full proof, since that would guarantee a correct final answer).</p>",
        "id": 493245974,
        "sender_full_name": "Jason Rute",
        "timestamp": 1736736336
    },
    {
        "content": "<p>It seems to me that the accuracy of reasoning traces in LLMs in general, even with process reward modeling, greatly lag the accuracy of final answers. Indeed there is nothing requiring them to be accurate.</p>",
        "id": 493249319,
        "sender_full_name": "llllvvuu",
        "timestamp": 1736738993
    },
    {
        "content": "<p>But also there is nothing requiring them to be human understandable, so it is possible that they are more rigorous than they look on the surface.  But this is just a hunch.</p>",
        "id": 493249663,
        "sender_full_name": "Jason Rute",
        "timestamp": 1736739180
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"607118\">llllvvuu</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Questions.20to.20the.20ML.20community/near/493244133\">said</a>:</p>\n<blockquote>\n<p>o3, my experience with o1 (when I tested it on some Olympiad stuff) is it seemed to be RL-ed so heavily towards “find the answer” that even when I ask it to prove things, it just outputs “find the answer” type reasoning and not proofs. I suspect it doesn’t really know how to prove things at all because there’s no verifier for informal-to-informal to train on.</p>\n</blockquote>\n<p>This is interesting. It would be great if you can share the output/ChatGPT link here!</p>",
        "id": 493251112,
        "sender_full_name": "Ayush Agrawal",
        "timestamp": 1736740068
    },
    {
        "content": "<p>I think it would be great to have a channel where everyone can share their experience with o1 series on mathematics - proving or solving and also the ChatGPT outputs.</p>",
        "id": 493251764,
        "sender_full_name": "Ayush Agrawal",
        "timestamp": 1736740550
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"115715\">Jason Rute</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Questions.20to.20the.20ML.20community/near/493249663\">said</a>:</p>\n<blockquote>\n<p>But also there is nothing requiring them to be human understandable, so it is possible that they are more rigorous than they look on the surface.  But this is just a hunch.</p>\n</blockquote>\n<p>There's been the idea, for a while, that somewhere in embeddingspace, the model is thinking more intelligently than it knows how to put into words. (Put into tokens?) I didn't take this idea too seriously ~two years ago, but with RLed agents like o1/o3, I think it's quite plausible.</p>\n<p>I think models like <a href=\"https://arxiv.org/abs/2412.17747\">https://arxiv.org/abs/2412.17747</a> make this even more plausible. It's really encouraging the model to \"think\" in latent space across several non-human-readable tokens. It wasn't the first paper to try this, but it seems to be the first one to make it really work very well.</p>",
        "id": 493376939,
        "sender_full_name": "Alex Meiburg",
        "timestamp": 1736781384
    },
    {
        "content": "<p>What does this even mean? How does one gather conclusive evidence that this is happening?</p>",
        "id": 493377944,
        "sender_full_name": "Shreyas Srinivas",
        "timestamp": 1736781670
    },
    {
        "content": "<p>probing I assume</p>",
        "id": 493392026,
        "sender_full_name": "llllvvuu",
        "timestamp": 1736785308
    },
    {
        "content": "<blockquote>\n<p>What does this even mean?</p>\n</blockquote>\n<p>Well, deep networks essentially are finding circuits that compute things. At first order they're learning circuits to predict words, and at second order they're building \"circuits\" over spans of paragraphs to reach logical conclusions, just like humans are. (What is a proof but a circuit building up proof terms?) When it's just pretraining+finetuning, the second order circuits are really just learned from imitating human arguments. If it can accurately mimic human arguments token-by-token, then we hope this generally steers it towards mostly-right answers. The first order circuits (how to predict a token from its preceding tokens) can operate however the network wants to.</p>\n<p>If you do reinforcement learning, though, then you're sort of letting the second order circuit learn too. Instead of just imitating human arguments, it can synthesize its own arguments, possibly in a very different way, as long as it's producing correct answers. If you 'snap' each token produced to a text input before feeding it back in, then you're sort of anchoring this reasoning argument to be in text. Attention mechanisms still let it use intermediate-layer embeddings computed earlier, but this allows only \"shallow\" circuits in embedding space, and the deep second-order circuits are kept in human text.</p>\n<p>But if you stop 'snapping' and let tokens just be arbitrary embedding vectors, then you can differentiate all the way back through the model and really learn the second-order circuits. This puts you back in the domain of LSTMs instead of transformers. It's more expensive to train, but the circuits are now arbitrary depth and can do more complicated argument styles.</p>\n<p>This is the idea, at least.</p>\n<blockquote>\n<p>How does one gather conclusive evidence that this is happening?</p>\n</blockquote>\n<p>I think that's a wide open question. You do have this embedding token stream, so most evidence has to be something about observing what's going on in that stream, or some interventional experiments.</p>",
        "id": 493404455,
        "sender_full_name": "Alex Meiburg",
        "timestamp": 1736788628
    },
    {
        "content": "<p>A relevant thread from the Coq Zulip : <a href=\"https://coq.zulipchat.com/#narrow/channel/237977-Coq-users/topic/Translation.20of.20HOL-Light.20base.20library.20to.20Coq/near/495238985\">https://coq.zulipchat.com/#narrow/channel/237977-Coq-users/topic/Translation.20of.20HOL-Light.20base.20library.20to.20Coq/near/495238985</a></p>",
        "id": 495266469,
        "sender_full_name": "Shreyas Srinivas",
        "timestamp": 1737547339
    },
    {
        "content": "<p>It is a translation of HOL Light to Coq</p>",
        "id": 495266514,
        "sender_full_name": "Shreyas Srinivas",
        "timestamp": 1737547353
    }
]