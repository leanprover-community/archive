[
    {
        "content": "<p>We have submitted a technical report on  <a href=\"https://arxiv.org/abs/2410.15700\">arXiv</a> introducing a new set of open-source language models designed for theorem proving in Lean 4, including our newest policy model, InternLM2.5-StepProver, and its corresponding critic model, InternLM2.5-StepProver-critic. Our models achieve new state-of-the-art results on the miniF2F benchmark (65.9%) and the ProofNet benchmark (27.0%).</p>\n<p>We utilize Lean-Workbook, one of the largest open-source problem collections available, for large-scale expert iteration. We prove/disprove 17.0% of problems in Lean-Workbook-Plus, constituting an enhanced theorem proving dataset and showing significant improvement compared to only 9.5% of problems proved when Lean-Workbook-Plus was released. With the search trajectories obtained during the iteration, we train a critic model, InternLM2.5-StepProver-critic, to provide guidance for the policy model in searching for deeper (and better) proofs on average. The integration of a critic model shows clear performance improvement compared to naïve best-first search methods.</p>\n<p>The <a href=\"https://huggingface.co/internlm/internlm2_5-step-prover\">policy</a> and <a href=\"https://huggingface.co/internlm/internlm2_5-step-prover-critic\">critic</a> models, as well as the enhanced Lean-Workbook-Plus dataset, have been open-sourced on Hugging Face.</p>",
        "id": 478190002,
        "sender_full_name": "Zijian Wu",
        "timestamp": 1729564410
    },
    {
        "content": "<p>Also see our work on twitter: <a href=\"https://x.com/hungsuzh143318/status/1848604474555961804\">https://x.com/hungsuzh143318/status/1848604474555961804</a> <span aria-label=\"heart kiss\" class=\"emoji emoji-1f618\" role=\"img\" title=\"heart kiss\">:heart_kiss:</span></p>",
        "id": 478217685,
        "sender_full_name": "Huang Suozhi",
        "timestamp": 1729580760
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"724318\">Zijian Wu</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/InternLM2.2E5-StepProver/near/478190002\">said</a>:</p>\n<blockquote>\n<p>We have submitted a technical report on  <a href=\"https://arxiv.org/abs/2410.15700\">arXiv</a> introducing a new set of open-source language models designed for theorem proving in Lean 4, including our newest policy model, InternLM2.5-StepProver, and its corresponding critic model, InternLM2.5-StepProver-critic. Our models achieve new state-of-the-art results on the miniF2F benchmark (65.9%) and the ProofNet benchmark (27.0%).</p>\n<p>We utilize Lean-Workbook, one of the largest open-source problem collections available, for large-scale expert iteration. We prove/disprove 17.0% of problems in Lean-Workbook-Plus, constituting an enhanced theorem proving dataset and showing significant improvement compared to only 9.5% of problems proved when Lean-Workbook-Plus was released. With the search trajectories obtained during the iteration, we train a critic model, InternLM2.5-StepProver-critic, to provide guidance for the policy model in searching for deeper (and better) proofs on average. The integration of a critic model shows clear performance improvement compared to naïve best-first search methods.</p>\n<p>The <a href=\"https://huggingface.co/internlm/internlm2_5-step-prover\">policy</a> and <a href=\"https://huggingface.co/internlm/internlm2_5-step-prover-critic\">critic</a> models, as well as the enhanced Lean-Workbook-Plus dataset, have been open-sourced on Hugging Face.</p>\n</blockquote>\n<p>Interesting paper! I had a couple of questions</p>\n<ol>\n<li>Do you put just the last tactic or all previous tactics as part of the prompt in addition to the state. </li>\n<li>In theory the state should have all the information right so do you have a sense of why putting in the past tactics helps?</li>\n</ol>",
        "id": 478350473,
        "sender_full_name": "Sid",
        "timestamp": 1729624196
    },
    {
        "content": "<p>Very minor quibble: the report says that your score of 6/640 on PutnamBench is state-of-the-art, but it seems that as of <a href=\"https://openreview.net/forum?id=kk3mSjVCUO\">a few weeks ago</a> the <a href=\"https://trishullab.github.io/PutnamBench/leaderboard.html\">leading score</a> is 7/640.</p>",
        "id": 478351540,
        "sender_full_name": "Heather Macbeth",
        "timestamp": 1729624593
    },
    {
        "content": "<p>Sorry, we didn't notice that. We will update that soon.</p>",
        "id": 478393995,
        "sender_full_name": "Huang Suozhi",
        "timestamp": 1729647484
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"246665\">Sid</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/InternLM2.2E5-StepProver/near/478350473\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"724318\">Zijian Wu</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/InternLM2.2E5-StepProver/near/478190002\">said</a>:</p>\n<blockquote>\n<p>We have submitted a technical report on  <a href=\"https://arxiv.org/abs/2410.15700\">arXiv</a> introducing a new set of open-source language models designed for theorem proving in Lean 4, including our newest policy model, InternLM2.5-StepProver, and its corresponding critic model, InternLM2.5-StepProver-critic. Our models achieve new state-of-the-art results on the miniF2F benchmark (65.9%) and the ProofNet benchmark (27.0%).</p>\n<p>We utilize Lean-Workbook, one of the largest open-source problem collections available, for large-scale expert iteration. We prove/disprove 17.0% of problems in Lean-Workbook-Plus, constituting an enhanced theorem proving dataset and showing significant improvement compared to only 9.5% of problems proved when Lean-Workbook-Plus was released. With the search trajectories obtained during the iteration, we train a critic model, InternLM2.5-StepProver-critic, to provide guidance for the policy model in searching for deeper (and better) proofs on average. The integration of a critic model shows clear performance improvement compared to naïve best-first search methods.</p>\n<p>The <a href=\"https://huggingface.co/internlm/internlm2_5-step-prover\">policy</a> and <a href=\"https://huggingface.co/internlm/internlm2_5-step-prover-critic\">critic</a> models, as well as the enhanced Lean-Workbook-Plus dataset, have been open-sourced on Hugging Face.</p>\n</blockquote>\n<p>Interesting paper! I had a couple of questions</p>\n<ol>\n<li>Do you put just the last tactic or all previous tactics as part of the prompt in addition to the state. </li>\n<li>In theory the state should have all the information right so do you have a sense of why putting in the past tactics helps?</li>\n</ol>\n</blockquote>\n<ol>\n<li>We opt to put all previous tactics as part of the prompt.</li>\n<li>Though not thoroughly studied, we have conducted tests on a policy model with prompts containing only state information. We observed a performance drop, especially on problems that require many power/logarithm operations. Such problems can be solved in different ways, depending on how the model simplifies the equations (in exponential form or logarithm form). However, the model has to stick to one method. We believe that including all previous tactics in the prompt provides a \"direction\" for the proof, while models trained with only state information are more likely to \"swing\" back and forth, going in circles. Similar effects are also observed on problems that require estimating the upper bound of an integer variable and enumerating on that, such as mathd_numbertheory_296.</li>\n</ol>",
        "id": 478613668,
        "sender_full_name": "Zijian Wu",
        "timestamp": 1729735619
    },
    {
        "content": "<p>As for swinging back and forth, in PACT (which only depends on the current state), I've observed the model suggesting to rewrite with commutivity, and then suggesting to rewrite with commutivity again, effectively undoing the last rewrite.  (I've also heard others say that sometimes adding extra information like this can hurt performance, so it probably depends on the model and approach and needs to be thoroughly experimented in practice.)</p>",
        "id": 478615033,
        "sender_full_name": "Jason Rute",
        "timestamp": 1729736620
    }
]