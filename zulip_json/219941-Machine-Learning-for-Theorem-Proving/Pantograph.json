[
    {
        "content": "<p>Just found a new tool for research purposes called <a href=\"https://github.com/lenianiva/PyPantograph\">PyPantograph</a>, which is worth exploring.</p>\n<blockquote>\n<p>Pantograph’s innovative features pave the way for more advanced machine learning models to perform complex proof searches and high-level reasoning, equipping future researchers to design more versatile and powerful theorem provers.</p>\n</blockquote>\n<p>As stated in the paper <a href=\"https://arxiv.org/abs/2410.16429\">here</a>:</p>\n<blockquote>\n<p>The main motivation for creating Pantograph is to overcome the limitations of the interface provided by the Lean 4 Language Server Protocol (LSP),…</p>\n</blockquote>\n<p>It is related to the third approach mentioned by <span class=\"user-mention\" data-user-id=\"115715\">@Jason Rute</span>:</p>\n<blockquote>\n<ol start=\"3\">\n<li>Using Lean's language server</li>\n</ol>\n</blockquote>",
        "id": 485497618,
        "sender_full_name": "RexWang",
        "timestamp": 1733072452
    },
    {
        "content": "<p>This looks very cool. We were just wondering in <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Autoformalization.20of.20Coding.20Problems\">another thread</a> about the possibility of doing Draft-Sketch-Prove in Lean. Will definitely check this out.</p>",
        "id": 485525696,
        "sender_full_name": "GasStationManager",
        "timestamp": 1733098256
    },
    {
        "content": "<p>2 messages were moved here from <a class=\"stream-topic\" data-stream-id=\"219941\" href=\"/#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Interacting.20with.20Lean.204\">#Machine Learning for Theorem Proving &gt; Interacting with Lean 4</a> by <span class=\"user-mention silent\" data-user-id=\"115715\">Jason Rute</span>.</p>",
        "id": 485528932,
        "sender_full_name": "Notification Bot",
        "timestamp": 1733101349
    },
    {
        "content": "<p>she's in zulip <span class=\"user-mention\" data-user-id=\"599027\">@Leni Aniva</span></p>",
        "id": 485685861,
        "sender_full_name": "Quinn",
        "timestamp": 1733164444
    },
    {
        "content": "<p>Hi <span class=\"user-mention\" data-user-id=\"599027\">@Leni Aniva</span> , I've been exploring the Lean tool, and I’m impressed with its quick response(although haven't test the exact time).<br>\nThe tool also supports features like <code>load_sorrys</code> for sketch proofs and <code>inneraction_analyse</code> for tracking MCTS trees.</p>\n<p>However, some cases might lead to incorrect proof states, as noted in <a href=\"https://github.com/lenianiva/Pantograph/issues/1\">this issue</a>. I believe it should be prioritized for resolution. <br>\nAlso, the tool's interaction relies on the prebuilt <code>pantograph-repl</code> executable, built with Lean version 12. I encounter HeaderErrors when tracing the <a href=\"https://github.com/yangky11/lean4-example\">lean4-example</a> using versions 11 and 13. I'm unsure if there's a workaround for this issue.</p>",
        "id": 485779985,
        "sender_full_name": "RexWang",
        "timestamp": 1733213096
    },
    {
        "content": "<p>I was going to post this after I add a couple more features into the tool. I'm glad you found it</p>",
        "id": 485791857,
        "sender_full_name": "Leni Aniva",
        "timestamp": 1733216623
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"572535\">RexWang</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Pantograph/near/485779985\">said</a>:</p>\n<blockquote>\n<p>Hi <span class=\"user-mention silent\" data-user-id=\"599027\">Leni Aniva</span> , I've been exploring the Lean tool, and I’m impressed with its quick response(although haven't test the exact time).<br>\nThe tool also supports features like <code>load_sorrys</code> for sketch proofs and <code>inneraction_analyse</code> for tracking MCTS trees.</p>\n<p>However, some cases might lead to incorrect proof states, as noted in <a href=\"https://github.com/lenianiva/Pantograph/issues/1\">this issue</a>. I believe it should be prioritized for resolution. <br>\nAlso, the tool's interaction relies on the prebuilt <code>pantograph-repl</code> executable, built with Lean version 12. I encounter HeaderErrors when tracing the <a href=\"https://github.com/yangky11/lean4-example\">lean4-example</a> using versions 11 and 13. I'm unsure if there's a workaround for this issue.</p>\n</blockquote>\n<p>Pantograph's version is anchored to Lean v4.12.0 (or whatever version the <code>lean-toolchain</code> file says), so you can't trace a file in a different version of Lean</p>",
        "id": 485794620,
        "sender_full_name": "Leni Aniva",
        "timestamp": 1733217338
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"599027\">@Leni Aniva</span> when you are ready to make an official announcement, feel free to post it here or another thread (or if you think it is something the broader lean community is interested in, you could announce it in #announcements and then post it a like to this thread for follow-up discussions).  Also, I have some comments about this work, but maybe I’ll save them until you feel it is ready (unless you would like them earlier).</p>",
        "id": 485826580,
        "sender_full_name": "Jason Rute",
        "timestamp": 1733225837
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"115715\">Jason Rute</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Pantograph/near/485826580\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"599027\">Leni Aniva</span> when you are ready to make an official announcement, feel free to post it here or another thread (or if you think it is something the broader lean community is interested in, you could announce it in #announcements and then post it a like to this thread for follow-up discussions).  Also, I have some comments about this work, but maybe I’ll save them until you feel it is ready (unless you would like them earlier).</p>\n</blockquote>\n<p>if you have feature suggestions feel free to post them now</p>",
        "id": 485920524,
        "sender_full_name": "Leni Aniva",
        "timestamp": 1733249732
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"572535\">RexWang</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Pantograph/near/485779985\">said</a>:</p>\n<blockquote>\n<p>However, some cases might lead to incorrect proof states, as noted in <a href=\"https://github.com/lenianiva/Pantograph/issues/1\">this issue</a>. I believe it should be prioritized for resolution.</p>\n</blockquote>\n<p>I believe that issue was an indication of a pathological tactic behaviour in Lean 4, and not bug in Pantograph. I've reached out to the author of it for further details.</p>",
        "id": 485921703,
        "sender_full_name": "Leni Aniva",
        "timestamp": 1733250109
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"776090\">GasStationManager</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Pantograph/near/485525696\">said</a>:</p>\n<blockquote>\n<p>This looks very cool. We were just wondering in <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Autoformalization.20of.20Coding.20Problems\">another thread</a> about the possibility of doing Draft-Sketch-Prove in Lean. Will definitely check this out.</p>\n</blockquote>\n<p>We have an example for DSP in <code>experiments/dsp</code> folder.</p>",
        "id": 485924206,
        "sender_full_name": "Leni Aniva",
        "timestamp": 1733250889
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"599027\">Leni Aniva</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Pantograph/near/485794620\">said</a>:</p>\n<blockquote>\n<p>Pantograph's version is anchored to Lean v4.12.0 (or whatever version the <code>lean-toolchain</code> file says), so you can't trace a file in a different version of Lean</p>\n</blockquote>\n<p>I'm not sure what your plan is moving forward, but I just want to give you a cautionary tale about versioning.  Our <a href=\"https://arxiv.org/abs/2401.02949\">Graph2Tac</a> automated theorem prover for Coq as well as <a href=\"https://coq-tactician.github.io/api/introduction/\">Tactician API</a> used to interface it to Coq (for data and Coq interaction) are fixed to Coq v8.11.  But Coq is now on v8.20.  A bunch of new AI for Coq papers have come out recently, none of which could compare with Graph2Tac because of the version differences (and benchmark differences).  We really don't have a good idea how Graph2Tac would do on their benchmarks.  Also, no one uses Graph2Tac as a tool.  (That may also be for other reasons besides the version differences.) Honestly, it is a bit depressing to have 2 years of work be quickly ignored by the community.  In general, I think folks will want to build models and do benchmarks using the newest version of Mathlib.  If your system is tied to an outdated version of Lean (or worse if your system is left to bitrot), I think people will quickly move to another system even if yours is superior.</p>",
        "id": 485977790,
        "sender_full_name": "Jason Rute",
        "timestamp": 1733270001
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"115715\">Jason Rute</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Pantograph/near/485977790\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"599027\">Leni Aniva</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Pantograph/near/485794620\">said</a>:</p>\n<blockquote>\n<p>Pantograph's version is anchored to Lean v4.12.0 (or whatever version the <code>lean-toolchain</code> file says), so you can't trace a file in a different version of Lean</p>\n</blockquote>\n<p>I'm not sure what your plan is moving forward, but I just want to give you a cautionary tale about versioning.  Our <a href=\"https://arxiv.org/abs/2401.02949\">Graph2Tac</a> automated theorem prover for Coq as well as <a href=\"https://coq-tactician.github.io/api/introduction/\">Tactician API</a> used to interface it to Coq (for data and Coq interaction) are fixed to Coq v8.11.  But Coq is now on v8.20.  A bunch of new AI for Coq papers have come out recently, none of which could compare with Graph2Tac because of the version differences (and benchmark differences).  We really don't have a good idea how Graph2Tac would do on their benchmarks.  Also, no one uses Graph2Tac as a tool.  (That may also be for other reasons besides the version differences.) Honestly, it is a bit depressing to have 2 years of work be quickly ignored by the community.  In general, I think folks will want to build models and do benchmarks using the newest version of Mathlib.  If your system is tied to an outdated version of Lean (or worse if your system is left to bitrot), I think people will quickly move to another system even if yours is superior.</p>\n</blockquote>\n<p>I plan to update to v4.14 in the next minor version release, and backport the changes if someone wants it for a different version</p>",
        "id": 485995885,
        "sender_full_name": "Leni Aniva",
        "timestamp": 1733278623
    },
    {
        "content": "<p>If I were to deliver Pantograph for multiple versions, would it be a good idea to do it via Nix? I'm also the creator of lean4-nix. I don't know if most people in ML research would like this idea</p>",
        "id": 485998918,
        "sender_full_name": "Leni Aniva",
        "timestamp": 1733280009
    },
    {
        "content": "<p>Just make sure there is a <code>v4.X.0</code> tag for each <code>X</code>, which uses that stable toolchain.</p>",
        "id": 486008569,
        "sender_full_name": "Kim Morrison",
        "timestamp": 1733284889
    },
    {
        "content": "<p>(Ideally, if you have any upstream dependencies, you pin them also to the <code>v4.X.0</code> tag at the moment.)</p>",
        "id": 486008601,
        "sender_full_name": "Kim Morrison",
        "timestamp": 1733284919
    },
    {
        "content": "<p>Our current approach to version compatibility in Lean is everyone striving to release compatible versions of libraries for each release. It's far from ideal, but it's what we can do right now. Batteries/Aesop/ProofWidgets/Verso/lean-repl/import-graph/Mathlib all do this.</p>",
        "id": 486008751,
        "sender_full_name": "Kim Morrison",
        "timestamp": 1733285012
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"115715\">Jason Rute</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Pantograph/near/485977790\">said</a>:</p>\n<blockquote>\n<p>I'm not sure what your plan is moving forward, but I just want to give you a cautionary tale about versioning.  Our <a href=\"https://arxiv.org/abs/2401.02949\">Graph2Tac</a> automated theorem prover for Coq as well as <a href=\"https://coq-tactician.github.io/api/introduction/\">Tactician API</a> used to interface it to Coq (for data and Coq interaction) are fixed to Coq v8.11.  </p>\n</blockquote>\n<p><span class=\"user-mention\" data-user-id=\"115715\">@Jason Rute</span>  What happened? I'm maintaining Coq packages going back two decades. The coq community and coq platform are very helpful in updating to new versions.</p>",
        "id": 486037742,
        "sender_full_name": "Bas Spitters",
        "timestamp": 1733301525
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"259452\">@Bas Spitters</span> I'll DM you the details to avoid cluttering this thread.  It is not an insurmountable technical issue, but a prioritization of work (made more complex by how we designed things).</p>",
        "id": 486085930,
        "sender_full_name": "Jason Rute",
        "timestamp": 1733316833
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"572535\">RexWang</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Pantograph/near/485779985\">said</a>:</p>\n<blockquote>\n<p>However, some cases might lead to incorrect proof states, as noted in <a href=\"https://github.com/lenianiva/Pantograph/issues/1\">this issue</a>. I believe it should be prioritized for resolution. </p>\n</blockquote>\n<p>This bug has been fixed. I'm asking the author of the issue to verify it before I merge it into the mainline</p>",
        "id": 486447692,
        "sender_full_name": "Leni Aniva",
        "timestamp": 1733465598
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110087\">Kim Morrison</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Pantograph/near/486008569\">said</a>:</p>\n<blockquote>\n<p>Just make sure there is a <code>v4.X.0</code> tag for each <code>X</code>, which uses that stable toolchain.</p>\n</blockquote>\n<p>If I tag each version then I can't backport features from future versions into the \"past\", so I think a better solution is to create backport branches on demand from the users.</p>",
        "id": 486447807,
        "sender_full_name": "Leni Aniva",
        "timestamp": 1733465663
    },
    {
        "content": "<p>There are some features I did not write in the paper: Pantograph can</p>\n<ol>\n<li>Pickle goal states and environments allowing for distributed training and proof search</li>\n<li>Output s-expressions for any Lean expression. This may be of interest for transpiling</li>\n<li>Catalog environment including display of which file contains a symbol</li>\n<li>Modify the environment</li>\n<li>Output the \"parent expression\" of a goal state</li>\n</ol>",
        "id": 486614197,
        "sender_full_name": "Leni Aniva",
        "timestamp": 1733530584
    },
    {
        "content": "<p>Does your picking in 1. also pickle the state of environment extensions?</p>",
        "id": 486766492,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1733661421
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"310045\">Eric Wieser</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Pantograph/near/486766492\">said</a>:</p>\n<blockquote>\n<p>Does your picking in 1. also pickle the state of environment extensions?</p>\n</blockquote>\n<p>No. Do you want this feature?</p>",
        "id": 486794576,
        "sender_full_name": "Leni Aniva",
        "timestamp": 1733684527
    },
    {
        "content": "<p>My memory is that unfortunately many tactics rely on environment extensions (such as auxiliary declarations generated by <code>simp</code>), and so in practice you can't correctly restore from a pickled environment alone.</p>",
        "id": 486815694,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1733702992
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"310045\">Eric Wieser</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Pantograph/near/486815694\">said</a>:</p>\n<blockquote>\n<p>My memory is that unfortunately many tactics rely on environment extensions (such as auxiliary declarations generated by <code>simp</code>), and so in practice you can't correctly restore from a pickled environment alone.</p>\n</blockquote>\n<p>I'll add that (tracking issue <a href=\"https://git.leni.sh/aniva/Pantograph/issues/137\">https://git.leni.sh/aniva/Pantograph/issues/137</a>). The pickling mechanism in pantograph is the same as lean-repl.</p>\n<p>Are the env extensions totally opaque objects in Lean? I don't see their definitions.</p>",
        "id": 486815905,
        "sender_full_name": "Leni Aniva",
        "timestamp": 1733703174
    },
    {
        "content": "<p>yes, they are basically dynamically typed</p>",
        "id": 486817779,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1733704834
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110049\">Mario Carneiro</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Pantograph/near/486817779\">said</a>:</p>\n<blockquote>\n<p>yes, they are basically dynamically typed</p>\n</blockquote>\n<p>I see. I'll do some engineering to ensure this works out with distributed proof search and terminal state insertion</p>",
        "id": 486817826,
        "sender_full_name": "Leni Aniva",
        "timestamp": 1733704889
    },
    {
        "content": "<p>when you declare an environment extension you say what type it will have, and the types are erased by the framework</p>",
        "id": 486817832,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1733704901
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110049\">Mario Carneiro</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Pantograph/near/486817832\">said</a>:</p>\n<blockquote>\n<p>when you declare an environment extension you say what type it will have, and the types are erased by the framework</p>\n</blockquote>\n<p>Where are extensions referenced in CoreM/MetaM/TermElabM? If there is some extension with ptr <code>0x123456</code>, does that mean another ptr somewhere else will point to the same place?</p>",
        "id": 486817958,
        "sender_full_name": "Leni Aniva",
        "timestamp": 1733705030
    },
    {
        "content": "<p>Environment extensions are indexes into an array stored in the environment</p>",
        "id": 486818493,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1733705462
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110049\">Mario Carneiro</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Pantograph/near/486818493\">said</a>:</p>\n<blockquote>\n<p>Environment extensions are indexes into an array stored in the environment</p>\n</blockquote>\n<p>I know this. I'm just asking are these extensions referenced anywhere else other than <code>Environment</code>?</p>",
        "id": 486818524,
        "sender_full_name": "Leni Aniva",
        "timestamp": 1733705485
    },
    {
        "content": "<p>I'm not sure what you mean</p>",
        "id": 486818533,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1733705497
    },
    {
        "content": "<p>The registration mechanism is all global state</p>",
        "id": 486818639,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1733705546
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110049\">Mario Carneiro</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Pantograph/near/486818639\">said</a>:</p>\n<blockquote>\n<p>The registration mechanism is all global state</p>\n</blockquote>\n<p>when <code>simp</code> adds some extension to the environment, does it store the pointer to the extension anywhere else? If I resurrect a proof state from a pickled file the proof state would need to load the extension into the environment, and any reference to the extension would need to be redirected to this reloaded copy of the extension ptr</p>",
        "id": 486818761,
        "sender_full_name": "Leni Aniva",
        "timestamp": 1733705647
    },
    {
        "content": "<p>I don't think simp adds extensions to the environment? Simp <em>is</em> an extension to the environment</p>",
        "id": 486818808,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1733705703
    },
    {
        "content": "<p>There is no pointer comparing involved</p>",
        "id": 486818831,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1733705725
    },
    {
        "content": "<p>an environment extension is logically just an allocation of a particular number which will henceforth be in the arrays of every environment</p>",
        "id": 486818915,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1733705769
    },
    {
        "content": "<p>so it doesn't matter whether you hold on to the extension object itself</p>",
        "id": 486818969,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1733705809
    },
    {
        "content": "<p>the thing you get back from the registration function is just some sugar to make it easy to index into an arbitrary environment and cast the result to the right type</p>",
        "id": 486819031,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1733705856
    },
    {
        "content": "<p>Is there a simple example of a proof where env extensions get generated?</p>",
        "id": 486819149,
        "sender_full_name": "Leni Aniva",
        "timestamp": 1733705972
    },
    {
        "content": "<p>There is usually one environment extension per \"system component\", you don't generate environment extensions dynamically usually</p>",
        "id": 486819232,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1733706015
    },
    {
        "content": "<p>most attributes are associated with an environment extension</p>",
        "id": 486819257,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1733706038
    },
    {
        "content": "<p>So you would not expect a proof to be creating any environment extensions</p>",
        "id": 486819336,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1733706107
    },
    {
        "content": "<p>but tactics sometimes define new env extensions</p>",
        "id": 486819342,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1733706115
    },
    {
        "content": "<p>the main entry point is <a href=\"https://leanprover-community.github.io/mathlib4_docs/find/?pattern=Lean.registerPersistentEnvExtension#src\">src#Lean.registerPersistentEnvExtension</a></p>",
        "id": 486819414,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1733706157
    },
    {
        "content": "<p>you can see that it is modifying the global variable <code>persistentEnvExtensionsRef</code> there</p>",
        "id": 486819469,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1733706233
    },
    {
        "content": "<p>and the <code>unsafeCast</code> there is doing a lot of work</p>",
        "id": 486819514,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1733706267
    },
    {
        "content": "<p>the <a href=\"https://github.com/leanprover/lean4/blob/ffac974dba799956a97d63ffcb13a774f700149c/src/Lean/Environment.lean#L733-L746\">setImportedEntries</a> function pulls extension data out of the \"pickled\" <code>ModuleData</code> in olean files by matching them up by name</p>",
        "id": 486819836,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1733706496
    },
    {
        "content": "<p>To be clear, I was referring to the <code>simp</code> tactic, which I think keeps a cache of generated lemmas in an extension, not the <code>@[simp]</code>  attribute which stores the lemmas in the simp database</p>",
        "id": 486823359,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1733709322
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110049\">Mario Carneiro</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Pantograph/near/486819336\">said</a>:</p>\n<blockquote>\n<p>So you would not expect a proof to be creating any environment extensions</p>\n</blockquote>\n<p>Is it sufficient to replay the constant map like what repl does?</p>",
        "id": 486837894,
        "sender_full_name": "Leni Aniva",
        "timestamp": 1733719171
    },
    {
        "content": "<p>I updated Pantograph to v0.2.23: <a href=\"https://github.com/lenianiva/PyPantograph/pull/50\">https://github.com/lenianiva/PyPantograph/pull/50</a></p>\n<ul>\n<li>fix: An unsoundness bug that is also present in LeanDojo and REPL which causes errenous acceptance of tactics. Note that if you use the proof collection feature (<code>goal.print</code>, existed for 1 year already) at the end of each proof, Pantograph would never become unsound.</li>\n<li>feat: Pickle environments and goal states (the pickling of goal states is experimental)</li>\n<li>feat: Collect newly generated constants for each compilation unit</li>\n<li>feat: Turn type errors into goals, and show exactly where each error happens</li>\n<li>feat: Show used constants in each tactic execution</li>\n<li>feat: MCTS interface (in PyPantograph)</li>\n</ul>",
        "id": 488534068,
        "sender_full_name": "Leni Aniva",
        "timestamp": 1733966768
    }
]