[
    {
        "content": "<p><a href=\"https://arxiv.org/abs/2309.15806\">Lyra: Orchestrating Dual Correction in Automated Theorem Proving</a> by Chuanyang Zheng, Haiming Wang, Enze Xie, <span class=\"user-mention\" data-user-id=\"398687\">@Zhengying Liu</span>, Jiankai Sun, <span class=\"user-mention\" data-user-id=\"481527\">@Huajian Xin</span>, <span class=\"user-mention\" data-user-id=\"480144\">@Jianhao Shen</span>, Zhenguo Li, Yu Li</p>\n<p>Mostly the same authors of DT-Solver (<a class=\"stream-topic\" data-stream-id=\"219941\" href=\"/#narrow/stream/219941-Machine-Learning-for-Theorem-Proving/topic/DT-Solver\">#Machine Learning for Theorem Proving &gt; DT-Solver</a>).</p>\n<p>Uses large language models like GPT-4 to prove theorems in Isabelle.  They claim SoTA on MiniF2F including solving 3 IMO problems.  (Of course one should take this with a grain of salt as has been discussed in the past.)  I think it has similarities to Draft Sketch Prove (<a class=\"stream-topic\" data-stream-id=\"219941\" href=\"/#narrow/stream/219941-Machine-Learning-for-Theorem-Proving/topic/More.20papers.20on.20autoformalization\">#Machine Learning for Theorem Proving &gt; More papers on autoformalization</a>).  They have two mechanisms I don't understand yet.  <em>Tool correction</em> somehow uses SledgeHammer, and <em>Conjecture Correction</em> somehow uses previous Isabelle error messages.  (I wonder if it is similar to Baldur, <a class=\"stream-topic\" data-stream-id=\"219941\" href=\"/#narrow/stream/219941-Machine-Learning-for-Theorem-Proving/topic/Baldur.3A.20Whole-Proof.20Generation.20and.20Repair.20with.20Large.20Lang.2E.2E.2E\">#Machine Learning for Theorem Proving &gt; Baldur: Whole-Proof Generation and Repair with Large Lang...</a>.)</p>",
        "id": 394109222,
        "sender_full_name": "Jason Rute",
        "timestamp": 1696103313
    },
    {
        "content": "<p>Yeah the two new IMO problems they claim to solve: the first is <code>imo_1981_p6</code> but this is not IMO 1981 problem 6. IMO problem 6 ends \"determine <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>f</mi><mo stretchy=\"false\">(</mo><mn>4</mn><mo separator=\"true\">,</mo><mn>1981</mn><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">f(4,1981)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10764em;\">f</span><span class=\"mopen\">(</span><span class=\"mord\">4</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord\">1981</span><span class=\"mclose\">)</span></span></span></span>\" and the Isabelle formalisation proves <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi mathvariant=\"normal\">∀</mi><mi>y</mi><mo separator=\"true\">,</mo><mi>f</mi><mo stretchy=\"false\">(</mo><mn>4</mn><mo separator=\"true\">,</mo><mi>y</mi><mo>+</mo><mn>1</mn><mo stretchy=\"false\">)</mo><mo>=</mo><msup><mn>2</mn><mrow><mi>f</mi><mo stretchy=\"false\">(</mo><mn>4</mn><mo separator=\"true\">,</mo><mi>y</mi><mo stretchy=\"false\">)</mo><mo>+</mo><mn>3</mn></mrow></msup><mo>−</mo><mn>3</mn></mrow><annotation encoding=\"application/x-tex\">\\forall y, f(4,y+1)=2^{f(4,y)+3}-3</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\">∀</span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">y</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10764em;\">f</span><span class=\"mopen\">(</span><span class=\"mord\">4</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">y</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\">1</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.9713em;vertical-align:-0.0833em;\"></span><span class=\"mord\"><span class=\"mord\">2</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.888em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.10764em;\">f</span><span class=\"mopen mtight\">(</span><span class=\"mord mtight\">4</span><span class=\"mpunct mtight\">,</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03588em;\">y</span><span class=\"mclose mtight\">)</span><span class=\"mbin mtight\">+</span><span class=\"mord mtight\">3</span></span></span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6444em;\"></span><span class=\"mord\">3</span></span></span></span> which is most definitely not the same thing (and in particular the formalisation contains crucial information not in the question, although it is unfortunately still an open problem to figure out how to actually turn these kinds of \"work out this number\" question into a formal theorem statement without giving away information). And the second one they claim to solve is IMO 1974 P5 but this is not in the dataset as far as I can see (I can't find it here <a href=\"https://github.com/openai/miniF2F/tree/main\">https://github.com/openai/miniF2F/tree/main</a>) . On the other hand on p9 they do state an Isabelle formalisation of something related to IMO 1974 problem 5, however it is extremely far from the IMO problem. The IMO problem says \"there's some function S of 4 positive real inputs; find its image\"; the answer is \"the open interval (1,2)\" and the hard part is to prove that everything in that range is attained; the fact that the image is obviously contained in (1,2) is just a remark in the first line of the human solution; however the formalisation only proves this trivial inclusion. This is perhaps the most egregious abuse of the phrase \"we successfully solve an IMO problem\" which we've seen yet in this area. They successfully solve the trivial direction of an if and only if. This is not to take anything away from the research! But we are not seeing any new solutions of what humans would call IMO problems here, whatever miniF2F says an IMO problem is.</p>",
        "id": 394117942,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1696112492
    },
    {
        "content": "<p>I guess there's also the issue that as part of the process they're asking an LLM to give a sketch proof of a question which it's seen already.</p>",
        "id": 394118220,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1696112866
    },
    {
        "content": "<p>16 messages were moved from this topic to <a class=\"stream-topic\" data-stream-id=\"208328\" href=\"/#narrow/stream/208328-IMO-grand-challenge/topic/fill.20in.20the.20blank\">#IMO-grand-challenge &gt; fill in the blank</a> by <span class=\"user-mention silent\" data-user-id=\"112680\">Johan Commelin</span>.</p>",
        "id": 394334922,
        "sender_full_name": "Notification Bot",
        "timestamp": 1696228345
    },
    {
        "content": "<p>While not at all disputing Kevin's analysis of these purported IMO solutions, I'll say again that it would be great if the IMO challenge committee could specify clearly what a successful solution would constitute.</p>\n<p>Even a document with a checklist of items \"does your proposed formalised statement contain crucial information about the solution not present in the informal statement\", \"does your statement include both directions of any iff\", etc. would be useful. It doesn't need to definitively answer the \"find\" problem.</p>\n<p>Then at least when claims are made about IMO solutions it is straightforward to ask authors \"are you claiming your solution meets this standard?\".</p>",
        "id": 394352846,
        "sender_full_name": "Scott Morrison",
        "timestamp": 1696233798
    },
    {
        "content": "<p>That could be a start.  On the miniF2F benchmark however, that ship may have sailed…</p>",
        "id": 394430033,
        "sender_full_name": "Jason Rute",
        "timestamp": 1696253320
    },
    {
        "content": "<p>Right -- the authors are just saying \"we proved something labelled <code>IMO_...</code> in miniF2F\", but they naturally translate this as \"we solve an IMO problem\" which is very much not the same thing in the two new examples in the paper.</p>",
        "id": 394458472,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1696260010
    },
    {
        "content": "<p>Could miniF2F release a new version of the benchmark? I suppose that comes with its own set of problems, because benchmarks aren't supposed to change. But if those statements could at least come with an <code>*</code>, that would already help a bit.</p>",
        "id": 394460215,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1696260523
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"112680\">Johan Commelin</span> <a href=\"#narrow/stream/219941-Machine-Learning-for-Theorem-Proving/topic/Lyra/near/394460215\">said</a>:</p>\n<blockquote>\n<p>Could miniF2F release a new version of the benchmark? I suppose that comes with its own set of problems, because benchmarks aren't supposed to change. But if those statements could at least come with an <code>*</code>, that would already help a bit.</p>\n</blockquote>\n<p>There's a complicated history to miniF2F. It's initially an openai project: <a href=\"https://github.com/openai/miniF2F\">https://github.com/openai/miniF2F</a>. Then all of its authors left openai (apart from Dan?) and the library becomes unmaintained. No PR can be merged.</p>\n<p>Last year during my internship, I figured out there are ~10-20 mistakes in the formalisations (unsolvable, trivial typos, and incorrect indices, I know there are non-trivial mistakes as discussed above), so created a new repo for it since I cannot push to the original: <a href=\"https://github.com/facebookresearch/miniF2F\">https://github.com/facebookresearch/miniF2F</a>. This is v2 and Fabian Glöckle is maintaining it atm. For future versions one should PR to the facebook repo.</p>",
        "id": 394571596,
        "sender_full_name": "Albert Jiang",
        "timestamp": 1696316174
    },
    {
        "content": "<p>Thanks for pointing this out! And thanks to both you and <span class=\"user-mention\" data-user-id=\"210057\">@Fabian Glöckle</span> for creating and maintaining v2.</p>",
        "id": 394582057,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1696320464
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"115715\">Jason Rute</span> <a href=\"#narrow/stream/219941-Machine-Learning-for-Theorem-Proving/topic/Lyra/near/394109222\">said</a>:</p>\n<blockquote>\n<p>Conjecture Correction somehow uses previous Isabelle error messages.</p>\n</blockquote>\n<p>The Lyra Conjecture Correction procedure reminds me of the Kaggle competition (LLM Science Exam)<br>\n<a href=\"https://www.kaggle.com/competitions/kaggle-llm-science-exam/overview\">https://www.kaggle.com/competitions/kaggle-llm-science-exam/overview</a></p>\n<p>In that competition, we are given 200 multiple-choice questions and must use an LLM to choose the correct answer to each question. The questions are very challenging and require some physics knowledge. To answer each question, we collect relevant Wikipedia texts as context and pass them to the LLM model along with the question. The conext is similar to the content (previous formal proof) used in the Conjecture Correction procedure. The issues with this approach are</p>\n<p>(1) The context to be used as input to LLM models<br>\n(a) Similar text search methods work for Wikipedia, but mathematical reasoning requires a different approach due to mathematical notions and symbols.  <br>\n(b) LLM models have a maximal input length. If the context for a question is too long, the LLM model will truncate it. However, if the context is too short, it may not be enough for the LLM model to make an accurate prediction.</p>\n<p>(2)  The computational resources required to run an LLM model.<br>\n<del>7-B</del> <strong>  <em>70-B</em> </strong>  parameter LLMs require at least 160GB of memory. To run such a large model on limited GPU memory, we need to run the model one layer after another. The model has 87 layers (+ input/ouptut layers) and running through all these layers is time-conusming (200 questions take over 5 hours on 2 T5 GPUs).</p>",
        "id": 394925089,
        "sender_full_name": "Min-Hsien Weng",
        "timestamp": 1696458199
    },
    {
        "content": "<blockquote>\n<p>7B parameter LLMs require at least 160GB of memory. </p>\n</blockquote>\n<p>One of these numbers must be off! 7B unquantized should only require around <a href=\"https://github.com/ggerganov/llama.cpp/issues/13#issuecomment-1464950237\">16GB</a>. Given that the model has 87 layers, I bet you're talking about 70B models (for comparison Llama 65B has 80 layers).</p>",
        "id": 395056404,
        "sender_full_name": "Junyan Xu",
        "timestamp": 1696516145
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"638383\">Min-Hsien Weng</span> <a href=\"#narrow/stream/219941-Machine-Learning-for-Theorem-Proving/topic/Lyra/near/394925089\">said</a>:</p>\n<blockquote>\n<p>7B parameter LLMs require at least 160GB of memory.</p>\n</blockquote>\n<p>Is this really true? I have 64GB of RAM on my laptop, and I can run llama2 7B on my CPU just fine (albeit quite slowly)</p>",
        "id": 395057326,
        "sender_full_name": "Adam Topaz",
        "timestamp": 1696516438
    },
    {
        "content": "<p>If you just want to infer, 7B parameter requires 16GB memory max :)</p>\n<p>Quantised versions (int4/8) can run on a mac m1 max / m2 no problem</p>",
        "id": 395393678,
        "sender_full_name": "Albert Jiang",
        "timestamp": 1696669571
    },
    {
        "content": "<p>Thanks for pointing that out. Sorry for my typo. I was using Platypus2-70B-instruct, which has 70 billion parameters. 7-B parameter is not that big <span aria-label=\"sweat smile\" class=\"emoji emoji-1f605\" role=\"img\" title=\"sweat smile\">:sweat_smile:</span><br>\nHere is the LLM model: <a href=\"https://huggingface.co/garage-bAInd/Platypus2-70B-instruct\">https://huggingface.co/garage-bAInd/Platypus2-70B-instruct</a></p>\n<p>This 70-billion-parameter large language model can infer multiple-choice answers from relevant Wikipedia contexts (like in an open-book exam) with 86% accuracy. Some teams have achieved over 93% accuracy, and they may find ways to further improve performance.</p>\n<p>I found it interesting and learned more about LLMs. The competition is ending soon, so join if you're interested!</p>",
        "id": 395578817,
        "sender_full_name": "Min-Hsien Weng",
        "timestamp": 1696801997
    }
]