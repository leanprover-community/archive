[
    {
        "content": "<p>I saw some news of \"Aleph Prover\" getting 500/660 on putnam bench. Are any of the authors here to answer questions? congrats on the result.</p>",
        "id": 561321019,
        "sender_full_name": "Andy Jiang",
        "timestamp": 1764648397
    },
    {
        "content": "<p>They have mentioned that they use non-autoregressive energy-based models. That's it.  <br>\n<a href=\"https://x.com/logic_int/status/1968044980791841193?s=20\">https://x.com/logic_int/status/1968044980791841193?s=20</a></p>",
        "id": 561328350,
        "sender_full_name": "Ayush Agrawal",
        "timestamp": 1764653736
    },
    {
        "content": "<p>Perhaps <span class=\"user-mention\" data-user-id=\"819811\">@Vladislav Isenbaev</span> / <span class=\"user-mention\" data-user-id=\"878104\">@Vladislav Isenbaev</span>, judging by <a href=\"https://www.upstartsmedia.com/p/math-ai-startups-push-new-models\">https://www.upstartsmedia.com/p/math-ai-startups-push-new-models</a>?</p>",
        "id": 561338749,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1764659721
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"439607\">Ayush Agrawal</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/PutnamBench/near/561328350\">said</a>:</p>\n<blockquote>\n<p>They have mentioned that they use non-autoregressive energy-based models. That's it.  <br>\n<a href=\"https://x.com/logic_int/status/1968044980791841193?s=20\">https://x.com/logic_int/status/1968044980791841193?s=20</a></p>\n</blockquote>\n<p>energy-based?? like deep boltzman machines or what??? people don't call diffusion models energy-based right? This description honestly raises much more questions to me than it answers. if it's really a completely new architecture style, wouldn't that be MUCH bigger news?</p>",
        "id": 561340552,
        "sender_full_name": "Andy Jiang",
        "timestamp": 1764660553
    },
    {
        "content": "<p>Why the non-autoregressive claim? It seems a strange claim, but I'm happy to be educated about wrong assumptions. Language is autoregressive by its very nature (unless you consider the aliens from Arrival <span aria-label=\"smile\" class=\"emoji emoji-1f604\" role=\"img\" title=\"smile\">:smile:</span>). That would imply to me that there will always be an autoregressive future for AI. This doesn't mean that other models aren't possible for other things (think BERT!), but definitely a strange claim to my mind.</p>",
        "id": 561343640,
        "sender_full_name": "Gerben Koopman",
        "timestamp": 1764661863
    },
    {
        "content": "<p>Unless there's some more information I'd assume this is some version of diffusion <span class=\"user-mention\" data-user-id=\"662620\">@Andy Jiang</span> (there's certainly such a thing as an \"energy-based view\" on diffusion models which you're probably aware of, e.g. as explained <a href=\"https://arxiv.org/pdf/2510.21890\">here</a>). </p>\n<p>I'm not an expert, but the idea that something more like diffusion could be better for proofs has been around for a while and I think makes intuitive sense: In a proof, you have  a well-defined start and an end, and you want to fill out the middle, ideally refining/updating the pieces that don't fit well. So you could hope that diffusion based architectures capture this better than autoregressive models, where it has to be imposed somewhat artificially.</p>",
        "id": 561356263,
        "sender_full_name": "Nikolas Kuhn",
        "timestamp": 1764666203
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"496319\">Nikolas Kuhn</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/PutnamBench/near/561356263\">said</a>:</p>\n<blockquote>\n<p>...the idea that something more like diffusion could be better for proofs has been around for a while and I think makes intuitive sense: In a proof, you have  a well-defined start and an end, and you want to fill out the middle, ideally refining/updating the pieces that don't fit well. So you could hope that diffusion based architectures capture this better than autoregressive models, where it has to be imposed somewhat artificially.</p>\n</blockquote>\n<p>Using diffusion based models in this sense <em>is</em> an interesting idea.</p>\n<p>However, one can contrast this with the thinking mode of modern LLMs with \"large\" context windows allowing them to attend to text they produced previously, giving them essentially the ability to \"fill out the middle\".  (The Kimina Prover work emphasized  this point but mostly in the context of MCTS.) So, it's not clear which approach is \"better\".</p>\n<p>As to which \"wins\" (diffusion, thinking modes of modern LLMs, or something else) I've no \"horse in that race\".</p>",
        "id": 561362168,
        "sender_full_name": "Kelly Davis",
        "timestamp": 1764667982
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"496319\">Nikolas Kuhn</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/PutnamBench/near/561356263\">said</a>:</p>\n<blockquote>\n<p>Unless there's some more information I'd assume this is some version of diffusion <span class=\"user-mention silent\" data-user-id=\"662620\">Andy Jiang</span> (there's certainly such a thing as an \"energy-based view\" on diffusion models which you're probably aware of, e.g. as explained <a href=\"https://arxiv.org/pdf/2510.21890\">here</a>). </p>\n<p>I'm not an expert, but the idea that something more like diffusion could be better for proofs has been around for a while and I think makes intuitive sense: In a proof, you have  a well-defined start and an end, and you want to fill out the middle, ideally refining/updating the pieces that don't fit well. So you could hope that diffusion based architectures capture this better than autoregressive models, where it has to be imposed somewhat artificially.</p>\n</blockquote>\n<p>Ah ok, that makes a lot of sense. I didn't know about the energy interpretations of diffusion (but I am not extremely surprised as a science laymen that you can have energy-based interpretations of most physicy processes). Yeah diffusion models for proof generation is certainly an interesting idea but at least it is also one seen in the literature from other people so it's less crazy.</p>",
        "id": 561366103,
        "sender_full_name": "Andy Jiang",
        "timestamp": 1764669055
    },
    {
        "content": "<p>I think that diffusion models sound very fit to the task of theorem proving. There are reasons why almost all LLM are autogressive, not diffusion model. However, we can see that in the future there will be more diffusion models for language</p>",
        "id": 561381612,
        "sender_full_name": "Anh Nguyễn",
        "timestamp": 1764673368
    },
    {
        "content": "<p>9 messages were moved here from <a class=\"stream-topic\" data-stream-id=\"219941\" href=\"/#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/PutnamBench/with/555190970\">#Machine Learning for Theorem Proving &gt; PutnamBench</a> by <span class=\"user-mention silent\" data-user-id=\"115715\">Jason Rute</span>.</p>",
        "id": 561410380,
        "sender_full_name": "Notification Bot",
        "timestamp": 1764681684
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"874606\">Anh Nguyễn</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Aleph.20Prover.20by.20Logical.20Intelligence/near/561381612\">said</a>:</p>\n<blockquote>\n<p>However, we can see that in the future there will be more diffusion models for language</p>\n</blockquote>\n<p>Can you substantiate this claim? I'd be interested to read a paper or blog on diffusion for NLP, <del>even if it is outside the Lean scope.</del></p>\n<p>Edit: So I've found some research and overview papers on general use, but it seems worse at reasoning? Sounds like transformers are still very much the way to go for theorem proving no?</p>",
        "id": 561412663,
        "sender_full_name": "Gerben Koopman",
        "timestamp": 1764682253
    },
    {
        "content": "<p><a href=\"https://x.com/logic_int/status/1995949127252017499?s=20\">https://x.com/logic_int/status/1995949127252017499?s=20</a></p>",
        "id": 561537959,
        "sender_full_name": "Jason Rute",
        "timestamp": 1764717476
    },
    {
        "content": "<p>^ More claims by this company of automatically solving open conjectures in Lean</p>",
        "id": 561538057,
        "sender_full_name": "Jason Rute",
        "timestamp": 1764717542
    },
    {
        "content": "<p>Hmm, not sure of the google scholar is poorly matched with the CEO.  <a href=\"https://scholar.google.com/citations?hl=en&amp;user=LyA_iI0AAAAJ&amp;view_op=list_works&amp;sortby=pubdate\">https://scholar.google.com/citations?hl=en&amp;user=LyA_iI0AAAAJ&amp;view_op=list_works&amp;sortby=pubdate</a></p>\n<p><a href=\"https://quantumfoundry.ucsb.edu/people/associates/eve-bodnia\">https://quantumfoundry.ucsb.edu/people/associates/eve-bodnia</a></p>\n<p>I couldn't find any research.  Lot of red flags here, but always a problem with companies like this, improbable, but you never know.   There is also very strong incentive not to openly publish breakthroughs right now in AI.</p>\n<p>Quantum background would definitely point at EBM and lecun is a big fan.</p>",
        "id": 561547346,
        "sender_full_name": "Deleted User 968128",
        "timestamp": 1764723989
    },
    {
        "content": "<p>I think whoever runs the Lean X account should encourage them to engage here too.</p>",
        "id": 561560118,
        "sender_full_name": "Jason Rute",
        "timestamp": 1764735175
    },
    {
        "content": "<p>Anyway, here is one of the proofs they just announced. <a href=\"https://github.com/logical-intelligence/proofs\">https://github.com/logical-intelligence/proofs</a></p>",
        "id": 561560188,
        "sender_full_name": "Jason Rute",
        "timestamp": 1764735238
    },
    {
        "content": "<p>sorry can someone more knowledgable on diffusion models chime in for this? how easy is it for me to fix some parts of the output of the diffusion. for example I fix the theorem statement and some intermediate lemmas and try to use diffusion model to gen the rest of the proof. And is there advantages in parallelization? (I personally don't see any advantages in parallelization bc you can always just start another subgoal in the middle and break your final goal into subgoal + subgoal =&gt; goal and then you can parallelize the generation of the two parts even using autoregressive llms i assume). Sorry hope someone who knows more about diffusion models in writing formal proofs can speak on this</p>",
        "id": 561564384,
        "sender_full_name": "Andy Jiang",
        "timestamp": 1764738650
    },
    {
        "content": "<p>fix means keep constant in the above paragraph not to correct btw.</p>",
        "id": 561564434,
        "sender_full_name": "Andy Jiang",
        "timestamp": 1764738690
    },
    {
        "content": "<p>The timeline here is interesting: <a href=\"https://x.com/evelovesolive\">https://x.com/evelovesolive</a>  </p>\n<p><a href=\"https://x.com/evelovesolive/status/1971230688818102668\">https://x.com/evelovesolive/status/1971230688818102668</a> \"our audit agent <a href=\"https://noa.logicalintelligence.com\">https://noa.logicalintelligence.com</a> It is free\"<br>\n<a href=\"https://x.com/evelovesolive/status/1974259155851698323\">https://x.com/evelovesolive/status/1974259155851698323</a> \"blockchains for emergency response to recent npm attacks.\"<br>\n<a href=\"https://x.com/evelovesolive/status/1975754450112553408\">https://x.com/evelovesolive/status/1975754450112553408</a> \"Can’t wait to do formal verification and zkp on quantum chips<br>\n<a href=\"https://x.com/evelovesolive/status/1996037932864733501\">https://x.com/evelovesolive/status/1996037932864733501</a> \"Aleph prover was initially our internal tool to compare our model with other models, never planned it to be a product\"</p>\n<p>Feels like a crypto-ish company that probably started doing smart contract verification with lean and stumbled into proof verification.   </p>\n<p>Whether they stumbled into a breakthrough is the question, I suppose.   Even autoregressive transformer based models can be viewed as energy based using the right perspective.  Certainly, they don't seem adverse to using other approaches:  <a href=\"https://x.com/evelovesolive/status/1995357309736812903\">https://x.com/evelovesolive/status/1995357309736812903</a></p>\n<p>It's a bit of a struggle to get labs to invest in open ML math research.  Quants research,  but they don't publish.  It's <em>important to leverage every opportunity</em> to get folks to help out.   We're lucky to have companies like DeepSeek publish so openly.</p>",
        "id": 561569765,
        "sender_full_name": "Deleted User 968128",
        "timestamp": 1764742697
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"496319\">Nikolas Kuhn</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Aleph.20Prover.20by.20Logical.20Intelligence/near/561356263\">said</a>:</p>\n<blockquote>\n<p>Unless there's some more information I'd assume this is some version of diffusion</p>\n</blockquote>\n<p><a href=\"https://www.linkedin.com/feed/update/urn:li:activity:7373814242799628288/\">From linkedin</a>, this certainly sounds like diffusion:</p>\n<blockquote>\n<p>Most AI (like LLMs) solve problems one piece at a time—like doing a jigsaw blindfolded. If you place a piece wrong early, the whole picture suffers. LI-1.0 thinks differently: all the pieces move together, like magnets snapping into place until the puzzle is complete.</p>\n</blockquote>",
        "id": 561717273,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1764783756
    },
    {
        "content": "<p>PR - <a href=\"https://www.01net.it/logical-intelligence-achieves-76-percent-on-putnam-benchmark-highlighting-shift-beyond-large-language-models-to-language-free-mathematically-grounded-models/\">https://www.01net.it/logical-intelligence-achieves-76-percent-on-putnam-benchmark-highlighting-shift-beyond-large-language-models-to-language-free-mathematically-grounded-models/</a></p>\n<blockquote>\n<p>\"While Aleph is an internal tool built on top of an LLM, its performance places it ahead of all publicly evaluated LLMs and the hybrid EBM systems that still depend on LLM scaffolding. The results are a strong signal that native EBM architectures offer a clear path to trustworthy AI.\"</p>\n</blockquote>\n<p>This is what I expected and increases my trust level. It sounds more incremental, but their benchmarks are strong and they are likely doing solid work.  They sound confident it's the native EBM doing the heavy lifting, but the devil is in the details.</p>",
        "id": 561725869,
        "sender_full_name": "Deleted User 968128",
        "timestamp": 1764786552
    },
    {
        "content": "<p>Bit disappointed they aren't crediting lean in the PR because that is very likely providing all of the certainty they talk about.  EBM just provides a more effective (in theory) way to get there.  So, there is that gap.</p>",
        "id": 561729559,
        "sender_full_name": "Deleted User 968128",
        "timestamp": 1764787719
    }
]