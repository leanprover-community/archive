[
    {
        "content": "<p>Previously, I was in charge of the proof strategy, and the AI only solved simple lemmas.</p>\n<p><strong>Now, the AI is in charge, and I end up fixing errors made by AI.</strong></p>\n<p>Before diving deeper, I'd like to highlight a few caveats:</p>\n<ul>\n<li>AI agents are slow. And they make errors quite often.</li>\n<li>My AI setup isn't optimal. AI often has to work based on incomplete error lists and has no visibility into the goal state.</li>\n</ul>\n<p>Here is my AI setup.</p>\n<ol>\n<li>The problem statement is processed by Gemini Deep Think, and after around 10 to 20 minutes, I get a proof in natural language. I have yet to see an incorrect proof coming from Gemini Deep Think.</li>\n<li>I put the proof generated by Gemini in the Lean file as a comment.</li>\n<li>I use Cursor with the GPT-5 model. No additional MCP servers are installed. <code>.gitignore</code> is deleted, and the model is instructed to operate in agent mode. I tell the model to use the <code>read_lints</code> tool to check for errors, look into the <code>.lake</code> folder to find helpful mathlib lemmas and not to declare new axioms.</li>\n<li>The model works hard, then stops when it thinks there are no errors. I then tell it to run <code>read_lints</code> again and fix remaining errors. I babysit the model so if the model deletes the whole proof then I stop the model and revert the change.</li>\n<li>If the model refuses to do any work, I start a new conversation and try again.</li>\n</ol>\n<p>At the end, I end up with a proof with some errors. I can just fix the errors manually. And in some cases iterative error fixing means the final proof is perfect without more manual intervention. And I am not in charge of the high level proof strategy. The AI is in charge, and I become a janitor. How humiliating. But it shows that we are clearly in a new age.</p>",
        "id": 541052908,
        "sender_full_name": "(deleted)",
        "timestamp": 1758643646
    },
    {
        "content": "<p>Soon, as the AI becomes faster and more reliable, we can become architects. Our work is not just to formalize individual theorems, but rather we can build a whole theory. Or a whole framework. And we can let AI do the grunt work. I don't think this new development makes humans useless, but rather it elevates us. And this finally makes formal verification practical for use in the industry.</p>",
        "id": 541054865,
        "sender_full_name": "(deleted)",
        "timestamp": 1758644331
    },
    {
        "content": "<p><a href=\"/user_uploads/3121/Q45wsa0o5j9faScVFr_dD104/Screenshot_2025-09-23-23-22-53-850_com.android.chrome.jpg\">Screenshot_2025-09-23-23-22-53-850_com.android.chrome.jpg</a></p>\n<div class=\"message_inline_image\"><a href=\"/user_uploads/3121/Q45wsa0o5j9faScVFr_dD104/Screenshot_2025-09-23-23-22-53-850_com.android.chrome.jpg\" title=\"Screenshot_2025-09-23-23-22-53-850_com.android.chrome.jpg\"><img data-original-content-type=\"image/jpeg\" data-original-dimensions=\"1080x2400\" src=\"/user_uploads/thumbnail/3121/Q45wsa0o5j9faScVFr_dD104/Screenshot_2025-09-23-23-22-53-850_com.android.chrome.jpg/840x560.webp\"></a></div><p>There are still rough edges however.</p>",
        "id": 541055726,
        "sender_full_name": "(deleted)",
        "timestamp": 1758644607
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"511228\">Huỳnh Trần Khanh</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Role.20reversal/near/541052908\">said</a>:</p>\n<blockquote>\n<p>Here is my AI setup.</p>\n</blockquote>\n<p>Have you experimented with other setups?  LeanDojo, lean copilot and other models like deepseek prover?  Agentic search (o3-search, gpt5-search) can help a lot here for making suggestions.</p>",
        "id": 541061512,
        "sender_full_name": "Deleted User 968128",
        "timestamp": 1758646743
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"511228\">Huỳnh Trần Khanh</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Role.20reversal/near/541054865\">said</a>:</p>\n<blockquote>\n<p>Soon, as the AI becomes faster and more reliable, we can become architects. Our work is not just to formalize individual theorems, but rather we can build a whole theory. Or a whole framework. And we can let AI do the grunt work. I don't think this new development makes humans useless, but rather it elevates us. And this finally makes formal verification practical for use in the industry.</p>\n</blockquote>\n<p>Yeah, the trick of the moment is to find the right point at which we can do the sorry/abstractions.   If you go to low, you end up doing all the works the AI can do for you.  If you go too high, it just breaks.  AI is moving so quickly, this sorry level is increasing just as soon as you find the right balance.  It's also different, ofc, depending on the specific domain.</p>\n<p>One thing that I believe will become a more important field of study is \"Proof Axiology\" where the problem is less about proving, but more about what should be proved first.</p>",
        "id": 541062136,
        "sender_full_name": "Deleted User 968128",
        "timestamp": 1758646947
    },
    {
        "content": "<p>I have used Kimina Prover, DeepSeek Prover v2 and Goedel Prover v2. They can only prove easy theorems. GPT-5 is the first model to be able to prove harder theorems.</p>",
        "id": 541064762,
        "sender_full_name": "(deleted)",
        "timestamp": 1758647946
    },
    {
        "content": "<p>I've reviewed these models on this Zulip instance. DeepSeek Prover v2 was the strongest model.</p>",
        "id": 541064827,
        "sender_full_name": "(deleted)",
        "timestamp": 1758647979
    },
    {
        "content": "<p>Goedel Prover v2 is very weak, near useless.</p>",
        "id": 541064863,
        "sender_full_name": "(deleted)",
        "timestamp": 1758647997
    },
    {
        "content": "<p>Kimina Prover is moderately strong.</p>",
        "id": 541064885,
        "sender_full_name": "(deleted)",
        "timestamp": 1758648006
    },
    {
        "content": "<p>I have yet to try LeanDojo, Lean copilot or agentic search</p>",
        "id": 541064940,
        "sender_full_name": "(deleted)",
        "timestamp": 1758648027
    },
    {
        "content": "<p>Is that pro reasoning?  <a href=\"https://chatgpt.com/?openaicom_referred=true#pricing\">https://chatgpt.com/?openaicom_referred=true#pricing</a> <br>\n<a href=\"/user_uploads/3121/OAk7VxawdfO5mnod753XzmTh/image.png\">image.png</a></p>\n<div class=\"message_inline_image\"><a href=\"/user_uploads/3121/OAk7VxawdfO5mnod753XzmTh/image.png\" title=\"image.png\"><img data-original-content-type=\"image/png\" data-original-dimensions=\"911x520\" src=\"/user_uploads/thumbnail/3121/OAk7VxawdfO5mnod753XzmTh/image.png/840x560.webp\"></a></div><p>I had it for awhile, but at the time it wasn't SOTA for the cost, but I am considering trying again with gpt-5</p>",
        "id": 541065472,
        "sender_full_name": "Deleted User 968128",
        "timestamp": 1758648252
    },
    {
        "content": "<p>I don't have a paid ChatGPT plan. I use GPT-5 through Cursor.</p>",
        "id": 541065718,
        "sender_full_name": "(deleted)",
        "timestamp": 1758648334
    },
    {
        "content": "<p><a href=\"https://github.com/aziksh-ospanov/APOLLO\">https://github.com/aziksh-ospanov/APOLLO</a> looks interesting as well. (removed offtopic stuff)</p>",
        "id": 541067277,
        "sender_full_name": "Deleted User 968128",
        "timestamp": 1758648864
    },
    {
        "content": "<p>It's a pity that Apollo does not evaluate on modern benchmarks...</p>",
        "id": 541178092,
        "sender_full_name": "Bas Spitters",
        "timestamp": 1758704656
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"511228\">@Huỳnh Trần Khanh</span> What kind of problems are you giving to the LLMs? Basic maths? CS? ...?</p>",
        "id": 541178494,
        "sender_full_name": "Bas Spitters",
        "timestamp": 1758704778
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"259452\">@Bas Spitters</span> What do you consider a modern benchmark?  It evaluates on MiniF2F.  Or do you mean benchmarks with less possibility of data leakage?</p>",
        "id": 541178952,
        "sender_full_name": "Jason Rute",
        "timestamp": 1758704918
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"259452\">Bas Spitters</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Role.20reversal/near/541178494\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"511228\">Huỳnh Trần Khanh</span> What kind of problems are you giving to the LLMs? Basic maths? CS? ...?</p>\n</blockquote>\n<p>Here's a sample:</p>\n<p><a href=\"/user_uploads/3121/HNuGq6Xa3G9f_iGBW6JI4TKL/PastedText.txt\">PastedText.txt</a></p>\n<p>Download to view the file without mojibake</p>",
        "id": 541181337,
        "sender_full_name": "(deleted)",
        "timestamp": 1758705625
    },
    {
        "content": "<p>This file will end up in the Project Numina data dump next year. You're given a preview of next year's data dump :))</p>",
        "id": 541181659,
        "sender_full_name": "(deleted)",
        "timestamp": 1758705722
    },
    {
        "content": "<p>Here's another sample. It's a monstrous proof.<br>\n<a href=\"/user_uploads/3121/Ov95LbC6AdRYla_IfeSfhx-7/PastedText.txt\">PastedText.txt</a></p>",
        "id": 541182150,
        "sender_full_name": "(deleted)",
        "timestamp": 1758705875
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"115715\">@Jason Rute</span> i hear that <a href=\"https://huggingface.co/datasets/PAug/ProofNetSharp\">https://huggingface.co/datasets/PAug/ProofNetSharp</a> has less leakage, but I'm happy to be corrected. What are your favorite benchmarks?</p>",
        "id": 541183359,
        "sender_full_name": "Bas Spitters",
        "timestamp": 1758706214
    },
    {
        "content": "<p>CombiBench is my favorite</p>",
        "id": 541185213,
        "sender_full_name": "(deleted)",
        "timestamp": 1758706747
    },
    {
        "content": "<p>And MiniF2F is my least favorite</p>",
        "id": 541185237,
        "sender_full_name": "(deleted)",
        "timestamp": 1758706756
    },
    {
        "content": "<p>Goedel Prover v2 is a model that performs well on MiniF2F while being useless in real world use</p>",
        "id": 541185331,
        "sender_full_name": "(deleted)",
        "timestamp": 1758706782
    },
    {
        "content": "<p><a href=\"https://github.com/MoonshotAI/CombiBench/\">https://github.com/MoonshotAI/CombiBench/</a></p>",
        "id": 541186237,
        "sender_full_name": "(deleted)",
        "timestamp": 1758707069
    },
    {
        "content": "<p>interresting idea. i use directly GPT-5 exclusively inside vscode in Ask/Edit or Agent mode. But your idea to get it first write a human readable proof is interresting. i'll try this setup in vscode to see if it makes GPT-5 become even better.</p>",
        "id": 541186445,
        "sender_full_name": "Alfredo Moreira-Rosa",
        "timestamp": 1758707132
    },
    {
        "content": "<p>Thanks <span class=\"user-mention\" data-user-id=\"511228\">@Huỳnh Trần Khanh</span> , so basically IMO style problems. That's a good benchmark.</p>",
        "id": 541195314,
        "sender_full_name": "Bas Spitters",
        "timestamp": 1758710049
    },
    {
        "content": "<p>Both Lean-Star and NLIR (for Rocq) use natural language as an intermediate language, since this is what the models are trained on.</p>",
        "id": 541195592,
        "sender_full_name": "Bas Spitters",
        "timestamp": 1758710152
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"259452\">Bas Spitters</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Role.20reversal/near/541178092\">said</a>:</p>\n<blockquote>\n<p>It's a pity that Apollo does not evaluate on modern benchmarks...</p>\n</blockquote>\n<p>It is my intuition that benchmarks in general have much less value compared to transparent leaderboards(LBs).   A great deal of the effort in evals is just performing the evals, especially as new models / agentic flows are released so frequently.  Also, 3rd party evals are always more credible than self-evals, if they're done in a transparent fashion.</p>\n<p>If someone in the local community were to create an LB (they can use a weighted blend of benchmarks already available) it would become a hub of innovation for sure.  A useful template for this is <a href=\"https://swe-rebench.com/\">https://swe-rebench.com/</a> (date slider is quite nice), though they are not that transparent and could focus more on agentic flows rather than just models.</p>\n<p>Benchmarks can be added/removed and re-weighted over time, as long as historical values are kept like swe-rebench and there is credible evidence that there is no untoward bias and it's done in a thoughtful / transparent and evolutionary fashion.</p>",
        "id": 541335360,
        "sender_full_name": "Deleted User 968128",
        "timestamp": 1758750338
    },
    {
        "content": "<p>For the sake of honesty: today, Gemini Deep Think generated a very wrong proof. I'm sad. But not surprised, it's AI after all.</p>",
        "id": 541528659,
        "sender_full_name": "(deleted)",
        "timestamp": 1758827526
    },
    {
        "content": "<p>I told it to prove a theorem, but it only considered the simplest case</p>",
        "id": 541528815,
        "sender_full_name": "(deleted)",
        "timestamp": 1758827595
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"511228\">Huỳnh Trần Khanh</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Role.20reversal/near/541528659\">said</a>:</p>\n<blockquote>\n<p>For the sake of honesty: today, Gemini Deep Think generated a very wrong proof. I'm sad. But not surprised, it's AI after all.</p>\n</blockquote>\n<p>This would be a really great topic to start.   AI failures.  I'd like to try this proof out on some different systems</p>",
        "id": 541533718,
        "sender_full_name": "Deleted User 968128",
        "timestamp": 1758829568
    }
]