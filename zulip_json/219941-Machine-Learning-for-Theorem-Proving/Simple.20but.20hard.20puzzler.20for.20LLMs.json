[
    {
        "content": "<p>I have tried Perplexity.AI, ChatGPT, Claude, Microsoft Copilot and Meta.AI on this simple theorem.  They all get it wrong and most of them invent Mathlib theorems as they go along to apply their proofs.  I think it has to do with a transition between Boolean and Prop usage for theorems about lists that happened in the past 18 months in Lean 4, differences between IsPrefix and isPrefixOf which become extremely tricky when going back and forth between Bool and Prop notations.  I tried LeanGPT which also failed.  Are there any openly accessible Lean AI proof assistants that can get this one right?</p>\n<div class=\"codehilite\" data-code-language=\"Lean4\"><pre><span></span><code><span class=\"kn\">theorem</span><span class=\"w\"> </span><span class=\"n\">prefix_to_suffix</span><span class=\"w\"> </span><span class=\"o\">{</span><span class=\"n\">a</span><span class=\"w\"> </span><span class=\"n\">l</span><span class=\"w\"> </span><span class=\"o\">:</span><span class=\"w\"> </span><span class=\"n\">List</span><span class=\"w\"> </span><span class=\"o\">(</span><span class=\"n\">ℕ</span><span class=\"w\"> </span><span class=\"bp\">×</span><span class=\"w\"> </span><span class=\"n\">ℕ</span><span class=\"w\"> </span><span class=\"bp\">×</span><span class=\"w\"> </span><span class=\"n\">ℕ</span><span class=\"w\"> </span><span class=\"bp\">×</span><span class=\"w\"> </span><span class=\"n\">ℕ</span><span class=\"o\">)}</span><span class=\"w\"> </span><span class=\"o\">(</span><span class=\"n\">h</span><span class=\"w\"> </span><span class=\"o\">:</span><span class=\"w\"> </span><span class=\"n\">l</span><span class=\"w\"> </span><span class=\"bp\">&lt;</span><span class=\"o\">:</span><span class=\"bp\">+</span><span class=\"w\"> </span><span class=\"n\">a</span><span class=\"o\">)</span><span class=\"w\"> </span><span class=\"o\">:</span><span class=\"w\"> </span><span class=\"n\">l</span><span class=\"bp\">.</span><span class=\"n\">reverse</span><span class=\"w\"> </span><span class=\"bp\">&lt;</span><span class=\"o\">:</span><span class=\"bp\">+</span><span class=\"w\"> </span><span class=\"n\">a</span><span class=\"bp\">.</span><span class=\"n\">reverse</span><span class=\"w\"> </span><span class=\"o\">:=</span><span class=\"w\"> </span><span class=\"gr\">sorry</span>\n</code></pre></div>",
        "id": 488880432,
        "sender_full_name": "Lars Ericson",
        "timestamp": 1734108211
    },
    {
        "content": "<p>Well, I think your theorem statement is wrong. You have IsSuffix, <code>&lt;:+</code>, on both h and the conclusion. One of those should be IsPrefix, <code>&lt;+:</code>, instead. If I fix it, then it's a theorem (in Init, not even in Mathlib!) and so <code>exact?</code> or <code>apply?</code> find it immediately.</p>\n<div class=\"codehilite\" data-code-language=\"Lean4\"><pre><span></span><code><span class=\"kn\">theorem</span><span class=\"w\"> </span><span class=\"n\">prefix_to_suffix</span><span class=\"w\"> </span><span class=\"o\">{</span><span class=\"n\">a</span><span class=\"w\"> </span><span class=\"n\">l</span><span class=\"w\"> </span><span class=\"o\">:</span><span class=\"w\"> </span><span class=\"n\">List</span><span class=\"w\"> </span><span class=\"o\">(</span><span class=\"n\">ℕ</span><span class=\"w\"> </span><span class=\"bp\">×</span><span class=\"w\"> </span><span class=\"n\">ℕ</span><span class=\"w\"> </span><span class=\"bp\">×</span><span class=\"w\"> </span><span class=\"n\">ℕ</span><span class=\"w\"> </span><span class=\"bp\">×</span><span class=\"w\"> </span><span class=\"n\">ℕ</span><span class=\"o\">)}</span><span class=\"w\"> </span><span class=\"o\">(</span><span class=\"n\">h</span><span class=\"w\"> </span><span class=\"o\">:</span><span class=\"w\"> </span><span class=\"n\">l</span><span class=\"w\"> </span><span class=\"bp\">&lt;</span><span class=\"o\">:</span><span class=\"bp\">+</span><span class=\"w\"> </span><span class=\"n\">a</span><span class=\"o\">)</span><span class=\"w\"> </span><span class=\"o\">:</span><span class=\"w\"> </span><span class=\"n\">l</span><span class=\"bp\">.</span><span class=\"n\">reverse</span><span class=\"w\"> </span><span class=\"bp\">&lt;+</span><span class=\"o\">:</span><span class=\"w\"> </span><span class=\"n\">a</span><span class=\"bp\">.</span><span class=\"n\">reverse</span><span class=\"w\"> </span><span class=\"o\">:=</span><span class=\"w\"> </span><span class=\"k\">by</span>\n<span class=\"w\">  </span><span class=\"n\">exact</span><span class=\"w\"> </span><span class=\"n\">List</span><span class=\"bp\">.</span><span class=\"n\">reverse_prefix</span><span class=\"bp\">.</span><span class=\"n\">mpr</span><span class=\"w\"> </span><span class=\"n\">h</span>\n</code></pre></div>\n<p>is a working proof. Technically,</p>\n<div class=\"codehilite\" data-code-language=\"Lean4\"><pre><span></span><code><span class=\"kn\">theorem</span><span class=\"w\"> </span><span class=\"n\">prefix_to_suffix</span><span class=\"w\"> </span><span class=\"o\">{</span><span class=\"n\">a</span><span class=\"w\"> </span><span class=\"n\">l</span><span class=\"w\"> </span><span class=\"o\">:</span><span class=\"w\"> </span><span class=\"n\">List</span><span class=\"w\"> </span><span class=\"o\">(</span><span class=\"n\">ℕ</span><span class=\"w\"> </span><span class=\"bp\">×</span><span class=\"w\"> </span><span class=\"n\">ℕ</span><span class=\"w\"> </span><span class=\"bp\">×</span><span class=\"w\"> </span><span class=\"n\">ℕ</span><span class=\"w\"> </span><span class=\"bp\">×</span><span class=\"w\"> </span><span class=\"n\">ℕ</span><span class=\"o\">)}</span><span class=\"w\"> </span><span class=\"o\">(</span><span class=\"n\">h</span><span class=\"w\"> </span><span class=\"o\">:</span><span class=\"w\"> </span><span class=\"n\">l</span><span class=\"w\"> </span><span class=\"bp\">&lt;</span><span class=\"o\">:</span><span class=\"bp\">+</span><span class=\"w\"> </span><span class=\"n\">a</span><span class=\"o\">)</span><span class=\"w\"> </span><span class=\"o\">:</span><span class=\"w\"> </span><span class=\"n\">l</span><span class=\"bp\">.</span><span class=\"n\">reverse</span><span class=\"w\"> </span><span class=\"bp\">&lt;+</span><span class=\"o\">:</span><span class=\"w\"> </span><span class=\"n\">a</span><span class=\"bp\">.</span><span class=\"n\">reverse</span><span class=\"w\"> </span><span class=\"o\">:=</span><span class=\"w\"> </span><span class=\"k\">by</span>\n<span class=\"w\">  </span><span class=\"n\">exact?</span>\n</code></pre></div>\n<p>is a complete proof too.</p>\n<p>Basically every AI agent <em>can</em> output <code>exact?</code> pretty easily, so they will all solve this with ease.</p>",
        "id": 488881688,
        "sender_full_name": "Alex Meiburg",
        "timestamp": 1734108606
    },
    {
        "content": "<p>ChatGPT o1 got this right for me (I think)</p>\n<p><a href=\"https://chatgpt.com/share/675c651a-c6c8-8000-bca0-382199bda1b0\">https://chatgpt.com/share/675c651a-c6c8-8000-bca0-382199bda1b0</a></p>\n<div class=\"codehilite\" data-code-language=\"Lean4\"><pre><span></span><code><span class=\"kn\">theorem</span><span class=\"w\"> </span><span class=\"n\">prefix_to_suffix</span><span class=\"w\"> </span><span class=\"o\">{</span><span class=\"n\">a</span><span class=\"w\"> </span><span class=\"n\">l</span><span class=\"w\"> </span><span class=\"o\">:</span><span class=\"w\"> </span><span class=\"n\">List</span><span class=\"w\"> </span><span class=\"o\">(</span><span class=\"n\">ℕ</span><span class=\"w\"> </span><span class=\"bp\">×</span><span class=\"w\"> </span><span class=\"n\">ℕ</span><span class=\"w\"> </span><span class=\"bp\">×</span><span class=\"w\"> </span><span class=\"n\">ℕ</span><span class=\"w\"> </span><span class=\"bp\">×</span><span class=\"w\"> </span><span class=\"n\">ℕ</span><span class=\"o\">)}</span><span class=\"w\"> </span><span class=\"o\">(</span><span class=\"n\">h</span><span class=\"w\"> </span><span class=\"o\">:</span><span class=\"w\"> </span><span class=\"n\">l</span><span class=\"w\"> </span><span class=\"bp\">&lt;+</span><span class=\"o\">:</span><span class=\"w\"> </span><span class=\"n\">a</span><span class=\"o\">)</span><span class=\"w\"> </span><span class=\"o\">:</span><span class=\"w\"> </span><span class=\"n\">l</span><span class=\"bp\">.</span><span class=\"n\">reverse</span><span class=\"w\"> </span><span class=\"bp\">&lt;</span><span class=\"o\">:</span><span class=\"bp\">+</span><span class=\"w\"> </span><span class=\"n\">a</span><span class=\"bp\">.</span><span class=\"n\">reverse</span><span class=\"w\"> </span><span class=\"o\">:=</span><span class=\"w\"> </span><span class=\"k\">by</span>\n<span class=\"w\">  </span><span class=\"k\">obtain</span><span class=\"w\"> </span><span class=\"bp\">⟨</span><span class=\"n\">t</span><span class=\"o\">,</span><span class=\"w\"> </span><span class=\"n\">rfl</span><span class=\"bp\">⟩</span><span class=\"w\"> </span><span class=\"o\">:=</span><span class=\"w\"> </span><span class=\"n\">h</span>\n<span class=\"w\">  </span><span class=\"n\">rw</span><span class=\"w\"> </span><span class=\"o\">[</span><span class=\"n\">List</span><span class=\"bp\">.</span><span class=\"n\">reverse_append</span><span class=\"o\">]</span>\n<span class=\"w\">  </span><span class=\"n\">exact</span><span class=\"w\"> </span><span class=\"bp\">⟨</span><span class=\"n\">t</span><span class=\"bp\">.</span><span class=\"n\">reverse</span><span class=\"o\">,</span><span class=\"w\"> </span><span class=\"n\">rfl</span><span class=\"bp\">⟩</span>\n</code></pre></div>",
        "id": 488881837,
        "sender_full_name": "Joseph Tooby-Smith",
        "timestamp": 1734108661
    },
    {
        "content": "<p>ChatGPT actually spat out <code>exact List.IsSuffix.reverse h</code> for me, which works too.</p>",
        "id": 488882095,
        "sender_full_name": "Alex Meiburg",
        "timestamp": 1734108738
    },
    {
        "content": "<p>I would be impressed though if an AI could do it all as an explicit term without referring to the <code>reverse_prefix</code> theorem. :)</p>\n<div class=\"codehilite\" data-code-language=\"Lean4\"><pre><span></span><code><span class=\"kn\">theorem</span><span class=\"w\"> </span><span class=\"n\">prefix_to_suffix</span><span class=\"w\"> </span><span class=\"o\">{</span><span class=\"n\">a</span><span class=\"w\"> </span><span class=\"n\">l</span><span class=\"w\"> </span><span class=\"o\">:</span><span class=\"w\"> </span><span class=\"n\">List</span><span class=\"w\"> </span><span class=\"o\">(</span><span class=\"n\">ℕ</span><span class=\"w\"> </span><span class=\"bp\">×</span><span class=\"w\"> </span><span class=\"n\">ℕ</span><span class=\"w\"> </span><span class=\"bp\">×</span><span class=\"w\"> </span><span class=\"n\">ℕ</span><span class=\"w\"> </span><span class=\"bp\">×</span><span class=\"w\"> </span><span class=\"n\">ℕ</span><span class=\"o\">)}</span><span class=\"w\"> </span><span class=\"o\">(</span><span class=\"n\">h</span><span class=\"w\"> </span><span class=\"o\">:</span><span class=\"w\"> </span><span class=\"n\">l</span><span class=\"w\"> </span><span class=\"bp\">&lt;</span><span class=\"o\">:</span><span class=\"bp\">+</span><span class=\"w\"> </span><span class=\"n\">a</span><span class=\"o\">)</span><span class=\"w\"> </span><span class=\"o\">:</span><span class=\"w\"> </span><span class=\"n\">l</span><span class=\"bp\">.</span><span class=\"n\">reverse</span><span class=\"w\"> </span><span class=\"bp\">&lt;+</span><span class=\"o\">:</span><span class=\"w\"> </span><span class=\"n\">a</span><span class=\"bp\">.</span><span class=\"n\">reverse</span><span class=\"w\"> </span><span class=\"o\">:=</span>\n<span class=\"w\">  </span><span class=\"n\">h</span><span class=\"bp\">.</span><span class=\"n\">rec</span><span class=\"w\"> </span><span class=\"k\">fun</span><span class=\"w\"> </span><span class=\"n\">w</span><span class=\"w\"> </span><span class=\"n\">h</span><span class=\"w\"> </span><span class=\"bp\">↦</span><span class=\"w\"> </span><span class=\"bp\">⟨</span><span class=\"n\">w</span><span class=\"bp\">.</span><span class=\"n\">reverse</span><span class=\"o\">,</span><span class=\"w\"> </span><span class=\"n\">h</span><span class=\"bp\">.</span><span class=\"n\">rec</span><span class=\"w\"> </span><span class=\"o\">(</span><span class=\"n\">List</span><span class=\"bp\">.</span><span class=\"n\">reverse_append</span><span class=\"w\"> </span><span class=\"bp\">_</span><span class=\"w\"> </span><span class=\"bp\">_</span><span class=\"o\">)</span><span class=\"bp\">.</span><span class=\"n\">symm</span><span class=\"bp\">⟩</span>\n</code></pre></div>",
        "id": 488882930,
        "sender_full_name": "Alex Meiburg",
        "timestamp": 1734109026
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"448405\">@Alex Meiburg</span> you're right I intended to do prefix to suffix so +: to :+.</p>",
        "id": 488915101,
        "sender_full_name": "Lars Ericson",
        "timestamp": 1734121572
    },
    {
        "content": "<p>It seems like the general LLMs have caught up enough with Lean that specialized LLM fine-tunes like LeanGPT aren't as much of a topic, where they were more so maybe last year.</p>",
        "id": 488915321,
        "sender_full_name": "Lars Ericson",
        "timestamp": 1734121684
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"448405\">Alex Meiburg</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Simple.20but.20hard.20puzzler.20for.20LLMs/near/488881688\">said</a>:</p>\n<blockquote>\n<p>Basically every AI agent <em>can</em> output <code>exact?</code> pretty easily, so they will all solve this with ease.</p>\n</blockquote>\n<p>I don't know of a single AI agent for Lean, either local neural-symbolic AIs (e.g. Lean Copilot), LLM chatbots (e.g. Claude, ChatGPT, etc), or even symbolic AIs (e.g. <code>aesop</code>) that uses <code>exact?</code> (or it's underlying discrimination tree).  Sure, they <em>could</em>.  And maybe with the right prompting, they <em>would</em>.  And arguably, they <em>should</em> (especially since it is so fast now).  But I think in practice, they just <em>don't</em>.</p>",
        "id": 488943989,
        "sender_full_name": "Jason Rute",
        "timestamp": 1734136996
    },
    {
        "content": "<p>I think this discussion is really great.  In this case it happened to be that the lemma was false as originally stated, but overall, I'd love to see a lot <strong>more in-the-trenches AI for Lean</strong>.  What works and what doesn't?  (For example, I learned in the last week that Sonnet doesn't have near the Lean troubles that OpenAI's models do.)  What problems are tricky for AI but shouldn't be?  What tips and tricks do those who do Lean day-to-day have?</p>",
        "id": 488944254,
        "sender_full_name": "Jason Rute",
        "timestamp": 1734137201
    },
    {
        "content": "<p>Here is another example from same context, which is that I am trying to port <a href=\"https://github.com/alexoltean61\">this github</a> from 18 months ago Lean 4 to today Lean 4, as a learning exercise.  In particular, <a href=\"https://github.com/alexoltean61/hybrid_logic_lean/blob/main/Hybrid/FormCountable.lean#L48\">this lemma</a>:</p>\n<div class=\"codehilite\" data-code-language=\"Lean4\"><pre><span></span><code><span class=\"kn\">import</span><span class=\"w\"> </span><span class=\"n\">Mathlib</span>\n\n<span class=\"kn\">lemma</span><span class=\"w\"> </span><span class=\"n\">sum_is_prefix</span><span class=\"w\"> </span><span class=\"o\">{</span><span class=\"n\">a</span><span class=\"w\"> </span><span class=\"n\">b</span><span class=\"w\"> </span><span class=\"n\">n</span><span class=\"w\"> </span><span class=\"n\">m</span><span class=\"w\"> </span><span class=\"o\">:</span><span class=\"w\"> </span><span class=\"n\">List</span><span class=\"w\"> </span><span class=\"o\">(</span><span class=\"n\">ℕ</span><span class=\"w\"> </span><span class=\"bp\">×</span><span class=\"w\"> </span><span class=\"n\">ℕ</span><span class=\"w\"> </span><span class=\"bp\">×</span><span class=\"w\"> </span><span class=\"n\">ℕ</span><span class=\"w\"> </span><span class=\"bp\">×</span><span class=\"w\"> </span><span class=\"n\">ℕ</span><span class=\"o\">)}</span><span class=\"w\"> </span><span class=\"o\">(</span><span class=\"n\">h1</span><span class=\"w\"> </span><span class=\"o\">:</span><span class=\"w\"> </span><span class=\"n\">a</span><span class=\"w\"> </span><span class=\"bp\">++</span><span class=\"w\"> </span><span class=\"n\">b</span><span class=\"w\"> </span><span class=\"bp\">=</span><span class=\"w\"> </span><span class=\"n\">n</span><span class=\"w\"> </span><span class=\"bp\">++</span><span class=\"w\"> </span><span class=\"n\">m</span><span class=\"o\">)</span><span class=\"w\"> </span><span class=\"o\">(</span><span class=\"n\">h2</span><span class=\"w\"> </span><span class=\"o\">:</span><span class=\"w\"> </span><span class=\"n\">a</span><span class=\"bp\">.</span><span class=\"n\">length</span><span class=\"w\"> </span><span class=\"bp\">≤</span><span class=\"w\"> </span><span class=\"n\">n</span><span class=\"bp\">.</span><span class=\"n\">length</span><span class=\"o\">)</span><span class=\"w\"> </span><span class=\"o\">:</span><span class=\"w\"> </span><span class=\"n\">a</span><span class=\"bp\">.</span><span class=\"n\">isPrefixOf</span><span class=\"w\"> </span><span class=\"n\">n</span><span class=\"w\"> </span><span class=\"o\">:=</span><span class=\"w\"> </span><span class=\"k\">by</span>\n<span class=\"w\">  </span><span class=\"n\">induction</span><span class=\"w\"> </span><span class=\"n\">a</span><span class=\"w\"> </span><span class=\"n\">generalizing</span><span class=\"w\"> </span><span class=\"n\">n</span><span class=\"w\"> </span><span class=\"k\">with</span>\n<span class=\"w\">  </span><span class=\"bp\">|</span><span class=\"w\"> </span><span class=\"n\">nil</span><span class=\"w\"> </span><span class=\"bp\">=&gt;</span><span class=\"w\">  </span><span class=\"n\">simp</span><span class=\"w\"> </span><span class=\"o\">[</span><span class=\"n\">List</span><span class=\"bp\">.</span><span class=\"n\">isPrefixOf</span><span class=\"o\">]</span>\n<span class=\"w\">  </span><span class=\"bp\">|</span><span class=\"w\"> </span><span class=\"n\">cons</span><span class=\"w\"> </span><span class=\"n\">ha</span><span class=\"w\"> </span><span class=\"n\">ta</span><span class=\"w\"> </span><span class=\"n\">iha</span><span class=\"w\"> </span><span class=\"bp\">=&gt;</span>\n<span class=\"w\">      </span><span class=\"n\">cases</span><span class=\"w\"> </span><span class=\"n\">n</span><span class=\"w\"> </span><span class=\"k\">with</span>\n<span class=\"w\">      </span><span class=\"bp\">|</span><span class=\"w\"> </span><span class=\"n\">nil</span><span class=\"w\"> </span><span class=\"bp\">=&gt;</span>\n<span class=\"w\">          </span><span class=\"n\">simp</span><span class=\"w\"> </span><span class=\"k\">at</span><span class=\"w\"> </span><span class=\"n\">h2</span>\n<span class=\"w\">      </span><span class=\"bp\">|</span><span class=\"w\"> </span><span class=\"n\">cons</span><span class=\"w\"> </span><span class=\"n\">hn</span><span class=\"w\"> </span><span class=\"n\">tn</span><span class=\"w\"> </span><span class=\"bp\">=&gt;</span>\n<span class=\"w\">          </span><span class=\"n\">simp</span><span class=\"w\"> </span><span class=\"o\">[</span><span class=\"n\">List</span><span class=\"bp\">.</span><span class=\"n\">isPrefixOf</span><span class=\"o\">]</span>\n<span class=\"w\">          </span><span class=\"n\">simp</span><span class=\"w\"> </span><span class=\"k\">at</span><span class=\"w\"> </span><span class=\"n\">h1</span>\n<span class=\"w\">          </span><span class=\"n\">apply</span><span class=\"w\"> </span><span class=\"n\">And</span><span class=\"bp\">.</span><span class=\"n\">intro</span>\n<span class=\"w\">          </span><span class=\"bp\">.</span><span class=\"w\"> </span><span class=\"n\">simp</span><span class=\"w\"> </span><span class=\"o\">[</span><span class=\"n\">h1</span><span class=\"bp\">.</span><span class=\"n\">left</span><span class=\"o\">]</span>\n<span class=\"w\">          </span><span class=\"bp\">.</span><span class=\"w\"> </span><span class=\"n\">simp</span><span class=\"w\"> </span><span class=\"k\">at</span><span class=\"w\"> </span><span class=\"n\">h2</span>\n<span class=\"w\">            </span><span class=\"k\">have</span><span class=\"w\"> </span><span class=\"n\">h2</span><span class=\"w\"> </span><span class=\"o\">:=</span><span class=\"w\"> </span><span class=\"n\">Nat</span><span class=\"bp\">.</span><span class=\"n\">le_of_succ_le_succ</span><span class=\"w\"> </span><span class=\"n\">h2</span>\n<span class=\"w\">            </span><span class=\"n\">exact</span><span class=\"w\"> </span><span class=\"n\">iha</span><span class=\"w\"> </span><span class=\"n\">h1</span><span class=\"bp\">.</span><span class=\"n\">right</span><span class=\"w\"> </span><span class=\"n\">h2</span>\n</code></pre></div>\n<p>Current Lean 4 has a problem with the 2nd to last line.  I asked Perplexity for help.  It took <a href=\"https://www.perplexity.ai/search/this-lean-4-theorem-lemma-sum-erpZWy0HQd2sU597wq8QyQ\">9 passes and one hallucination</a> before Perplexity was able to port the code.  The final result was:</p>\n<div class=\"codehilite\" data-code-language=\"Lean4\"><pre><span></span><code><span class=\"kn\">import</span><span class=\"w\"> </span><span class=\"n\">Mathlib</span>\n\n<span class=\"kn\">lemma</span><span class=\"w\"> </span><span class=\"n\">sum_is_prefix</span><span class=\"w\"> </span><span class=\"o\">{</span><span class=\"n\">a</span><span class=\"w\"> </span><span class=\"n\">b</span><span class=\"w\"> </span><span class=\"n\">n</span><span class=\"w\"> </span><span class=\"n\">m</span><span class=\"w\"> </span><span class=\"o\">:</span><span class=\"w\"> </span><span class=\"n\">List</span><span class=\"w\"> </span><span class=\"o\">(</span><span class=\"n\">ℕ</span><span class=\"w\"> </span><span class=\"bp\">×</span><span class=\"w\"> </span><span class=\"n\">ℕ</span><span class=\"w\"> </span><span class=\"bp\">×</span><span class=\"w\"> </span><span class=\"n\">ℕ</span><span class=\"w\"> </span><span class=\"bp\">×</span><span class=\"w\"> </span><span class=\"n\">ℕ</span><span class=\"o\">)}</span><span class=\"w\"> </span><span class=\"o\">(</span><span class=\"n\">h1</span><span class=\"w\"> </span><span class=\"o\">:</span><span class=\"w\"> </span><span class=\"n\">a</span><span class=\"w\"> </span><span class=\"bp\">++</span><span class=\"w\"> </span><span class=\"n\">b</span><span class=\"w\"> </span><span class=\"bp\">=</span><span class=\"w\"> </span><span class=\"n\">n</span><span class=\"w\"> </span><span class=\"bp\">++</span><span class=\"w\"> </span><span class=\"n\">m</span><span class=\"o\">)</span><span class=\"w\"> </span><span class=\"o\">(</span><span class=\"n\">h2</span><span class=\"w\"> </span><span class=\"o\">:</span><span class=\"w\"> </span><span class=\"n\">a</span><span class=\"bp\">.</span><span class=\"n\">length</span><span class=\"w\"> </span><span class=\"bp\">≤</span><span class=\"w\"> </span><span class=\"n\">n</span><span class=\"bp\">.</span><span class=\"n\">length</span><span class=\"o\">)</span><span class=\"w\"> </span><span class=\"o\">:</span><span class=\"w\"> </span><span class=\"n\">a</span><span class=\"w\"> </span><span class=\"bp\">&lt;+</span><span class=\"o\">:</span><span class=\"w\"> </span><span class=\"n\">n</span><span class=\"w\"> </span><span class=\"o\">:=</span><span class=\"w\"> </span><span class=\"k\">by</span>\n<span class=\"w\">  </span><span class=\"n\">induction</span><span class=\"w\"> </span><span class=\"n\">a</span><span class=\"w\"> </span><span class=\"n\">generalizing</span><span class=\"w\"> </span><span class=\"n\">n</span><span class=\"w\"> </span><span class=\"k\">with</span>\n<span class=\"w\">  </span><span class=\"bp\">|</span><span class=\"w\"> </span><span class=\"n\">nil</span><span class=\"w\"> </span><span class=\"bp\">=&gt;</span><span class=\"w\">  </span><span class=\"n\">simp</span><span class=\"w\"> </span><span class=\"o\">[</span><span class=\"n\">List</span><span class=\"bp\">.</span><span class=\"n\">IsPrefix</span><span class=\"o\">]</span>\n<span class=\"w\">  </span><span class=\"bp\">|</span><span class=\"w\"> </span><span class=\"n\">cons</span><span class=\"w\"> </span><span class=\"n\">ha</span><span class=\"w\"> </span><span class=\"n\">ta</span><span class=\"w\"> </span><span class=\"n\">iha</span><span class=\"w\"> </span><span class=\"bp\">=&gt;</span>\n<span class=\"w\">      </span><span class=\"n\">cases</span><span class=\"w\"> </span><span class=\"n\">n</span><span class=\"w\"> </span><span class=\"k\">with</span>\n<span class=\"w\">      </span><span class=\"bp\">|</span><span class=\"w\"> </span><span class=\"n\">nil</span><span class=\"w\"> </span><span class=\"bp\">=&gt;</span>\n<span class=\"w\">          </span><span class=\"n\">simp</span><span class=\"w\"> </span><span class=\"k\">at</span><span class=\"w\"> </span><span class=\"n\">h2</span>\n<span class=\"w\">      </span><span class=\"bp\">|</span><span class=\"w\"> </span><span class=\"n\">cons</span><span class=\"w\"> </span><span class=\"n\">hn</span><span class=\"w\"> </span><span class=\"n\">tn</span><span class=\"w\"> </span><span class=\"bp\">=&gt;</span>\n<span class=\"w\">          </span><span class=\"n\">simp</span><span class=\"w\"> </span><span class=\"o\">[</span><span class=\"n\">List</span><span class=\"bp\">.</span><span class=\"n\">IsPrefix</span><span class=\"o\">]</span>\n<span class=\"w\">          </span><span class=\"n\">simp</span><span class=\"w\"> </span><span class=\"k\">at</span><span class=\"w\"> </span><span class=\"n\">h1</span>\n<span class=\"w\">          </span><span class=\"n\">apply</span><span class=\"w\"> </span><span class=\"n\">And</span><span class=\"bp\">.</span><span class=\"n\">intro</span>\n<span class=\"w\">          </span><span class=\"bp\">.</span><span class=\"w\"> </span><span class=\"n\">simp</span><span class=\"w\"> </span><span class=\"o\">[</span><span class=\"n\">h1</span><span class=\"bp\">.</span><span class=\"n\">left</span><span class=\"o\">]</span>\n<span class=\"w\">          </span><span class=\"bp\">.</span><span class=\"w\"> </span><span class=\"n\">simp</span><span class=\"w\"> </span><span class=\"k\">at</span><span class=\"w\"> </span><span class=\"n\">h2</span>\n<span class=\"w\">            </span><span class=\"k\">have</span><span class=\"w\"> </span><span class=\"n\">h2'</span><span class=\"w\"> </span><span class=\"o\">:</span><span class=\"w\"> </span><span class=\"n\">ta</span><span class=\"bp\">.</span><span class=\"n\">length</span><span class=\"bp\">.</span><span class=\"n\">succ</span><span class=\"w\"> </span><span class=\"bp\">≤</span><span class=\"w\"> </span><span class=\"n\">tn</span><span class=\"bp\">.</span><span class=\"n\">length</span><span class=\"bp\">.</span><span class=\"n\">succ</span><span class=\"w\"> </span><span class=\"o\">:=</span><span class=\"w\"> </span><span class=\"n\">Nat</span><span class=\"bp\">.</span><span class=\"n\">succ_le_succ</span><span class=\"w\"> </span><span class=\"n\">h2</span>\n<span class=\"w\">            </span><span class=\"k\">have</span><span class=\"w\"> </span><span class=\"n\">ih</span><span class=\"w\"> </span><span class=\"o\">:=</span><span class=\"w\"> </span><span class=\"n\">iha</span><span class=\"w\"> </span><span class=\"n\">h1</span><span class=\"bp\">.</span><span class=\"n\">right</span><span class=\"w\"> </span><span class=\"o\">(</span><span class=\"n\">Nat</span><span class=\"bp\">.</span><span class=\"n\">le_of_succ_le_succ</span><span class=\"w\"> </span><span class=\"n\">h2'</span><span class=\"o\">)</span>\n<span class=\"w\">            </span><span class=\"n\">exact</span><span class=\"w\"> </span><span class=\"n\">ih</span>\n</code></pre></div>\n<p>This also raises a question of the archival quality of Lean as a \"LaTeX of proofs\": it seems that the reliability of a proof is married to the version of the proof checker at the moment it checked.  Is this a problem that needs to be solved?  Does solving this problem inhibit and constrain further development?  Or is it a kind of passing phase, and things will settle down?  </p>\n<p>Separate question that comes to mind:  In Lean 4, for example, a <code>Field</code>is a <code>CommRing</code> and a <code>DivisionRing</code>, where a <code>CommRing</code> is a <code>Ring</code> and <code>CommMonoid</code>, and a <code>Ring</code> is a <code>Semiring</code> and an <code>AddCommGroup</code> and an <code>AddGroupWithOne</code>, and a <code>Semiring</code> is a <code>NonUnitalSemiring</code>, <code>NonAssocSemiring</code>, and a <code>MonoidWithZero</code>, and a <code>NonUnitalSemiring</code> is a<code>NonUnitalNonAssocSemiring</code> and a <code>SemigroupWithZero</code>, and a <code>NonUnitalNonAssocSemiring</code> is an <code>AddCommMonoid</code> and a <code>Distrib</code> and a <code>MulZeroClass</code>, and an <code>AddCommMonoid</code> is an <code>AddMonoid</code> and a <code>AddCommSemigroup</code>, and an <code>AddMonoid</code> is an <code>AddSemigroup</code> and an <code>AddZeroClass</code>, and an <code>AddSemigroup</code> is an <code>Add</code>, and somewhere along the line one of these is eventually a <code>CommMagma</code>, where a <code>Magma</code> is <a href=\"https://en.wikipedia.org/wiki/Magma_(algebra)\">something French</a> that used to be a <a href=\"https://en.wikipedia.org/wiki/Groupoid\">Brandt Groupoid</a> until it wasn't.  This filleting of <code>Field</code> goes way way beyond MacLane and Birkhoff's Algebra book, which has no <code>Magma</code> in it and in which <code>Field</code> is defined as \"a non-trivial commutative ring in which every non-zero element has a multiplicative inverse\".  I don't think that, <code>Magma</code> aside, if you carefully traversed all of the definitions underlying that sentence in <a href=\"https://archive.org/details/algebra0000unse_c0s0/page/132/mode/2up?q=magma\">pages 1-133 of the book</a>, that you would get the exact breakdown that exists in Mathlib.  So...what if the breakdown in Mathlib itself were to change, over time?  It could, couldn't it?  How people like to organize facts and definitions can change.  What happens to all the proofs that depend on an earlier revision of that hierarchy? The simple answer is that all those proofs might break.  Not because the syntax of the language has changed, but because the intellectual organization or semantics of the library has changed or been refactored.  </p>\n<p>Those are a couple of challenges to long-term use of Lean as a go-to archival language and lingua franca for proofs.  These are things which don't matter in the moment (it is very satisfying to see a proof check), but worth thinking about long term.  Otherwise we can expect to see a lot of digital rot of checkable proofs in the same way that people who own VHS videotapes and compact discs can see those assets age and become inaccessible as things change.</p>",
        "id": 488949245,
        "sender_full_name": "Lars Ericson",
        "timestamp": 1734141379
    },
    {
        "content": "<p>Well -- unless something very strange happened -- that GitHub repo from 18 months ago will still compile and check just fine right now. And, in case you're worried about there being some old bug in a previous version of Lean that is fixed today, you can still verify the proof with the checker today (I don't think the binary form has changed incompatibly.) It will still work, because it specifies a particular version of Lean (in <code>lean-toolchain</code>) and of Mathlib (in <code>lake-manifest</code>).</p>\n<p>I would argue that, based on this, the \"reliability\" of the proof isn't compromised: it's easy for me to download the repo and verify it now.</p>\n<p>Now, it is true that porting it the newer versions is not very easy, if you want to then use those proofs in some new repo. But that feels, to me, like a very different flavor than VHS which many people now simply cannot view. It's more like some old and somewhat-fragile C code that someone wants to port to a modern C++ codebase (remember that reverse-compatibility with C is one of the top priorities for the C++ consortium, to the grief of many). Will it mostly work? Sure. Will porting it to fully work be easy? No. Can I always just compile the old C code in C, instead of C++, and get a working object file? Yes.</p>",
        "id": 488951191,
        "sender_full_name": "Alex Meiburg",
        "timestamp": 1734143182
    },
    {
        "content": "<p>That being said ... it might be nice if there was some kind of bisection tool for forward porting. You've got a proof from an old version that you want to use now, but it doesn't work and you don't know what changed.</p>\n<p>So, imagine a script that run forward through revisions of mathlib and lean until the proof breaks. It shows you the offending commit to mathlib/lean that broke the proof. At that point, it should be much more obvious what changed, and you can probably fix it easily. Then you resume running forward, until you get to the current version.</p>\n<p>I know I could have used such a tool a few days ago...</p>",
        "id": 488951348,
        "sender_full_name": "Alex Meiburg",
        "timestamp": 1734143308
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"115715\">Jason Rute</span> <a href=\"#narrow/stream/219941-Machine-Learning-for-Theorem-Proving/topic/Simple.20but.20hard.20puzzler.20for.20LLMs/near/488943989\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"448405\">Alex Meiburg</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Simple.20but.20hard.20puzzler.20for.20LLMs/near/488881688\">said</a>:</p>\n<blockquote>\n<p>Basically every AI agent <em>can</em> output <code>exact?</code> pretty easily, so they will all solve this with ease.</p>\n</blockquote>\n<p>I don't know of a single AI agent for Lean, either local neural-symbolic AIs (e.g. Lean Copilot), LLM chatbots (e.g. Claude, ChatGPT, etc), or even symbolic AIs (e.g. <code>aesop</code>) that uses <code>exact?</code> (or it's underlying discrimination tree).  Sure, they <em>could</em>.  And maybe with the right prompting, they <em>would</em>.  And arguably, they <em>should</em> (especially since it is so fast now).  But I think in practice, they just <em>don't</em>.</p>\n</blockquote>\n<p>Actually, we know that AlphaProof calls exact?. In their solution to IMO2024P6 <a href=\"https://storage.googleapis.com/deepmind-media/DeepMind.com/Blog/imo-2024-solutions/P6/index.html\">https://storage.googleapis.com/deepmind-media/DeepMind.com/Blog/imo-2024-solutions/P6/index.html</a> on one line they used \"by hint\", where hint is a tactic that tries a group of tactics including exact?.</p>\n<p>Similar to exact?, you wouldn't find hint in any actual human written proof, because people would see the squiggly line and click to replace with the message in Infoview. So the only possibility is that AlphaProof either has human demonstration of specifically using hint, or has a prompt to try it (eg giving it the entire tactic documentation)</p>",
        "id": 488952804,
        "sender_full_name": "Thomas Zhu",
        "timestamp": 1734144640
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"631691\">Thomas Zhu</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Simple.20but.20hard.20puzzler.20for.20LLMs/near/488952804\">said</a>:</p>\n<blockquote>\n<p>Actually, we know that AlphaProof calls exact?.</p>\n</blockquote>\n<p>Great, I stand corrected!  Still glad I made the claim, otherwise I wouldn't have noticed this. I'll now weaken it to saying no <em>publically usable</em> AI for Lean uses <code>exact?</code>, but happy to be corrected again. <span aria-label=\"stuck out tongue\" class=\"emoji emoji-1f61b\" role=\"img\" title=\"stuck out tongue\">:stuck_out_tongue:</span></p>",
        "id": 488953051,
        "sender_full_name": "Jason Rute",
        "timestamp": 1734144879
    },
    {
        "content": "<p>I think this speaks to another flaw in many LLM for Lean training procedures: there are many tactics natural to proof search (aesop, simp_all, hint) but bad for proof representation (one would replace with simp only, exact _, etc). LLMs are trained with the latter data because of Mathlib code style, but the former might in fact prove more theorems. I remember the ABEL paper saying they replaced simp only with simp in the Appendix, because of this.</p>\n<p>A parallel mismatch is between Mathlib and competition-style problems: for example, I am pretty sure basically 0 theorems on Mathlib can be proved using the tactic omega. But \"by omega\" solves a nontrivial percentage of miniF2F problems.</p>",
        "id": 488953636,
        "sender_full_name": "Thomas Zhu",
        "timestamp": 1734145419
    },
    {
        "content": "<p>Here is one more I tried on Perplexity and just couldn't get anywhere.   Perplexity assumes a Mathlib of a while ago and also frequently hallucinates Mathlib theorems that probably never existed.  The theorem to prove is</p>\n<div class=\"codehilite\" data-code-language=\"Lean4\"><pre><span></span><code><span class=\"kn\">theorem</span><span class=\"w\"> </span><span class=\"n\">prime_2_3</span><span class=\"w\"> </span><span class=\"o\">(</span><span class=\"n\">n</span><span class=\"w\"> </span><span class=\"n\">m</span><span class=\"w\"> </span><span class=\"o\">:</span><span class=\"w\"> </span><span class=\"n\">Nat</span><span class=\"o\">)</span><span class=\"w\"> </span><span class=\"o\">:</span><span class=\"w\"> </span><span class=\"mi\">3</span><span class=\"bp\">^</span><span class=\"o\">(</span><span class=\"n\">n</span><span class=\"bp\">+</span><span class=\"mi\">1</span><span class=\"o\">)</span><span class=\"w\"> </span><span class=\"bp\">≠</span><span class=\"w\"> </span><span class=\"mi\">2</span><span class=\"bp\">^</span><span class=\"o\">(</span><span class=\"n\">m</span><span class=\"bp\">+</span><span class=\"mi\">1</span><span class=\"o\">)</span><span class=\"w\"> </span><span class=\"o\">:=</span><span class=\"w\"> </span><span class=\"k\">by</span><span class=\"w\"> </span><span class=\"gr\">sorry</span>\n</code></pre></div>\n<p>The unsuccessful dialogue is here:  <a href=\"https://www.perplexity.ai/search/please-help-me-finish-this-lea-83qN.5UMRi6sgAl_.WabnQ\">https://www.perplexity.ai/search/please-help-me-finish-this-lea-83qN.5UMRi6sgAl_.WabnQ</a></p>",
        "id": 489004841,
        "sender_full_name": "Lars Ericson",
        "timestamp": 1734191396
    },
    {
        "content": "<p>I tried this with Microsoft Copilot, Google Gemini, Meta AI and Claude and they all flailed in very similar ways.  That makes this a nice benchmark problem because it is short and self-contained.   I was hoping to try DeepMind AlphaProof but they don't have a public portal for that.</p>",
        "id": 489008524,
        "sender_full_name": "Lars Ericson",
        "timestamp": 1734194506
    },
    {
        "content": "<p>There are two other somewhat public LLMs fine tuned for Lean, LeanGPT and Morph Prover.  <a href=\"https://www.yeschat.ai/gpts-9t55kJKd7Uh-LeanGPT\">LeanGPT</a> fails exactly like the others.  Rather than saying just <code>import Mathlib</code>, it says <code>import Mathlib.Data.Nat.Basic</code>, which all the others do, and this dates them all to training on something like Zulipchat at say a year ago:</p>\n<div class=\"codehilite\" data-code-language=\"Lean4\"><pre><span></span><code><span class=\"kn\">import</span><span class=\"w\"> </span><span class=\"n\">Mathlib</span><span class=\"bp\">.</span><span class=\"n\">Data</span><span class=\"bp\">.</span><span class=\"n\">Nat</span><span class=\"bp\">.</span><span class=\"n\">Basic</span>\n\n<span class=\"kn\">theorem</span><span class=\"w\"> </span><span class=\"n\">prime_2_3</span><span class=\"w\"> </span><span class=\"o\">(</span><span class=\"n\">n</span><span class=\"w\"> </span><span class=\"n\">m</span><span class=\"w\"> </span><span class=\"o\">:</span><span class=\"w\"> </span><span class=\"n\">Nat</span><span class=\"o\">)</span><span class=\"w\"> </span><span class=\"o\">:</span><span class=\"w\"> </span><span class=\"mi\">3</span><span class=\"bp\">^</span><span class=\"o\">(</span><span class=\"n\">n</span><span class=\"bp\">+</span><span class=\"mi\">1</span><span class=\"o\">)</span><span class=\"w\"> </span><span class=\"bp\">≠</span><span class=\"w\"> </span><span class=\"mi\">2</span><span class=\"bp\">^</span><span class=\"o\">(</span><span class=\"n\">m</span><span class=\"bp\">+</span><span class=\"mi\">1</span><span class=\"o\">)</span><span class=\"w\"> </span><span class=\"o\">:=</span><span class=\"w\"> </span><span class=\"k\">by</span>\n<span class=\"w\">  </span><span class=\"n\">intro</span><span class=\"w\"> </span><span class=\"n\">h</span>\n<span class=\"w\">  </span><span class=\"k\">have</span><span class=\"w\"> </span><span class=\"n\">hmod3</span><span class=\"w\"> </span><span class=\"o\">:=</span><span class=\"w\"> </span><span class=\"n\">Nat</span><span class=\"bp\">.</span><span class=\"n\">pow_mod</span><span class=\"w\"> </span><span class=\"mi\">3</span><span class=\"w\"> </span><span class=\"o\">(</span><span class=\"n\">n</span><span class=\"bp\">+</span><span class=\"mi\">1</span><span class=\"o\">)</span><span class=\"w\"> </span><span class=\"mi\">2</span>\n<span class=\"w\">  </span><span class=\"k\">have</span><span class=\"w\"> </span><span class=\"n\">hmod2</span><span class=\"w\"> </span><span class=\"o\">:=</span><span class=\"w\"> </span><span class=\"n\">Nat</span><span class=\"bp\">.</span><span class=\"n\">pow_mod</span><span class=\"w\"> </span><span class=\"mi\">2</span><span class=\"w\"> </span><span class=\"o\">(</span><span class=\"n\">m</span><span class=\"bp\">+</span><span class=\"mi\">1</span><span class=\"o\">)</span><span class=\"w\"> </span><span class=\"mi\">3</span>\n<span class=\"w\">  </span><span class=\"n\">rw</span><span class=\"w\"> </span><span class=\"o\">[</span><span class=\"n\">h</span><span class=\"o\">]</span><span class=\"w\"> </span><span class=\"k\">at</span><span class=\"w\"> </span><span class=\"n\">hmod3</span>\n<span class=\"w\">  </span><span class=\"k\">have</span><span class=\"w\"> </span><span class=\"o\">:</span><span class=\"w\"> </span><span class=\"mi\">2</span><span class=\"bp\">^</span><span class=\"o\">((</span><span class=\"n\">m</span><span class=\"bp\">+</span><span class=\"mi\">1</span><span class=\"o\">)</span><span class=\"w\"> </span><span class=\"bp\">%</span><span class=\"w\"> </span><span class=\"mi\">3</span><span class=\"o\">)</span><span class=\"w\"> </span><span class=\"bp\">≡</span><span class=\"w\"> </span><span class=\"mi\">0</span><span class=\"w\"> </span><span class=\"o\">[</span><span class=\"n\">MOD</span><span class=\"w\"> </span><span class=\"mi\">3</span><span class=\"o\">]</span><span class=\"w\"> </span><span class=\"o\">:=</span><span class=\"w\"> </span><span class=\"n\">hmod3</span>\n<span class=\"w\">  </span><span class=\"c1\">-- Contradiction by modular arithmetic</span>\n<span class=\"w\">  </span><span class=\"n\">exact</span><span class=\"w\"> </span><span class=\"n\">Nat</span><span class=\"bp\">.</span><span class=\"n\">not_mod_eq_zero_of_prime_ne</span><span class=\"w\"> </span><span class=\"o\">(</span><span class=\"n\">Nat</span><span class=\"bp\">.</span><span class=\"n\">prime_two</span><span class=\"o\">)</span><span class=\"w\"> </span><span class=\"o\">(</span><span class=\"n\">Nat</span><span class=\"bp\">.</span><span class=\"n\">prime_three</span><span class=\"o\">)</span><span class=\"w\"> </span><span class=\"n\">this</span>\n</code></pre></div>\n<p>The other thing it does, which they all do, is hallucinate convenient theorems which are not currently in Mathlib and maybe never where. In the above case, <code>Nat.not_mod_eq_zero_of_prime_ne </code>.</p>",
        "id": 489014359,
        "sender_full_name": "Lars Ericson",
        "timestamp": 1734199440
    },
    {
        "content": "<p>To use <a href=\"https://huggingface.co/typeof/morph-prover-v0-7b-sharded\">Morph Prover</a>, the steps are to pip install some libraries</p>\n<div class=\"codehilite\" data-code-language=\"Lean4\"><pre><span></span><code><span class=\"n\">pip</span><span class=\"w\"> </span><span class=\"n\">install</span><span class=\"w\"> </span><span class=\"n\">transformers</span><span class=\"w\"> </span><span class=\"n\">accelerate</span>\n</code></pre></div>\n<p>and then run the prompt in a script</p>\n<div class=\"codehilite\" data-code-language=\"Lean4\"><pre><span></span><code><span class=\"k\">from</span><span class=\"w\"> </span><span class=\"n\">transformers</span><span class=\"w\"> </span><span class=\"kn\">import</span><span class=\"w\"> </span><span class=\"n\">AutoModelForCausalLM</span><span class=\"o\">,</span><span class=\"w\"> </span><span class=\"n\">AutoTokenizer</span>\n\n<span class=\"bp\">#</span><span class=\"w\"> </span><span class=\"n\">Load</span><span class=\"w\"> </span><span class=\"n\">the</span><span class=\"w\"> </span><span class=\"n\">tokenizer</span>\n<span class=\"n\">tokenizer</span><span class=\"w\"> </span><span class=\"bp\">=</span><span class=\"w\"> </span><span class=\"n\">AutoTokenizer</span><span class=\"bp\">.</span><span class=\"n\">from_pretrained</span><span class=\"o\">(</span><span class=\"s2\">\"typeof/morph-prover-v0-7b-sharded\"</span><span class=\"o\">)</span>\n\n<span class=\"bp\">#</span><span class=\"w\"> </span><span class=\"n\">Load</span><span class=\"w\"> </span><span class=\"n\">the</span><span class=\"w\"> </span><span class=\"n\">model</span>\n<span class=\"n\">model</span><span class=\"w\"> </span><span class=\"bp\">=</span><span class=\"w\"> </span><span class=\"n\">AutoModelForCausalLM</span><span class=\"bp\">.</span><span class=\"n\">from_pretrained</span><span class=\"o\">(</span><span class=\"s2\">\"typeof/morph-prover-v0-7b-sharded\"</span><span class=\"o\">,</span><span class=\"w\"> </span><span class=\"n\">device_map</span><span class=\"bp\">=</span><span class=\"s2\">\"auto\"</span><span class=\"o\">)</span>\n\n<span class=\"bp\">#</span><span class=\"w\"> </span><span class=\"n\">Use</span><span class=\"w\"> </span><span class=\"n\">the</span><span class=\"w\"> </span><span class=\"n\">model</span>\n<span class=\"n\">text</span><span class=\"w\"> </span><span class=\"bp\">=</span><span class=\"w\"> </span><span class=\"s2\">\"Provide a logical proof for: theorem prime_2_3 (n m : Nat) : 3^(n+1) ≠ 2^(m+1)  \"</span>\n<span class=\"n\">inputs</span><span class=\"w\"> </span><span class=\"bp\">=</span><span class=\"w\"> </span><span class=\"n\">tokenizer</span><span class=\"o\">(</span><span class=\"n\">text</span><span class=\"o\">,</span><span class=\"w\"> </span><span class=\"n\">return_tensors</span><span class=\"bp\">=</span><span class=\"s2\">\"pt\"</span><span class=\"o\">)</span><span class=\"bp\">.</span><span class=\"n\">to</span><span class=\"o\">(</span><span class=\"s2\">\"cuda\"</span><span class=\"o\">)</span><span class=\"w\">  </span><span class=\"bp\">#</span><span class=\"w\"> </span><span class=\"n\">Use</span><span class=\"w\"> </span><span class=\"n\">GPU</span><span class=\"w\"> </span><span class=\"k\">if</span><span class=\"w\"> </span><span class=\"n\">available</span>\n<span class=\"n\">outputs</span><span class=\"w\"> </span><span class=\"bp\">=</span><span class=\"w\"> </span><span class=\"n\">model</span><span class=\"bp\">.</span><span class=\"n\">generate</span><span class=\"o\">(</span><span class=\"n\">inputs</span><span class=\"o\">[</span><span class=\"s2\">\"input_ids\"</span><span class=\"o\">],</span><span class=\"w\"> </span><span class=\"n\">max_new_tokens</span><span class=\"bp\">=</span><span class=\"mi\">100</span><span class=\"o\">)</span>\n\n<span class=\"bp\">#</span><span class=\"w\"> </span><span class=\"n\">Decode</span><span class=\"w\"> </span><span class=\"n\">the</span><span class=\"w\"> </span><span class=\"n\">output</span>\n<span class=\"n\">response</span><span class=\"w\"> </span><span class=\"bp\">=</span><span class=\"w\"> </span><span class=\"n\">tokenizer</span><span class=\"bp\">.</span><span class=\"n\">decode</span><span class=\"o\">(</span><span class=\"n\">outputs</span><span class=\"o\">[</span><span class=\"mi\">0</span><span class=\"o\">],</span><span class=\"w\"> </span><span class=\"n\">skip_special_tokens</span><span class=\"bp\">=</span><span class=\"n\">True</span><span class=\"o\">)</span>\n<span class=\"n\">print</span><span class=\"o\">(</span><span class=\"n\">response</span><span class=\"o\">)</span>\n</code></pre></div>\n<p>This downloads a large sharded model which takes some time.</p>",
        "id": 489014675,
        "sender_full_name": "Lars Ericson",
        "timestamp": 1734199692
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"364351\">Lars Ericson</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Simple.20but.20hard.20puzzler.20for.20LLMs/near/489014359\">said</a>:</p>\n<blockquote>\n<p>The other thing it does, which they all do, is hallucinate convenient theorems which are not currently in Mathlib and maybe never where. In the above case, <code>Nat.not_mod_eq_zero_of_prime_ne</code> .</p>\n</blockquote>\n<p>By the way, this is possibly valuable information, either for spotting theorems that are badly named or for spotting natural theorems that don't exist yet in mathlib. Our naming convention is <em>designed</em> so that you can guess a theorem name without knowing if it exists and find it a significant fraction of the time</p>",
        "id": 489017701,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1734202417
    },
    {
        "content": "<p>On MorphProver above, the output is not helpful compared to the current state of the not specifically Lean 4 trained and publicly accessible LLMs:</p>\n<div class=\"codehilite\" data-code-language=\"Lean4\"><pre><span></span><code><span class=\"n\">Provide</span><span class=\"w\"> </span><span class=\"n\">a</span><span class=\"w\"> </span><span class=\"n\">logical</span><span class=\"w\"> </span><span class=\"n\">proof</span><span class=\"w\"> </span><span class=\"n\">for</span><span class=\"o\">:</span><span class=\"w\"> </span><span class=\"kn\">theorem</span><span class=\"w\"> </span><span class=\"n\">prime_2_3</span><span class=\"w\"> </span><span class=\"o\">(</span><span class=\"n\">n</span><span class=\"w\"> </span><span class=\"n\">m</span><span class=\"w\"> </span><span class=\"o\">:</span><span class=\"w\"> </span><span class=\"n\">Nat</span><span class=\"o\">)</span><span class=\"w\"> </span><span class=\"o\">:</span><span class=\"w\"> </span><span class=\"mi\">3</span><span class=\"bp\">^</span><span class=\"o\">(</span><span class=\"n\">n</span><span class=\"bp\">+</span><span class=\"mi\">1</span><span class=\"o\">)</span><span class=\"w\"> </span><span class=\"bp\">≠</span><span class=\"w\"> </span><span class=\"mi\">2</span><span class=\"bp\">^</span><span class=\"o\">(</span><span class=\"n\">m</span><span class=\"bp\">+</span><span class=\"mi\">1</span><span class=\"o\">)</span>\n\n<span class=\"n\">In</span><span class=\"w\"> </span><span class=\"n\">the</span><span class=\"w\"> </span><span class=\"n\">first</span><span class=\"w\"> </span><span class=\"n\">paragraph</span><span class=\"w\"> </span><span class=\"o\">(</span><span class=\"n\">labeled</span><span class=\"w\"> </span><span class=\"n\">Context</span><span class=\"o\">),</span><span class=\"w\"> </span><span class=\"n\">give</span><span class=\"w\"> </span><span class=\"n\">context</span><span class=\"w\"> </span><span class=\"n\">on</span><span class=\"w\"> </span><span class=\"n\">the</span><span class=\"w\"> </span><span class=\"n\">mathematical</span><span class=\"w\"> </span><span class=\"n\">concepts</span><span class=\"o\">,</span><span class=\"w\"> </span><span class=\"n\">definitions</span><span class=\"o\">,</span><span class=\"w\"> </span><span class=\"n\">and</span><span class=\"w\"> </span><span class=\"n\">arguments</span><span class=\"bp\">.</span>\n\n<span class=\"n\">In</span><span class=\"w\"> </span><span class=\"n\">the</span><span class=\"w\"> </span><span class=\"n\">second</span><span class=\"w\"> </span><span class=\"n\">paragraph</span><span class=\"w\"> </span><span class=\"o\">(</span><span class=\"n\">labeled</span><span class=\"w\"> </span><span class=\"n\">Statement</span><span class=\"o\">),</span><span class=\"w\"> </span><span class=\"n\">explain</span><span class=\"w\"> </span><span class=\"n\">how</span><span class=\"w\"> </span><span class=\"n\">to</span><span class=\"w\"> </span><span class=\"n\">arrive</span><span class=\"w\"> </span><span class=\"k\">at</span><span class=\"w\"> </span><span class=\"n\">the</span><span class=\"w\"> </span><span class=\"n\">key</span><span class=\"w\"> </span><span class=\"n\">insight</span><span class=\"o\">,</span><span class=\"w\"> </span><span class=\"n\">providing</span><span class=\"w\"> </span><span class=\"n\">a</span><span class=\"w\"> </span><span class=\"n\">detailed</span><span class=\"w\"> </span><span class=\"n\">natural</span><span class=\"w\"> </span><span class=\"n\">language</span><span class=\"w\"> </span><span class=\"n\">line</span><span class=\"bp\">-</span><span class=\"k\">by</span><span class=\"bp\">-</span><span class=\"n\">line</span><span class=\"w\"> </span><span class=\"n\">account</span><span class=\"w\"> </span><span class=\"n\">of</span><span class=\"w\"> </span><span class=\"n\">the</span><span class=\"w\"> </span><span class=\"n\">proof</span><span class=\"bp\">.</span>\n\n<span class=\"n\">In</span><span class=\"w\"> </span><span class=\"n\">the</span><span class=\"w\"> </span><span class=\"n\">third</span><span class=\"w\"> </span><span class=\"n\">paragraph</span><span class=\"w\"> </span><span class=\"o\">(</span><span class=\"n\">labeled</span><span class=\"w\"> </span><span class=\"n\">Summary</span><span class=\"o\">),</span><span class=\"w\"> </span><span class=\"n\">briefly</span><span class=\"w\"> </span><span class=\"n\">summarize</span><span class=\"w\"> </span><span class=\"n\">what</span><span class=\"w\"> </span><span class=\"n\">you</span><span class=\"bp\">’</span><span class=\"n\">ve</span><span class=\"w\"> </span><span class=\"n\">said</span><span class=\"o\">,</span><span class=\"w\"> </span><span class=\"k\">in</span><span class=\"w\"> </span><span class=\"n\">a</span><span class=\"w\"> </span><span class=\"n\">declarative</span><span class=\"w\"> </span><span class=\"n\">tone</span><span class=\"bp\">.</span><span class=\"w\"> </span><span class=\"o\">[</span><span class=\"bp\">/</span><span class=\"n\">INST</span><span class=\"o\">]</span><span class=\"w\"> </span><span class=\"n\">Context</span><span class=\"o\">:</span>\n<span class=\"n\">In</span><span class=\"w\"> </span><span class=\"n\">this</span><span class=\"w\"> </span><span class=\"n\">code</span><span class=\"w\"> </span><span class=\"n\">block</span><span class=\"o\">,</span><span class=\"w\"> </span><span class=\"n\">we</span><span class=\"w\"> </span><span class=\"n\">are</span><span class=\"w\"> </span><span class=\"n\">working</span><span class=\"w\"> </span><span class=\"k\">with</span>\n</code></pre></div>\n<p>It seems to be giving back the system prompt which is hidden instructions to the model on what is expected of it, without actually doing anything.  It doesn't seem like there is a public version of Morph Labs model that does much Lean.  I'm guessing that this was a demo and not the focus of Morph Labs going forward.  If anybody knows better please chime in.</p>",
        "id": 489018897,
        "sender_full_name": "Lars Ericson",
        "timestamp": 1734203449
    },
    {
        "content": "<p>Here is one more benchmark case:</p>\n<div class=\"codehilite\" data-code-language=\"Lean4\"><pre><span></span><code><span class=\"kn\">theorem</span><span class=\"w\"> </span><span class=\"n\">pow_injective</span><span class=\"w\"> </span><span class=\"o\">{</span><span class=\"n\">a</span><span class=\"w\"> </span><span class=\"n\">b</span><span class=\"w\"> </span><span class=\"o\">:</span><span class=\"w\"> </span><span class=\"n\">ℕ</span><span class=\"o\">}</span><span class=\"w\"> </span><span class=\"o\">(</span><span class=\"n\">h</span><span class=\"w\"> </span><span class=\"o\">:</span><span class=\"w\"> </span><span class=\"mi\">2</span><span class=\"bp\">^</span><span class=\"n\">a</span><span class=\"w\"> </span><span class=\"bp\">=</span><span class=\"w\"> </span><span class=\"mi\">2</span><span class=\"bp\">^</span><span class=\"n\">b</span><span class=\"o\">)</span><span class=\"w\"> </span><span class=\"o\">:</span><span class=\"w\"> </span><span class=\"n\">a</span><span class=\"w\"> </span><span class=\"bp\">=</span><span class=\"w\"> </span><span class=\"n\">b</span><span class=\"w\">  </span><span class=\"o\">:=</span><span class=\"w\"> </span><span class=\"gr\">sorry</span>\n</code></pre></div>\n<p>and flailing Perplexity transcript:  <a href=\"https://www.perplexity.ai/search/see-if-you-can-complete-this-p-hNsUjBHqQT6z.wHZK_in5Q\">https://www.perplexity.ai/search/see-if-you-can-complete-this-p-hNsUjBHqQT6z.wHZK_in5Q</a></p>",
        "id": 489020488,
        "sender_full_name": "Lars Ericson",
        "timestamp": 1734204847
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"116045\">@Jesse Michael Han</span> what is this Morph Prover?</p>",
        "id": 489047638,
        "sender_full_name": "Jason Rute",
        "timestamp": 1734232062
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"364351\">@Lars Ericson</span> I heard from others here that Sonnet 3.5 seems to get Lean syntax correct.  Is that the version of Claude you are using?</p>",
        "id": 489047830,
        "sender_full_name": "Jason Rute",
        "timestamp": 1734232259
    },
    {
        "content": "<p>But maybe we shouldn’t be surprised these models struggle so much on Lean, especially since (1) they don’t have access to Lean’s goals and (2) Lean changes so fast and so drastically.</p>",
        "id": 489047961,
        "sender_full_name": "Jason Rute",
        "timestamp": 1734232420
    },
    {
        "content": "<p>It would be interesting if the situation was a lot better in Isabelle or Coq, but especially Isabelle, since it has a canonical library which has been more stable for a while.</p>",
        "id": 489048128,
        "sender_full_name": "Jason Rute",
        "timestamp": 1734232574
    },
    {
        "content": "<p>Also, there are locally run models.  While AlphaProof isn’t (and may never be) available, there are solvers like Lean Copilot and LeanLLM that are user facing.  There are also open models (not user facing) like DeepSeek-Prover, InternLM-Step, Able, Corpra, etc that one could try if one was adventurous.  If I had more time, I’d make a personal arena of all these solvers (as well as the Coq/Isabelle ones) so I could test problems like this on them.</p>",
        "id": 489048501,
        "sender_full_name": "Jason Rute",
        "timestamp": 1734233013
    },
    {
        "content": "<p>A preliminary try with Sonnet 3.5: it outputting correct proof sketches with sorry, and was able to articulate what kind of lemma it is looking for, but was not able to precisely recall the lemma. Is there a good natural language search engine for Mathlib?</p>",
        "id": 489086611,
        "sender_full_name": "GasStationManager",
        "timestamp": 1734271763
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"776090\">GasStationManager</span> <a href=\"#narrow/stream/219941-Machine-Learning-for-Theorem-Proving/topic/Simple.20but.20hard.20puzzler.20for.20LLMs/near/489086611\">said</a>:</p>\n<blockquote>\n<p>Is there a good natural language search engine for Mathlib?</p>\n</blockquote>\n<p>There are three: <a href=\"https://www.moogle.ai\">https://www.moogle.ai</a>, <a href=\"https://leansearch.net\">https://leansearch.net</a>, and <a href=\"https://loogle.lean-lang.org\">https://loogle.lean-lang.org</a>.  The last one is symbolic, while the other two are machine learning.  I think you can now call all three from inside Lean, but I don’t know the details.  (There was also a third machine learning search engine, but I don’t remember the name off hand.)</p>",
        "id": 489087184,
        "sender_full_name": "Jason Rute",
        "timestamp": 1734272360
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"115715\">Jason Rute</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Simple.20but.20hard.20puzzler.20for.20LLMs/near/489047830\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"364351\">Lars Ericson</span> I heard from others here that Sonnet 3.5 seems to get Lean syntax correct.  Is that the version of Claude you are using?</p>\n</blockquote>\n<p>I used Claude.AI free version, which means Claude 3.5 Haiku.  Claude gives a link to <a href=\"https://claude.ai/new\">https://claude.ai/new</a> but that just redirects you to Claude 3.5 Haiku.  I think to get Sonnet you have to commit to sending $20/month to Anthropic, which is beyond my budget.</p>",
        "id": 489089687,
        "sender_full_name": "Lars Ericson",
        "timestamp": 1734274686
    },
    {
        "content": "<p>Lean Copilot is at  <a href=\"https://leandojo.org/\">https://leandojo.org/</a>. I guessed (wrong) that that was a <a href=\"https://www.microsoft.com/en-us/microsoft-copilot/microsoft-copilot-studio\">fine-tuning of Microsoft Copilot</a>.  I think they just borrowed the Copilot name, which Microsoft lawyers might eventually complain about.  Not to mention:</p>\n<blockquote>\n<p><span aria-label=\"warning\" class=\"emoji emoji-26a0\" role=\"img\" title=\"warning\">:warning:</span> Native Windows currently not supported</p>\n</blockquote>\n<p>They also have a ChatGPT plugin.  To get Lean (not-fintuned-Microsoft-)Copilot, it is an install using <code>lake</code> of a VS Code extension: <a href=\"https://github.com/lean-dojo/LeanCopilot?tab=readme-ov-file#getting-started-with-lean-copilot\">https://github.com/lean-dojo/LeanCopilot?tab=readme-ov-file#getting-started-with-lean-copilot</a> </p>\n<p>I will try it.</p>",
        "id": 489090119,
        "sender_full_name": "Lars Ericson",
        "timestamp": 1734275054
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"364351\">Lars Ericson</span> <a href=\"#narrow/stream/219941-Machine-Learning-for-Theorem-Proving/topic/Simple.20but.20hard.20puzzler.20for.20LLMs/near/489090119\">said</a>:</p>\n<blockquote>\n<p>I think they just borrowed the Copilot name,</p>\n</blockquote>\n<p>This feels a little unfair. The idea of an \"AI Copilot\" was certainly a phrase tossed around plenty before Microsoft announced their product.</p>",
        "id": 489091310,
        "sender_full_name": "Alex Meiburg",
        "timestamp": 1734276094
    },
    {
        "content": "<p>Here is another example which came up on PA.SX. <a href=\"https://proofassistants.stackexchange.com/a/4467/122\">https://proofassistants.stackexchange.com/a/4467/122</a>. Can you either get an AI to correctly make an outline of the proof or get one to correctly fill in the steps.  The steps should be standard analysis facts, but maybe Mathlib doesn’t have them yet or they are too hard to use with all the needed side conditions.</p>",
        "id": 489091803,
        "sender_full_name": "Jason Rute",
        "timestamp": 1734276525
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"448405\">Alex Meiburg</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Simple.20but.20hard.20puzzler.20for.20LLMs/near/489091310\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"364351\">Lars Ericson</span> <a href=\"#narrow/stream/219941-Machine-Learning-for-Theorem-Proving/topic/Simple.20but.20hard.20puzzler.20for.20LLMs/near/489090119\">said</a>:</p>\n<blockquote>\n<p>I think they just borrowed the Copilot name,</p>\n</blockquote>\n<p>This feels a little unfair. The idea of an \"AI Copilot\" was certainly a phrase tossed around plenty before Microsoft announced their product.</p>\n</blockquote>\n<p>You are correct, complex history: <a href=\"https://www.perplexity.ai/search/is-ai-copilot-a-coinage-that-p-eAQvaiXITy2ngVyokNIODQ\">https://www.perplexity.ai/search/is-ai-copilot-a-coinage-that-p-eAQvaiXITy2ngVyokNIODQ</a></p>",
        "id": 489092059,
        "sender_full_name": "Lars Ericson",
        "timestamp": 1734276733
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"115715\">Jason Rute</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Simple.20but.20hard.20puzzler.20for.20LLMs/near/489091803\">said</a>:</p>\n<blockquote>\n<p>Here is another example which came up on PA.SX. <a href=\"https://proofassistants.stackexchange.com/a/4467/122\">https://proofassistants.stackexchange.com/a/4467/122</a>. Can you either get an AI to correctly make an outline of the proof or get one to correctly fill in the steps.  The steps should be standard analysis facts, but maybe Mathlib doesn’t have them yet or they are too hard to use with all the needed side conditions.</p>\n</blockquote>\n<p><a href=\"https://github.com/lean-dojo/LeanCopilot?tab=readme-ov-file#proof-search\">Lean Copilot has</a> <code>search_proof</code> which pretty much ends the matter.   I am getting it configured now.   The instructions say to add this in <code>lakefile.lean</code> inside my <code>package</code> declaration:</p>\n<div class=\"codehilite\" data-code-language=\"Lean4\"><pre><span></span><code><span class=\"w\">  </span><span class=\"n\">moreLinkArgs</span><span class=\"w\"> </span><span class=\"o\">:=</span><span class=\"w\"> </span><span class=\"bp\">#</span><span class=\"o\">[</span>\n<span class=\"w\">    </span><span class=\"s2\">\"-L./.lake/packages/LeanCopilot/.lake/build/lib\"</span><span class=\"o\">,</span>\n<span class=\"w\">    </span><span class=\"s2\">\"-lctranslate2\"</span>\n</code></pre></div>\n<p>and before that this <code>require</code> line:</p>\n<div class=\"codehilite\" data-code-language=\"Lean4\"><pre><span></span><code><span class=\"n\">require</span><span class=\"w\"> </span><span class=\"n\">LeanCopilot</span><span class=\"w\"> </span><span class=\"k\">from</span><span class=\"w\"> </span><span class=\"n\">git</span><span class=\"w\"> </span><span class=\"s2\">\"https://github.com/lean-dojo/LeanCopilot.git\"</span><span class=\"w\"> </span><span class=\"bp\">@</span><span class=\"w\"> </span><span class=\"s2\">\"LEAN_COPILOT_VERSION\"</span>\n</code></pre></div>\n<p>where <code>LEAN_COPILOT_VERSION</code> is looked up from the table <a href=\"https://github.com/lean-dojo/LeanCopilot?tab=readme-ov-file#adding-lean-copilot-as-a-dependency\">here</a>, which goes up to <code>lean-toolchain</code> v4.11.0.  I am actually at <code>leanprover/lean4:v4.15.0-rc1</code>, so I will try Copilot version <code>v1.6.0</code>, which is their latest version.</p>",
        "id": 489092365,
        "sender_full_name": "Lars Ericson",
        "timestamp": 1734277053
    },
    {
        "content": "<p>Additionally for Linux it is necessary to install Git LFS:</p>\n<div class=\"codehilite\" data-code-language=\"Lean4\"><pre><span></span><code><span class=\"n\">sudo</span><span class=\"w\"> </span><span class=\"n\">apt</span><span class=\"bp\">-</span><span class=\"n\">get</span><span class=\"w\"> </span><span class=\"n\">update</span>\n<span class=\"n\">sudo</span><span class=\"w\"> </span><span class=\"n\">apt</span><span class=\"bp\">-</span><span class=\"n\">get</span><span class=\"w\"> </span><span class=\"n\">install</span><span class=\"w\"> </span><span class=\"n\">git</span><span class=\"bp\">-</span><span class=\"n\">lfs</span>\n</code></pre></div>",
        "id": 489092719,
        "sender_full_name": "Lars Ericson",
        "timestamp": 1734277406
    },
    {
        "content": "<p>and then run</p>\n<div class=\"codehilite\" data-code-language=\"Lean4\"><pre><span></span><code><span class=\"n\">lake</span><span class=\"w\"> </span><span class=\"n\">update</span><span class=\"w\"> </span><span class=\"n\">LeanCopilot</span>\n<span class=\"n\">lake</span><span class=\"w\"> </span><span class=\"n\">exe</span><span class=\"w\"> </span><span class=\"n\">LeanCopilot</span><span class=\"bp\">/</span><span class=\"n\">download</span>\n<span class=\"n\">lake</span><span class=\"w\"> </span><span class=\"n\">clean</span>\n<span class=\"n\">lake</span><span class=\"w\"> </span><span class=\"n\">build</span>\n</code></pre></div>\n<p>This downloads around 23GB of model files.</p>",
        "id": 489092801,
        "sender_full_name": "Lars Ericson",
        "timestamp": 1734277479
    },
    {
        "content": "<p>I don’t understand how your message relates to mine.  Ends what matter?  (Also I think I tried Lean Copilot on the sorries in my problem and it didn’t solve them if I recall correctly, but I could be mistaken.)</p>",
        "id": 489093339,
        "sender_full_name": "Jason Rute",
        "timestamp": 1734277927
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"115715\">Jason Rute</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Simple.20but.20hard.20puzzler.20for.20LLMs/near/489093339\">said</a>:</p>\n<blockquote>\n<p>I don’t understand how your message relates to mine.  Ends what matter?  (Also I think I tried Lean Copilot on the sorries in my problem and it didn’t solve them if I recall correctly, but I could be mistaken.)</p>\n</blockquote>\n<p>That was an example of overly dry humor that missed the mark.  My standup comedy skills need improvement.</p>",
        "id": 489094093,
        "sender_full_name": "Lars Ericson",
        "timestamp": 1734278501
    },
    {
        "content": "<p>Unfortunately, my <code>lake build</code> now hangs even after a <code>lake clean</code>:</p>\n<div class=\"codehilite\" data-code-language=\"Lean4\"><pre><span></span><code><span class=\"bp\">$</span><span class=\"w\"> </span><span class=\"n\">lake</span><span class=\"w\"> </span><span class=\"n\">clean</span>\n<span class=\"bp\">$</span><span class=\"w\"> </span><span class=\"n\">lake</span><span class=\"w\"> </span><span class=\"n\">build</span><span class=\"w\"> </span><span class=\"bp\">-</span><span class=\"n\">v</span>\n<span class=\"bp\">⣿</span><span class=\"w\"> </span><span class=\"o\">[</span><span class=\"bp\">?/?</span><span class=\"o\">]</span><span class=\"w\"> </span><span class=\"n\">Computing</span><span class=\"w\"> </span><span class=\"n\">build</span><span class=\"w\"> </span><span class=\"n\">jobs</span>\n</code></pre></div>\n<p>with this <code>lakefile.lean</code>:</p>\n<div class=\"codehilite\" data-code-language=\"Lean4\"><pre><span></span><code><span class=\"kn\">import</span><span class=\"w\"> </span><span class=\"n\">Lake</span>\n<span class=\"kn\">open</span><span class=\"w\"> </span><span class=\"n\">Lake</span><span class=\"w\"> </span><span class=\"n\">DSL</span>\n\n<span class=\"n\">require</span><span class=\"w\"> </span><span class=\"n\">mathlib</span><span class=\"w\"> </span><span class=\"k\">from</span><span class=\"w\"> </span><span class=\"n\">git</span><span class=\"w\"> </span><span class=\"s2\">\"https://github.com/leanprover-community/mathlib4.git\"</span>\n\n<span class=\"n\">require</span><span class=\"w\"> </span><span class=\"n\">LeanCopilot</span><span class=\"w\"> </span><span class=\"k\">from</span><span class=\"w\"> </span><span class=\"n\">git</span><span class=\"w\"> </span><span class=\"s2\">\"https://github.com/lean-dojo/LeanCopilot.git\"</span><span class=\"w\"> </span><span class=\"bp\">@</span><span class=\"w\"> </span><span class=\"s2\">\"v1.6.0\"</span>\n\n<span class=\"n\">package</span><span class=\"w\"> </span><span class=\"n\">Hybrid</span><span class=\"w\"> </span><span class=\"o\">{</span>\n<span class=\"w\">  </span><span class=\"n\">moreLinkArgs</span><span class=\"w\"> </span><span class=\"o\">:=</span><span class=\"w\"> </span><span class=\"bp\">#</span><span class=\"o\">[</span>\n<span class=\"w\">    </span><span class=\"s2\">\"-L./.lake/packages/LeanCopilot/.lake/build/lib\"</span><span class=\"o\">,</span>\n<span class=\"w\">    </span><span class=\"s2\">\"-lctranslate2\"</span>\n<span class=\"w\">  </span><span class=\"o\">]</span>\n<span class=\"o\">}</span>\n\n<span class=\"kd\">@[</span><span class=\"n\">default_target</span><span class=\"kd\">]</span>\n<span class=\"n\">lean_lib</span><span class=\"w\"> </span><span class=\"n\">Hybrid</span><span class=\"w\"> </span><span class=\"o\">{</span>\n<span class=\"w\">  </span><span class=\"c1\">-- Explicitly list all your .lean files here</span>\n<span class=\"w\">  </span><span class=\"n\">roots</span><span class=\"w\"> </span><span class=\"o\">:=</span><span class=\"w\"> </span><span class=\"bp\">#</span><span class=\"o\">[</span>\n<span class=\"w\">    </span><span class=\"ss\">`Hybrid.PROP</span><span class=\"o\">,</span><span class=\"w\"> </span><span class=\"ss\">`Hybrid.TotalSet</span><span class=\"o\">,</span><span class=\"w\"> </span><span class=\"ss\">`Hybrid.SVAR</span><span class=\"o\">,</span><span class=\"w\"> </span><span class=\"ss\">`Hybrid.TypeIff</span><span class=\"o\">,</span>\n<span class=\"w\">    </span><span class=\"ss\">`Hybrid.Completeness</span><span class=\"o\">,</span><span class=\"w\"> </span><span class=\"ss\">`Hybrid.Eval</span><span class=\"o\">,</span><span class=\"w\"> </span><span class=\"ss\">`Hybrid.Model</span><span class=\"o\">,</span><span class=\"w\"> </span><span class=\"ss\">`Hybrid.Tautology</span><span class=\"o\">,</span>\n<span class=\"w\">    </span><span class=\"ss\">`Hybrid.Substitutions</span><span class=\"o\">,</span><span class=\"w\"> </span><span class=\"ss\">`Hybrid.IteratedModalities</span><span class=\"o\">,</span><span class=\"w\"> </span><span class=\"ss\">`Hybrid.Variables</span><span class=\"o\">,</span>\n<span class=\"w\">    </span><span class=\"ss\">`Hybrid.New_NOM</span><span class=\"o\">,</span><span class=\"w\"> </span><span class=\"ss\">`Hybrid.NominalSubstitution</span><span class=\"o\">,</span><span class=\"w\"> </span><span class=\"ss\">`Hybrid.FormSubstitution</span><span class=\"o\">,</span>\n<span class=\"w\">    </span><span class=\"ss\">`Hybrid.Nominals</span><span class=\"o\">,</span><span class=\"w\"> </span><span class=\"ss\">`Hybrid.NOM</span><span class=\"o\">,</span><span class=\"w\"> </span><span class=\"ss\">`Hybrid.Form</span><span class=\"o\">,</span><span class=\"w\"> </span><span class=\"ss\">`Hybrid.Util</span><span class=\"o\">,</span><span class=\"w\"> </span><span class=\"ss\">`Hybrid.Proof</span><span class=\"o\">,</span>\n<span class=\"w\">    </span><span class=\"ss\">`Hybrid.Tautologies</span><span class=\"o\">,</span><span class=\"w\"> </span><span class=\"ss\">`Hybrid.Variants</span><span class=\"o\">,</span><span class=\"w\"> </span><span class=\"ss\">`Hybrid.Satisfaction</span><span class=\"o\">,</span><span class=\"w\"> </span><span class=\"ss\">`Hybrid.Truth</span><span class=\"o\">,</span>\n<span class=\"w\">    </span><span class=\"ss\">`Hybrid.Lemmas</span><span class=\"o\">,</span><span class=\"w\"> </span><span class=\"ss\">`Hybrid.Soundness</span><span class=\"o\">,</span><span class=\"w\"> </span><span class=\"ss\">`Hybrid.ExistenceLemma</span><span class=\"o\">,</span><span class=\"w\"> </span><span class=\"ss\">`Hybrid.ListUtils</span><span class=\"o\">,</span>\n<span class=\"w\">    </span><span class=\"ss\">`Hybrid.RenameBound</span><span class=\"o\">,</span><span class=\"w\"> </span><span class=\"ss\">`Hybrid.GeneralModel</span><span class=\"o\">,</span><span class=\"w\"> </span><span class=\"ss\">`Hybrid.Canonical</span><span class=\"o\">,</span>\n<span class=\"w\">    </span><span class=\"ss\">`Hybrid.GeneratedSubmodel</span><span class=\"o\">,</span><span class=\"w\"> </span><span class=\"ss\">`Hybrid.WitnessedModel</span><span class=\"o\">,</span><span class=\"w\"> </span><span class=\"ss\">`Hybrid.ProofUtils</span><span class=\"o\">,</span>\n<span class=\"w\">    </span><span class=\"ss\">`Hybrid.FormCountable</span><span class=\"o\">,</span><span class=\"w\"> </span><span class=\"ss\">`Hybrid.MCS</span><span class=\"o\">,</span><span class=\"w\"> </span><span class=\"ss\">`Hybrid.CompletedModel</span><span class=\"o\">,</span>\n<span class=\"w\">    </span><span class=\"ss\">`Hybrid.StandardCompletedModel</span><span class=\"o\">,</span><span class=\"w\"> </span><span class=\"ss\">`Hybrid.Lindenbaum</span><span class=\"o\">,</span><span class=\"w\"> </span><span class=\"ss\">`Hybrid.LanguageExtension</span>\n<span class=\"w\">  </span><span class=\"o\">]</span>\n<span class=\"o\">}</span>\n</code></pre></div>",
        "id": 489096598,
        "sender_full_name": "Lars Ericson",
        "timestamp": 1734280750
    },
    {
        "content": "<p>I have one CPU cpre running 100% so it is spinning it's wheels doing something.</p>\n<p>I would appreciate any suggestions on how to debug the <code>lake build</code>.</p>",
        "id": 489096712,
        "sender_full_name": "Lars Ericson",
        "timestamp": 1734280865
    },
    {
        "content": "<p>I would try it in a fresh project first to make sure it isn’t an issue with your project.</p>",
        "id": 489096721,
        "sender_full_name": "Jason Rute",
        "timestamp": 1734280878
    },
    {
        "content": "<p>And one without mathlib.  (I assume you downloaded the mathlib cache, right.  If not you will be waiting for all of mathlib to compile.)</p>",
        "id": 489096840,
        "sender_full_name": "Jason Rute",
        "timestamp": 1734281006
    },
    {
        "content": "<p>All of mathlib is there.  I think I may need to move back from latest Lean to Lean v4.11.0 which corresponds to their September release of LeanDojo.  I will try making a new  emptyproject, add the lines for LeanDojo, and see if it builds.</p>",
        "id": 489098538,
        "sender_full_name": "Lars Ericson",
        "timestamp": 1734282357
    },
    {
        "content": "<p>I think I have it built, like this:</p>\n<div class=\"codehilite\" data-code-language=\"Lean4\"><pre><span></span><code><span class=\"n\">lake</span><span class=\"w\"> </span><span class=\"bp\">+</span><span class=\"n\">leanprover</span><span class=\"bp\">/</span><span class=\"n\">lean4</span><span class=\"o\">:</span><span class=\"mf\">4.11</span><span class=\"bp\">.</span><span class=\"m\">0</span><span class=\"w\"> </span><span class=\"n\">new</span><span class=\"w\"> </span><span class=\"n\">lean_dojo</span><span class=\"w\"> </span><span class=\"n\">math</span>\n<span class=\"n\">cd</span><span class=\"w\"> </span><span class=\"n\">lean_dojo</span>\n<span class=\"n\">emacs</span><span class=\"w\"> </span><span class=\"n\">lakefile</span><span class=\"bp\">.</span><span class=\"n\">lean</span>\n<span class=\"n\">lake</span><span class=\"w\"> </span><span class=\"n\">update</span>\n<span class=\"n\">lake</span><span class=\"w\"> </span><span class=\"n\">clean</span>\n<span class=\"n\">lake</span><span class=\"w\"> </span><span class=\"n\">build</span><span class=\"w\"> </span><span class=\"bp\">-</span><span class=\"n\">v</span>\n<span class=\"n\">code</span><span class=\"w\"> </span><span class=\"bp\">.</span>\n</code></pre></div>\n<p>where I edit <code>lakefile.lean</code> to be</p>\n<div class=\"codehilite\" data-code-language=\"Lean4\"><pre><span></span><code><span class=\"kn\">import</span><span class=\"w\"> </span><span class=\"n\">Lake</span>\n<span class=\"kn\">open</span><span class=\"w\"> </span><span class=\"n\">Lake</span><span class=\"w\"> </span><span class=\"n\">DSL</span>\n\n<span class=\"n\">package</span><span class=\"w\"> </span><span class=\"s2\">\"lean_dojo\"</span><span class=\"w\"> </span><span class=\"kn\">where</span>\n<span class=\"w\">  </span><span class=\"c1\">-- Settings applied to both builds and interactive editing</span>\n<span class=\"w\">  </span><span class=\"n\">leanOptions</span><span class=\"w\"> </span><span class=\"o\">:=</span><span class=\"w\"> </span><span class=\"bp\">#</span><span class=\"o\">[</span>\n<span class=\"w\">    </span><span class=\"bp\">⟨</span><span class=\"ss\">`pp.unicode.fun</span><span class=\"o\">,</span><span class=\"w\"> </span><span class=\"n\">true</span><span class=\"bp\">⟩</span><span class=\"w\"> </span><span class=\"c1\">-- pretty-prints `fun a ↦ b`</span>\n<span class=\"w\">  </span><span class=\"o\">]</span>\n<span class=\"w\">  </span><span class=\"n\">moreLinkArgs</span><span class=\"w\"> </span><span class=\"o\">:=</span><span class=\"w\"> </span><span class=\"bp\">#</span><span class=\"o\">[</span>\n<span class=\"w\">    </span><span class=\"s2\">\"-L./.lake/packages/LeanCopilot/.lake/build/lib\"</span><span class=\"o\">,</span>\n<span class=\"w\">    </span><span class=\"s2\">\"-lctranslate2\"</span>\n<span class=\"w\">  </span><span class=\"o\">]</span>\n\n<span class=\"n\">require</span><span class=\"w\"> </span><span class=\"s2\">\"leanprover-community\"</span><span class=\"w\"> </span><span class=\"bp\">/</span><span class=\"w\"> </span><span class=\"s2\">\"mathlib\"</span>\n\n<span class=\"n\">require</span><span class=\"w\"> </span><span class=\"n\">LeanCopilot</span><span class=\"w\"> </span><span class=\"k\">from</span><span class=\"w\"> </span><span class=\"n\">git</span><span class=\"w\"> </span><span class=\"s2\">\"https://github.com/lean-dojo/LeanCopilot.git\"</span>\n\n<span class=\"kd\">@[</span><span class=\"n\">default_target</span><span class=\"kd\">]</span>\n<span class=\"n\">lean_lib</span><span class=\"w\"> </span><span class=\"bp\">«</span><span class=\"n\">LeanDojo</span><span class=\"bp\">»</span>\n</code></pre></div>",
        "id": 489100886,
        "sender_full_name": "Lars Ericson",
        "timestamp": 1734283848
    },
    {
        "content": "<p>At this point with a test like</p>\n<div class=\"codehilite\" data-code-language=\"Lean4\"><pre><span></span><code><span class=\"kn\">import</span><span class=\"w\"> </span><span class=\"n\">Mathlib</span>\n<span class=\"kn\">import</span><span class=\"w\"> </span><span class=\"n\">LeanCopilot</span>\n\n<span class=\"kn\">theorem</span><span class=\"w\"> </span><span class=\"n\">prime_2_3</span><span class=\"w\"> </span><span class=\"o\">(</span><span class=\"n\">n</span><span class=\"w\"> </span><span class=\"n\">m</span><span class=\"w\"> </span><span class=\"o\">:</span><span class=\"w\"> </span><span class=\"n\">Nat</span><span class=\"o\">)</span><span class=\"w\"> </span><span class=\"o\">:</span><span class=\"w\"> </span><span class=\"mi\">3</span><span class=\"bp\">^</span><span class=\"o\">(</span><span class=\"n\">n</span><span class=\"bp\">+</span><span class=\"mi\">1</span><span class=\"o\">)</span><span class=\"w\"> </span><span class=\"bp\">≠</span><span class=\"w\"> </span><span class=\"mi\">2</span><span class=\"bp\">^</span><span class=\"o\">(</span><span class=\"n\">m</span><span class=\"bp\">+</span><span class=\"mi\">1</span><span class=\"o\">)</span><span class=\"w\"> </span><span class=\"o\">:=</span><span class=\"w\"> </span><span class=\"k\">by</span>\n<span class=\"w\">  </span><span class=\"n\">search_proof</span>\n</code></pre></div>\n<p>I have to rebuild the imports including all of Mathlib which takes a while.</p>",
        "id": 489101273,
        "sender_full_name": "Lars Ericson",
        "timestamp": 1734284228
    },
    {
        "content": "<p>Open issue of build circularity: <a href=\"https://github.com/lean-dojo/LeanCopilot/discussions/57\">https://github.com/lean-dojo/LeanCopilot/discussions/57</a></p>\n<p>Clean Dojo-use project here, I will try this: <a href=\"https://github.com/yangky11/lean4-example/tree/LeanCopilot-demo\">https://github.com/yangky11/lean4-example/tree/LeanCopilot-demo</a></p>",
        "id": 489101763,
        "sender_full_name": "Lars Ericson",
        "timestamp": 1734284690
    },
    {
        "content": "<div class=\"codehilite\" data-code-language=\"Lean4\"><pre><span></span><code><span class=\"n\">sudo</span><span class=\"w\"> </span><span class=\"n\">apt</span><span class=\"bp\">-</span><span class=\"n\">get</span><span class=\"w\"> </span><span class=\"n\">update</span>\n<span class=\"n\">sudo</span><span class=\"w\"> </span><span class=\"n\">apt</span><span class=\"bp\">-</span><span class=\"n\">get</span><span class=\"w\"> </span><span class=\"n\">install</span><span class=\"w\"> </span><span class=\"bp\">-</span><span class=\"n\">y</span><span class=\"w\"> </span><span class=\"n\">curl</span><span class=\"w\"> </span><span class=\"n\">git</span><span class=\"w\"> </span><span class=\"n\">git</span><span class=\"bp\">-</span><span class=\"n\">lfs</span><span class=\"w\"> </span><span class=\"n\">clang</span><span class=\"w\"> </span><span class=\"n\">lld</span><span class=\"w\"> </span><span class=\"n\">libc</span><span class=\"bp\">++-</span><span class=\"n\">dev</span>\n<span class=\"n\">git</span><span class=\"w\"> </span><span class=\"n\">clone</span><span class=\"w\"> </span><span class=\"bp\">-</span><span class=\"n\">b</span><span class=\"w\"> </span><span class=\"n\">LeanCopilot</span><span class=\"bp\">-</span><span class=\"n\">demo</span><span class=\"w\"> </span><span class=\"n\">https</span><span class=\"o\">:</span><span class=\"bp\">//</span><span class=\"n\">github</span><span class=\"bp\">.</span><span class=\"n\">com</span><span class=\"bp\">/</span><span class=\"n\">yangky11</span><span class=\"bp\">/</span><span class=\"n\">lean4</span><span class=\"bp\">-</span><span class=\"kn\">example</span><span class=\"bp\">.</span><span class=\"n\">git</span>\n<span class=\"n\">cd</span><span class=\"w\"> </span><span class=\"n\">lean4</span><span class=\"bp\">-</span><span class=\"kn\">example</span><span class=\"bp\">/</span>\n<span class=\"n\">lake</span><span class=\"w\"> </span><span class=\"n\">update</span><span class=\"w\"> </span><span class=\"n\">LeanCopilot</span>\n<span class=\"n\">lake</span><span class=\"w\"> </span><span class=\"n\">exe</span><span class=\"w\"> </span><span class=\"n\">LeanCopilot</span><span class=\"bp\">/</span><span class=\"n\">download</span>\n<span class=\"n\">lake</span><span class=\"w\"> </span><span class=\"n\">build</span>\n<span class=\"n\">code</span><span class=\"w\"> </span><span class=\"bp\">.</span>\n</code></pre></div>\n<p><a href=\"/user_uploads/3121/xhLi1Qdogpb-A0aYaR6fYEUP/image.png\">image.png</a></p>\n<div class=\"message_inline_image\"><a href=\"/user_uploads/3121/xhLi1Qdogpb-A0aYaR6fYEUP/image.png\" title=\"image.png\"><img data-original-dimensions=\"1595x556\" src=\"/user_uploads/thumbnail/3121/xhLi1Qdogpb-A0aYaR6fYEUP/image.png/840x560.webp\"></a></div>",
        "id": 489102187,
        "sender_full_name": "Lars Ericson",
        "timestamp": 1734285098
    },
    {
        "content": "<p><em>sigh</em><br>\n<a href=\"/user_uploads/3121/f3g20U53-dD_cmaL-pc4zkhz/image.png\">image.png</a></p>\n<div class=\"message_inline_image\"><a href=\"/user_uploads/3121/f3g20U53-dD_cmaL-pc4zkhz/image.png\" title=\"image.png\"><img data-original-dimensions=\"1088x440\" src=\"/user_uploads/thumbnail/3121/f3g20U53-dD_cmaL-pc4zkhz/image.png/840x560.webp\"></a></div>",
        "id": 489104949,
        "sender_full_name": "Lars Ericson",
        "timestamp": 1734287297
    },
    {
        "content": "<p>With <code>maxRecDepth</code> of 1000.  It would be nice to be able to configure this to run inference on GPU.  My GPU is idle.  All CPU cores are running hot.  Not much memory is being used, so stack space is not a problem.<br>\n<a href=\"/user_uploads/3121/BzSB5xGrF6TXCUkkTe6wKt-Q/image.png\">image.png</a></p>\n<div class=\"message_inline_image\"><a href=\"/user_uploads/3121/BzSB5xGrF6TXCUkkTe6wKt-Q/image.png\" title=\"image.png\"><img data-original-dimensions=\"610x273\" src=\"/user_uploads/thumbnail/3121/BzSB5xGrF6TXCUkkTe6wKt-Q/image.png/840x560.webp\"></a></div>",
        "id": 489105181,
        "sender_full_name": "Lars Ericson",
        "timestamp": 1734287466
    },
    {
        "content": "<p><code>suggest_tactics</code> also gets nowhere.  <code>pow_injective</code> is super hard it seems.</p>",
        "id": 489105559,
        "sender_full_name": "Lars Ericson",
        "timestamp": 1734287787
    },
    {
        "content": "<p>So exact? doesn't get it the <code>pow_injective</code> problem? <a href=\"https://leanprover-community.github.io/mathlib4_docs/find/?pattern=Nat.pow_right_injective#doc\">docs#Nat.pow_right_injective</a> is basically exactly this theorem</p>",
        "id": 489106183,
        "sender_full_name": "Alex Meiburg",
        "timestamp": 1734288396
    },
    {
        "content": "<p>I didn't know <code>exact?</code>, I'm a beginner.  <code>exact apply?</code> I know and it didn't get that.  I'm still trying to configure Lean Dojo.  It got lost trying to do a proof.  Running <code>suggest_tactics</code> gives these ideas after 10 minutes of thinking:</p>\n<div class=\"codehilite\" data-code-language=\"Lean4\"><pre><span></span><code><span class=\"bp\">•</span><span class=\"w\"> </span><span class=\"n\">exact</span><span class=\"w\"> </span><span class=\"n\">Nat</span><span class=\"bp\">.</span><span class=\"n\">pow_eq_zero_iff</span><span class=\"bp\">.</span><span class=\"m\">1</span><span class=\"w\"> </span><span class=\"n\">h</span>\n<span class=\"bp\">•</span><span class=\"w\"> </span><span class=\"n\">induction</span><span class=\"w\"> </span><span class=\"n\">a</span>\n<span class=\"bp\">•</span><span class=\"w\"> </span><span class=\"n\">cases</span><span class=\"w\"> </span><span class=\"n\">a</span><span class=\"w\"> </span><span class=\"bp\">&lt;;&gt;</span><span class=\"w\"> </span><span class=\"n\">contradiction</span>\n<span class=\"bp\">•</span><span class=\"w\"> </span><span class=\"n\">induction</span><span class=\"w\"> </span><span class=\"n\">a</span><span class=\"w\"> </span><span class=\"n\">generalizing</span><span class=\"w\"> </span><span class=\"n\">b</span>\n<span class=\"bp\">•</span><span class=\"w\"> </span><span class=\"n\">cases</span><span class=\"w\"> </span><span class=\"n\">a</span>\n<span class=\"bp\">•</span><span class=\"w\"> </span><span class=\"n\">cases</span><span class=\"w\"> </span><span class=\"n\">a</span><span class=\"w\"> </span><span class=\"bp\">&lt;;&gt;</span><span class=\"w\"> </span><span class=\"n\">cases</span><span class=\"w\"> </span><span class=\"n\">b</span><span class=\"w\"> </span><span class=\"bp\">&lt;;&gt;</span><span class=\"w\"> </span><span class=\"n\">rfl</span>\n<span class=\"bp\">•</span><span class=\"w\"> </span><span class=\"n\">cases</span><span class=\"w\"> </span><span class=\"n\">a</span><span class=\"w\"> </span><span class=\"bp\">&lt;;&gt;</span><span class=\"w\"> </span><span class=\"n\">cases</span><span class=\"w\"> </span><span class=\"n\">b</span><span class=\"w\"> </span><span class=\"bp\">&lt;;&gt;</span><span class=\"w\"> </span><span class=\"n\">simp</span><span class=\"w\"> </span><span class=\"o\">[</span><span class=\"n\">h</span><span class=\"o\">]</span>\n<span class=\"bp\">•</span><span class=\"w\"> </span><span class=\"n\">cases</span><span class=\"w\"> </span><span class=\"n\">a</span><span class=\"w\"> </span><span class=\"bp\">&lt;;&gt;</span><span class=\"w\"> </span><span class=\"n\">cases</span><span class=\"w\"> </span><span class=\"n\">b</span><span class=\"w\"> </span><span class=\"bp\">&lt;;&gt;</span><span class=\"w\"> </span><span class=\"n\">simp</span>\n<span class=\"bp\">•</span><span class=\"w\"> </span><span class=\"n\">cases</span><span class=\"w\"> </span><span class=\"n\">a</span><span class=\"w\"> </span><span class=\"bp\">&lt;;&gt;</span><span class=\"w\"> </span><span class=\"n\">cases</span><span class=\"w\"> </span><span class=\"n\">b</span>\n<span class=\"bp\">•</span><span class=\"w\"> </span><span class=\"n\">cases</span><span class=\"w\"> </span><span class=\"n\">a</span><span class=\"w\"> </span><span class=\"bp\">&lt;;&gt;</span><span class=\"w\"> </span><span class=\"n\">cases</span><span class=\"w\"> </span><span class=\"n\">b</span><span class=\"w\"> </span><span class=\"bp\">&lt;;&gt;</span><span class=\"w\"> </span><span class=\"n\">cases</span><span class=\"w\"> </span><span class=\"n\">b</span>\n<span class=\"bp\">•</span><span class=\"w\"> </span><span class=\"n\">cases</span><span class=\"w\"> </span><span class=\"n\">a</span><span class=\"w\"> </span><span class=\"bp\">&lt;;&gt;</span><span class=\"w\"> </span><span class=\"n\">cases</span><span class=\"w\"> </span><span class=\"n\">b</span><span class=\"w\"> </span><span class=\"bp\">&lt;;&gt;</span><span class=\"w\"> </span><span class=\"n\">contradiction</span>\n<span class=\"bp\">•</span><span class=\"w\"> </span><span class=\"n\">cases</span><span class=\"w\"> </span><span class=\"n\">a</span><span class=\"w\"> </span><span class=\"bp\">&lt;;&gt;</span><span class=\"w\"> </span><span class=\"n\">cases</span><span class=\"w\"> </span><span class=\"n\">b</span><span class=\"w\"> </span><span class=\"bp\">&lt;;&gt;</span><span class=\"w\"> </span><span class=\"n\">assumption</span>\n</code></pre></div>\n<p>It seems that <code>Nat.pow_eq_zero_iff</code> is not in the standard library, it is in Mathlib.   </p>\n<p>The <code>lean4-example</code> GItHub doesn't include Mathlib, but LeanDojo knows Mathlib.  It is a real tangle.  I'm trying to add back Mathlib into the build but it is failing.  I'm about to give up for now.  <code>LeanDojo</code> doesn't seem to be an actively supported deliverable and doesn't look like it plays well with full Mathlib.</p>",
        "id": 489106916,
        "sender_full_name": "Lars Ericson",
        "timestamp": 1734289161
    },
    {
        "content": "<p>(deleted)</p>",
        "id": 489109728,
        "sender_full_name": "Alex Meiburg",
        "timestamp": 1734292003
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"364351\">Lars Ericson</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Simple.20but.20hard.20puzzler.20for.20LLMs/near/489014359\">said</a>:</p>\n<blockquote>\n<p>There are two other somewhat public LLMs fine tuned for Lean, LeanGPT and Morph Prover.  <a href=\"https://www.yeschat.ai/gpts-9t55kJKd7Uh-LeanGPT\">LeanGPT</a> fails exactly like the others.  Rather than saying just <code>import Mathlib</code>, it says <code>import Mathlib.Data.Nat.Basic</code>, which all the others do, and this dates them all to training on something like Zulipchat at say a year ago:</p>\n<div class=\"codehilite\" data-code-language=\"Lean4\"><pre><span></span><code><span class=\"kn\">import</span><span class=\"w\"> </span><span class=\"n\">Mathlib</span><span class=\"bp\">.</span><span class=\"n\">Data</span><span class=\"bp\">.</span><span class=\"n\">Nat</span><span class=\"bp\">.</span><span class=\"n\">Basic</span>\n\n<span class=\"kn\">theorem</span><span class=\"w\"> </span><span class=\"n\">prime_2_3</span><span class=\"w\"> </span><span class=\"o\">(</span><span class=\"n\">n</span><span class=\"w\"> </span><span class=\"n\">m</span><span class=\"w\"> </span><span class=\"o\">:</span><span class=\"w\"> </span><span class=\"n\">Nat</span><span class=\"o\">)</span><span class=\"w\"> </span><span class=\"o\">:</span><span class=\"w\"> </span><span class=\"mi\">3</span><span class=\"bp\">^</span><span class=\"o\">(</span><span class=\"n\">n</span><span class=\"bp\">+</span><span class=\"mi\">1</span><span class=\"o\">)</span><span class=\"w\"> </span><span class=\"bp\">≠</span><span class=\"w\"> </span><span class=\"mi\">2</span><span class=\"bp\">^</span><span class=\"o\">(</span><span class=\"n\">m</span><span class=\"bp\">+</span><span class=\"mi\">1</span><span class=\"o\">)</span><span class=\"w\"> </span><span class=\"o\">:=</span><span class=\"w\"> </span><span class=\"k\">by</span>\n<span class=\"w\">  </span><span class=\"n\">intro</span><span class=\"w\"> </span><span class=\"n\">h</span>\n<span class=\"w\">  </span><span class=\"k\">have</span><span class=\"w\"> </span><span class=\"n\">hmod3</span><span class=\"w\"> </span><span class=\"o\">:=</span><span class=\"w\"> </span><span class=\"n\">Nat</span><span class=\"bp\">.</span><span class=\"n\">pow_mod</span><span class=\"w\"> </span><span class=\"mi\">3</span><span class=\"w\"> </span><span class=\"o\">(</span><span class=\"n\">n</span><span class=\"bp\">+</span><span class=\"mi\">1</span><span class=\"o\">)</span><span class=\"w\"> </span><span class=\"mi\">2</span>\n<span class=\"w\">  </span><span class=\"k\">have</span><span class=\"w\"> </span><span class=\"n\">hmod2</span><span class=\"w\"> </span><span class=\"o\">:=</span><span class=\"w\"> </span><span class=\"n\">Nat</span><span class=\"bp\">.</span><span class=\"n\">pow_mod</span><span class=\"w\"> </span><span class=\"mi\">2</span><span class=\"w\"> </span><span class=\"o\">(</span><span class=\"n\">m</span><span class=\"bp\">+</span><span class=\"mi\">1</span><span class=\"o\">)</span><span class=\"w\"> </span><span class=\"mi\">3</span>\n<span class=\"w\">  </span><span class=\"n\">rw</span><span class=\"w\"> </span><span class=\"o\">[</span><span class=\"n\">h</span><span class=\"o\">]</span><span class=\"w\"> </span><span class=\"k\">at</span><span class=\"w\"> </span><span class=\"n\">hmod3</span>\n<span class=\"w\">  </span><span class=\"k\">have</span><span class=\"w\"> </span><span class=\"o\">:</span><span class=\"w\"> </span><span class=\"mi\">2</span><span class=\"bp\">^</span><span class=\"o\">((</span><span class=\"n\">m</span><span class=\"bp\">+</span><span class=\"mi\">1</span><span class=\"o\">)</span><span class=\"w\"> </span><span class=\"bp\">%</span><span class=\"w\"> </span><span class=\"mi\">3</span><span class=\"o\">)</span><span class=\"w\"> </span><span class=\"bp\">≡</span><span class=\"w\"> </span><span class=\"mi\">0</span><span class=\"w\"> </span><span class=\"o\">[</span><span class=\"n\">MOD</span><span class=\"w\"> </span><span class=\"mi\">3</span><span class=\"o\">]</span><span class=\"w\"> </span><span class=\"o\">:=</span><span class=\"w\"> </span><span class=\"n\">hmod3</span>\n<span class=\"w\">  </span><span class=\"c1\">-- Contradiction by modular arithmetic</span>\n<span class=\"w\">  </span><span class=\"n\">exact</span><span class=\"w\"> </span><span class=\"n\">Nat</span><span class=\"bp\">.</span><span class=\"n\">not_mod_eq_zero_of_prime_ne</span><span class=\"w\"> </span><span class=\"o\">(</span><span class=\"n\">Nat</span><span class=\"bp\">.</span><span class=\"n\">prime_two</span><span class=\"o\">)</span><span class=\"w\"> </span><span class=\"o\">(</span><span class=\"n\">Nat</span><span class=\"bp\">.</span><span class=\"n\">prime_three</span><span class=\"o\">)</span><span class=\"w\"> </span><span class=\"n\">this</span>\n</code></pre></div>\n<p>The other thing it does, which they all do, is hallucinate convenient theorems which are not currently in Mathlib and maybe never where. In the above case, <code>Nat.not_mod_eq_zero_of_prime_ne </code>.</p>\n</blockquote>\n<p>Why not give DeepSeek-Prover (<a href=\"https://github.com/deepseek-ai/DeepSeek-Prover-V1.5\">https://github.com/deepseek-ai/DeepSeek-Prover-V1.5</a>) a try? It is currently the best-performing specialized LLM for Lean4 and is open-source. For example, in the case you provided, the RL version of DeepSeek-Prover V1.5 can produce a correct proof:</p>\n<div class=\"codehilite\" data-code-language=\"Lean4\"><pre><span></span><code><span class=\"kn\">import</span><span class=\"w\"> </span><span class=\"n\">Mathlib</span>\n\n<span class=\"sd\">/-- Show that 3^(n+1) ≠ 2^(m+1)-/</span>\n<span class=\"kn\">theorem</span><span class=\"w\"> </span><span class=\"n\">prime_2_3</span><span class=\"w\"> </span><span class=\"o\">(</span><span class=\"n\">n</span><span class=\"w\"> </span><span class=\"n\">m</span><span class=\"w\"> </span><span class=\"o\">:</span><span class=\"w\"> </span><span class=\"n\">Nat</span><span class=\"o\">)</span><span class=\"w\"> </span><span class=\"o\">:</span><span class=\"w\"> </span><span class=\"mi\">3</span><span class=\"bp\">^</span><span class=\"o\">(</span><span class=\"n\">n</span><span class=\"bp\">+</span><span class=\"mi\">1</span><span class=\"o\">)</span><span class=\"w\"> </span><span class=\"bp\">≠</span><span class=\"w\"> </span><span class=\"mi\">2</span><span class=\"bp\">^</span><span class=\"o\">(</span><span class=\"n\">m</span><span class=\"bp\">+</span><span class=\"mi\">1</span><span class=\"o\">)</span><span class=\"w\"> </span><span class=\"o\">:=</span><span class=\"w\"> </span><span class=\"k\">by</span>\n<span class=\"w\">  </span><span class=\"c\">/-</span>\n<span class=\"cm\">  We aim to show that \\(3^{n+1} \\neq 2^{m+1}\\) for any natural numbers \\(n\\) and \\(m\\). We will use a proof by contradiction. Assume, for the sake of contradiction, that \\(3^{n+1} = 2^{m+1}\\). We will then derive a contradiction by examining the properties of the powers of 2 and 3.</span>\n<span class=\"cm\">  1. First, we consider the parity of both sides of the equation \\(3^{n+1} = 2^{m+1}\\).</span>\n<span class=\"cm\">  2. The left-hand side, \\(3^{n+1}\\), is odd because any power of 3 is odd.</span>\n<span class=\"cm\">  3. The right-hand side, \\(2^{m+1}\\), is even because any power of 2 is even.</span>\n<span class=\"cm\">  4. Since an odd number cannot equal an even number, we have a contradiction.</span>\n<span class=\"cm\">  5. Therefore, our assumption that \\(3^{n+1} = 2^{m+1}\\) must be false.</span>\n<span class=\"cm\">  Thus, we conclude that \\(3^{n+1} \\neq 2^{m+1}\\).</span>\n<span class=\"cm\">  -/</span>\n<span class=\"w\">  </span><span class=\"c1\">-- Assume, for the sake of contradiction, that 3^(n+1) = 2^(m+1).</span>\n<span class=\"w\">  </span><span class=\"n\">by_contra</span><span class=\"w\"> </span><span class=\"n\">h</span>\n<span class=\"w\">  </span><span class=\"c1\">-- Consider the parity of both sides of the equation.</span>\n<span class=\"w\">  </span><span class=\"k\">have</span><span class=\"w\"> </span><span class=\"n\">h₀</span><span class=\"w\"> </span><span class=\"o\">:</span><span class=\"w\"> </span><span class=\"mi\">3</span><span class=\"bp\">^</span><span class=\"o\">(</span><span class=\"n\">n</span><span class=\"bp\">+</span><span class=\"mi\">1</span><span class=\"o\">)</span><span class=\"w\"> </span><span class=\"bp\">%</span><span class=\"w\"> </span><span class=\"mi\">2</span><span class=\"w\"> </span><span class=\"bp\">=</span><span class=\"w\"> </span><span class=\"mi\">1</span><span class=\"w\"> </span><span class=\"o\">:=</span><span class=\"w\"> </span><span class=\"k\">by</span>\n<span class=\"w\">    </span><span class=\"c1\">-- The left-hand side, 3^(n+1), is odd because any power of 3 is odd.</span>\n<span class=\"w\">    </span><span class=\"n\">simp</span><span class=\"w\"> </span><span class=\"o\">[</span><span class=\"n\">Nat</span><span class=\"bp\">.</span><span class=\"n\">pow_mod</span><span class=\"o\">,</span><span class=\"w\"> </span><span class=\"n\">Nat</span><span class=\"bp\">.</span><span class=\"n\">mod_eq_of_lt</span><span class=\"o\">,</span><span class=\"w\"> </span><span class=\"k\">show</span><span class=\"w\"> </span><span class=\"mi\">3</span><span class=\"w\"> </span><span class=\"bp\">%</span><span class=\"w\"> </span><span class=\"mi\">2</span><span class=\"w\"> </span><span class=\"bp\">=</span><span class=\"w\"> </span><span class=\"mi\">1</span><span class=\"w\"> </span><span class=\"k\">by</span><span class=\"w\"> </span><span class=\"n\">decide</span><span class=\"o\">]</span>\n<span class=\"w\">  </span><span class=\"k\">have</span><span class=\"w\"> </span><span class=\"n\">h₁</span><span class=\"w\"> </span><span class=\"o\">:</span><span class=\"w\"> </span><span class=\"mi\">2</span><span class=\"bp\">^</span><span class=\"o\">(</span><span class=\"n\">m</span><span class=\"bp\">+</span><span class=\"mi\">1</span><span class=\"o\">)</span><span class=\"w\"> </span><span class=\"bp\">%</span><span class=\"w\"> </span><span class=\"mi\">2</span><span class=\"w\"> </span><span class=\"bp\">=</span><span class=\"w\"> </span><span class=\"mi\">0</span><span class=\"w\"> </span><span class=\"o\">:=</span><span class=\"w\"> </span><span class=\"k\">by</span>\n<span class=\"w\">    </span><span class=\"c1\">-- The right-hand side, 2^(m+1), is even because any power of 2 is even.</span>\n<span class=\"w\">    </span><span class=\"n\">simp</span><span class=\"w\"> </span><span class=\"o\">[</span><span class=\"n\">Nat</span><span class=\"bp\">.</span><span class=\"n\">pow_mod</span><span class=\"o\">,</span><span class=\"w\"> </span><span class=\"n\">Nat</span><span class=\"bp\">.</span><span class=\"n\">mod_eq_of_lt</span><span class=\"o\">,</span><span class=\"w\"> </span><span class=\"k\">show</span><span class=\"w\"> </span><span class=\"mi\">2</span><span class=\"w\"> </span><span class=\"bp\">%</span><span class=\"w\"> </span><span class=\"mi\">2</span><span class=\"w\"> </span><span class=\"bp\">=</span><span class=\"w\"> </span><span class=\"mi\">0</span><span class=\"w\"> </span><span class=\"k\">by</span><span class=\"w\"> </span><span class=\"n\">decide</span><span class=\"o\">]</span>\n<span class=\"w\">  </span><span class=\"c1\">-- Since an odd number cannot equal an even number, we have a contradiction.</span>\n<span class=\"w\">  </span><span class=\"n\">simp_all</span>\n</code></pre></div>",
        "id": 489111901,
        "sender_full_name": "Huajian Xin",
        "timestamp": 1734294055
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"481527\">@Huajian Xin</span> I wish you would advertise more.  I find one problem is that researchers don’t try to get anyone to use their research.  For example, is it easy to install/use DeepSeek-Prover v1.5 on a laptop?  Also what are the expectations?  Since the target was minif2f, does it work on more advanced math, or just competition problems?</p>",
        "id": 489114325,
        "sender_full_name": "Jason Rute",
        "timestamp": 1734296368
    },
    {
        "content": "<p>Thanks <span class=\"user-mention\" data-user-id=\"481527\">@Huajian Xin</span> I will be happy to give DeepSeek a try.</p>",
        "id": 489115595,
        "sender_full_name": "Lars Ericson",
        "timestamp": 1734297486
    },
    {
        "content": "<p>Nice one <span class=\"user-mention\" data-user-id=\"481527\">@Huajian Xin</span> ! <br>\nAfter Sonnet 3.5 got stuck, I asked what it would search for if given a search engine for Mathlib. It asked for Nat.pow_mod. I searched for it on <a href=\"http://moogle.ai\">moogle.ai</a> and pasted the definition of the theorem to Sonnet. It was able to use the theorem to complete the proof. This is done on my  <a href=\"https://github.com/GasStationManager/LeanTool/tree/extract-goal-states-from-sorrys\">command line chat interface</a> where Sonnet can invoke Lean and fix its own syntax errors.  </p>\n<div class=\"codehilite\" data-code-language=\"Lean4\"><pre><span></span><code><span class=\"kn\">import</span><span class=\"w\"> </span><span class=\"n\">Mathlib</span>\n<span class=\"kn\">theorem</span><span class=\"w\"> </span><span class=\"n\">prime_2_3</span><span class=\"w\"> </span><span class=\"o\">(</span><span class=\"n\">n</span><span class=\"w\"> </span><span class=\"n\">m</span><span class=\"w\"> </span><span class=\"o\">:</span><span class=\"w\"> </span><span class=\"n\">Nat</span><span class=\"o\">)</span><span class=\"w\"> </span><span class=\"o\">:</span><span class=\"w\"> </span><span class=\"mi\">3</span><span class=\"bp\">^</span><span class=\"o\">(</span><span class=\"n\">n</span><span class=\"bp\">+</span><span class=\"mi\">1</span><span class=\"o\">)</span><span class=\"w\"> </span><span class=\"bp\">≠</span><span class=\"w\"> </span><span class=\"mi\">2</span><span class=\"bp\">^</span><span class=\"o\">(</span><span class=\"n\">m</span><span class=\"bp\">+</span><span class=\"mi\">1</span><span class=\"o\">)</span><span class=\"w\"> </span><span class=\"o\">:=</span><span class=\"w\"> </span><span class=\"k\">by</span>\n<span class=\"w\">  </span><span class=\"n\">intro</span><span class=\"w\"> </span><span class=\"n\">h</span>\n\n<span class=\"w\">  </span><span class=\"c1\">-- For 3^(n+1) % 2</span>\n<span class=\"w\">  </span><span class=\"k\">have</span><span class=\"w\"> </span><span class=\"n\">h1</span><span class=\"w\"> </span><span class=\"o\">:</span><span class=\"w\"> </span><span class=\"mi\">3</span><span class=\"bp\">^</span><span class=\"o\">(</span><span class=\"n\">n</span><span class=\"bp\">+</span><span class=\"mi\">1</span><span class=\"o\">)</span><span class=\"w\"> </span><span class=\"bp\">%</span><span class=\"w\"> </span><span class=\"mi\">2</span><span class=\"w\"> </span><span class=\"bp\">=</span><span class=\"w\"> </span><span class=\"mi\">1</span><span class=\"w\"> </span><span class=\"o\">:=</span><span class=\"w\"> </span><span class=\"k\">calc</span>\n<span class=\"w\">    </span><span class=\"mi\">3</span><span class=\"bp\">^</span><span class=\"o\">(</span><span class=\"n\">n</span><span class=\"bp\">+</span><span class=\"mi\">1</span><span class=\"o\">)</span><span class=\"w\"> </span><span class=\"bp\">%</span><span class=\"w\"> </span><span class=\"mi\">2</span><span class=\"w\"> </span><span class=\"bp\">=</span><span class=\"w\"> </span><span class=\"o\">(</span><span class=\"mi\">3</span><span class=\"w\"> </span><span class=\"bp\">%</span><span class=\"w\"> </span><span class=\"mi\">2</span><span class=\"o\">)</span><span class=\"bp\">^</span><span class=\"o\">(</span><span class=\"n\">n</span><span class=\"bp\">+</span><span class=\"mi\">1</span><span class=\"o\">)</span><span class=\"w\"> </span><span class=\"bp\">%</span><span class=\"w\"> </span><span class=\"mi\">2</span><span class=\"w\"> </span><span class=\"o\">:=</span><span class=\"w\"> </span><span class=\"k\">by</span><span class=\"w\"> </span><span class=\"n\">apply</span><span class=\"w\"> </span><span class=\"n\">Nat</span><span class=\"bp\">.</span><span class=\"n\">pow_mod</span>\n<span class=\"w\">    </span><span class=\"bp\">_</span><span class=\"w\"> </span><span class=\"bp\">=</span><span class=\"w\"> </span><span class=\"mi\">1</span><span class=\"bp\">^</span><span class=\"o\">(</span><span class=\"n\">n</span><span class=\"bp\">+</span><span class=\"mi\">1</span><span class=\"o\">)</span><span class=\"w\"> </span><span class=\"bp\">%</span><span class=\"w\"> </span><span class=\"mi\">2</span><span class=\"w\"> </span><span class=\"o\">:=</span><span class=\"w\"> </span><span class=\"k\">by</span><span class=\"w\"> </span><span class=\"n\">rw</span><span class=\"w\"> </span><span class=\"o\">[</span><span class=\"k\">show</span><span class=\"w\"> </span><span class=\"mi\">3</span><span class=\"w\"> </span><span class=\"bp\">%</span><span class=\"w\"> </span><span class=\"mi\">2</span><span class=\"w\"> </span><span class=\"bp\">=</span><span class=\"w\"> </span><span class=\"mi\">1</span><span class=\"w\"> </span><span class=\"k\">by</span><span class=\"w\"> </span><span class=\"n\">norm_num</span><span class=\"o\">]</span>\n<span class=\"w\">    </span><span class=\"bp\">_</span><span class=\"w\"> </span><span class=\"bp\">=</span><span class=\"w\"> </span><span class=\"mi\">1</span><span class=\"w\"> </span><span class=\"bp\">%</span><span class=\"w\"> </span><span class=\"mi\">2</span><span class=\"w\"> </span><span class=\"o\">:=</span><span class=\"w\"> </span><span class=\"k\">by</span><span class=\"w\"> </span><span class=\"n\">simp</span>\n<span class=\"w\">    </span><span class=\"bp\">_</span><span class=\"w\"> </span><span class=\"bp\">=</span><span class=\"w\"> </span><span class=\"mi\">1</span><span class=\"w\"> </span><span class=\"o\">:=</span><span class=\"w\"> </span><span class=\"k\">by</span><span class=\"w\"> </span><span class=\"n\">norm_num</span>\n\n<span class=\"w\">  </span><span class=\"c1\">-- For 2^(m+1) % 2</span>\n<span class=\"w\">  </span><span class=\"k\">have</span><span class=\"w\"> </span><span class=\"n\">h2</span><span class=\"w\"> </span><span class=\"o\">:</span><span class=\"w\"> </span><span class=\"mi\">2</span><span class=\"bp\">^</span><span class=\"o\">(</span><span class=\"n\">m</span><span class=\"bp\">+</span><span class=\"mi\">1</span><span class=\"o\">)</span><span class=\"w\"> </span><span class=\"bp\">%</span><span class=\"w\"> </span><span class=\"mi\">2</span><span class=\"w\"> </span><span class=\"bp\">=</span><span class=\"w\"> </span><span class=\"mi\">0</span><span class=\"w\"> </span><span class=\"o\">:=</span><span class=\"w\"> </span><span class=\"k\">calc</span>\n<span class=\"w\">    </span><span class=\"mi\">2</span><span class=\"bp\">^</span><span class=\"o\">(</span><span class=\"n\">m</span><span class=\"bp\">+</span><span class=\"mi\">1</span><span class=\"o\">)</span><span class=\"w\"> </span><span class=\"bp\">%</span><span class=\"w\"> </span><span class=\"mi\">2</span><span class=\"w\"> </span><span class=\"bp\">=</span><span class=\"w\"> </span><span class=\"o\">(</span><span class=\"mi\">2</span><span class=\"w\"> </span><span class=\"bp\">%</span><span class=\"w\"> </span><span class=\"mi\">2</span><span class=\"o\">)</span><span class=\"bp\">^</span><span class=\"o\">(</span><span class=\"n\">m</span><span class=\"bp\">+</span><span class=\"mi\">1</span><span class=\"o\">)</span><span class=\"w\"> </span><span class=\"bp\">%</span><span class=\"w\"> </span><span class=\"mi\">2</span><span class=\"w\"> </span><span class=\"o\">:=</span><span class=\"w\"> </span><span class=\"k\">by</span><span class=\"w\"> </span><span class=\"n\">apply</span><span class=\"w\"> </span><span class=\"n\">Nat</span><span class=\"bp\">.</span><span class=\"n\">pow_mod</span>\n<span class=\"w\">    </span><span class=\"bp\">_</span><span class=\"w\"> </span><span class=\"bp\">=</span><span class=\"w\"> </span><span class=\"mi\">0</span><span class=\"bp\">^</span><span class=\"o\">(</span><span class=\"n\">m</span><span class=\"bp\">+</span><span class=\"mi\">1</span><span class=\"o\">)</span><span class=\"w\"> </span><span class=\"bp\">%</span><span class=\"w\"> </span><span class=\"mi\">2</span><span class=\"w\"> </span><span class=\"o\">:=</span><span class=\"w\"> </span><span class=\"k\">by</span><span class=\"w\"> </span><span class=\"n\">rw</span><span class=\"w\"> </span><span class=\"o\">[</span><span class=\"k\">show</span><span class=\"w\"> </span><span class=\"mi\">2</span><span class=\"w\"> </span><span class=\"bp\">%</span><span class=\"w\"> </span><span class=\"mi\">2</span><span class=\"w\"> </span><span class=\"bp\">=</span><span class=\"w\"> </span><span class=\"mi\">0</span><span class=\"w\"> </span><span class=\"k\">by</span><span class=\"w\"> </span><span class=\"n\">norm_num</span><span class=\"o\">]</span>\n<span class=\"w\">    </span><span class=\"bp\">_</span><span class=\"w\"> </span><span class=\"bp\">=</span><span class=\"w\"> </span><span class=\"mi\">0</span><span class=\"w\"> </span><span class=\"o\">:=</span><span class=\"w\"> </span><span class=\"k\">by</span><span class=\"w\"> </span><span class=\"n\">simp</span>\n\n<span class=\"w\">  </span><span class=\"c1\">-- From h: 3^(n+1) = 2^(m+1), their remainders mod 2 must be equal</span>\n<span class=\"w\">  </span><span class=\"k\">have</span><span class=\"w\"> </span><span class=\"n\">contra</span><span class=\"w\"> </span><span class=\"o\">:</span><span class=\"w\"> </span><span class=\"mi\">1</span><span class=\"w\"> </span><span class=\"bp\">=</span><span class=\"w\"> </span><span class=\"mi\">0</span><span class=\"w\"> </span><span class=\"o\">:=</span><span class=\"w\"> </span><span class=\"k\">by</span>\n<span class=\"w\">    </span><span class=\"n\">rw</span><span class=\"w\"> </span><span class=\"o\">[</span><span class=\"bp\">←</span><span class=\"n\">h1</span><span class=\"o\">,</span><span class=\"w\"> </span><span class=\"bp\">←</span><span class=\"n\">h2</span><span class=\"o\">,</span><span class=\"w\"> </span><span class=\"n\">h</span><span class=\"o\">]</span>\n\n<span class=\"w\">  </span><span class=\"c1\">-- This is our contradiction</span>\n<span class=\"w\">  </span><span class=\"n\">exact</span><span class=\"w\"> </span><span class=\"n\">Nat</span><span class=\"bp\">.</span><span class=\"n\">one_ne_zero</span><span class=\"w\"> </span><span class=\"n\">contra</span>\n</code></pre></div>\n<p>Next is to make this automatic. Does <a href=\"http://moogle.ai\">moogle.ai</a> have an API?</p>",
        "id": 489116556,
        "sender_full_name": "GasStationManager",
        "timestamp": 1734298336
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"115715\">Jason Rute</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Simple.20but.20hard.20puzzler.20for.20LLMs/near/489114325\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"481527\">Huajian Xin</span> I wish you would advertise more.  I find one problem is that researchers don’t try to get anyone to use their research.  For example, is it easy to install/use DeepSeek-Prover v1.5 on a laptop?  Also what are the expectations?  Since the target was minif2f, does it work on more advanced math, or just competition problems?</p>\n</blockquote>\n<p>Thank you <span class=\"user-mention\" data-user-id=\"115715\">@Jason Rute</span> !</p>\n<ul>\n<li>\n<p>Running a 7B large language model directly on a personal laptop is generally not practical without significant compromises, such as using heavily quantized versions (e.g., <a href=\"https://x.com/awnihannun/status/1824812654189559888\">as mentioned here</a>). However, quantization often leads to further performance degradation. For this reason, we believe that the most effective way to make tools like DeepSeek-Prover v1.5 widely accessible is for developers to build remote-access services, similar to how GitHub Copilot operates. This would allow users to interact with the model seamlessly without needing specialized hardware.</p>\n</li>\n<li>\n<p>As for more advanced math, we haven't conducted extensive experiments beyond MiniF2F. We do have some preliminary results on ProofNet, but those are still in the early stages. Additionally, while we did a limited amount of training on mathlib, we haven’t fully evaluated the model on advanced math benchmarks. Maybe we can evaluate the model further on suitable benchmarks like miniCTX.</p>\n</li>\n</ul>",
        "id": 489173792,
        "sender_full_name": "Huajian Xin",
        "timestamp": 1734337566
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"481527\">@Huajian Xin</span> does DeepSeek need GPU to run the 8B model?  For inference can it run on CPU?  In that case, a laptop with 32GB of RAM should be sufficient?  Or can you suggest a minimum RAM requirement for CPU inference?</p>\n<p>Can you make a GitHub which shows a working Lean install using DeepSeek?  For example  along the lines of this one used to demo LeanCopilot which has the correctly configured lakefiles and so on: <a href=\"https://github.com/yangky11/lean4-example/tree/LeanCopilot-demo\">https://github.com/yangky11/lean4-example/tree/LeanCopilot-demo</a>, together with exact build steps.  I'm asking because you can see above in thread that I struggled for several hours trying to get LeanCopilot to install with Lean before I got it working more or less. </p>\n<p>Is it able to handle <code>import Mathlib</code>? Importing mathlib seemed to cause problems for LeanCopilot .</p>",
        "id": 489246964,
        "sender_full_name": "Lars Ericson",
        "timestamp": 1734358260
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"364351\">@Lars Ericson</span> As for Mathlib and lean copilot, did you downloaded the mathlib cache so you aren’t building mathlib locally?  <span class=\"user-mention\" data-user-id=\"481527\">@Huajian Xin</span> why do your instructions say to build mathlib locally instead of just downloading the cache?</p>",
        "id": 489251795,
        "sender_full_name": "Jason Rute",
        "timestamp": 1734359451
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"364351\">@Lars Ericson</span> Basically a GPU with at least 24G memory (e.g. RTX 4090) is required to run the full-sized model.<br>\n<span class=\"user-mention\" data-user-id=\"115715\">@Jason Rute</span> That's mainly because we modify the lakefile to support our custom setting for REPL. Maybe downloading the cache before building will also work.</p>",
        "id": 489253204,
        "sender_full_name": "Huajian Xin",
        "timestamp": 1734359819
    },
    {
        "content": "<p>Ok, so to run DS-P I think one either needs to host a server with a GPU or get quanitization working.  Neither is easy for the typical Lean user, but some people here are pretty talented and adventurous.  (By the way, I’m going to talk about this sort of stuff at Lean Together next month, and I also gave a talk about it at AITP.  The point is that there is a huge disconnect between research and users, and I think this discussion we are having right now really illustrates that divide.)</p>",
        "id": 489257019,
        "sender_full_name": "Jason Rute",
        "timestamp": 1734360744
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"481527\">Huajian Xin</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Simple.20but.20hard.20puzzler.20for.20LLMs/near/489253204\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"364351\">Lars Ericson</span> Basically a GPU with at least 24G memory (e.g. RTX 4090) is required to run the full-sized model.<br>\n<span class=\"user-mention silent\" data-user-id=\"115715\">Jason Rute</span> That's mainly because we modify the lakefile to support our custom setting for REPL. Maybe downloading the cache before building will also work.</p>\n</blockquote>\n<p>I don't understand why inference for the trained model can't run on CPU.  Have you tried it?  Typically GPU is only required for training.  Does it train on the fly?  What makes it different from most other machine learning models on this point?</p>\n<p>Otherwise the try-at-home price is around USD2500 including the 4090 card and power supply upgrade: <a href=\"https://www.amazon.com/ASUS-Gaming-GeForce-Graphics-DisplayPort/dp/B0C7JYX6LN/\">https://www.amazon.com/ASUS-Gaming-GeForce-Graphics-DisplayPort/dp/B0C7JYX6LN/</a></p>\n<p>Free tier Google Colab won't have as much VRAM for either GPU or TPU as the 4090: <a href=\"https://www.perplexity.ai/search/how-much-vram-is-on-a-google-c-rX.ezKv.RySkOuYCx_Nx4A\">https://www.perplexity.ai/search/how-much-vram-is-on-a-google-c-rX.ezKv.RySkOuYCx_Nx4A</a></p>",
        "id": 489332414,
        "sender_full_name": "Lars Ericson",
        "timestamp": 1734379911
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"364351\">Lars Ericson</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Simple.20but.20hard.20puzzler.20for.20LLMs/near/489332414\">said</a>:</p>\n<blockquote>\n<p>I don't understand why inference for the trained model can't run on CPU. Have you tried it? Typically GPU is only required for training.</p>\n</blockquote>\n<p>I don't think that's accurate. At least, not these days, with current LLMs. Neural networks are highly parallel structures, and benefit from the parallel power of GPUs for both training and inference. If you look at what people do with \"inference-at-the-edge\", it almost all uses accelerators (i.e. GPUs).</p>\n<p>Of course you <em>can</em> run it on a CPU. But it's roughly 100x slower, usually much too slow to be interesting or useful.</p>",
        "id": 489333253,
        "sender_full_name": "Alex Meiburg",
        "timestamp": 1734380172
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"364351\">@Lars Ericson</span> If you have enough memory, you could try on your CPU.  It is an 8B model so it isn’t impossible, I think, just slow and memory intensive.  But I’m also not sure what kind of search <span class=\"user-mention\" data-user-id=\"481527\">@Huajian Xin</span> was using to get the result above.  One sample?  Many samples (like hundreds)?  Or Monte Carlo tree search?  The later would probably be quite slow on a CPU.</p>",
        "id": 489335100,
        "sender_full_name": "Jason Rute",
        "timestamp": 1734380770
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"115715\">@Jason Rute</span> in your AITP talk you might want to discuss the hardware requirements for inference for the available models like LeanCopilot and DS-P.   Here is <a href=\"https://www.perplexity.ai/search/please-make-a-table-with-your-mILLBaQxQ0K4VRk0UO3PrA\">a guess from Perplexity</a>.</p>",
        "id": 489354520,
        "sender_full_name": "Lars Ericson",
        "timestamp": 1734387161
    },
    {
        "content": "<p>I don’t really appreciate big dumps on Zulip of AI written explainations.</p>",
        "id": 489362257,
        "sender_full_name": "Jason Rute",
        "timestamp": 1734389801
    },
    {
        "content": "<p>But for DS-P, it is a normal-ish size model for this type of research.  I think it is sort of big to be running on a laptop (especially if you need multiple generations to do anything of value), but it is also a research model not intended to be run as such.  (Hence, I was really surprised when they said \"Have you tried DeepSeek-Prover?\".)  To make it more user-friendly, there are options like quantization or running it on a local GPU like those found on gamer laptops or newer Macbooks.  There are also important questions about how this sort of thing looks in the future.  For example, if some organization wants to start supporting a server of Lean-specific models or if there needs to be research into how exactly to make usable models that can fit on a laptop and finish in real-world time.  I think it will come down to the various use cases.  (For example, many Lean projects would be happy with tools that run in the background on a server.  And there are plenty of non-transformer approaches that may be better for running on a laptop.  Also, there are approaches that use existing LLM APIs but with ITP-specific integration to clean up the code.  These again, could be good for laptop users.)</p>",
        "id": 489364529,
        "sender_full_name": "Jason Rute",
        "timestamp": 1734390709
    },
    {
        "content": "<p>As for LeanCopilot, it uses a smaller model that can more easily run on a laptop.   I'm sure it is a very good model from experience, but some have said they got value out of it (and I don't know if we have ever had a particularly good user-facing model for Lean proof generation).</p>",
        "id": 489366244,
        "sender_full_name": "Jason Rute",
        "timestamp": 1734391383
    },
    {
        "content": "<p>The laptop 4090 has 16GB of VRAM, so it wouldn't work.  This size and type of model in current day will only run on suitably sized servers.  For users who are not developers of the model, the model would need to be hosted on a server under some funding model, either users pay to use or a funding agency pays to make it free.</p>",
        "id": 489370149,
        "sender_full_name": "Lars Ericson",
        "timestamp": 1734393181
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"115715\">Jason Rute</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Simple.20but.20hard.20puzzler.20for.20LLMs/near/489364529\">said</a>:</p>\n<blockquote>\n<p>But for DS-P, it is a normal-ish size model for this type of research.  I think it is sort of big to be running on a laptop (especially if you need multiple generations to do anything of value), but it is also a research model not intended to be run as such.  (Hence, I was really surprised when they said \"Have you tried DeepSeek-Prover?\".)  To make it more user-friendly, there are options like quantization or running it on a local GPU like those found on gamer laptops or newer Macbooks.  There are also important questions about how this sort of thing looks in the future.  For example, if some organization wants to start supporting a server of Lean-specific models or if there needs to be research into how exactly to make usable models that can fit on a laptop and finish in real-world time.  I think it will come down to the various use cases.  (For example, many Lean projects would be happy with tools that run in the background on a server.  And there are plenty of non-transformer approaches that may be better for running on a laptop.  Also, there are approaches that use existing LLM APIs but with ITP-specific integration to clean up the code.  These again, could be good for laptop users.)</p>\n</blockquote>\n<p>OpenAI and the experiences of many other players have shown us that we must first scale up before we can scale down—only after developing a hundreds-of-billion-parameter, superhuman theorem-proving model can we distill it into a smaller, faster, and also stronger model with hundreds of millions of parameters. Therefore, our current progress is only halfway through the first half.</p>",
        "id": 489537912,
        "sender_full_name": "Huajian Xin",
        "timestamp": 1734456727
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"481527\">@Huajian Xin</span> Lots of information here, I am looking forward a DeepSeekProver 2 model based on DeepSeek v2.5 236B and accessible through API then ^^ Speculation aside, DeepSeekProver 1.5 is a good model, thanks for making it open-source!</p>",
        "id": 489544364,
        "sender_full_name": "Auguste Poiroux",
        "timestamp": 1734458933
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"321854\">@Auguste Poiroux</span> when you say a “good model”, do you mean from personal experience or the benchmarks in their paper.  I’m mostly just curious how many people have been able to get it working for themselves.  And if so, what have you tried doing with it?</p>",
        "id": 489546162,
        "sender_full_name": "Jason Rute",
        "timestamp": 1734459571
    },
    {
        "content": "<p>I mean from personal experience. When we use the provided prompts and generation parameters it works fairly well. I recommend using 32&lt;=n_samples&lt;=256. This range is a good trade-off between accuracy and compute-time. I am just using the whole-proof generation mode though, I didn't try the tree-search approach given the low improvement it seems to bring (according to the <a href=\"https://arxiv.org/pdf/2408.08152\">official paper</a> results).<br>\nAnd beyond the provided prompts it is also capable of following some additional instructions. I wasn't expecting this in the beginning because I thought the heavy RL tuning would have destroyed these capabilities.<br>\nI am using it on ProofNet-like problems, but I didn't try it on real problems.</p>",
        "id": 489549112,
        "sender_full_name": "Auguste Poiroux",
        "timestamp": 1734460577
    },
    {
        "content": "<p>Is there any Lean interaction, or do you manually check each proof?  Also how long does it take to generate 32 to 256 proofs?  And what kind of machine are you running it on?</p>",
        "id": 489550163,
        "sender_full_name": "Jason Rute",
        "timestamp": 1734460966
    },
    {
        "content": "<p>I use Lean to check the proofs, I am not crazy enough to check thousands of Lean proofs by hand <span aria-label=\"big smile\" class=\"emoji emoji-1f604\" role=\"img\" title=\"big smile\">:big_smile:</span><br>\nAs long as you have a good GPU with enough memory (A100, H100, RTX4090), generating proofs using parallel sampling is really fast. Currently, checking the proofs is the bottleneck in the pipeline for me (but not too bad).</p>",
        "id": 489551177,
        "sender_full_name": "Auguste Poiroux",
        "timestamp": 1734461378
    },
    {
        "content": "<p>Sorry for the silly question, but does DeepSeek come with a way to check proofs in Lean, or did you write your own scripts?  And are the proofs checked the “naive” way where one just checks a separate Lean text file from beginning to end for each generation, or do you use metaprogramming to check all the proofs in the same Lean instance?</p>",
        "id": 489551585,
        "sender_full_name": "Jason Rute",
        "timestamp": 1734461553
    },
    {
        "content": "<p>DeepSeek has some code to run the model on benchmarks: <a href=\"https://github.com/deepseek-ai/DeepSeek-Prover-V1.5\">https://github.com/deepseek-ai/DeepSeek-Prover-V1.5</a>. So yes it comes with a way to check proofs. From what I understand in their code, they check complete files (approximately true). Under the hood they use <a href=\"https://github.com/leanprover-community/repl\">Lean REPL</a>. I am not using their code, but I am also using Lean REPL. It has a nice way to iterate on environment states, so we can load the context once and then reuse that environment multiple times to check several proofs. In practice, in benchmarks, the context is just \"import Mathlib\" and checking proofs has a tendency to take more CPU-time than to run \"import Mathlib\". So separating the import from the statement+proof is not that interesting in this case.</p>",
        "id": 489553277,
        "sender_full_name": "Auguste Poiroux",
        "timestamp": 1734462157
    },
    {
        "content": "<p>I may have read too fast DeepSeek's code, my bad. It seems that they use the REPL environment states: <a href=\"https://github.com/deepseek-ai/DeepSeek-Prover-V1.5/blob/main/prover/lean/verifier.py#L25\">https://github.com/deepseek-ai/DeepSeek-Prover-V1.5/blob/main/prover/lean/verifier.py#L25</a></p>",
        "id": 489553821,
        "sender_full_name": "Auguste Poiroux",
        "timestamp": 1734462348
    },
    {
        "content": "<p>I just tried the <code>theorem prime_2_3 (n m : Nat) : 3^(n+1) ≠ 2^(m+1)</code> on o3-mini (ChatGPT with reasoning turned on).  (<a href=\"https://chatgpt.com/c/679df465-0a6c-8001-ad84-318bfd363c32\">https://chatgpt.com/c/679df465-0a6c-8001-ad84-318bfd363c32</a>)  It got pretty close.  I had to fix the Lean 4 syntax and replace a hallucinated theorem name with <code>dvd_of_dvd_pow</code>.  Hard stuff for a new user, but not so hard for an experienced user.  (I was also going to try DeepSeek-r1 since it might have been trained on Deepseek-Prover's data, or so someone here said.  But alas it was busy when I tried.)</p>",
        "id": 497152587,
        "sender_full_name": "Jason Rute",
        "timestamp": 1738405732
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"115715\">Jason Rute</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Simple.20but.20hard.20puzzler.20for.20LLMs/near/497152587\">said</a>:</p>\n<blockquote>\n<p>Hard stuff for a new user, but not so hard for an experienced user.</p>\n</blockquote>\n<p>Over the last two years since ChatGPT became public that statement has become so common that it should get a name and a Wikipedia entry. Would be curious to see examples as the years progress.</p>",
        "id": 497154094,
        "sender_full_name": "Eric Taucher",
        "timestamp": 1738407118
    },
    {
        "content": "<p>Deepseek-r1's solution didn't seem as helpful.  <del>(https://chat.deepseek.com/a/chat/s/f1cfb2dc-3a98-4d16-9f3b-f2226f6bf359)</del> It just tried to solve the whole thing with one hallucinated theorem.  I don't know how to fix it.</p>",
        "id": 497154221,
        "sender_full_name": "Jason Rute",
        "timestamp": 1738407238
    },
    {
        "content": "<p>Unfortunately, the link provided isn't accessible to others. Could you please share the relevant parts of the conversation in another way?</p>",
        "id": 497155465,
        "sender_full_name": "Drophet",
        "timestamp": 1738408295
    },
    {
        "content": "<p>Ok, wasn't sure how it works.  Here is the final \"proof\" from DS-r1:</p>\n<div class=\"spoiler-block\"><div class=\"spoiler-header\">\n<p>\"Proof\"</p>\n</div><div class=\"spoiler-content\" aria-hidden=\"true\">\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"kd\">theorem</span><span class=\"w\"> </span><span class=\"n\">prime_2_3</span><span class=\"w\"> </span><span class=\"o\">(</span><span class=\"n\">n</span><span class=\"w\"> </span><span class=\"n\">m</span><span class=\"w\"> </span><span class=\"o\">:</span><span class=\"w\"> </span><span class=\"n\">Nat</span><span class=\"o\">)</span><span class=\"w\"> </span><span class=\"o\">:</span><span class=\"w\"> </span><span class=\"mi\">3</span><span class=\"bp\">^</span><span class=\"o\">(</span><span class=\"n\">n</span><span class=\"bp\">+</span><span class=\"mi\">1</span><span class=\"o\">)</span><span class=\"w\"> </span><span class=\"bp\">≠</span><span class=\"w\"> </span><span class=\"mi\">2</span><span class=\"bp\">^</span><span class=\"o\">(</span><span class=\"n\">m</span><span class=\"bp\">+</span><span class=\"mi\">1</span><span class=\"o\">)</span><span class=\"w\"> </span><span class=\"o\">:=</span><span class=\"w\"> </span><span class=\"kd\">by</span>\n<span class=\"w\">  </span><span class=\"c1\">-- Use the fundamental theorem of arithmetic to show that the prime factorizations of 3^(n+1) and 2^(m+1) are distinct.</span>\n<span class=\"w\">  </span><span class=\"n\">apply</span><span class=\"w\"> </span><span class=\"n\">Nat.pow_ne_pow_of_ne_of_lt</span><span class=\"w\"> </span><span class=\"o\">(</span><span class=\"kd\">by</span><span class=\"w\"> </span><span class=\"n\">norm_num</span><span class=\"o\">)</span><span class=\"w\"> </span><span class=\"o\">(</span><span class=\"kd\">by</span><span class=\"w\"> </span><span class=\"n\">norm_num</span><span class=\"o\">)</span>\n<span class=\"w\">  </span><span class=\"c1\">-- `norm_num` is used to verify that 3 ≠ 2 and 3 &lt; 2^(m+1) for all m ∈ ℕ, which are necessary conditions for the theorem to hold.</span>\n<span class=\"w\">  </span><span class=\"bp\">&lt;;&gt;</span><span class=\"w\"> </span><span class=\"n\">norm_num</span>\n<span class=\"w\">  </span><span class=\"bp\">&lt;;&gt;</span><span class=\"w\"> </span><span class=\"n\">linarith</span>\n</code></pre></div>\n</div></div>",
        "id": 497157909,
        "sender_full_name": "Jason Rute",
        "timestamp": 1738410414
    },
    {
        "content": "<p>The reasoning trace (not shown) doesn't mention Lean until the proof at the end.  It was just thinking through an English proof going through the fundamental theorem of arithmetic.  Then the Lean \"proof\" uses some magic lemma that I don't think exists in Mathlib.</p>",
        "id": 497158172,
        "sender_full_name": "Jason Rute",
        "timestamp": 1738410662
    },
    {
        "content": "<p>It's hard to guess what the lemma would say, for example 8^2=4^3, you will need some kind of primality assumption somewhere (4 != 8 and 4 &lt; 8^(m+1))</p>",
        "id": 497158283,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1738410768
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"115715\">Jason Rute</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Simple.20but.20hard.20puzzler.20for.20LLMs/near/497152587\">said</a>:</p>\n<blockquote>\n<p>I just tried the <code>theorem prime_2_3 (n m : Nat) : 3^(n+1) ≠ 2^(m+1)</code> on o3-mini (ChatGPT with reasoning turned on).  (<a href=\"https://chatgpt.com/c/679df465-0a6c-8001-ad84-318bfd363c32\">https://chatgpt.com/c/679df465-0a6c-8001-ad84-318bfd363c32</a>) </p>\n</blockquote>\n<p>I can't see anything at <em>this</em> link (Unable to load conversation 679df465-0a6c-8001-ad84-318bfd363c32), would you care to copy out the o3-mini answer as well?</p>",
        "id": 497968971,
        "sender_full_name": "Bolton Bailey",
        "timestamp": 1738784020
    }
]