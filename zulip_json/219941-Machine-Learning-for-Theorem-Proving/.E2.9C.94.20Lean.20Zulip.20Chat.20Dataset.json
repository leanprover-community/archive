[
    {
        "content": "<p><a href=\"https://huggingface.co/datasets/dx2102/lean-zulip-data\">https://huggingface.co/datasets/dx2102/lean-zulip-data</a></p>\n<p>I just realized that there is a public <a href=\"https://zulip.com/api/get-messages\">Zulip API</a> to download the history of this Lean Zulip Chat, so I wrote the code to download all messages and uploaded them to huggingface. </p>\n<p>This data might be useful for training Lean-based language models, because it covers a lot of minimal code snippets and beginner-friendly explanations compared to pure Mathlib data.</p>",
        "id": 514298211,
        "sender_full_name": "Deming Xu",
        "timestamp": 1745562854
    },
    {
        "content": "<p><a href=\"/user_uploads/3121/NsMsY2M2m8o0THSQH08LbnhI/image.png\">image.png</a></p>\n<div class=\"message_inline_image\"><a href=\"/user_uploads/3121/NsMsY2M2m8o0THSQH08LbnhI/image.png\" title=\"image.png\"><img data-original-content-type=\"image/png\" data-original-dimensions=\"2704x1344\" src=\"/user_uploads/thumbnail/3121/NsMsY2M2m8o0THSQH08LbnhI/image.png/840x560.webp\"></a></div>",
        "id": 514298325,
        "sender_full_name": "Deming Xu",
        "timestamp": 1745562925
    },
    {
        "content": "<p>I realize the potential value of this data, and I realize that this Zulip instance is a public chat and so that messages in it are \"public\" (even though I’m not sure under which license nor terms exactly) and so that they may be used for training purpose, and now that you've uploaded this it’s already too late, but I personally did not sign up here to train models with my messages, nor do I feel comfortable about you doing this without notice beforehand. Did you have any permission from the owners of this chat to do this? Has there been an announce that I missed that this was going to happen?</p>\n<p>From what I see, even if the dataset does not contain poster names for the messages, it does contain users full name when they are motioned in an other post. I also cannot find anything about the license under which this dataset falls. Can you at least clarify this?</p>",
        "id": 514324800,
        "sender_full_name": "Robin Carlier",
        "timestamp": 1745571106
    },
    {
        "content": "<p>I personally think this is an extremely rude move.</p>",
        "id": 514350025,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1745578230
    },
    {
        "content": "<p>Please remove from this dataset every message from me.</p>",
        "id": 514350276,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1745578313
    },
    {
        "content": "<p>I once asked about this in <a class=\"stream-topic\" data-stream-id=\"113489\" href=\"/#narrow/channel/113489-new-members/topic/Is.20the.20Zulip.20chat.20data.20available.20for.20noncommercial.20use.3F/with/432003604\">#new members &gt; Is the Zulip chat data available for noncommercial use?</a> , though I didn't receive a clear answer. There is an official archive <a href=\"https://leanprover-community.github.io/archive/\">https://leanprover-community.github.io/archive/</a>, but it seems not being maintained anymore. In the end, I collected the data and used them in my own project(for beginners in my team to search zulip more conviniently), but I didn't upload the data and the model to any public platform.</p>",
        "id": 514350793,
        "sender_full_name": "Yicheng Tao",
        "timestamp": 1745578473
    },
    {
        "content": "<p>There is something very clear here: this chat website began long before the world went crazy with LLM, so it was never intended as food for LLMs. Users simply never agreed for having their work stolen like this.</p>",
        "id": 514351270,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1745578667
    },
    {
        "content": "<p>Yicheng Tao, the new  members channel is really not appropriate for such a discussion. It’s clear that many community members did not see it.</p>",
        "id": 514353092,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1745579260
    },
    {
        "content": "<p>It seems the zulip dataset has been removed from hugging face before I was able to report it.</p>",
        "id": 514353225,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1745579297
    },
    {
        "content": "<p>I think the licence problem should be clarified. I saw Zulip offering API to export data. Now there is no restrictions for people to do such kind of things. </p>\n<p>For me, I have stopped collecting data and the application built from these data has been deprecated a long time ago.</p>",
        "id": 514353621,
        "sender_full_name": "Yicheng Tao",
        "timestamp": 1745579448
    },
    {
        "content": "<p>Yes. I deleted the dataset.</p>",
        "id": 514354055,
        "sender_full_name": "Deming Xu",
        "timestamp": 1745579587
    },
    {
        "content": "<p>I don’t think any clarification is needed. There is nothing saying this is allowed, so it’s not allowed. And really it’s not about law, it’s about politeness and common sense.</p>",
        "id": 514354666,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1745579799
    },
    {
        "content": "<p>Thank you.</p>",
        "id": 514355045,
        "sender_full_name": "Deming Xu",
        "timestamp": 1745579936
    },
    {
        "content": "<p>Thanks for this quick deletion.</p>",
        "id": 514355973,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1745580295
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110031\">Patrick Massot</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Lean.20Zulip.20Chat.20Dataset/near/514351270\">said</a>:</p>\n<blockquote>\n<p>Users simply never agreed for having their work stolen like this.</p>\n</blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"286014\">Robin Carlier</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Lean.20Zulip.20Chat.20Dataset/near/514324800\">said</a>:</p>\n<blockquote>\n<p>From what I see, even if the dataset does not contain poster names for the messages, it does contain users full name when they are motioned in an other post.</p>\n</blockquote>\n<p>In some sense these two things are at odds with each other; in a perfect world the LLM is trained to attribute the work here to its original authors to mitigate this theft, but it cannot do this if the author information is stripped from the dataset.</p>",
        "id": 514356607,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1745580528
    },
    {
        "content": "<p>Modulo that I'm not a lawyer, but I read the Zulip terms of service last time something like this came up, and if I remember correctly, it seemed to be fairly clear that creating public databases like this cannot be done without the prior explicit consent of both Zulip and the Lean Zulip organization owners</p>",
        "id": 514358627,
        "sender_full_name": "Luigi Massacci",
        "timestamp": 1745581190
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"310045\">@Eric Wieser</span> : this is why licenses exist. When I put a the copyright header in a .lean file that I intend to merge to mathlib, it clearly states (through the Apache 2.0 license) that I’m okay (or at least that I have to be okay with it if I want this merged) with whatever happening to this code as long as there is proper attribution (this includes training LLMs with that code, and realistically all code on github is scraped for LLM training anyways, though they certainly do not give attribution as they should).</p>\n<p>I don’t put licences headers on the crap code snippets I might post on this Zulip though, and I’d rather not have an LLM give me attribution for those either (this, arguably, is a subjective matter, others might prefer the contrary). So in the event that the responsibles of this chat decide  that training LLMs with this chat's data is okay (personally, I’d rather not, but again, this is a public chat and the public internet is scraped for things like this anyway and there’s not much we can do anyway), I’d like to ask at least for proper anonymization of data.</p>",
        "id": 514359087,
        "sender_full_name": "Robin Carlier",
        "timestamp": 1745581325
    },
    {
        "content": "<p>I think you're right that the Zulip chat data and Mathlib code are very different in nature. Mathlib code is an open source project that is explicitly Apache-2.0, while Zulip chat is not. The mindset of a user posting messages on Zulip is very different from submitting code on Mathlib. Zulip chat contains many real names, and in this respect it is perhaps more sensitive than most public datasets.</p>\n<p>The format I uploaded is all the fields of the original raw JSON returned by the Zulip API. It includes the sender name, the send time, and even seems to include the modification history of the Zulip Stream name, but there seems to be no modification history of specific messages. It should also only list streams that I have permission to see. (I think data filtering and cleaning are essential steps in training good language models. This includes the removal of all sensitive personal information.)</p>",
        "id": 514365295,
        "sender_full_name": "Deming Xu",
        "timestamp": 1745583150
    },
    {
        "content": "<p>As an example, this is the JSON of one of my previous messages</p>\n<div class=\"codehilite\" data-code-language=\"JSON\"><pre><span></span><code><span class=\"w\">  </span><span class=\"p\">{</span>\n<span class=\"w\">    </span><span class=\"nt\">\"id\"</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"mi\">455680197</span><span class=\"p\">,</span>\n<span class=\"w\">    </span><span class=\"nt\">\"sender_id\"</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"mi\">740877</span><span class=\"p\">,</span>\n<span class=\"w\">    </span><span class=\"nt\">\"content\"</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"s2\">\"&lt;p&gt;Could you explain a little bit on why we have two tactics, &lt;code&gt;sorry&lt;/code&gt; and &lt;code&gt;admit&lt;/code&gt;, in tactic mode, to temporarily accept any axiom? What is the difference between them? I feel like the documentation doesn't explain this.&lt;/p&gt;\\n&lt;p&gt;I know that besides tactic mode, &lt;code&gt;sorry&lt;/code&gt; is also a valid placeholder in term mode, while &lt;code&gt;admit&lt;/code&gt; is not.&lt;/p&gt;\\n&lt;div class=\\\"codehilite\\\" data-code-language=\\\"Lean4\\\"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class=\\\"kn\\\"&gt;axiom&lt;/span&gt;......\"</span><span class=\"p\">,</span>\n<span class=\"w\">    </span><span class=\"nt\">\"recipient_id\"</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"mi\">127391</span><span class=\"p\">,</span>\n<span class=\"w\">    </span><span class=\"nt\">\"timestamp\"</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"mi\">1722525973</span><span class=\"p\">,</span>\n<span class=\"w\">    </span><span class=\"nt\">\"client\"</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"s2\">\"website\"</span><span class=\"p\">,</span>\n<span class=\"w\">    </span><span class=\"nt\">\"subject\"</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"s2\">\"\\u2714 difference between sorry and admit\"</span><span class=\"p\">,</span>\n<span class=\"w\">    </span><span class=\"nt\">\"topic_links\"</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"p\">[],</span>\n<span class=\"w\">    </span><span class=\"nt\">\"edit_history\"</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"p\">[</span>\n<span class=\"w\">      </span><span class=\"p\">{</span>\n<span class=\"w\">        </span><span class=\"nt\">\"user_id\"</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"mi\">740877</span><span class=\"p\">,</span>\n<span class=\"w\">        </span><span class=\"nt\">\"timestamp\"</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"mi\">1722557634</span><span class=\"p\">,</span>\n<span class=\"w\">        </span><span class=\"nt\">\"prev_topic\"</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"s2\">\"difference between sorry and admit\"</span><span class=\"p\">,</span>\n<span class=\"w\">        </span><span class=\"nt\">\"topic\"</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"s2\">\"\\u2714 difference between sorry and admit\"</span>\n<span class=\"w\">      </span><span class=\"p\">},</span>\n<span class=\"w\">      </span><span class=\"p\">{</span>\n<span class=\"w\">        </span><span class=\"nt\">\"user_id\"</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"mi\">740877</span><span class=\"p\">,</span>\n<span class=\"w\">        </span><span class=\"nt\">\"timestamp\"</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"mi\">1722538482</span><span class=\"p\">,</span>\n<span class=\"w\">        </span><span class=\"nt\">\"prev_topic\"</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"s2\">\"difference between `sorry` and `admit`\"</span><span class=\"p\">,</span>\n<span class=\"w\">        </span><span class=\"nt\">\"topic\"</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"s2\">\"difference between sorry and admit\"</span>\n<span class=\"w\">      </span><span class=\"p\">}</span>\n<span class=\"w\">    </span><span class=\"p\">],</span>\n<span class=\"w\">    </span><span class=\"nt\">\"is_me_message\"</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"kc\">false</span><span class=\"p\">,</span>\n<span class=\"w\">    </span><span class=\"nt\">\"reactions\"</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"p\">[],</span>\n<span class=\"w\">    </span><span class=\"nt\">\"submessages\"</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"p\">[],</span>\n<span class=\"w\">    </span><span class=\"nt\">\"flags\"</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"p\">[</span>\n<span class=\"w\">      </span><span class=\"s2\">\"read\"</span>\n<span class=\"w\">    </span><span class=\"p\">],</span>\n<span class=\"w\">    </span><span class=\"nt\">\"last_moved_timestamp\"</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"mi\">1722538482</span><span class=\"p\">,</span>\n<span class=\"w\">    </span><span class=\"nt\">\"sender_full_name\"</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"s2\">\"Deming Xu\"</span><span class=\"p\">,</span>\n<span class=\"w\">    </span><span class=\"nt\">\"sender_email\"</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"s2\">\"user740877@leanprover.zulipchat.com\"</span><span class=\"p\">,</span>\n<span class=\"w\">    </span><span class=\"nt\">\"sender_realm_str\"</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"s2\">\"leanprover\"</span><span class=\"p\">,</span>\n<span class=\"w\">    </span><span class=\"nt\">\"display_recipient\"</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"s2\">\"new members\"</span><span class=\"p\">,</span>\n<span class=\"w\">    </span><span class=\"nt\">\"type\"</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"s2\">\"stream\"</span><span class=\"p\">,</span>\n<span class=\"w\">    </span><span class=\"nt\">\"stream_id\"</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"mi\">113489</span><span class=\"p\">,</span>\n<span class=\"w\">    </span><span class=\"nt\">\"avatar_url\"</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"s2\">\"https://secure.gravatar.com/avatar/270d1c95cc0bdd4e4f3a5367e62d0580?d=identicon&amp;version=1\"</span><span class=\"p\">,</span>\n<span class=\"w\">    </span><span class=\"nt\">\"content_type\"</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"s2\">\"text/html\"</span>\n<span class=\"w\">  </span><span class=\"p\">},</span>\n</code></pre></div>",
        "id": 514366796,
        "sender_full_name": "Deming Xu",
        "timestamp": 1745583602
    },
    {
        "content": "<p>I’ve actually been thinking a lot about this broader issue of data coverage in recent weeks. That’s what got me to the Zulip API.</p>\n<p>I often see people assert that language models are still not good at research-level math. People in the AI ​​field think this proves the need to train reasoning language models. People in the math field think this proves how complicated mathematics is.</p>\n<p>But interestingly, perhaps this weakness of language models currently comes from the fact that we don’t have complete training data. Many language model training reports focus on how they process HTML web data, but many of the detailed proofs of the math may only exist in textbooks. These books don’t have HTML web versions, only paper or PDF versions. In theory, we can convert each page of the PDF into an image, give it to the current visual language model to recognize the text, and then use it as training data, but I have hardly heard of any training reports mentioning this. I also suspect that the Lean Zulip website is not used by these companies to train models, because it does not appear in Google searches, which means that Google does not index it.</p>\n<p>If the training data for these language models is really only HTML web pages, then these language models are almost purely relying on Wikipedia, MathOverflow, ProofWiki, etc. to learn. These websites probably do not cover the proof of all theorems. There are no textbooks, and also all the training data is randomly shuffled. Learning knowledge with so much missing data is difficult even for humans. Most knowledge fields may have similar problems. As long as they have some knowledge sources beyond HTML web pages, language models will have obstacles to learning them. In this state, the evaluation of the learning ability of the language model may be inaccurate. Their defects may not come from lack of learning ability, but incomplete coverage of training data.</p>",
        "id": 514380505,
        "sender_full_name": "Deming Xu",
        "timestamp": 1745587701
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"466290\">Luigi Massacci</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Lean.20Zulip.20Chat.20Dataset/near/514358627\">said</a>:</p>\n<blockquote>\n<p>Modulo that I'm not a lawyer, but I read the Zulip terms of service last time something like this came up, and if I remember correctly, it seemed to be fairly clear that creating public databases like this cannot be done without the prior explicit consent of both Zulip and the Lean Zulip organization owners</p>\n</blockquote>\n<p>There are a few things in the terms of services here. The following part seems to grant ownership to comments made by users to themselves:</p>\n<blockquote>\n<p>Your User Submissions remain yours. These Terms don’t give us any ownership in your User Submissions, or any rights to them except the limited rights set forth below.</p>\n</blockquote>\n<p>And that exporting content must be approved by the individuals who organize this server:</p>\n<blockquote>\n<p>Export Content via the official Zulip API and distribute such Content for legitimate purposes (e.g., a public archive or mirror which is approved by organization owners).</p>\n</blockquote>\n<p>I think <span class=\"user-mention\" data-user-id=\"740877\">@Deming Xu</span> raised a great point about the lack of availability of Lean training data. I think not including the Zulip chat in training data would be deleting a crucial piece to understanding the choices we make when building Lean repositories, such as Mathlib.</p>",
        "id": 514422542,
        "sender_full_name": "Justin Asher",
        "timestamp": 1745599877
    },
    {
        "content": "<p>My two cents: If the choice is between “more data for LLMs” vs “users right to not have their messages used witthout permission/compensation”, I would choose the latter.</p>",
        "id": 514439284,
        "sender_full_name": "Shreyas Srinivas",
        "timestamp": 1745605846
    },
    {
        "content": "<blockquote>\n<p>I think @Deming Xu raised a great point about the lack of availability of Lean training data. I think not including the Zulip chat in training data would be deleting a crucial piece to understanding the choices we make when building Lean repositories, such as Mathlib.</p>\n</blockquote>\n<p>Yeah, OpenAI won't tell you what data they use, and it's not in our interest to put open datasets / models at a comparative disadvantage against big corps.<br>\nShould we set up some opt-in/opt-out mechanism? Send a message to all current Zulip members and ask new members whether they consent? Based on individual members' choices, we may release a dataset that is only for non-commercial use and a smaller subset with a more permissive license.</p>",
        "id": 514474967,
        "sender_full_name": "Junyan Xu",
        "timestamp": 1745622866
    },
    {
        "content": "<p>I feel like a lot of the questions that I ask on general should be able to be answered by an LLM. But we simply don't have good enough structured chat data for it. Particularly in regards to metaproggraming. If permission is an issue, I think we can create a channel for future LLM training data. And then for any thread, if everyone on the thread agrees we can move it onto the LLM training channel.</p>",
        "id": 514477236,
        "sender_full_name": "Frederick Pu",
        "timestamp": 1745624320
    },
    {
        "content": "<p>I don't think that's likely to happen much in practice. Why would you anyone elect to move a thread out of \"IMO-grand-challenge\" or out of \"new members\" to a different channel, where it will no longer be organized by topic, and it will (presumably) reduce discovery?</p>",
        "id": 514540604,
        "sender_full_name": "Alex Meiburg",
        "timestamp": 1745675160
    },
    {
        "content": "<p>maybe we could a have a script for duplicating threads or marking them as \"for LLM training\" that way we wouldn't need to move them off of thread</p>",
        "id": 514555136,
        "sender_full_name": "Frederick Pu",
        "timestamp": 1745685311
    },
    {
        "content": "<p>Original author was polite to post about this. But given how the api is public, isn't it likely big corp LLMs have most probably scraped the api already</p>",
        "id": 514555670,
        "sender_full_name": "Sabbir Rahman",
        "timestamp": 1745685714
    },
    {
        "content": "<p>Agreed, but that doesn’t mean we as individuals decide to not care about privacy anymore do we? When big corp LLMs scrape content without user permission, they are doing something unethical. I don’t see how that justifies doing more of the same</p>",
        "id": 514568491,
        "sender_full_name": "Shreyas Srinivas",
        "timestamp": 1745695343
    },
    {
        "content": "<p>I agree it's not justified. Just pointing out that anyone who doesn't care to ask can still scrape and use the data.</p>",
        "id": 514568785,
        "sender_full_name": "Sabbir Rahman",
        "timestamp": 1745695575
    },
    {
        "content": "<p>Actually, I don't think we can assume that employees at major LLM companies were meticulous enough to manually write code to scrape Zulip API's data. (But maybe they will in the future.) At least for now, most academic papers on LLM for Lean seem to only use Lean repositories from GitHub and ignore data from Zulip.</p>\n<p>The training data sources mentioned in current LLM training reports mainly include: websites (CommonCrawl / FineWeb), GitHub, Arxiv, StackExchange, Reddit, public domain books from Gutenberg, and pirated books from LibGen included in Books3, etc. I'm afraid this does not include any scanned PDFs, nor have they done careful optimization for small, specialized domains.</p>\n<p>Also, current web crawlers probably can't automatically figure out the parameter formats accepted by those Zulip JSON APIs.</p>\n<p>Similarly, I don't think the crawlers were able to correctly access Zulip’s web version either, because the messages are dynamically loaded through JavaScript embedded in the HTML, which web crawlers typically struggle with. For example, you can't find Lean Zulip messages via Google Search.</p>\n<p>Overall, I believe your data would only become visible to LLMs after some manual optimization—similar to how websites need SEO (Search Engine Optimization) to be searchable. PDFs and private chats are not the most \"LLM-friendly\" formats.</p>\n<hr>",
        "id": 514587563,
        "sender_full_name": "Deming Xu",
        "timestamp": 1745711520
    },
    {
        "content": "<p>You already mentioned the old, unmaintained official Zulip Chat Archive. These web pages <em>can</em> be found through Google search. However, the messages there are mostly about Lean 3. I'm starting to suspect that this Lean 3 data might have contaminated the training data of LLMs.</p>\n<p>Over the past few months, when I tried asking LLMs to write Lean code, they still tended to produce Lean 3 code. Only recently have they finally started to produce Lean 4 code, especially when I explicitly mention \"Lean 4.\"</p>\n<p>These LLMs might have only seen Lean 3 code from the Zulip Archive and Lean 4 code from GitHub repositories. Because the \"question-answering\" format is closer to Zulip chats, they tend to mimic the Lean 3 style from Zulip rather than the Lean 4 code from GitHub.</p>\n<p>If the official Zulip Chat Archive could be maintained again, LLMs would be able to see the correct Lean 4 training data. It would also make it easier for Lean learners to find information through Google search.</p>",
        "id": 514587610,
        "sender_full_name": "Deming Xu",
        "timestamp": 1745711543
    },
    {
        "content": "<p>It's not so much unmaintained as it is requiring a manual trigger by me to update it</p>",
        "id": 514599604,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1745721451
    },
    {
        "content": "<ul>\n<li>Deming Xu, you are constantly assuming everybody here wants to live in a world where questions are answered by LLMs and not by human beings. This is a very strong assumption.</li>\n</ul>",
        "id": 514625734,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1745743693
    },
    {
        "content": "<p>Why don’t you try to learn Lean without LLMs and benefit from the community here instead of trying to gather more data and waste more energy and water?</p>",
        "id": 514625769,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1745743743
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110031\">Patrick Massot</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Lean.20Zulip.20Chat.20Dataset/near/514625769\">said</a>:</p>\n<blockquote>\n<p>Why don’t you try to learn Lean without LLMs and benefit from the community here instead of trying to gather more data and waste more energy and water?</p>\n</blockquote>\n<p>I understand the concerns about data privacy. At the same time, suggesting someone's efforts are a 'waste' felt like it crossed a line into devaluing their interests, which doesn't seem aligned with our <a href=\"https://www.contributor-covenant.org/version/2/0/code_of_conduct/\">code of conduct's</a> emphasis on respectful discussion. I really hope we can keep this community a place where people feel comfortable sharing their ideas and questions without facing personal attacks.</p>",
        "id": 514652766,
        "sender_full_name": "Justin Asher",
        "timestamp": 1745765207
    },
    {
        "content": "<p>The waste is created by running LLMs, not by human efforts. I'm sorry if this wasn't clear in my message.</p>",
        "id": 514672225,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1745779163
    },
    {
        "content": "<p>And precisely I encouraged Deming Xu to ask us questions instead of asking LLMs, so I really don't understand your attack on me.</p>",
        "id": 514672375,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1745779278
    },
    {
        "content": "<p>Professor Massot, I mainly wanted to describe to you this broader interesting problem of training data coverage, including the problem of Zulip data, from a factual level. I think that although it has not received much attention before, this coverage problem may actually have quite a significant impact on basic abilities of LLMs and academia's evaluation of LLMs.</p>\n<p>These are just interesting phenomena I want to share. I am not assuming that everyone is keen on LLMs, but no matter what your preferences are, I certainly hope that everyone can get more accurate facts, and make decisions when they understand the outcome. I hope you can think about this.</p>\n<p>In terms of the waste of energy and water, if you are serious, I think the cost is not too big. This Zulip data is only about 600MB of text, and LLM trainers seem to be able to collect a total of about 60TB (15T tokens). So this Zulip data is 0.001% of that (0.6GB / 60000GB), and the electricity consumed for this may be enough to run an air conditioner for one to three days.</p>\n<p>As for your statement that LLMs will replace this Zulip chat to answer any questions, or that I am assuming that everyone likes LLMs, or that I am using LLMs to learn Lean, or that I am trying to steal Zulip data and waste energy to train huge models myself, I am sure you also know that this is simply unrealistic at present.</p>\n<p>Personally, if one day LLMs can help me write simple Lean code to test my ideas, or quickly and accurately summarize the details of a certain aspect of Lean to me (just like other programming languages and libraries), I think it is a good thing. This can automate the tedious and unproductive steps in writing Lean code and accelerate the development of the Lean ecosystem.</p>",
        "id": 514684663,
        "sender_full_name": "Deming Xu",
        "timestamp": 1745788058
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"740877\">@Deming Xu</span>  Part of the negative sentiment on this Zulip against LLMs right now exists because there has been a lot of low-effort questions within the past few weeks where the code was written primarily by LLM and it was clear that the original poster did not put in the time to actually understand what question they were asking. This wasted a lot of people's time as they tried to debug code which was nowhere close to being correct. I don't think it's reasonable to extend a dislike of low-effort LLM-generated questions to a dislike of LLMs in general, but it can be very tempting to do so and I wouldn't hold it against anyone who does.</p>\n<p>The larger question of whether or not it is acceptable to train off the messages on this Zulip, including concerns about copyright, privacy, and not disadvantaging open source models, should probably be discussed in a channel like general where more people are likely to see it.</p>",
        "id": 514690635,
        "sender_full_name": "Niels Voss",
        "timestamp": 1745792919
    },
    {
        "content": "<blockquote>\n<p>If the official Zulip Chat Archive could be maintained again, LLMs would be able to see the correct Lean 4 training data. It would also make it easier for Lean learners to find information through Google search.</p>\n</blockquote>\n<p>It isnt our responsibility if ML engineers design wasteful and dumb models that require endless data to train.</p>",
        "id": 514708494,
        "sender_full_name": "Leni Aniva",
        "timestamp": 1745807392
    },
    {
        "content": "<p>Again, this is why I said \"coverage of training data\" instead of \"lack of training data\" before. We should measure the size of these data in percentages, not in GBs. If the data that human experts can see is missing for the model, then we cannot claim that the model design is flawed when evaluating. Unfortunately, this data gap may exist in many fields.</p>\n<p>It's like different children receive different educational environments, so we can't immediately claim that children who don't study well are dumb.</p>",
        "id": 514709580,
        "sender_full_name": "Deming Xu",
        "timestamp": 1745808110
    },
    {
        "content": "<p>There are large corpora of Lean 3 and 4 data on Github that LLM agents are \"free\" to scrape, and there is a public documentation page that describes their difference. Human experts can see and distinguish this. LLMs are a fundamentally flawed architecture, and can't do the same.</p>",
        "id": 514709975,
        "sender_full_name": "Leni Aniva",
        "timestamp": 1745808398
    },
    {
        "content": "<p>That is a great point, but now they can more or less write Lean4, right? And again I think you can also think of it this way: Suppose you took all the code and documentation for Lean3 and Lean4 on Github, and the chat data on Zulip Archive (which is mostly Lean3, several times larger than the Github code, more readable, closer to the \"chat\" format, and relatively much larger than the documentation), and shuffled it completely randomly. Then you gave the text to a human to read it <em>just once and out of order</em>, and then asked them to answer a user's Lean4 question. The human would probably just be very confused, but the language model would still be able to make up a decent answer even if it is in Lean3.</p>",
        "id": 514712221,
        "sender_full_name": "Deming Xu",
        "timestamp": 1745810128
    },
    {
        "content": "<p>They can write more of Lean 4 because more Lean 4 exist in their training set. That is orthogonal to my point that we're responsible for feeding data into these models. These language models are a double edged sword at best and having slop generating machines also is not a common good</p>\n<blockquote>\n<p>shuffled it completely randomly</p>\n</blockquote>\n<p>A human would not read these texts randomly. If an ML engineer decides to train an LLM in this manner, that is entirely on the engineer and their model.</p>\n<blockquote>\n<p>just once</p>\n</blockquote>\n<p>doubt</p>\n<blockquote>\n<p>very confused</p>\n</blockquote>\n<p>being able to admit incapability is a sign of intelligence, which LLMs seriously lack</p>\n<blockquote>\n<p>a decent answer</p>\n</blockquote>\n<p>Given recent slops posted on this zulip chat, the answers are not decent, but misleading</p>",
        "id": 514714179,
        "sender_full_name": "Leni Aniva",
        "timestamp": 1745811484
    },
    {
        "content": "<p>Yes, I think you are right that there is enough data to distinguish Lean 3/4, and you also mentioned the corresponding actual deficiencies of these models yourself, and that is a great point.</p>\n<p>Looking back, I think it is indeed not the responsibility of the Lean team to provide data. In fact, in the first place, the Lean team has no responsibility to help train models that are good at Lean at all. Unfortunately, I am also afraid that many ML engineers / researchers do not know or care a lot about the Lean capabilities of LLMs in details. I think training Lean models is just a research direction that people actively decide to spend time into, and it should not be a responsibility.</p>\n<p>What do you think about the evaluation on the MiniF2F benchmark? As far as I know, problems in MiniF2F are ultimately not based on college math, but closer to high school math knowledge, right? The proofs of these problems mainly require you to be familiar with <code>intro exact constructor cases by_cases use apply have let rfl rw simp field_simp ring norm_num linarith nlinarith omega calc</code>, as well as theorems about sin/cos/tan/exp/log, treatment of undefined points in divison/log/tan, summation formula theorems, and integer divisibility theorems. These should appear more frequently in Zulip's <code>new_memebers</code> channel than in the more advanced <code>Mathlib</code> source code, right? For myself, I learned some of them by looking at the examples on Zulip. Without Zulip, this task would be more difficult for me with only the documentation string, the official books, and some possibly outdated unofficial tutorials. I think the same is true for langauge models.</p>\n<p>You can certainly mitigate these problems with synthetic data, tree search, retrieval augmentation, and reinforcement learning (or you can hire people to collect a private dataset, or even try to train a non-language model from scratch). But I think the original intention of these techniques is to teach the model to learn new knowledge that explicitly requires pure exploration without prior examples, rather than to learn codified knowledge like how to use Lean. If the model is familiar with Lean, I think future LLM for Lean papers will be able to focus on the search for actual math ideas, rather than the search for some correct Lean code.</p>",
        "id": 514716925,
        "sender_full_name": "Deming Xu",
        "timestamp": 1745813306
    },
    {
        "content": "<p>One core issue I haven't seen focused on, is that people on this chat use their real names. If this was an anonymous forum it would have made a bit more sense. What if its fed into a larger one, and then you can just ask this LLM a specific question about your uncommon full-name -- and it has something to say cause of this forum.</p>\n<p>Companies like Meta at least mitigate that issue, you can't ask it about random private people that have an account with Meta.</p>\n<p>(I am aware it only shows names when tagged, apparently.)</p>",
        "id": 514720865,
        "sender_full_name": "Yan Yablonovskiy",
        "timestamp": 1745815960
    },
    {
        "content": "<p>I think they have personal information removal as a part of their training process. Privacy is of cource really important.</p>",
        "id": 514721205,
        "sender_full_name": "Deming Xu",
        "timestamp": 1745816180
    },
    {
        "content": "<p>I think if you really trained a language model on this chat with all full names, of course it would memorize facts about the people here, but moreover it would try really hard to mimic the language style associated with these names, which is also really weird. </p>\n<p>And I start to realize that posting almost permanent messages with real names on a public platform with a public HTML archive indexed by Google is itself pretty sensitive in the first place. (Maybe the Zulip API provides a way to help me clear all my messages?)</p>",
        "id": 514721448,
        "sender_full_name": "Deming Xu",
        "timestamp": 1745816363
    },
    {
        "content": "<p>However, these names will most likely harm the model performance by quite a lot, because the models will get distracted by a complicated learning goal that will not be useful in evaluation.</p>",
        "id": 514721759,
        "sender_full_name": "Deming Xu",
        "timestamp": 1745816535
    },
    {
        "content": "<p>So to train a good model, and of course also for privacy concerns, I think people will still try to filter out all names here. Another approach will be to summarize all Zulip topics with LLMs and extract the key points and code snippets to completely remove the personal language styles...</p>",
        "id": 514722228,
        "sender_full_name": "Deming Xu",
        "timestamp": 1745816845
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"740877\">Deming Xu</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Lean.20Zulip.20Chat.20Dataset/near/514721448\">said</a>:</p>\n<blockquote>\n<p>I think if you really trained a language model on this chat with all full names, of course it will memorize facts of the people here, but moreover it will try really hard to mimic the language style associated with these names, which is also really weird. </p>\n<p>And I start to realize that posting almost permanent messages with real names on a public platform with a public HTML archive with is itself pretty sensitive in the first place. (Maybe the Zulip API provides a way to help me clear all my messages?)</p>\n</blockquote>\n<p>If i google my full name + Zulip i get no hits, i don't think its indexed is it?</p>",
        "id": 514723550,
        "sender_full_name": "Yan Yablonovskiy",
        "timestamp": 1745817712
    },
    {
        "content": "<p>The archive (<a href=\"https://leanprover-community.github.io/archive/\">https://leanprover-community.github.io/archive/</a>) seems to be up to Dec 20 2023 currently, but Eric Wieser mentioned above that \"it is requiring a manual trigger by me to update it\". </p>\n<p>The first official release of Lean 4 seems to be <a href=\"https://leanprover-community.github.io/blog/posts/first-lean-release/\">2023-09-08</a>, which I think means the archive contains only 3 months of Lean 4 information.</p>",
        "id": 514723797,
        "sender_full_name": "Deming Xu",
        "timestamp": 1745817872
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"740877\">Deming Xu</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Lean.20Zulip.20Chat.20Dataset/near/514723797\">said</a>:</p>\n<blockquote>\n<p>The archive (<a href=\"https://leanprover-community.github.io/archive/\">https://leanprover-community.github.io/archive/</a>) seems to be up to Dec 20 2022 currently, but Eric Wieser mentioned above that \"it is requiring a manual trigger by me to update it\".</p>\n</blockquote>\n<p>Ah i see, yea that does seem to be indexed.</p>",
        "id": 514723839,
        "sender_full_name": "Yan Yablonovskiy",
        "timestamp": 1745817914
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"740877\">Deming Xu</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Lean.20Zulip.20Chat.20Dataset/near/514721448\">said</a>:</p>\n<blockquote>\n<p>And I start to realize that posting almost permanent messages with real names on a public platform with a public HTML archive indexed by Google is itself pretty sensitive in the first place. (Maybe the Zulip API provides a way to help me clear all my messages?)</p>\n</blockquote>\n<p>I can’t claim to have read this thread carefully, but it seems like there is emerging the question of the continued existence of the Zulip Chat Archive. The community should probably make a conscious decision about this rather than leaving it as it accidentally is.</p>",
        "id": 514806115,
        "sender_full_name": "A.",
        "timestamp": 1745844825
    },
    {
        "content": "<p>(deleted)</p>",
        "id": 514807459,
        "sender_full_name": "A.",
        "timestamp": 1745845176
    },
    {
        "content": "<p>I don’t think deleting the archive is an option. There are way too many design choices, explanations, development information about Mathlib that are only documented explained in Zulip conversations, and many PRs in the github repository link to conversations here. Deleting this would probably mean dealing a huge blow to overall maintainability, and make further development harder.<br>\n(if anything, this should question whether splitting critical development discussions from the where the development actually happen, i.e Github, is a good idea in the first place, but that is a different topic.)</p>",
        "id": 514809773,
        "sender_full_name": "Robin Carlier",
        "timestamp": 1745845745
    },
    {
        "content": "<p>(deleted)</p>",
        "id": 514812492,
        "sender_full_name": "A.",
        "timestamp": 1745846457
    },
    {
        "content": "<p>I read from your message that you would vote for deleting <a href=\"https://leanprover-community.github.io/archive/\">this archive</a>. I am saying that due to the fact that it contains a lot of development information for projects such as mathlib, having continued access to the content of it, even if it’s just as a backup, is critical.</p>",
        "id": 514815374,
        "sender_full_name": "Robin Carlier",
        "timestamp": 1745847136
    },
    {
        "content": "<p>A good compromise might be to add /archive into the robots.txt?</p>",
        "id": 514816136,
        "sender_full_name": "Simon Sorg",
        "timestamp": 1745847318
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"766274\">Simon Sorg</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Lean.20Zulip.20Chat.20Dataset/near/514816136\">said</a>:</p>\n<blockquote>\n<p>A good compromise might be to add /archive into the robots.txt?</p>\n</blockquote>\n<p>unfortunately many AI crawlers don't care about robots.txt. imo it should be guarded with anubis</p>",
        "id": 514824497,
        "sender_full_name": "Leni Aniva",
        "timestamp": 1745849304
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"740877\">Deming Xu</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Lean.20Zulip.20Chat.20Dataset/near/514716925\">said</a>:</p>\n<blockquote>\n<p>What do you think about the evaluation on the MiniF2F benchmark? As far as I know, problems in MiniF2F are ultimately not based on college math, but closer to high school math knowledge, right? The proofs of these problems mainly require you to be familiar with <code>intro exact constructor cases by_cases use apply have let rfl rw simp field_simp ring norm_num linarith nlinarith omega calc</code>, as well as theorems about sin/cos/tan/exp/log, treatment of undefined points in divison/log/tan, summation formula theorems, and integer divisibility theorems. These should appear more frequently in Zulip's <code>new_memebers</code> channel than in the more advanced <code>Mathlib</code> source code, right? For myself, I learned some of them by looking at the examples on Zulip. Without Zulip, this task would be more difficult for me with only the documentation string, the official books, and some possibly outdated unofficial tutorials. I think the same is true for langauge models.</p>\n<p>You can certainly mitigate these problems with synthetic data, tree search, retrieval augmentation, and reinforcement learning (or you can hire people to collect a private dataset, or even try to train a non-language model from scratch). But I think the original intention of these techniques is to teach the model to learn new knowledge that explicitly requires pure exploration without prior examples, rather than to learn codified knowledge like how to use Lean. If the model is familiar with Lean, I think future LLM for Lean papers will be able to focus on the search for actual math ideas, rather than the search for some correct Lean code.</p>\n</blockquote>\n<p>I think the \"evaluation\" for MiniF2F benchmark is a problematic proposition in its own. If a language model has seen solutions of these problems, even in terms of natural language, then you cannot evaluate them on the same problems. LLMs were often trained on huge corpus of natural language data including solutions to contest level math problems. LLM researchers routinely ignore this issue when they post performance metrics of their models. Our lab's director talked about encrypting data sets when we upload them online for this reason.</p>",
        "id": 514825894,
        "sender_full_name": "Leni Aniva",
        "timestamp": 1745849610
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"599027\">Leni Aniva</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Lean.20Zulip.20Chat.20Dataset/near/514824497\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"766274\">Simon Sorg</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Lean.20Zulip.20Chat.20Dataset/near/514816136\">said</a>:</p>\n<blockquote>\n<p>A good compromise might be to add /archive into the robots.txt?</p>\n</blockquote>\n<p>unfortunately many AI crawlers don't care about robots.txt. imo it should be guarded with anubis</p>\n</blockquote>\n<p>I personally am also in favour of using Nepenthes and/or friends to enforce this: well-behaving crawlers are not penalised. (But I realise this is more controversial.)</p>",
        "id": 514830648,
        "sender_full_name": "Michael Rothgang",
        "timestamp": 1745850775
    },
    {
        "content": "<p>The zulip archive goes back to when there was no public channels in Zulip. It is no longer playing any role.</p>",
        "id": 514843956,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1745854158
    },
    {
        "content": "<p>That's not true, it plays the role of making Zulip appear in Google searches</p>",
        "id": 514858974,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1745858421
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"599027\">Leni Aniva</span> has marked this topic as resolved.</p>",
        "id": 515568844,
        "sender_full_name": "Notification Bot",
        "timestamp": 1746128416
    }
]