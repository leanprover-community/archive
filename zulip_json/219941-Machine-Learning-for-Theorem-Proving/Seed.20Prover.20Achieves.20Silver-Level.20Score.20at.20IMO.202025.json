[
    {
        "content": "<p>Official score: 2/7/7/7/7/0<br>\nP2 is solved using subsystem Seed Geometry<br>\nAnnouncement: <a href=\"https://mp.weixin.qq.com/s/MWo8dIg4bqQXzB_W9UZ7Ow\">https://mp.weixin.qq.com/s/MWo8dIg4bqQXzB_W9UZ7Ow</a> (Chinese)<br>\nSolutions: <a href=\"https://github.com/ByteDance-Seed/Seed-Prover/tree/main/SeedProver/imo2025\">https://github.com/ByteDance-Seed/Seed-Prover/tree/main/SeedProver/imo2025</a></p>",
        "id": 530246952,
        "sender_full_name": "Junyan Xu",
        "timestamp": 1753233361
    },
    {
        "content": "<p>Congrats to <span class=\"user-mention\" data-user-id=\"481527\">@Huajian Xin</span> and the team</p>",
        "id": 530247240,
        "sender_full_name": "Junyan Xu",
        "timestamp": 1753233632
    },
    {
        "content": "<p>Link to announcement: <a class=\"stream-topic\" data-stream-id=\"113486\" href=\"/#narrow/channel/113486-announce/topic/Seed.20Prover.20Achieves.20Silver-Level.20Score.20at.20IMO.202025/with/530248002\">#announce &gt; Seed Prover Achieves Silver-Level Score at IMO 2025</a></p>",
        "id": 530248129,
        "sender_full_name": "Thomas Zhu",
        "timestamp": 1753234415
    },
    {
        "content": "<p>331 solved on PutnamBench, that's impressive! They have <a href=\"https://github.com/ByteDance-Seed/Seed-Prover/tree/main/SeedProver/PutnamBench\">posted</a> their solutions publicly though -- I had the impression that the PutnamBench prefer people not do this? cc <span class=\"user-mention\" data-user-id=\"644040\">@George Tsoukalas</span></p>",
        "id": 530250520,
        "sender_full_name": "Heather Macbeth",
        "timestamp": 1753236542
    },
    {
        "content": "<p>There also seem to be <code>apply?</code>s in a lot of the solutions, I wonder whether any of them exploit the bug DeepSeek found.</p>",
        "id": 530250660,
        "sender_full_name": "Heather Macbeth",
        "timestamp": 1753236680
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"260507\">Heather Macbeth</span> <a href=\"#narrow/stream/219941-Machine-Learning-for-Theorem-Proving/topic/ByteDance.20Seed.20Prover.20earned.20IMO.20silver.20using.20Lean/near/530250520\">said</a>:</p>\n<blockquote>\n<p>331 solved on PutnamBench, that's impressive! They have <a href=\"https://github.com/ByteDance-Seed/Seed-Prover/tree/main/SeedProver/PutnamBench\">posted</a> their solutions publicly though -- I had the impression that the PutnamBench prefer people not do this? cc <span class=\"user-mention silent\" data-user-id=\"644040\">George Tsoukalas</span></p>\n</blockquote>\n<p>Hi <span class=\"user-mention\" data-user-id=\"260507\">@Heather Macbeth</span> , I will relay this to the repo manager. Thank you!</p>",
        "id": 530250704,
        "sender_full_name": "Thomas Zhu",
        "timestamp": 1753236732
    },
    {
        "content": "<p><em>Retracted.</em></p>",
        "id": 530250767,
        "sender_full_name": "Justin Asher",
        "timestamp": 1753236796
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"260507\">Heather Macbeth</span> <a href=\"#narrow/stream/219941-Machine-Learning-for-Theorem-Proving/topic/ByteDance.20Seed.20Prover.20earned.20IMO.20silver.20using.20Lean/near/530250660\">said</a>:</p>\n<blockquote>\n<p>There also seem to be <code>apply?</code>s in a lot of the solutions, I wonder whether any of them exploit the bug DeepSeek found.</p>\n</blockquote>\n<p>We are aware of the bug, and I can confirm it is not exploited.</p>",
        "id": 530250796,
        "sender_full_name": "Thomas Zhu",
        "timestamp": 1753236819
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"780541\">@Justin Asher</span> Can you point to the soundness issues of Lean REPL thread (if there is one) or make a new thread about it? (Edit: I see you redacted your statement.  Should I delete this?)</p>",
        "id": 530250898,
        "sender_full_name": "Jason Rute",
        "timestamp": 1753236939
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"115715\">@Jason Rute</span> (Leni said this, but Auguste said they were patched. I do not know too much. I figured this discussion is off-topic.)</p>",
        "id": 530250981,
        "sender_full_name": "Justin Asher",
        "timestamp": 1753237011
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"115715\">Jason Rute</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/ByteDance.20Seed.20Prover.20earned.20IMO.20silver.20using.20Lean/near/530250898\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"780541\">Justin Asher</span> Can you point to the soundness issues of Lean REPL thread (if there is one) or make a new thread about it?</p>\n</blockquote>\n<p>We may release our Lean verification infra later :)</p>",
        "id": 530250990,
        "sender_full_name": "Huajian Xin",
        "timestamp": 1753237024
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"481527\">@Huajian Xin</span> Would be super useful! Seems like everyone has their own…</p>",
        "id": 530251021,
        "sender_full_name": "Justin Asher",
        "timestamp": 1753237054
    },
    {
        "content": "<p>As for the repo, at least zip them.  I appreciate the desire to have others check that they are correct, but too many people train on github projects without thought.</p>",
        "id": 530251072,
        "sender_full_name": "Jason Rute",
        "timestamp": 1753237095
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"115715\">Jason Rute</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Seed.20Prover.20Achieves.20Silver-Level.20Score.20at.20IMO.202025/near/530251072\">said</a>:</p>\n<blockquote>\n<p>As for the repo, at least zip them.  I appreciate the desire to have others check that they are correct, but too many people train on github projects without thought.</p>\n</blockquote>\n<p>Sure, we are fixing this issue</p>",
        "id": 530251197,
        "sender_full_name": "Huajian Xin",
        "timestamp": 1753237227
    },
    {
        "content": "<p>We do not use REPL for checking solutions, and we use a <code>#print axioms</code> check at the end. We are using Lean v4.14.0, and AFAIK DeepSeek's bug does not work at this version. (FYI: I discovered the mechanism behind DeepSeek's apply? bug with the community <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/DeepSeek-Prover.20V2\">here</a>; I now work on the verification infrastructure and inference-time strategies at ByteDance Seed and also checked a subset of the solutions manually).</p>",
        "id": 530251340,
        "sender_full_name": "Thomas Zhu",
        "timestamp": 1753237390
    },
    {
        "content": "<p>Here is an English translation of the announcement that was originally in Chinese generated by Gemini 2.5 Pro. My apologies if anything is mistranslated.</p>\n<p><a href=\"/user_uploads/3121/bJEesrE754Lfs3PaUv4-75dJ/Seed_Prover_Announcement.pdf\">Seed_Prover_Announcement.pdf</a></p>",
        "id": 530251624,
        "sender_full_name": "Justin Asher",
        "timestamp": 1753237635
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"224323\">@Junyan Xu</span> I have taken the liberty to change the title of the topic to \"Seed Prover Achieves Silver-Level Score at IMO 2025\", because we haven't actually achieved the silver medal! The latter requires being a human <span aria-label=\"slight smile\" class=\"emoji emoji-1f642\" role=\"img\" title=\"slight smile\">:slight_smile:</span></p>",
        "id": 530251780,
        "sender_full_name": "Thomas Zhu",
        "timestamp": 1753237769
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"780541\">Justin Asher</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Seed.20Prover.20Achieves.20Silver-Level.20Score.20at.20IMO.202025/near/530251624\">said</a>:</p>\n<blockquote>\n<p>Here is an English translation of the announcement that was originally in Chinese generated by Gemini 2.5 Pro. My apologies if anything is mistranslated.</p>\n<p><a href=\"/user_uploads/3121/Ri4wAHvcKLTGa_ivTMUQUPTs/Seed_Prover_Announcement.pdf\">Seed_Prover_Announcement.pdf</a></p>\n</blockquote>\n<p>Thank you! As for the text in the table, I can also show you the English version for reference <span aria-label=\"slight smile\" class=\"emoji emoji-1f642\" role=\"img\" title=\"slight smile\">:slight_smile:</span> :</p>\n<p><a href=\"/user_uploads/3121/D0n91w_rrYQJC50Z97XvoJxf/image.png\">image.png</a></p>\n<div class=\"message_inline_image\"><a href=\"/user_uploads/3121/D0n91w_rrYQJC50Z97XvoJxf/image.png\" title=\"image.png\"><img data-original-content-type=\"image/png\" data-original-dimensions=\"1280x601\" src=\"/user_uploads/thumbnail/3121/D0n91w_rrYQJC50Z97XvoJxf/image.png/840x560.webp\"></a></div>",
        "id": 530251842,
        "sender_full_name": "Huajian Xin",
        "timestamp": 1753237825
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"481527\">@Huajian Xin</span> Thanks! Fixed it.</p>",
        "id": 530252249,
        "sender_full_name": "Justin Asher",
        "timestamp": 1753238169
    },
    {
        "content": "<p>The PutnamBench result is super exciting. <a href=\"https://openreview.net/pdf?id=YXnwlZe0yf\">Putnam-AXIOM</a> already demonstrated that LLMs are capable of solving a relatively similar percentage of Putnam problems. Now we see that, with a sufficiently strong Lean programming system, we can achieve this score in practice. Awesome!</p>\n<p>It also seems like these LLMs love using \"have\" expressions. I think this is due to the way they are pretrained / how they interact with the Lean environment. You can see a somewhat similar patten in <a href=\"https://github.com/morph-labs/lean-abc-true-almost-always/blob/main/ABCTrueAlmostAlways/ABCTrueAlmostAlways.lean\">Morph Labs' autoformalization</a>. I do not think this is optimal (Mathlib is certainly not written this way).</p>",
        "id": 530253146,
        "sender_full_name": "Justin Asher",
        "timestamp": 1753238960
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"780541\">Justin Asher</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Seed.20Prover.20Achieves.20Silver-Level.20Score.20at.20IMO.202025/near/530253146\">said</a>:</p>\n<blockquote>\n<p>The PutnamBench result is super exciting. <a href=\"https://openreview.net/pdf?id=YXnwlZe0yf\">Putnam-AXIOM</a> already demonstrated that LLMs are capable of solving a relatively similar percentage of Putnam problems. Now we see that, with a sufficiently strong Lean programming system, we can achieve this score in practice. Awesome!</p>\n<p>It also seems like these LLMs love using \"have\" expressions. I think this is due to the way they are pretrained / how they interact with the Lean environment. You can see a somewhat similar patten in <a href=\"https://github.com/morph-labs/lean-abc-true-almost-always/blob/main/ABCTrueAlmostAlways/ABCTrueAlmostAlways.lean\">Morph Labs' autoformalization</a>. I do not think this is optimal (Mathlib is certainly not written this way).</p>\n</blockquote>\n<p>I think LLMs prefer using have is mainly because it can show what we need to prove now as a hint.</p>",
        "id": 530256898,
        "sender_full_name": "Zheng Yuan",
        "timestamp": 1753242334
    },
    {
        "content": "<p>Do you think the RL system is producing all the \"have\" expressions, since you are using compiler feedback? In particular, from the translation:</p>\n<blockquote>\n<p>Our team discovered that by using feedback from the Lean compiler combined with the model’s summarization capabilities to iteratively refine proofs, we could overcome the token budget limitations of a single inference pass and significantly enhance proving capabilities.</p>\n</blockquote>\n<p>It seems like this would incentivize the model to break the proof into as small of steps as possible, so that the LLM can get feedback on each little step. I think this fairly typical and expected as we go</p>\n<p>entire proof -&gt; proof with retries -&gt; diff requests </p>\n<p>Setting up the training process to provide real-time LSP feedback, and letting the model \"type\" while looking at the current LSP just like we do, would presumably resolve this. Albeit, I do not know how much this would slow down the underlying token-generation speed.</p>",
        "id": 530257043,
        "sender_full_name": "Justin Asher",
        "timestamp": 1753242486
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"686407\">Zheng Yuan</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Seed.20Prover.20Achieves.20Silver-Level.20Score.20at.20IMO.202025/near/530256898\">said</a>:</p>\n<blockquote>\n<p>I think LLMs prefer using have is mainly because it can show what we need to prove now as a hint.</p>\n</blockquote>\n<p>This seems right, when considering what information the diagnostics would provide.</p>",
        "id": 530257165,
        "sender_full_name": "Justin Asher",
        "timestamp": 1753242588
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"780541\">Justin Asher</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Seed.20Prover.20Achieves.20Silver-Level.20Score.20at.20IMO.202025/near/530257043\">said</a>:</p>\n<blockquote>\n<p>Do you think the RL system is producing all the \"have\" expressions, since you are using compiler feedback? In particular, from the translation:</p>\n<blockquote>\n<p>Our team discovered that by using feedback from the Lean compiler combined with the model’s summarization capabilities to iteratively refine proofs, we could overcome the token budget limitations of a single inference pass and significantly enhance proving capabilities.</p>\n</blockquote>\n<p>It seems like this would incentivize the model to break the proof into as small of steps as possible, so that the LLM can get feedback on each little step. I think this fairly typical and expected as we go</p>\n<p>entire proof -&gt; proof with retries -&gt; diff requests </p>\n<p>Setting up the training process to provide real-time LSP feedback, and letting the model \"type\" while looking at the current LSP just like we do, would presumably resolve this. Albeit, I do not know how much this would slow down the underlying token-generation speed.</p>\n</blockquote>\n<p>An example is <a href=\"https://github.com/xqyww123/Isa-Proof-Shell\">Isa-Proof-Shell</a>, in which there exists only statement declarations and all supporting proofs are generated automatically.</p>",
        "id": 530257501,
        "sender_full_name": "Huajian Xin",
        "timestamp": 1753242913
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"780541\">Justin Asher</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Seed.20Prover.20Achieves.20Silver-Level.20Score.20at.20IMO.202025/near/530257043\">said</a>:</p>\n<blockquote>\n<p>Albeit, I do not know how much this would slow down the underlying token-generation speed.</p>\n</blockquote>\n<p>This should not be a problem with efficient LLM cache management, I believe? Correct me if I am wrong, because I have not written much code to manage the cache myself before.</p>",
        "id": 530258596,
        "sender_full_name": "Justin Asher",
        "timestamp": 1753243850
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"481527\">@Huajian Xin</span> <span class=\"user-mention\" data-user-id=\"631691\">@Thomas Zhu</span> Are you planning to release the tech report and the model?</p>",
        "id": 530259230,
        "sender_full_name": "Opt",
        "timestamp": 1753244441
    },
    {
        "content": "<p>I feel it's not RL causing the have statements, but rather the SFT stage before RL</p>",
        "id": 530259723,
        "sender_full_name": "(deleted)",
        "timestamp": 1753244841
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"511228\">Huỳnh Trần Khanh</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Seed.20Prover.20Achieves.20Silver-Level.20Score.20at.20IMO.202025/near/530259723\">said</a>:</p>\n<blockquote>\n<p>but rather the SFT stage before RL</p>\n</blockquote>\n<p>Would be happy to hear more on why you say this?</p>",
        "id": 530259789,
        "sender_full_name": "Justin Asher",
        "timestamp": 1753244885
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"900177\">Opt</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Seed.20Prover.20Achieves.20Silver-Level.20Score.20at.20IMO.202025/near/530259230\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"481527\">Huajian Xin</span> <span class=\"user-mention silent\" data-user-id=\"631691\">Thomas Zhu</span> Are you planning to release the tech report and the model?</p>\n</blockquote>\n<p>Tech report is on the way. No plan to release model now.</p>",
        "id": 530260104,
        "sender_full_name": "Zheng Yuan",
        "timestamp": 1753245072
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"780541\">Justin Asher</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Seed.20Prover.20Achieves.20Silver-Level.20Score.20at.20IMO.202025/near/530259789\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"511228\">Huỳnh Trần Khanh</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Seed.20Prover.20Achieves.20Silver-Level.20Score.20at.20IMO.202025/near/530259723\">said</a>:</p>\n<blockquote>\n<p>but rather the SFT stage before RL</p>\n</blockquote>\n<p>Would be happy to hear more on why you say this?</p>\n</blockquote>\n<p>For Kimina Prover, the have statements are already in the chain of thought, not just in the final proof.</p>\n<p><a href=\"https://github.com/MoonshotAI/Kimina-Prover-Preview/tree/master\">https://github.com/MoonshotAI/Kimina-Prover-Preview/tree/master</a></p>\n<blockquote>\n<p>Distinct Reasoning Style: We carefully design a reasoning style that we call Formal Reasoning Pattern that bridges the gap between formal verification and informal mathematical intuition.</p>\n</blockquote>\n<p>Quite obvious that this is intentional.</p>",
        "id": 530260467,
        "sender_full_name": "(deleted)",
        "timestamp": 1753245404
    },
    {
        "content": "<p><a href=\"/user_uploads/3121/B0FN5e9DoHEr135pkcjQPKuJ/17532455506305169576064469475789.png\">17532455506305169576064469475789.png</a></p>\n<div class=\"message_inline_image\"><a href=\"/user_uploads/3121/B0FN5e9DoHEr135pkcjQPKuJ/17532455506305169576064469475789.png\" title=\"17532455506305169576064469475789.png\"><img data-original-content-type=\"image/png\" data-original-dimensions=\"716x1314\" src=\"/user_uploads/thumbnail/3121/B0FN5e9DoHEr135pkcjQPKuJ/17532455506305169576064469475789.png/840x560.webp\"></a></div>",
        "id": 530260648,
        "sender_full_name": "(deleted)",
        "timestamp": 1753245558
    },
    {
        "content": "<p>Each reasoning block is a have statement.</p>",
        "id": 530260693,
        "sender_full_name": "(deleted)",
        "timestamp": 1753245599
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"511228\">@Huỳnh Trần Khanh</span> Thanks! Fantastic reference w.r.t. the Kimina paper. Still think direct LSP access and more integrated systems would be helpful.</p>",
        "id": 530261369,
        "sender_full_name": "Justin Asher",
        "timestamp": 1753246114
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"511228\">Huỳnh Trần Khanh</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Seed.20Prover.20Achieves.20Silver-Level.20Score.20at.20IMO.202025/near/530260467\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"780541\">Justin Asher</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Seed.20Prover.20Achieves.20Silver-Level.20Score.20at.20IMO.202025/near/530259789\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"511228\">Huỳnh Trần Khanh</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Seed.20Prover.20Achieves.20Silver-Level.20Score.20at.20IMO.202025/near/530259723\">said</a>:</p>\n<blockquote>\n<p>but rather the SFT stage before RL</p>\n</blockquote>\n<p>Would be happy to hear more on why you say this?</p>\n</blockquote>\n<p>For Kimina Prover, the have statements are already in the chain of thought, not just in the final proof.</p>\n<p><a href=\"https://github.com/MoonshotAI/Kimina-Prover-Preview/tree/master\">https://github.com/MoonshotAI/Kimina-Prover-Preview/tree/master</a></p>\n<blockquote>\n<p>Distinct Reasoning Style: We carefully design a reasoning style that we call Formal Reasoning Pattern that bridges the gap between formal verification and informal mathematical intuition.</p>\n</blockquote>\n<p>Quite obvious that this is intentional.</p>\n</blockquote>\n<p>Interesting. Well it does seem to have the side effect of perhaps allowing the model to decompose the proofs in a nice manner. The source of the SFT data is Claude which the Kimi team instructed to align the informal and formal proofs into their format. Maybe then the formal proofs they used had a lot of have statements?</p>",
        "id": 530262105,
        "sender_full_name": "Opt",
        "timestamp": 1753246687
    },
    {
        "content": "<p>It must be some sort of synthetic data, the data we provided isn't that neatly decomposed into have statements</p>",
        "id": 530262292,
        "sender_full_name": "(deleted)",
        "timestamp": 1753246825
    },
    {
        "content": "<p>really impressive! will wait for tech report but is it following <a href=\"https://arxiv.org/pdf/2502.03438\">https://arxiv.org/pdf/2502.03438</a> and calling some policy LLM to generate each tactic one at a time? and doing some search over tactics? if so what does the pass@ number mean? like parallel instances of search? (this doesn't quite make sense to me bc wouldn't it just overlap in its work) or is it calling LLM in a autoregressive entire proof generation and then you do pass@?</p>\n<p>would be interesting to see like model size and some numbers on compute needed :) I know I'll never get them from GDM and OAI so here's hoping for Bytedance!</p>",
        "id": 530262811,
        "sender_full_name": "Andy Jiang",
        "timestamp": 1753247073
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"662620\">Andy Jiang</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Seed.20Prover.20Achieves.20Silver-Level.20Score.20at.20IMO.202025/near/530262811\">said</a>:</p>\n<blockquote>\n<p>really impressive! will wait for tech report but is it following <a href=\"https://arxiv.org/pdf/2502.03438\">https://arxiv.org/pdf/2502.03438</a> and calling some policy LLM to generate each tactic one at a time? and doing some search over tactics? if so what does the pass@ number mean? like parallel instances of search? (this doesn't quite make sense to me bc wouldn't it just overlap in its work) or is it calling LLM in a autoregressive entire proof generation and then you do pass@?</p>\n<p>would be interesting to see like model size and some numbers on compute needed :) I know I'll never get them from GDM and OAI so here's hoping for Bytedance!</p>\n</blockquote>\n<p>Our team is different from BFS-prover. We will release a tech report with some details we can say.</p>",
        "id": 530262997,
        "sender_full_name": "Zheng Yuan",
        "timestamp": 1753247165
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"511228\">Huỳnh Trần Khanh</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Seed.20Prover.20Achieves.20Silver-Level.20Score.20at.20IMO.202025/near/530262292\">said</a>:</p>\n<blockquote>\n<p>It must be some sort of synthetic data, the data we provided isn't that neatly decomposed into have statements</p>\n</blockquote>\n<p>Not sure I follow. If it's the SFT stage then it must be the data you gave right? Or do you mean you're building off a model that might have this in their SFT?</p>",
        "id": 530263130,
        "sender_full_name": "Opt",
        "timestamp": 1753247256
    },
    {
        "content": "<p>OK so the thing is it is pure speculation based on what we were told... and what the paper says. The Kimina prover team made us prove a lot of theorems. But our proofs are very messy. They are not clean. And they don't have that many have statements. Initially they wanted our proofs to be clean and well commented, but then as the project progresses they practically just let us do anything as long as the proof compiles. So maybe our proofs are fed into the model to teach it reasoning patterns, but this alone doesn't explain the abundance of have statements.</p>\n<p>At the same time, the abundance of <code>have</code> statements is not emergent behavior. There are many of these statements in the chain of thought, and the chain of thought is explicitly engineered to have these have statements. They might use something else to train the model to create this chain of thought. The paper says Claude is used, but the paper might not tell the full story.</p>",
        "id": 530263631,
        "sender_full_name": "(deleted)",
        "timestamp": 1753247665
    },
    {
        "content": "<p>So I'm just a lowly data annotator and I have no say over how the model is trained. Well paid, but still.</p>",
        "id": 530263663,
        "sender_full_name": "(deleted)",
        "timestamp": 1753247694
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"511228\">Huỳnh Trần Khanh</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Seed.20Prover.20Achieves.20Silver-Level.20Score.20at.20IMO.202025/near/530263631\">said</a>:</p>\n<blockquote>\n<p>OK so the thing is it is pure speculation based on what we were told... and what the paper says. The Kimina prover team made us prove a lot of theorems. But our proofs are very messy. They are not clean. And they don't have that many have statements. Initially they wanted our proofs to be clean and well commented, but then as the project progresses they practically just let us do anything as long as the proof compiles. So maybe our proofs are fed into the model to teach it reasoning patterns, but this alone doesn't explain the abundance of have statements.</p>\n<p>At the same time, the abundance of <code>have</code> statements is not emergent behavior. There are many of these statements in the chain of thought, and the chain of thought is explicitly engineered to have these have statements. They might use something else to train the model to create this chain of thought. The paper says Claude is used, but the paper might not tell the full story.</p>\n</blockquote>\n<p>Thanks a lot for the context!</p>",
        "id": 530263792,
        "sender_full_name": "Opt",
        "timestamp": 1753247789
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"115715\">Jason Rute</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Seed.20Prover.20Achieves.20Silver-Level.20Score.20at.20IMO.202025/near/530251072\">said</a>:</p>\n<blockquote>\n<p>As for the repo, at least zip them.  I appreciate the desire to have others check that they are correct, but too many people train on github projects without thought.</p>\n</blockquote>\n<p>We have zipped the results and deleted the commit history on GitHub, and removed the PutnamBench results. Thank you for the scrutiny, we appreciate it very much!</p>",
        "id": 530267352,
        "sender_full_name": "Thomas Zhu",
        "timestamp": 1753250497
    },
    {
        "content": "<p>Thanks Thomas! If you would like to have these results added to the leaderboard, please send the zipped proofs to me at <code>george.tsoukalas@utexas.edu</code> so I can confirm the result.</p>",
        "id": 530278962,
        "sender_full_name": "George Tsoukalas",
        "timestamp": 1753256227
    },
    {
        "content": "<p>Very impressive! I wonder if you plan to try your model on DeepMind's <a href=\"https://github.com/google-deepmind/formal-conjectures\">formal-conjectures</a> repo. Maybe your model will manage to solve an open problem there <span aria-label=\"eyes\" class=\"emoji emoji-1f440\" role=\"img\" title=\"eyes\">:eyes:</span></p>",
        "id": 530293327,
        "sender_full_name": "Auguste Poiroux",
        "timestamp": 1753260814
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"321854\">Auguste Poiroux</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Seed.20Prover.20Achieves.20Silver-Level.20Score.20at.20IMO.202025/near/530293327\">said</a>:</p>\n<blockquote>\n<p>Very impressive! I wonder if you plan to try your model on DeepMind's <a href=\"https://github.com/google-deepmind/formal-conjectures\">formal-conjectures</a> repo. Maybe your model will manage to solve an open problem there <span aria-label=\"eyes\" class=\"emoji emoji-1f440\" role=\"img\" title=\"eyes\">:eyes:</span></p>\n</blockquote>\n<p>This is our next step.</p>",
        "id": 530294072,
        "sender_full_name": "Zheng Yuan",
        "timestamp": 1753261046
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"631691\">Thomas Zhu</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Seed.20Prover.20Achieves.20Silver-Level.20Score.20at.20IMO.202025/near/530251780\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"224323\">Junyan Xu</span> I have taken the liberty to change the title of the topic to \"Seed Prover Achieves Silver-Level Score at IMO 2025\", because we haven't actually achieved the silver medal! The latter requires being a human <span aria-label=\"slight smile\" class=\"emoji emoji-1f642\" role=\"img\" title=\"slight smile\">:slight_smile:</span></p>\n</blockquote>\n<p>This is a very impressive achievement!<br>\nOne nitpick: am I correct that within the official time limit (2 * 4.5 hours), Seed Prover only scores 7 points, since all problems other than problem 2 took a day or more to complete?</p>",
        "id": 530296080,
        "sender_full_name": "Floris van Doorn",
        "timestamp": 1753261507
    },
    {
        "content": "<p>Also, are there any plans to open-source the model/code? Maybe I missed the info</p>",
        "id": 530298650,
        "sender_full_name": "Auguste Poiroux",
        "timestamp": 1753262250
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"111080\">Floris van Doorn</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Seed.20Prover.20Achieves.20Silver-Level.20Score.20at.20IMO.202025/near/530296080\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"631691\">Thomas Zhu</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Seed.20Prover.20Achieves.20Silver-Level.20Score.20at.20IMO.202025/near/530251780\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"224323\">Junyan Xu</span> I have taken the liberty to change the title of the topic to \"Seed Prover Achieves Silver-Level Score at IMO 2025\", because we haven't actually achieved the silver medal! The latter requires being a human <span aria-label=\"slight smile\" class=\"emoji emoji-1f642\" role=\"img\" title=\"slight smile\">:slight_smile:</span></p>\n</blockquote>\n<p>This is a very impressive achievement!<br>\nOne nitpick: am I correct that within the official time limit (2 * 4.5 hours), Seed Prover only scores 7 points, since all problems other than problem 2 took a day or more to complete?</p>\n</blockquote>\n<p>Within 4.5 hours, many useful lemmas have been proved. It is hard to say how many score it can obtain.</p>",
        "id": 530299739,
        "sender_full_name": "Zheng Yuan",
        "timestamp": 1753262643
    },
    {
        "content": "<p>It's stated (in the English-translated announcement) that the problem statements were first formalized by humans. (a) Can we see the statements (including P6 if you prepared one of those) in the form in which they were presented to the AI (including in particular how \"determine\" problems were represented)? (b) Did you coordinate with any other AIs starting with human-prepared Lean statements to ensure that a single common version of the problems was used? (c) Was there a particular reason for preparing your own Lean statements rather than having the IMO provide them?</p>",
        "id": 530310944,
        "sender_full_name": "Joseph Myers",
        "timestamp": 1753266289
    },
    {
        "content": "<p>As of the start of the IMO, Ivan (Chief Coordinator) didn't know whether they might want me to provide Lean versions for use by AIs working with Lean, but it was concluded within a few days that all the AI developers working with the IMO would just take the informal statements from the IMO and start from there. (I was going to prepare Lean statements anyway regardless of whether they had been requested. The possibility of a request for officially provided statements was why I made sure the statements worked with Lean and mathlib v4.21.0 not just a more recent version. General principles that <em>useful</em> AIs for mathematics in Lean need to keep up with mathlib meant I wasn't concerned with whether statements would work with anything older than the most recent tagged release.)</p>",
        "id": 530312076,
        "sender_full_name": "Joseph Myers",
        "timestamp": 1753266692
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"266253\">Joseph Myers</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Seed.20Prover.20Achieves.20Silver-Level.20Score.20at.20IMO.202025/near/530310944\">said</a>:</p>\n<blockquote>\n<p>It's stated (in the English-translated announcement) that the problem statements were first formalized by humans. (a) Can we see the statements (including P6 if you prepared one of those) in the form in which they were presented to the AI (including in particular how \"determine\" problems were represented)? (b) Did you coordinate with any other AIs starting with human-prepared Lean statements to ensure that a single common version of the problems was used? (c) Was there a particular reason for preparing your own Lean statements rather than having the IMO provide them?</p>\n</blockquote>\n<p>(a) We first prompt Seed-1.6 (i.e. Bytedance's flagship reasoning models to obtain the answer) and use this answer to formalize the problem by human. (b) No, we are not coordinate with any other AI companies. Actually, we have no idea who is joining the competition and who is going to use LEAN. (c) IMO doesn't provide formalize version to us. They only provide a English version pdf with a latex file each day.</p>",
        "id": 530317196,
        "sender_full_name": "Zheng Yuan",
        "timestamp": 1753268696
    },
    {
        "content": "<p>It seems increasingly clear to me that secrecy has impaired the process of evaluating different AIs on IMO 2025 problems. We have one company offered a Lean version that they declined because of not using Lean, and another using Lean that could have been provided with a Lean version by the IMO but wasn't. Even at the start of the IMO, the Chief Coordinator had very limited information about what the evaluation process for AIs might look like, and detailed arrangements evolved during the IMO. Although I'd expressed my willingness to prepare Lean versions, there was no actual suggestion from the IMO to me that such a thing would be of use until after the IMO started (meaning mathlib doesn't have all the geometrical definitions that could potentially have been required - a lot more notice would have been needed to ensure all that API was filled out in advance).</p>\n<p>A better process would have involved all concerned parties discussing things in a public forum starting at least several months ahead of the IMO, with all interested AI developers giving enough information about the form of input and output used by their AIs that we could tell whether an IMO-provided Lean version would make sense or not (and if an IMO-provided Lean version made sense on that basis, it would then have been possible to arrange for more than one person to be present at the IMO to prepare and check that version).</p>",
        "id": 530334400,
        "sender_full_name": "Joseph Myers",
        "timestamp": 1753274321
    },
    {
        "content": "<p>Organization of AI for the IMO or even the Putnam (since that is next) is an interesting and important topic, but should probably be its own thread.</p>",
        "id": 530337557,
        "sender_full_name": "Jason Rute",
        "timestamp": 1753275290
    },
    {
        "content": "<p>And I'm treating all claims of AI solving the IMO with skepticism.</p>",
        "id": 530338736,
        "sender_full_name": "(deleted)",
        "timestamp": 1753275640
    },
    {
        "content": "<p>Did you also find verbatim copies of some code you wrote yourself in their repo?</p>",
        "id": 530376982,
        "sender_full_name": "Martin Dvořák",
        "timestamp": 1753285121
    },
    {
        "content": "<p>But back to the topic; how can I compile <code>p1.lean</code> for example? I cannot find any lakefile.</p>",
        "id": 530378955,
        "sender_full_name": "Martin Dvořák",
        "timestamp": 1753285533
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"417654\">Martin Dvořák</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Seed.20Prover.20Achieves.20Silver-Level.20Score.20at.20IMO.202025/near/530378955\">said</a>:</p>\n<blockquote>\n<p>But back to the topic; how can I compile <code>p1.lean</code> for example? I cannot find any lakefile.</p>\n</blockquote>\n<p>We use Lean v4.14.0, and Mathlib v4.14.0 as a dependency.</p>",
        "id": 530397163,
        "sender_full_name": "Thomas Zhu",
        "timestamp": 1753291087
    },
    {
        "content": "<p>Should I create a new project on Lean v4.14.0 and add <code>p1.lean</code> as the only file? Is this the intended way your solutions should be browsed?</p>",
        "id": 530397457,
        "sender_full_name": "Martin Dvořák",
        "timestamp": 1753291184
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"417654\">@Martin Dvořák</span> currently that is the intended way they should be browsed. We are working on a web-based interactive view of our solutions.</p>",
        "id": 530398346,
        "sender_full_name": "Thomas Zhu",
        "timestamp": 1753291492
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"115715\">Jason Rute</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Seed.20Prover.20Achieves.20Silver-Level.20Score.20at.20IMO.202025/near/530337557\">said</a>:</p>\n<blockquote>\n<p>Organization of AI for the IMO or even the Putnam (since that is next) is an interesting and important topic, but should probably be its own thread.</p>\n</blockquote>\n<p>I wonder whether the upshot of the events of this year is that the tech companies now will lose interest in future IMO participation completely because \"IMO gold was achieved in 2025\" (and all the subtleties around this claim will be forgotten). Perhaps potential investors in tech companies will find it hard to understand why \"IMO gold achieved in 2026\" is interesting.</p>",
        "id": 530398885,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1753291680
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"110038\">@Kevin Buzzard</span> Yep, was thinking about this. Now, solving an open conjecture is the new benchmark.</p>",
        "id": 530400454,
        "sender_full_name": "Justin Asher",
        "timestamp": 1753292249
    },
    {
        "content": "<p>Probably will happen before the end of the year...</p>",
        "id": 530400925,
        "sender_full_name": "Justin Asher",
        "timestamp": 1753292433
    },
    {
        "content": "<p>It's easy to solve an \"open conjecture\" -- just make up a boring problem which is easy but has never been asked before. AI solved the Robbins conjecture (<a href=\"https://xenaproject.wordpress.com/2019/07/06/a-computer-generated-proof-that-nobody-understands/\">https://xenaproject.wordpress.com/2019/07/06/a-computer-generated-proof-that-nobody-understands/</a>) which was open for decades but it's not clear that anyone was working on it. What's hard is to solve an open conjecture which mathematicians would generally agree was interesting and difficult, and that smart humans had tried and failed to solve. I am not sure that this will happen within the next 5 years, let alone before the end of this year.</p>",
        "id": 530403805,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1753293534
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"110038\">@Kevin Buzzard</span> I doubt that big AI labs are as focused on “what investors think” as you think they are. Especially under the US model shareholders are quite weak because of how fragmented they are. This in practice leaves quite a lot of power in the hands of the CEO (the board can only really hire and fire the CEO, in practice they can do little else). And if the gossips about Demis Hassabis being groomed for the next CEO of Google are true, this should give even more wind into the sails of Google Deep Mind. So they should be able to get a lot done. I hope this will include maths, although it does seem like the Lean effort in particular is no longer the core focus.</p>\n<p>But your/Justin’s conclusion seems correct. Shockingly it does seem like the IMO got nearly saturated as a benchmark. It will have to now be open conjectures (as formidable a challenge as this sounds).</p>",
        "id": 530404168,
        "sender_full_name": "Adam Kurkiewicz",
        "timestamp": 1753293646
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110038\">Kevin Buzzard</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Seed.20Prover.20Achieves.20Silver-Level.20Score.20at.20IMO.202025/near/530403805\">said</a>:</p>\n<blockquote>\n<p>just make up a boring problem which is easy but has never been asked before.</p>\n</blockquote>\n<p>I mean a sufficiently difficult conjecture that would impress mathematicians. Of course, an REU problem is not going to impress. The DeepThink solutions show that the models can prove relatively difficult individual statements. Putting a model like this into an agentic framework where they can work on a paper over the course of many days would likely produce good results. I can write an open source framework for this if people are interested.</p>",
        "id": 530406088,
        "sender_full_name": "Justin Asher",
        "timestamp": 1753294303
    },
    {
        "content": "<p>I agree with Kevin's <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Blind.20Speculation.20about.20IMO.202025/near/529580216\">message</a>: It is unclear whether AIs that excel at IMO can transfer to important open problems where hard-to-find approaches, vast knowledge of previous work, and ability beyond proving a single, isolated, fixed theorem are called for. At ByteDance, we also tried to evaluate non-high-school-math performance by evaluating on PutnamBench and miniCTX. The 80% score on miniCTX means that a random theorem taken from an open source Lean repo has a 80% chance of being solved in our lightweight setting. However, this ability is still minuscule compared to true research math ability; I think important open questions will be the ultimate benchmark!</p>",
        "id": 530406834,
        "sender_full_name": "Thomas Zhu",
        "timestamp": 1753294588
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"631691\">@Thomas Zhu</span> The problem with evaluating on existing statements is that the models are often only trained on high school mathematics, or they lack strong agentic capabilities. (I do not know how this applies to your work.) This is why I am interested in search (cf. <a href=\"https://www.leanexplore.com/\">LeanExplore</a>) combined with autoformalization. I had an agentic loop with o4-mini which should be able to prove arbitrary statements in existing repositories, albeit it was super slow, so I started working on other things.</p>",
        "id": 530408042,
        "sender_full_name": "Justin Asher",
        "timestamp": 1753295048
    },
    {
        "content": "<p>The 80% score is promising, especially since it is your light-weight setting!</p>",
        "id": 530408424,
        "sender_full_name": "Justin Asher",
        "timestamp": 1753295178
    },
    {
        "content": "<p>To combine both topics, since you have the best Lean AI (save maybe AlphaProof), have you tried the problems in <a href=\"https://github.com/google-deepmind/formal-conjectures\">https://github.com/google-deepmind/formal-conjectures</a>? <span aria-label=\"slight smile\" class=\"emoji emoji-1f642\" role=\"img\" title=\"slight smile\">:slight_smile:</span></p>",
        "id": 530410259,
        "sender_full_name": "Jason Rute",
        "timestamp": 1753295790
    },
    {
        "content": "<p>We have not tried formal-conjectures yet.</p>",
        "id": 530414675,
        "sender_full_name": "Thomas Zhu",
        "timestamp": 1753297286
    },
    {
        "content": "<p>Every so often someone solves an open conjecture with a fairly simple solution based on known techniques that no-one had previously spotted could be applied to solve that problem. I fully expect that sort of thing is within reach of current AIs. It might however take millions of dollars of compute applied to a thousand problems to find one such solution, so the question then is whether the AI company would disclose the details of the compute used and all the problems the AI didn't solve, or just show off the one it did solve.</p>\n<p>(Did I mention I dislike the general secretiveness of the AI industry?)</p>",
        "id": 530416591,
        "sender_full_name": "Joseph Myers",
        "timestamp": 1753298084
    },
    {
        "content": "<p>Have they released any more detail about the architecture? Like the models involved and their sizes.</p>",
        "id": 530417879,
        "sender_full_name": "Phillip Harris",
        "timestamp": 1753298641
    },
    {
        "content": "<p>It was suggested at IMO 2025 that IMO 2026 wouldn't be of interest to AI companies because it would be too easy for them to solve all six problems then. Apart from whether that's actually a good extrapolation from current data (going from \"gold boundary minus one point\" to \"exactly on the gold boundary\" is comparatively small progress between 2024 and 2025), there are plenty of things that could reasonably be assessed based on AI attempts at IMO 2026 if you're concerned with getting scientifically meaningful data rather than just something that makes a good press release for the AI companies (and happy to work with those AIs interested in contributing to such data even if some of the big AI companies aren't interested).</p>\n<ul>\n<li>As above, can the AIs solve all six problems, which is surely the remaining AI goal for the IMO beyond achieving the gold threshold?</li>\n<li>What can be achieved with different AI techniques? Results with a technique that didn't previously do so well would arguably be more interesting than repeating success with a technique that's already known to do well. Just because \"AI\" has been demonstrated to do something doesn't mean we're anywhere close to knowing the potential of different ideas in the general space of AI, or what approaches or combination of approaches will end up being the best.</li>\n<li>What can be achieved with given resource limits? The less resources AIs need to solve problems, the more potentially useful they are.</li>\n<li>What can be done with open-weight AI, or, better, with fully open-source AI (everything about the training process open, including all training data and all code used to produce synthetic training data)?</li>\n<li>For AIs working with Lean or other formal languages: can they work usefully with the latest released version and a single standard version of the problems, even if training occurred with older versions? Keeping up to date with mathlib is important for practical use of such AIs. (The related issue, \"can they work usefully with definitions newly added to mathlib?\", isn't so readily testable through competition problems, though very relevant for working with research mathematics.)</li>\n<li>Suppose you run the same AI many times on the same problems (if resource consumption permits). What's the distribution of different solution approaches found? Do different AIs prefer different solution approaches? Can AIs be asked to look for genuinely different solutions and so help explore the solution space that way? Learning about the space of possible solutions to a problem is valuable for writing mark schemes for that problem; the PSC tries to include different approaches in the shortlist booklet and then more may be found during the IMO.</li>\n</ul>",
        "id": 530418476,
        "sender_full_name": "Joseph Myers",
        "timestamp": 1753298872
    },
    {
        "content": "<p>Why not just train an RL system which goes through papers on the arXiv and, each time it sees an open problem, tries to solve it? I think DeepThink could already start solving some of these, and since these models are now able to perform self-verification, it should be able to become increasingly better at mathematics.</p>",
        "id": 530420348,
        "sender_full_name": "Justin Asher",
        "timestamp": 1753299619
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"266253\">Joseph Myers</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Seed.20Prover.20Achieves.20Silver-Level.20Score.20at.20IMO.202025/near/530418476\">said</a>:</p>\n<blockquote>\n<ul>\n<li>For AIs working with Lean or other formal languages: can they work usefully with the latest released version and a single standard version of the problems, even if training occurred with older versions? Keeping up to date with mathlib is important for practical use of such AIs.</li>\n</ul>\n</blockquote>\n<p>I was thinking we should create a Lean ML library for this purpose, which would include tools for data indexing, search, verification, and so on. This would build on top of existing repositories like the REPL, Pantograph, SafeVerify, LeanInteract, and so on. I think there are a lot of competing standards right now (at least companies internally seem to have their own tools), and that having one central standard which is up-to-date and used by everyone would be good—at least everyone working on open-source. A lot of existing libraries seem to lag behind the current Lean version, so making a bot which submits PRs to Mathlib is not even really possible.</p>",
        "id": 530420839,
        "sender_full_name": "Justin Asher",
        "timestamp": 1753299831
    },
    {
        "content": "<p>A lot of open problems on the arXiv are probably of the form \"the authors thought about it for five minutes and didn't immediately spot how to solve it\" (and probably don't have many people other than the authors interested in a solution either). So solving one of them is a fairly weak signal of AI abilities (and attempting the maybe millions of such problems there could be in total on the arXiv in bulk, regardless of their value, seems very much like something that would make more sense to do later, once the cost of such AIs has gone down a lot - and any solution found needs to be of enough interest to someone for them to check it, or at least to check the definitions and statement in the case of a formal solution), compared to problems that have stood the test of time and lots of people have shown an interest in (which there are still plenty of available).</p>",
        "id": 530424080,
        "sender_full_name": "Joseph Myers",
        "timestamp": 1753301048
    },
    {
        "content": "<p>That's fair. I was more so just thinking about <br>\n(a) providing some immediate value to the community and <br>\n(b) getting a dataset which is (largely) uncontaminated.</p>",
        "id": 530424331,
        "sender_full_name": "Justin Asher",
        "timestamp": 1753301146
    },
    {
        "content": "<p>Solving a conjecture from formal-conjectures is more likely to be of wide interest than a conjecture from a random arXiv paper.</p>",
        "id": 530424473,
        "sender_full_name": "Joseph Myers",
        "timestamp": 1753301197
    },
    {
        "content": "<p>Don't forget about MathOverflow; AI can earn reputation by solving questions posted there. Also if the AI find a solution to a casual question in an arXiv paper, it can write an email to the author(s), and maybe it will become a collaborator.</p>",
        "id": 530435334,
        "sender_full_name": "Junyan Xu",
        "timestamp": 1753305709
    },
    {
        "content": "<p>It impresses me that the heavyweight Seed Prover is building a lemma pool with problems it tries to prove or refute. To me this is the sign that Seed Prover has become a developing mathematician, maybe not a good one yet, but still.</p>",
        "id": 530436545,
        "sender_full_name": "Junyan Xu",
        "timestamp": 1753306094
    },
    {
        "content": "<p><a href=\"https://www.reddit.com/r/math/comments/1m6sooc/a_brief_perspective_from_an_imo_coordinator/\">https://www.reddit.com/r/math/comments/1m6sooc/a_brief_perspective_from_an_imo_coordinator/</a></p>",
        "id": 530437220,
        "sender_full_name": "David Michael Roberts",
        "timestamp": 1753306403
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"224323\">Junyan Xu</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Seed.20Prover.20Achieves.20Silver-Level.20Score.20at.20IMO.202025/near/530435334\">said</a>:</p>\n<blockquote>\n<p>Don't forget about MathOverflow; AI can earn reputation by solving questions posted there. Also if the AI find a solution to a casual question in an arXiv paper, it can write an email to the author(s), and maybe it will become a collaborator.</p>\n</blockquote>\n<p>I am a moderator  on MathOverflow, and the answer is a solid NO. This is NOT welcome there.</p>",
        "id": 530439593,
        "sender_full_name": "David Michael Roberts",
        "timestamp": 1753307561
    },
    {
        "content": "<p>Making the analogy to IMO, AIs and their owners/operators would not be allowed at the venue, they would get booted, and get no official help at all.</p>",
        "id": 530439700,
        "sender_full_name": "David Michael Roberts",
        "timestamp": 1753307615
    },
    {
        "content": "<p>Seems like it's just doing clustering</p>",
        "id": 530444351,
        "sender_full_name": "Bo Qin",
        "timestamp": 1753310258
    },
    {
        "content": "<p>I doubt LLM can solve novel problems where the format hasn't been seen before</p>",
        "id": 530444478,
        "sender_full_name": "Bo Qin",
        "timestamp": 1753310355
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"772072\">Bo Qin</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Seed.20Prover.20Achieves.20Silver-Level.20Score.20at.20IMO.202025/near/530444351\">said</a>:</p>\n<blockquote>\n<p>Seems like it's just doing clustering</p>\n</blockquote>\n<p>I am curious what you mean by this?</p>",
        "id": 530444506,
        "sender_full_name": "Justin Asher",
        "timestamp": 1753310377
    },
    {
        "content": "<p><a href=\"https://en.wikipedia.org/wiki/Cluster_analysis\">https://en.wikipedia.org/wiki/Cluster_analysis</a></p>",
        "id": 530444554,
        "sender_full_name": "Bo Qin",
        "timestamp": 1753310409
    },
    {
        "content": "<p>Chain of thought is just breaking the bigger problem into smaller ones where the learner can easily cluster those smaller ones with small proof formats it has already seen</p>",
        "id": 530444598,
        "sender_full_name": "Bo Qin",
        "timestamp": 1753310445
    },
    {
        "content": "<p>Coming up with novel proof format has more to do with combinatorics</p>",
        "id": 530445312,
        "sender_full_name": "Bo Qin",
        "timestamp": 1753310914
    },
    {
        "content": "<p>aka brute forcing all the methods you know</p>",
        "id": 530445350,
        "sender_full_name": "Bo Qin",
        "timestamp": 1753310947
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"780541\">Justin Asher</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Seed.20Prover.20Achieves.20Silver-Level.20Score.20at.20IMO.202025/near/530420348\">said</a>:</p>\n<blockquote>\n<p>Why not just train an RL system which goes through papers on the arXiv and, each time it sees an open problem, tries to solve it? I think DeepThink could already start solving some of these, and since these models are now able to perform self-verification, it should be able to become increasingly better at mathematics.</p>\n</blockquote>\n<p>We don't know how out of distribution the verification ability extends though I'm sure OAI and DM are already trying to do so, not just on open problems but even on solved theorems on arxiv as part of their RL.</p>",
        "id": 530455852,
        "sender_full_name": "Opt",
        "timestamp": 1753318084
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"266253\">Joseph Myers</span> <a href=\"#narrow/stream/219941-Machine-Learning-for-Theorem-Proving/topic/Seed.20Prover.20Achieves.20Silver-Level.20Score.20at.20IMO.202025/near/530424473\">said</a>:</p>\n<blockquote>\n<p>Solving a conjecture from formal-conjectures is more likely to be of wide interest than a conjecture from a random arXiv paper.</p>\n</blockquote>\n<p>There's some relative merits of solving arxiv conjectures no? Like it shows the underlying system has some grasp of a large breadth of knowledge if it's capable in almost all areas. I don't know what's in the formal conjectures repo but somehow I doubt it's as representative/comprehensive in breadth and probably the difficulty will also not allow us to judge the capability spread of the systems.</p>",
        "id": 530464539,
        "sender_full_name": "Andy Jiang",
        "timestamp": 1753324226
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"130272\">David Michael Roberts</span> <a href=\"#narrow/stream/219941-Machine-Learning-for-Theorem-Proving/topic/Seed.20Prover.20Achieves.20Silver-Level.20Score.20at.20IMO.202025/near/530439593\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"224323\">Junyan Xu</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Seed.20Prover.20Achieves.20Silver-Level.20Score.20at.20IMO.202025/near/530435334\">said</a>:</p>\n<blockquote>\n<p>Don't forget about MathOverflow; AI can earn reputation by solving questions posted there. Also if the AI find a solution to a casual question in an arXiv paper, it can write an email to the author(s), and maybe it will become a collaborator.</p>\n</blockquote>\n<p>I am a moderator  on MathOverflow, and the answer is a solid NO. This is NOT welcome there.</p>\n</blockquote>\n<p>I don't understand this animosity (presumably it's targeted against current systems and also if one wants to ask AI I guess one often has the option to do it directly). But don't you think that being able to answer a large portion of MO questions also shows some ability of the AIs (they could show this without active participation)</p>",
        "id": 530464743,
        "sender_full_name": "Andy Jiang",
        "timestamp": 1753324386
    },
    {
        "content": "<p>Just to clarify, the point about arXiv was not that random conjectures are useful, but that the model practicing mathematics on questions people are already asking and then self-improving via this process is useful.</p>",
        "id": 530464850,
        "sender_full_name": "Justin Asher",
        "timestamp": 1753324479
    },
    {
        "content": "<p>By the way, even if you didn't intend it, I do think solving random conjectures on arxiv is useful (at the very least to the people who wrote them in the paper). But also in aggregate to our collective understanding of the field.</p>",
        "id": 530465611,
        "sender_full_name": "Andy Jiang",
        "timestamp": 1753325023
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"662620\">@Andy Jiang</span>  It's about site culture. If someone uses an AI system to answer a question offline, and understands the answer and can vouch for it, and the answer is written in a way indistinguishable from how a professional mathematician can write, then clearly we can't tell. But the amount of AI-generated junk we have to delete posted by people that have not enough mathematical understanding to check if its even reasonable, let alone right (and, for that matter, check the formatting syntax is sensible and consistent, and not just TeX output pasted on MO) - you can understand that this drives away high-value users who don't want to waste their time on what might turn into an API for an LLM that they could already consult themselves.</p>",
        "id": 530465642,
        "sender_full_name": "David Michael Roberts",
        "timestamp": 1753325041
    },
    {
        "content": "<p>The AI doesn't need MO rep, by the way, to somehow justify its ability. That is only used to slowly accrue moderation-like powers by osmosis in the site culture, as to what fits, how things work and so on. On MO reputation points are deliberately hidden to users by default.</p>\n<p>There's nothing wrong taking an MO question, running an AI over it, and storing the output on one's own blog/website/GitHub repo. Just don't paste it in the answer box, please. It's against site policy.</p>",
        "id": 530465848,
        "sender_full_name": "David Michael Roberts",
        "timestamp": 1753325215
    },
    {
        "content": "<p>A question to the seed team: of course this is not critique--since all the AI teams announced so far have failed on P6 not just you guys--but do you view the limitations of the system as mostly coming from limitation of the Seed LLM that you're calling to guess the solution? Especially if finding the solution is the bulk of the work--it does seem like it's not able to recognize that and devote most of compute to that (like it's not clear if you call an LLM a million times whether it guesses a hard answer). Do you have some plans to integrate the prover part with the answering part (maybe share some resources in both directions and to have a RL system train the LLM to guess the solution given partial progress on the prover side etc)</p>",
        "id": 530465893,
        "sender_full_name": "Andy Jiang",
        "timestamp": 1753325255
    },
    {
        "content": "<blockquote>\n<p>but do you view the limitations of the system as mostly coming from limitation of the Seed LLM that you're calling to guess the solution?</p>\n</blockquote>\n<p>Yes, I have yet to see any LLM to even guess the correct answer or come close to the construction.</p>",
        "id": 530466333,
        "sender_full_name": "Thomas Zhu",
        "timestamp": 1753325563
    },
    {
        "content": "<blockquote>\n<p>Do you have some plans to integrate the prover part with the answering part</p>\n</blockquote>\n<p>I think this question is more general than fill-in-the-blank competition questions: for humans in general, one constantly modifies the statement that they wanted to prove originally. For example, if you realize mid-proof that a condition is needed, you may strengthen the conditions; or you may start from an undetermined bound and only derive its precise value after a proof. This is certainly an interesting ability to explore.</p>",
        "id": 530466913,
        "sender_full_name": "Thomas Zhu",
        "timestamp": 1753325987
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"662620\">Andy Jiang</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Seed.20Prover.20Achieves.20Silver-Level.20Score.20at.20IMO.202025/near/530465893\">said</a>:</p>\n<blockquote>\n<p>A question to the seed team: of course this is not critique--since all the AI teams announced so far have failed on P6 not just you guys--but do you view the limitations of the system as mostly coming from limitation of the Seed LLM that you're calling to guess the solution? Especially if finding the solution is the bulk of the work--it does seem like it's not able to recognize that and devote most of compute to that (like it's not clear if you call an LLM a million times whether it guesses a hard answer). Do you have some plans to integrate the prover part with the answering part (maybe share some resources in both directions and to have a RL system train the LLM to guess the solution given partial progress on the prover side etc)</p>\n</blockquote>\n<p>That's a very good question, and will be one of our key research focuses in the future.</p>",
        "id": 530470098,
        "sender_full_name": "LiChenggang",
        "timestamp": 1753328528
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"631691\">@Thomas Zhu</span> How well have you seen LLMs do on P6? I am getting some pretty good bounds on the answer which seem reasonable, but need to set up a more complete agentic system with branching to explore ideas more quickly.</p>",
        "id": 530477456,
        "sender_full_name": "Justin Asher",
        "timestamp": 1753334277
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"780541\">@Justin Asher</span> I have not seen them make any partial progress at all (except for trivial bounds like ≤ 4048). Do you have an example answer?</p>",
        "id": 530480260,
        "sender_full_name": "Thomas Zhu",
        "timestamp": 1753336212
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"224323\">Junyan Xu</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Seed.20Prover.20Achieves.20Silver-Level.20Score.20at.20IMO.202025/near/530435334\">said</a>:</p>\n<blockquote>\n<p>Don't forget about MathOverflow; AI can earn reputation by solving questions posted there. Also if the AI find a solution to a casual question in an arXiv paper, it can write an email to the author(s), and maybe it will become a collaborator.</p>\n</blockquote>\n<p>It's a cool concept, but it does remove a lot of attainable work for researchers. </p>\n<p>In my view, those are often the source of consistent research output, I would be hesitant to let AI just take all of those and having to hope there is funding for known open problems that have been 'demonstrably hard.' </p>\n<p>I can't imagine it not having a negative impact on post-doc short term positions in my opinion.</p>",
        "id": 530481024,
        "sender_full_name": "Yan Yablonovskiy 🇺🇦",
        "timestamp": 1753336705
    },
    {
        "content": "<p>Which theorem in <code>p4.lean</code> provides the final answer to the question (the set of all possible values of <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>a</mi><mn>1</mn></msub></mrow><annotation encoding=\"application/x-tex\">a_1</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.5806em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">a</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3011em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> is ...)?</p>",
        "id": 530493755,
        "sender_full_name": "Martin Dvořák",
        "timestamp": 1753342746
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"417654\">Martin Dvořák</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Seed.20Prover.20Achieves.20Silver-Level.20Score.20at.20IMO.202025/near/530493755\">said</a>:</p>\n<blockquote>\n<p>Which theorem in <code>p4.lean</code> provides the final answer to the question (the set of all possible values of <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>a</mi><mn>1</mn></msub></mrow><annotation encoding=\"application/x-tex\">a_1</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.5806em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">a</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3011em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> is ...)?</p>\n</blockquote>\n<p>imo2025_p4_left, imo2025_p4_right</p>",
        "id": 530501276,
        "sender_full_name": "Zheng Yuan",
        "timestamp": 1753345212
    },
    {
        "content": "<p>I don't understand the solution. Is <code>Odd (padicValNat 2 (a 0)) ∧ padicValNat 2 (a 0) &lt; 2 * padicValNat 3 (a 0) ∧ padicValNat 5 (a 0) = 0</code> supposed to be the answer to the question that the IMO problem was asking? Where is the formalization of the <em>statement</em> of the problem?</p>",
        "id": 530505186,
        "sender_full_name": "Martin Dvořák",
        "timestamp": 1753346359
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"417654\">Martin Dvořák</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Seed.20Prover.20Achieves.20Silver-Level.20Score.20at.20IMO.202025/near/530505186\">said</a>:</p>\n<blockquote>\n<p>I don't understand the solution. Is <code>Odd (padicValNat 2 (a 0)) ∧ padicValNat 2 (a 0) &lt; 2 * padicValNat 3 (a 0) ∧ padicValNat 5 (a 0) = 0</code> supposed to be the answer to the question that the IMO problem was asking? Where is the formalization of the <em>statement</em> of the problem?</p>\n</blockquote>\n<p>The answer is any number n where its 2-adic is odd, 3-adic is larger than half of the 2-adic, and 5-adic is zero (i.e. 2^k||n, k is odd, 3^m||n, 2m&gt;k, n is not dividable by 5), which is same as 6 * 12^m * p (where p is coprime to 10).</p>",
        "id": 530509156,
        "sender_full_name": "Zheng Yuan",
        "timestamp": 1753347693
    },
    {
        "content": "<p>All right, but this is something nontrivial that the reader must do in their head. Why is there no <em>iff</em> theorem, or even better, a theorem about equality of sets (the set from the statement and the set that represents the solution)?</p>",
        "id": 530510030,
        "sender_full_name": "Martin Dvořák",
        "timestamp": 1753347976
    },
    {
        "content": "<p>The file looks as if you cut the solution right before the final answer.</p>",
        "id": 530510235,
        "sender_full_name": "Martin Dvořák",
        "timestamp": 1753348032
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"417654\">@Martin Dvořák</span> We have a fixed strategy (fixed before the IMO) to decompose any conjunction problem (including iff/equality of sets/IsLeast) into left and right parts and prove them separately, simply to facilitate our conjecturing pipeline.</p>",
        "id": 530510516,
        "sender_full_name": "Thomas Zhu",
        "timestamp": 1753348135
    },
    {
        "content": "<p>Yes, that would be reasonable if the statements of the \"-&gt;\" implication and the \"&lt;-\" implications were definitionally equivalent up to the direction (or even better, syntactically equivalent) but not if they are (nontrivially) propositionally equivalent.</p>",
        "id": 530510998,
        "sender_full_name": "Martin Dvořák",
        "timestamp": 1753348327
    },
    {
        "content": "<p>P4 does provide a very good example of a \"determine\" problem where there are many different reasonable ways to express the answer (and so automated verification of whether a particular version of the answer is legitimate would be hard).</p>",
        "id": 530542042,
        "sender_full_name": "Joseph Myers",
        "timestamp": 1753358123
    },
    {
        "content": "<p>You are right that there are several ways to express the answer in Lean. However, if your solution of \"characterize the set <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>S</mi></mrow><annotation encoding=\"application/x-tex\">S</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.05764em;\">S</span></span></span></span> described in the problem statement\" consists of a proof <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>S</mi><mo>⊆</mo><mi>T</mi></mrow><annotation encoding=\"application/x-tex\">S \\subseteq T</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8193em;vertical-align:-0.136em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.05764em;\">S</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">⊆</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">T</span></span></span></span> and a proof <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>R</mi><mo>⊆</mo><mi>S</mi></mrow><annotation encoding=\"application/x-tex\">R \\subseteq S</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8193em;vertical-align:-0.136em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.00773em;\">R</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">⊆</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.05764em;\">S</span></span></span></span>, you should also prove that <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>T</mi><mo>⊆</mo><mi>R</mi></mrow><annotation encoding=\"application/x-tex\">T \\subseteq R</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8193em;vertical-align:-0.136em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">T</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">⊆</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.00773em;\">R</span></span></span></span>. Without the last step, the solution is incomplete. Assuming that the AI knows that <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>T</mi><mo>=</mo><mi>R</mi></mrow><annotation encoding=\"application/x-tex\">T = R</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">T</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.00773em;\">R</span></span></span></span> and hence considers the solution to be finished, I don't know why the AI keeps the proof of <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>T</mi><mo>=</mo><mi>R</mi></mrow><annotation encoding=\"application/x-tex\">T = R</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">T</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.00773em;\">R</span></span></span></span> to itself. It should be a part of the solution.</p>",
        "id": 530563538,
        "sender_full_name": "Martin Dvořák",
        "timestamp": 1753363595
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"130272\">David Michael Roberts</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Seed.20Prover.20Achieves.20Silver-Level.20Score.20at.20IMO.202025/near/530465642\">said</a>:</p>\n<blockquote>\n<p>the amount of AI-generated junk we have to delete posted by people that have not enough mathematical understanding to check if its even reasonable, let alone right</p>\n</blockquote>\n<p>That just means those people aren't qualified to use AI and post the AI answers. You always need a qualified human to verify the results at the end of the aggregate function.</p>",
        "id": 530580215,
        "sender_full_name": "Bo Qin",
        "timestamp": 1753368163
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"631691\">Thomas Zhu</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Seed.20Prover.20Achieves.20Silver-Level.20Score.20at.20IMO.202025/near/530480260\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"780541\">Justin Asher</span> I have not seen them make any partial progress at all (except for trivial bounds like ≤ 4048). Do you have an example answer?</p>\n</blockquote>\n<p>No, I just wrote a basic script and told it to start deriving general theory. I had a lot of success previously on Putnam problems using basic models (e.g., Gemini 2.0 Flash) and having them write out a bunch of ideas in a paper like format. What this means is each time the model would write a section to add to the paper, reviewers would check that it is correct, and then this data would be added. This allows the model to build up theory recursively while knowing that it is correct.</p>\n<p>The big issue with this particular problem is that the model, even after extensive prompting, seems unable to identify that it needs to use the Erdős–Szekeres Theorem. I think this is a combination of (a) the problem is indeed very difficult and (b) the intuition for the problem is visual. Seeing how much models struggle on tasks like the ARC-AGI challenge, this is likely more due to how the model is trained.</p>\n<p>I think reformulating the problem into something which is less visual would probably help the model significantly.</p>",
        "id": 530606500,
        "sender_full_name": "Justin Asher",
        "timestamp": 1753376135
    },
    {
        "content": "<p>sorry actually I have a stupid question. In this case, all the Seed (nonprover) LLM model needs to do is guess the minimum number right? So actually in this case the main difficulty is actually on the prover side not the guesser part? because if the prover were good, then you could just like binary search to get the optimal bound if you know what I mean. like say you know that &lt;4048 or whatever, just try to prove both &gt; and &lt;2024 etc until you narrow it down. so basically the main question for this particular question is how much compute you need to prove it (that there exist construction for n) for the optimal bound n</p>",
        "id": 530613713,
        "sender_full_name": "Andy Jiang",
        "timestamp": 1753378468
    },
    {
        "content": "<p>I actually wonder if for the prover system, this erdos theorem is that hard(?)--I assume it's used to establish the lower bound--to figure out that it needs to be applied? [sorry I didn't try to solve/read the solution of this problem so maybe i'm saying complete bs] Or it's actually generating this example at that n. For the latter, it kind of reminded me of the equational theories thing that Terry did where some SAT solvers gave easy arguments for where examples can't exist, and then for the rest you have this hard problem of actually finding an example where theory can't rule it out easily.  Rambling a little, but maybe it's the case that generating such problems (for training data) isn't that hard, especially if you have a robust system (like in the SAT solver case) where ruling out examples is easy. Then you just like generate a lot of (nice?) examples of something, and then you try to use your solver to find some characteristics of your example which is extremal. And then that's a training sample for your model. Obviously very speculative but...</p>",
        "id": 530615217,
        "sender_full_name": "Andy Jiang",
        "timestamp": 1753378944
    },
    {
        "content": "<p>Come to think of it, now that the goal of competiting in IMO like a human and getting gold is achieved, it would be nice to see how well a system with also code execution at its disposal does? presumably with access to python, the models are finding the construction for P6?</p>",
        "id": 530619427,
        "sender_full_name": "Andy Jiang",
        "timestamp": 1753380358
    },
    {
        "content": "<p>Certainly I think a \"determine\" problem should have a single <code>answer</code> provided in any claimed formal solution, rather than separate <code>answer</code> for each direction.</p>",
        "id": 530665733,
        "sender_full_name": "Joseph Myers",
        "timestamp": 1753401082
    },
    {
        "content": "<p>On P6, there is a motivated way to find the construction: considering the edges that the Xs (1x1 squares not in any tile) share with the tiles, by double counting you see you want almost all the edges of tiles to be shared with Xs, which leads to the well-known tiling by squares of two different sizes. (It's also been remarked that this tiling can be seen in the floor at Sunshine Coast Airport, so contestants not already aware of it had a chance to learn about it on their way to the IMO.)</p>",
        "id": 530666122,
        "sender_full_name": "Joseph Myers",
        "timestamp": 1753401335
    },
    {
        "content": "<p>If you want a \"less visual\" statement, my formal statement expresses P6 in terms of intervals in the order on a product type <code>Fin 2025 × Fin 2025</code>. But a \"less visual\" statement may not help when the intuition behind solutions (there are many different solutions) is generally visual.</p>",
        "id": 530667068,
        "sender_full_name": "Joseph Myers",
        "timestamp": 1753401895
    },
    {
        "content": "<p>I asked O4-mini-high for n=9. It comes up with the wrong solution. Then I tell it the right one and ask it to identify the theorem needed to prove the bound. It's able to correctly identify the Erdős–Szekeres Theorem</p>",
        "id": 530667523,
        "sender_full_name": "Opt",
        "timestamp": 1753402151
    },
    {
        "content": "<p>Huh, neat. Gemini 2.5 Pro could not identify Erdős–Szekeres even after significant prodding and asking for many potential theorems.</p>",
        "id": 530667782,
        "sender_full_name": "Justin Asher",
        "timestamp": 1753402309
    },
    {
        "content": "<p>Erdős–Szekeres is only one of many different approaches to proving the bound for this problem.</p>",
        "id": 530668116,
        "sender_full_name": "Joseph Myers",
        "timestamp": 1753402523
    },
    {
        "content": "<p>That's fair. I did not read through the solutions thoroughly. Just surprised me the model never mentioned that theorem.</p>",
        "id": 530668513,
        "sender_full_name": "Justin Asher",
        "timestamp": 1753402770
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"780541\">Justin Asher</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Seed.20Prover.20Achieves.20Silver-Level.20Score.20at.20IMO.202025/near/530667782\">said</a>:</p>\n<blockquote>\n<p>Huh, neat. Gemini 2.5 Pro could not identify Erdős–Szekeres even after significant prodding and asking for many potential theorems.</p>\n</blockquote>\n<p>Gemini with a similar hint identifies the Dilworth theorem which ChatGPT tells me is the same as the Erdos theorem except in poset language</p>",
        "id": 530669026,
        "sender_full_name": "Opt",
        "timestamp": 1753403074
    },
    {
        "content": "<p>6 messages were moved from this topic to <a class=\"stream-topic\" data-stream-id=\"219941\" href=\"/#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Delta.20Prover/with/530758980\">#Machine Learning for Theorem Proving &gt; Delta Prover</a> by <span class=\"user-mention silent\" data-user-id=\"115715\">Jason Rute</span>.</p>",
        "id": 530758981,
        "sender_full_name": "Notification Bot",
        "timestamp": 1753445227
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"266253\">Joseph Myers</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Seed.20Prover.20Achieves.20Silver-Level.20Score.20at.20IMO.202025/near/530424473\">said</a>:</p>\n<blockquote>\n<p>Solving a conjecture from formal-conjectures is more likely to be of wide interest than a conjecture from a random arXiv paper.</p>\n</blockquote>\n<p>Currently there might be a bias in formal-conjectures towards harder and famous problem, and also problems from <a href=\"https://www.erdosproblems.com/\">https://www.erdosproblems.com/</a>. However conjectures from random arxiv or published papers are very welcome and definitely in scope! So if you see a suitable conjecture in a random arxiv paper (or in your paper)<br>\nfell invited to <a href=\"https://github.com/google-deepmind/formal-conjectures/issues/new/choose\">open an issue</a>. <br>\nCurrently we only have 9 conjectures from the arxiv: <a href=\"https://github.com/google-deepmind/formal-conjectures/tree/main/FormalConjectures/Arxiv\">https://github.com/google-deepmind/formal-conjectures/tree/main/FormalConjectures/Arxiv</a><br>\nand arguably some of than are somewhat famous and not random (but not famous enough to have a wikipedia article)<br>\nIf you feel like formalizing a random arxiv paper, look for <a href=\"https://github.com/google-deepmind/formal-conjectures/issues?q=is%3Aissue%20state%3Aopen%20label%3Aarxiv\">https://github.com/google-deepmind/formal-conjectures/issues?q=is%3Aissue%20state%3Aopen%20label%3Aarxiv</a> (currently there is only one issue there: <a href=\"https://github.com/google-deepmind/formal-conjectures/issues/227\">https://github.com/google-deepmind/formal-conjectures/issues/227</a> ).</p>",
        "id": 531848558,
        "sender_full_name": "Moritz Firsching",
        "timestamp": 1753883354
    },
    {
        "content": "<p>Is it fair to say that this is a relatively modest claim to only claim a silver medal? It seems like 5 problems were solved, but problem 1 took too long to solve so the Seed prover team didn't count it? <a href=\"https://seed.bytedance.com/en/blog/bytedance-seed-prover-achieves-silver-medal-score-in-imo-2025\">source</a> Were the other systems playing by those rules, where taking too long discounted the solution?</p>",
        "id": 531874275,
        "sender_full_name": "Chris Hughes",
        "timestamp": 1753890092
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110044\">Chris Hughes</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Seed.20Prover.20Achieves.20Silver-Level.20Score.20at.20IMO.202025/near/531874275\">said</a>:</p>\n<blockquote>\n<p>Is it fair to say that this is a relatively modest claim to only claim a silver medal? It seems like 5 problems were solved, but problem 1 took too long to solve so the Seed prover team didn't count it? <a href=\"https://seed.bytedance.com/en/blog/bytedance-seed-prover-achieves-silver-medal-score-in-imo-2025\">source</a> Were the other systems playing by those rules, where taking too long discounted the solution?</p>\n</blockquote>\n<p>In order for IMO to grade our results, they required submission by a specific time on July 18 (about 3 days after we got the problems). Seed-Prover solved 4 problems by the deadline and 1 other problem after the deadline. Perhaps one might interpret it as \"getting gold-level score in 7 days\" but this score would only be verified by Lean and not the IMO (hence the \"IMO-certified score of 30 points\" in our news release). We are working on significantly reducing our computational time.</p>",
        "id": 531908470,
        "sender_full_name": "Thomas Zhu",
        "timestamp": 1753901661
    },
    {
        "content": "<p>By the way, Huawei claimed 34/42 (backed by a quote from IMO). I could only find relevant news in Chinese. They claimed using \"formal proofs\" in the news release but the <a href=\"https://github.com/Huawei-xiaoyi/IMO2025-solutions\">final PDFs</a> were in natural language, and I assume they won't have a tech report, so I don't know the technical details.</p>",
        "id": 531909632,
        "sender_full_name": "Thomas Zhu",
        "timestamp": 1753902050
    },
    {
        "content": "<p>Our tech report is now available at: <a href=\"https://arxiv.org/pdf/2507.23726\">https://arxiv.org/pdf/2507.23726</a></p>",
        "id": 532196993,
        "sender_full_name": "Thomas Zhu",
        "timestamp": 1754009834
    },
    {
        "content": "<p>Could you release the dataset mentioned of 155 past IMO problems (under a suitable license for reuse) and the details of which ones you solved? Any statements not currently in Compfiles might well be of interest for that repository; I don't know what the Compfiles attitude is to taking AI-generated <em>proofs</em>, but there's plenty of scope for starting from such a proof and then cleaning it up heavily.</p>\n<p>That the dataset mainly taken from existing repositories has many fewer combinatorics problems than algebra or number theory certainly indicates a bias in what statements people have chosen to formalize. To be fair, combinatorics statements take a lot longer to formalize than algebra or number theory statements (but they don't tend to run into missing definitions the way geometry statements still do, except for some problems expressed geometrically).</p>",
        "id": 532199981,
        "sender_full_name": "Joseph Myers",
        "timestamp": 1754011409
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"266253\">@Joseph Myers</span> We have released our solutions the past IMO problems here: <a href=\"https://github.com/ByteDance-Seed/Seed-Prover/blob/main/SeedProver/imo.zip\">https://github.com/ByteDance-Seed/Seed-Prover/blob/main/SeedProver/imo.zip</a>. We will release all problem statements, including ones not solved shortly.</p>",
        "id": 532200429,
        "sender_full_name": "Thomas Zhu",
        "timestamp": 1754011662
    },
    {
        "content": "<p>Thanks!</p>\n<p>I'm interested myself in high-quality statements formalized following uniform conventions and covering all problems from given years without selection bias on which problems someone chose to formalize the statement of (I hope to extend IMOLean to earlier years at some point, after filling in more of the gaps in geometrical definitions in mathlib), but less uniform statements with selection bias are still certainly useful for evaluating solvers (mathematicians writing formal statements of research problems to ask AIs for help on those problems won't use uniform conventions) and also useful for comparison when writing one's own formal statements (ideas from someone else's formal statement can help write a better statement following one's own preferred conventions).</p>",
        "id": 532201108,
        "sender_full_name": "Joseph Myers",
        "timestamp": 1754012093
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"266253\">Joseph Myers</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Seed.20Prover.20Achieves.20Silver-Level.20Score.20at.20IMO.202025/near/532201108\">said</a>:</p>\n<blockquote>\n<p>Thanks!</p>\n<p>I'm interested myself in high-quality statements formalized following uniform conventions and covering all problems from given years without selection bias on which problems someone chose to formalize the statement of (I hope to extend IMOLean to earlier years at some point, after filling in more of the gaps in geometrical definitions in mathlib), but less uniform statements with selection bias are still certainly useful for evaluating solvers (mathematicians writing formal statements of research problems to ask AIs for help on those problems won't use uniform conventions) and also useful for comparison when writing one's own formal statements (ideas from someone else's formal statement can help write a better statement following one's own preferred conventions).</p>\n</blockquote>\n<p><a href=\"https://github.com/ByteDance-Seed/Seed-Prover/blob/main/SeedProver/imo_all.lean\">https://github.com/ByteDance-Seed/Seed-Prover/blob/main/SeedProver/imo_all.lean</a></p>\n<p>We have multiple versions of IMO2023P1, please just ignore them.</p>",
        "id": 532232550,
        "sender_full_name": "Zheng Yuan",
        "timestamp": 1754028730
    },
    {
        "content": "<p>Is imo_all.lean exhaustive coverage of all non-geometry past IMO problems?</p>",
        "id": 532262226,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1754039214
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"310045\">Eric Wieser</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Seed.20Prover.20Achieves.20Silver-Level.20Score.20at.20IMO.202025/near/532262226\">said</a>:</p>\n<blockquote>\n<p>Is imo_all.lean exhaustive coverage of all non-geometry past IMO problems?</p>\n</blockquote>\n<p>No, mainly from compfiles. We only add like 30+ formal statements by ourselves.</p>",
        "id": 532294039,
        "sender_full_name": "Zheng Yuan",
        "timestamp": 1754050583
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"780541\">Justin Asher</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Seed.20Prover.20Achieves.20Silver-Level.20Score.20at.20IMO.202025/near/530400925\">said</a>:</p>\n<blockquote>\n<p>Probably will happen before the end of the year...</p>\n</blockquote>\n<p>I know this is not the Riemann hypothesis or anything, but seems like we are heading in the right direction to start solving some good conjectures by the end of the year. The demo of DeepThink is it solving a small conjecture:<br>\n<a href=\"https://www.youtube.com/watch?v=QoXRfTb7ves\">https://www.youtube.com/watch?v=QoXRfTb7ves</a></p>\n<div class=\"youtube-video message_inline_image\"><a data-id=\"QoXRfTb7ves\" href=\"https://www.youtube.com/watch?v=QoXRfTb7ves\"><img src=\"https://uploads.zulipusercontent.net/7d5ae19aa530643564f4056143fd9012cb226667/68747470733a2f2f692e7974696d672e636f6d2f76692f516f5852665462377665732f6d7164656661756c742e6a7067\"></a></div><p>I think if you hooked this up to a larger agentic system you could start writing some decent research papers, but that would be terribly expensive.</p>\n<p>I am super excited to see how systems like Seed Prover and DeepThink contribute to this.</p>",
        "id": 532312567,
        "sender_full_name": "Justin Asher",
        "timestamp": 1754056569
    },
    {
        "content": "<p><a href=\"/user_uploads/3121/rAkXtcZ5zZcPg6hTF856g5wq/gemini-2-5-deep-think-solves-previously-unproven-v0-fbr5jhuneegf1.webp\">gemini-2-5-deep-think-solves-previously-unproven-v0-fbr5jhuneegf1.webp</a></p>\n<div class=\"message_inline_image\"><a href=\"/user_uploads/3121/rAkXtcZ5zZcPg6hTF856g5wq/gemini-2-5-deep-think-solves-previously-unproven-v0-fbr5jhuneegf1.webp\" title=\"gemini-2-5-deep-think-solves-previously-unproven-v0-fbr5jhuneegf1.webp\"><img data-original-content-type=\"image/webp\" data-original-dimensions=\"807x292\" src=\"/user_uploads/thumbnail/3121/rAkXtcZ5zZcPg6hTF856g5wq/gemini-2-5-deep-think-solves-previously-unproven-v0-fbr5jhuneegf1.webp/840x560.webp\"></a></div>",
        "id": 532353842,
        "sender_full_name": "Junyan Xu",
        "timestamp": 1754071030
    },
    {
        "content": "<p>The conjecture solved, from <a href=\"https://www.reddit.com/r/singularity/comments/1metslk/comment/n6c3dhm/\">https://www.reddit.com/r/singularity/comments/1metslk/comment/n6c3dhm/</a></p>",
        "id": 532353891,
        "sender_full_name": "Junyan Xu",
        "timestamp": 1754071060
    },
    {
        "content": "<p><a href=\"/user_uploads/3121/FM3BzS3bMPVNc90QfN03o9eo/image.png\">image.png</a><br>\nComments from YouTube; looks like the conjecture has been solved in 2023.</p>\n<div class=\"message_inline_image\"><a href=\"/user_uploads/3121/FM3BzS3bMPVNc90QfN03o9eo/image.png\" title=\"image.png\"><img data-original-content-type=\"image/png\" data-original-dimensions=\"1371x655\" src=\"/user_uploads/thumbnail/3121/FM3BzS3bMPVNc90QfN03o9eo/image.png/840x560.webp\"></a></div>",
        "id": 532355791,
        "sender_full_name": "Junyan Xu",
        "timestamp": 1754071721
    },
    {
        "content": "<p>I wonder if AI ever solves RH, if it will have just taken the proof from some supposed crank who was right all along. <span aria-label=\"slight smile\" class=\"emoji emoji-1f642\" role=\"img\" title=\"slight smile\">:slight_smile:</span></p>",
        "id": 532356031,
        "sender_full_name": "Jason Rute",
        "timestamp": 1754071824
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"224323\">Junyan Xu</span> <a href=\"#narrow/stream/219941-Machine-Learning-for-Theorem-Proving/topic/Seed.20Prover.20Achieves.20Silver-Level.20Score.20at.20IMO.202025/near/532353842\">said</a>:</p>\n<blockquote>\n<p><a href=\"/user_uploads/3121/rAkXtcZ5zZcPg6hTF856g5wq/gemini-2-5-deep-think-solves-previously-unproven-v0-fbr5jhuneegf1.webp\">gemini-2-5-deep-think-solves-previously-unproven-v0-fbr5jhuneegf1.webp</a></p>\n</blockquote>\n<p>I know that comparing it to FrontierMath is not a sensible thing to do (because FM is about finding a numerical answer). But which is more difficult</p>",
        "id": 532360195,
        "sender_full_name": "Anh Nguyễn",
        "timestamp": 1754073716
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"224323\">Junyan Xu</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Seed.20Prover.20Achieves.20Silver-Level.20Score.20at.20IMO.202025/near/532355791\">said</a>:</p>\n<blockquote>\n<p>Comments from YouTube; looks like the conjecture has been solved in 2023.</p>\n</blockquote>\n<p>Note that the first speaker (Michel) of the video is also an author of the paper which solved the conjecture. It seems to me that DeepThink came up with a different solution and that the proof was along different lines to the existing proof, but the problem wasn't previously unsolved.</p>",
        "id": 532369077,
        "sender_full_name": "Bhavik Mehta",
        "timestamp": 1754077575
    },
    {
        "content": "<p>That was confusing.  Thanks for clearing it up!</p>",
        "id": 532372065,
        "sender_full_name": "Jason Rute",
        "timestamp": 1754079053
    },
    {
        "content": "<p>The video certainly didn't make this clear, I had an advantage in that I know the speaker so recognised both his face and his surname from the youtube comment reference :)</p>",
        "id": 532374168,
        "sender_full_name": "Bhavik Mehta",
        "timestamp": 1754080044
    },
    {
        "content": "<p>I think finding alternative solutions and exploring the solution space of a problem is an interesting thing to do; indeed, I mentioned it above as one way in which evaluating AIs on future IMOs seems worthwhile even if \"can the AI solve the problems?\" isn't an interesting question at that point. (Problems do need a certain minimum difficulty level to have an interesting solution space, so I'm not sure you'd get much out of such an evaluation on the easier parts of miniF2F, for example. But national olympiad and IMO-easy problems can certainly have interesting solution spaces.)</p>\n<p>Finding alternative solutions to a solved problem (with or without knowledge of solutions you're looking for an alternative to) is, however, very different from solving an unsolved problem.</p>\n<p>To keep this more on topic as far as Lean is concerned: formalizing alternative proofs of something is also of value if they result in contributing different lemmas to mathlib, or in insights into how to formalize the different concepts involved in the different proofs.</p>",
        "id": 532388973,
        "sender_full_name": "Joseph Myers",
        "timestamp": 1754088287
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"631691\">Thomas Zhu</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Seed.20Prover.20Achieves.20Silver-Level.20Score.20at.20IMO.202025/near/532196993\">said</a>:</p>\n<blockquote>\n<p>Our tech report is now available at: <a href=\"https://arxiv.org/pdf/2507.23726\">https://arxiv.org/pdf/2507.23726</a></p>\n</blockquote>\n<p>Thanks <span class=\"user-mention\" data-user-id=\"631691\">@Thomas Zhu</span> . If it's something you can talk about - how do you generate the natural language hints and proofs? Do you have a separate LLM which you solicit for that or does your Lean LLM generate that automatically as part of its chain of thought?</p>",
        "id": 532517063,
        "sender_full_name": "Opt",
        "timestamp": 1754196453
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"246273\">@Bhavik Mehta</span> do you mean the video was edited in a way that when he says it came up with a different proof, but apparently never said it was proved already, it was intentional? I'm shocked,... shocked!</p>",
        "id": 532548964,
        "sender_full_name": "David Michael Roberts",
        "timestamp": 1754222066
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"900177\">Opt</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Seed.20Prover.20Achieves.20Silver-Level.20Score.20at.20IMO.202025/near/532517063\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"631691\">Thomas Zhu</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Seed.20Prover.20Achieves.20Silver-Level.20Score.20at.20IMO.202025/near/532196993\">said</a>:</p>\n<blockquote>\n<p>Our tech report is now available at: <a href=\"https://arxiv.org/pdf/2507.23726\">https://arxiv.org/pdf/2507.23726</a></p>\n</blockquote>\n<p>Thanks <span class=\"user-mention silent\" data-user-id=\"631691\">Thomas Zhu</span> . If it's something you can talk about - how do you generate the natural language hints and proofs? Do you have a separate LLM which you solicit for that or does your Lean LLM generate that automatically as part of its chain of thought?</p>\n</blockquote>\n<p>same model here</p>",
        "id": 532554479,
        "sender_full_name": "Zheng Yuan",
        "timestamp": 1754226040
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"631691\">@Thomas Zhu</span> The paper talks about a cool interface called <code>LooKeng </code>that would help in a lot of theorem proving tasks. Is this interface open-sourced? Also, can we know what is the size of seed-prover?</p>",
        "id": 532606204,
        "sender_full_name": "Ayush Agrawal",
        "timestamp": 1754259751
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"439607\">Ayush Agrawal</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Seed.20Prover.20Achieves.20Silver-Level.20Score.20at.20IMO.202025/near/532606204\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"631691\">Thomas Zhu</span> The paper talks about a cool interface called <code>LooKeng </code>that would help in a lot of theorem proving tasks. Is this interface open-sourced? Also, can we know what is the size of seed-prover?</p>\n</blockquote>\n<p>Lookeng will be open-sourced.</p>",
        "id": 532628560,
        "sender_full_name": "Zheng Yuan",
        "timestamp": 1754274351
    },
    {
        "content": "<p>Thanks <span class=\"user-mention\" data-user-id=\"631691\">@Thomas Zhu</span>! One more question: Is the lean4 compiler feedback (incorporation of errors etc. into the prompt) happening online during RL training? It was not totally clear from  the paper. Feel free to point to me specific parts of the paper if I missed something.</p>",
        "id": 532791531,
        "sender_full_name": "Ayush Agrawal",
        "timestamp": 1754338900
    },
    {
        "content": "<p>when can we use seedprover?</p>",
        "id": 532799259,
        "sender_full_name": "Jared green",
        "timestamp": 1754341998
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"439607\">Ayush Agrawal</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Seed.20Prover.20Achieves.20Silver-Level.20Score.20at.20IMO.202025/near/532791531\">said</a>:</p>\n<blockquote>\n<p>One more question: Is the lean4 compiler feedback (incorporation of errors etc. into the prompt) happening online during RL training? It was not totally clear from  the paper. Feel free to point to me specific parts of the paper if I missed something.</p>\n</blockquote>\n<p>Similar problem. I'm still not entirely sure what was done during training and what is part of the (very impressive) test-time inference. So you propose easier conjectures during training, and have some multi-task learning objective that trains to generate lemmas and use them at the same time but also to prove starting with already existing lemmas, right?<br>\nBut library learning is inference only? And self-summarization, is that part of training?</p>",
        "id": 532868401,
        "sender_full_name": "Simon Sorg",
        "timestamp": 1754384038
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"394803\">Jared green</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Seed.20Prover.20Achieves.20Silver-Level.20Score.20at.20IMO.202025/near/532799259\">said</a>:</p>\n<blockquote>\n<p>when can we use seedprover?</p>\n</blockquote>\n<p>We are not ready for other people to try this due to our complex test-time strategy.</p>",
        "id": 533010400,
        "sender_full_name": "Zheng Yuan",
        "timestamp": 1754444002
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"766274\">Simon Sorg</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Seed.20Prover.20Achieves.20Silver-Level.20Score.20at.20IMO.202025/near/532868401\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"439607\">Ayush Agrawal</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Seed.20Prover.20Achieves.20Silver-Level.20Score.20at.20IMO.202025/near/532791531\">said</a>:</p>\n<blockquote>\n<p>One more question: Is the lean4 compiler feedback (incorporation of errors etc. into the prompt) happening online during RL training? It was not totally clear from  the paper. Feel free to point to me specific parts of the paper if I missed something.</p>\n</blockquote>\n<p>Similar problem. I'm still not entirely sure what was done during training and what is part of the (very impressive) test-time inference. So you propose easier conjectures during training, and have some multi-task learning objective that trains to generate lemmas and use them at the same time but also to prove starting with already existing lemmas, right?<br>\nBut library learning is inference only? And self-summarization, is that part of training?</p>\n</blockquote>\n<p>Library learning and self summary is test-time only.</p>",
        "id": 533010454,
        "sender_full_name": "Zheng Yuan",
        "timestamp": 1754444058
    },
    {
        "content": "<p>The performance of Seed-Prover on PutanBench has been verified with 329/657. 2 problems are not counted due to using wrong version of formalizations.</p>",
        "id": 535410988,
        "sender_full_name": "Zheng Yuan",
        "timestamp": 1755738224
    },
    {
        "content": "<p>Has anyone actually run SeedProver's IMO2025 proofs? Their repository doesn't have a <code>lean-toolchain</code> or <code>lakefile.toml</code>, and the proofs don't work on the latest Mathlib master.</p>",
        "id": 539919282,
        "sender_full_name": "Kim Morrison",
        "timestamp": 1758076649
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110087\">Kim Morrison</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Seed.20Prover.20Achieves.20Silver-Level.20Score.20at.20IMO.202025/near/539919282\">said</a>:</p>\n<blockquote>\n<p>Has anyone actually run SeedProver's IMO2025 proofs? Their repository doesn't have a <code>lean-toolchain</code> or <code>lakefile.toml</code>, and the proofs don't work on the latest Mathlib master.</p>\n</blockquote>\n<p>Hi, SeedProver's proof should be compiled under v4.14.0</p>",
        "id": 539919373,
        "sender_full_name": "Zheng Yuan",
        "timestamp": 1758076753
    },
    {
        "content": "<p>The proof break in the lastest lean version mainly due to <code>∑ i in</code> -&gt; <code>∑ i ∈</code> issue</p>",
        "id": 539919488,
        "sender_full_name": "Zheng Yuan",
        "timestamp": 1758076898
    },
    {
        "content": "<p>Is it possible to set up the repository so that <code>lake build</code> will work? This seems like step 0 of verification.</p>",
        "id": 539919521,
        "sender_full_name": "Kim Morrison",
        "timestamp": 1758076935
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110087\">Kim Morrison</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Seed.20Prover.20Achieves.20Silver-Level.20Score.20at.20IMO.202025/near/539919521\">said</a>:</p>\n<blockquote>\n<p>Is it possible to set up the repository so that <code>lake build</code> will work? This seems like step 0 of verification.</p>\n</blockquote>\n<p>Since <a href=\"https://github.com/ByteDance-Seed/Seed-Prover\">https://github.com/ByteDance-Seed/Seed-Prover</a> is used for store multiple research projects and multiple benchmark results (minif2f, imo, putnam, combibench...). It is a little hard for us to maintain a mono-repo with default lean setting since they relies on different Lean version. The most easiest way to verify our file is using lean-web, and simply copy paste one proof. Any repo with v4.14.0 Lean+Mathlib should also work to verify IMO2025.</p>",
        "id": 539919893,
        "sender_full_name": "Zheng Yuan",
        "timestamp": 1758077236
    },
    {
        "content": "<p>It can probably be done one lake project per directory (such as under <code>imo2025/</code>)</p>",
        "id": 539920233,
        "sender_full_name": "Lawrence Wu (llllvvuu)",
        "timestamp": 1758077592
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"607118\">Lawrence Wu (llllvvuu)</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Seed.20Prover.20Achieves.20Silver-Level.20Score.20at.20IMO.202025/near/539920233\">said</a>:</p>\n<blockquote>\n<p>It can probably be done one lake project per directory (such as under <code>imo2025/</code>)</p>\n</blockquote>\n<p>We will update our github for imo2025 with a lake project <span aria-label=\"working on it\" class=\"emoji emoji-1f6e0\" role=\"img\" title=\"working on it\">:working_on_it:</span></p>",
        "id": 539920299,
        "sender_full_name": "Zheng Yuan",
        "timestamp": 1758077654
    },
    {
        "content": "<p>Thank you!</p>",
        "id": 539925907,
        "sender_full_name": "Kim Morrison",
        "timestamp": 1758082634
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110087\">Kim Morrison</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Seed.20Prover.20Achieves.20Silver-Level.20Score.20at.20IMO.202025/near/539925907\">said</a>:</p>\n<blockquote>\n<p>Thank you!</p>\n</blockquote>\n<p>Updated</p>",
        "id": 540387426,
        "sender_full_name": "Zheng Yuan",
        "timestamp": 1758266002
    }
]