[
    {
        "content": "<p>It looks like Google Deepmind has a new agent, Aletheia, which has proven an outstanding ErdÅ‘s problem! Here is the preprint:</p>\n<p><a href=\"https://arxiv.org/abs/2601.21442\">https://arxiv.org/abs/2601.21442</a></p>\n<p>The result was then formalized into Lean by <span class=\"user-mention\" data-user-id=\"957203\">@Kevin Barreto</span>, which you can see in the relevant thread:</p>\n<p><a href=\"https://www.erdosproblems.com/forum/thread/1051\">https://www.erdosproblems.com/forum/thread/1051</a></p>\n<p>They also claim to have solved many other open results and beyond:</p>\n<p><a href=\"https://x.com/lmthang/status/2017317250055999926\">https://x.com/lmthang/status/2017317250055999926</a></p>",
        "id": 571222827,
        "sender_full_name": "Justin Asher",
        "timestamp": 1769885944
    },
    {
        "content": "<p>Here the second preprint and X post:</p>\n<p><a href=\"https://arxiv.org/abs/2601.22401\">https://arxiv.org/abs/2601.22401</a><br>\n<a href=\"https://x.com/lmthang/status/2018355663404187830\">https://x.com/lmthang/status/2018355663404187830</a></p>",
        "id": 571641925,
        "sender_full_name": "Ralf Stephan",
        "timestamp": 1770120080
    },
    {
        "content": "<p>The part most relevant for Lean:</p>\n<blockquote>\n<p>Large Language Models can easily generate candidate solutions, but the number of experts who can judge the correctness of a solution is relatively small, and even for experts, substantial time is required to carry out such evaluations. In particular, it would have been infeasible for our team to evaluate model outputs on all of the problems marked â€˜Openâ€™.<br>\n[...]<br>\nAn alternative approach to the evaluation problem is via formal verification, such as through the Lean language. This has also led to a handful of success cases, but has limitations. First, because only a tiny proportion of the math research literature is formalized in Lean, this significantly restricts the modelâ€™s toolkit for solving problems. Second, many problem statements in the database are open-ended or susceptible to misinterpretation. An expert is still required to interpret the argument in natural language to determine if a formally verified proof addresses the intended mathematical meaning (see Appendix A for an interesting case study on this issue).</p>\n</blockquote>",
        "id": 571645727,
        "sender_full_name": "Bryan Wang",
        "timestamp": 1770121242
    },
    {
        "content": "<p>That text sounds like the target audience is people not particularly familiar with formalization or the open-ended nature of many research problems. I think it's fairly clear to people familiar with formalization that AIs formalizing their own work can help distinguish the 137 Fundamentally Flawed solutions from the 63 Technically Correct, not so much with deciding whether what the solutions had proved was interesting. (And the better AIs are at finding their own mistakes, the more potential there is for them to try the problems again autonomously after doing so.)</p>",
        "id": 571778548,
        "sender_full_name": "Joseph Myers",
        "timestamp": 1770158035
    },
    {
        "content": "<p>I am surprised that their ErdÃ¶s problem pipeline includes human grading. I guess the necessary mathematics has not yet been formalized in Lean for these solutions to all be autoformalized? This further seems indicative that the AI is not quite good enough to self-grade, and hence self-improve, yet; albeit, I would guess that we were getting close to this point.</p>\n<p>I am not sure why the AI struggles to see the mistakes in its own proofs unless each part is put under a microscope. Early last year I was running experiments where I would have the AI check each sentence in its proof, and then the overall proof, for correctness, which was pretty successful. Perhaps it is the nature of the attention mechanism and a limited output size that is prohibitive here. I would imagine agentic systems will naturally start to fill in these gaps.</p>\n<p>I am also curious whether there has been any progress made by Google DeepMind on their <a href=\"https://github.com/google-deepmind/formal-conjectures\">formal conjectures</a> repository, as it seems like the natural testing ground for AI.</p>\n<p>I do think that this paradigm of attacking individual problems is flawed, as it appears like there is not much an attempt of building up proper theory as a mathematician might. Strong technical ability is needed, but beyond that it is industrialization. The research that I have seen in this area over the past few months, where open problems have claimed to be solved by AI, have often focused on things that do not require significant long-term planning or construction.</p>",
        "id": 571814105,
        "sender_full_name": "Justin Asher",
        "timestamp": 1770178750
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"780541\">Justin Asher</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/DeepMind's.20Aletheia.20Erdos.20problem/near/571814105\">said</a>:</p>\n<blockquote>\n<p>I am also curious whether there has been any progress made by Google DeepMind on their <a href=\"https://github.com/google-deepmind/formal-conjectures\">formal conjectures</a> repository, as it seems like the natural testing ground for AI.</p>\n</blockquote>\n<p>Ironically it has a lot to teach about the interactions of Lean and AI, but so far itâ€™s not how youâ€™d expect.</p>\n<p>In particular it has been a sort of barometer of how easily someone can use commercially available AI blindly to formalise the conjectures in Lean, a lot of one time PRs from people just using AI blindly. </p>\n<p>Over time it has gotten a lot better at it , and people there sometimes just take what the knowledgeable reviewer says and feeds it to the AI as a middleman successfully.</p>",
        "id": 571817536,
        "sender_full_name": "Yan Yablonovskiy ðŸ‡ºðŸ‡¦",
        "timestamp": 1770181150
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"780541\">Justin Asher</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/DeepMind's.20Aletheia.20Erdos.20problem/near/571814105\">said</a>:</p>\n<blockquote>\n<p>I am surprised that their ErdÃ¶s problem pipeline includes human grading.</p>\n</blockquote>\n<p>As can be seen from misformalizations in the #&lt;Formal conjectures&gt; project one problem is that (from a formal perspective) ErdÃ¶s was sloppy with his statements. He had hidden assumptions that made it all consistent and valuable but, purely from his writing, it is impossible in many cases to get unambigous statements.</p>",
        "id": 572124274,
        "sender_full_name": "Ralf Stephan",
        "timestamp": 1770291467
    },
    {
        "content": "<p>So there is not only AI slop but also ErdÃ¶s slop, and we have to deal with both.</p>",
        "id": 572124940,
        "sender_full_name": "Ralf Stephan",
        "timestamp": 1770291672
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"780541\">Justin Asher</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/DeepMind's.20Aletheia.20Erdos.20problem/near/571814105\">said</a>:</p>\n<blockquote>\n<p>I am surprised that their ErdÃ¶s problem pipeline includes human grading. I guess the necessary mathematics has not yet been formalized in Lean for these solutions to all be autoformalized? </p>\n</blockquote>\n<p>I made a strong push for wanting to do autoformalisation, but unfortunately was shot down on this due to the effort needed to verify statements were formalised correctly.</p>",
        "id": 572127732,
        "sender_full_name": "Kevin Barreto",
        "timestamp": 1770292478
    },
    {
        "content": "<p>Here is the relevant blog article:</p>\n<p><a href=\"https://deepmind.google/blog/accelerating-mathematical-and-scientific-discovery-with-gemini-deep-think/\">https://deepmind.google/blog/accelerating-mathematical-and-scientific-discovery-with-gemini-deep-think/</a></p>",
        "id": 573520410,
        "sender_full_name": "Justin Asher",
        "timestamp": 1770902736
    },
    {
        "content": "<p>I mean they do know that if AI capabilities continue on this trajectory, that formalization is the only way, one can realistically have a handle on verifying all of these results. </p>\n<p>Its probably more a publicity stunt, as currently the natural language math abilities are still ahead of the formalized abilities, meaning if you want to get headlines by saying you solved some research problems, you have to do it the old school way.</p>\n<p>I dont think it really matters, in the sense that it shows that AI can do math and that it gets better at that. I think we all know that already, time and time again, we have been surprised. </p>\n<p>One can argue that doing math research is fundamentally harder / different, that theory  building requires other skills and vision. And while that is certainly true, it just implies that it might take longer getting to that level, it does not provide any evidence that AI will be fundamentally unable to do math on such level. In the end its just compute + a engineering problem and there are enough smart people working on it that we can be sure, that we will get there. Its just the question of how fast.</p>",
        "id": 573575390,
        "sender_full_name": "Franz Huschenbeth",
        "timestamp": 1770915777
    }
]