[
    {
        "content": "<p>We are happy to share an update on the SorryDB project, which aims to set up a continuously running competition for AI systems trying to prove sorries from real Lean repositories. This is joint work-in-progress with <span class=\"user-mention\" data-user-id=\"699684\">@Austin Letson</span>, <span class=\"user-mention\" data-user-id=\"802311\">@Oliver Dressler</span>, <span class=\"user-mention\" data-user-id=\"321854\">@Auguste Poiroux</span>.  Previous discussion can be found:</p>\n<ul>\n<li><a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Incentives.20.26.20sorry-filling.20leaderboard/with/501641915\">#Machine Learning for Theorem Proving &gt; Incentives &amp; sorry-filling leaderboard</a></li>\n<li><a href=\"https://icerm.brown.edu/video_archive/4104\">This lecture</a> at ICERM (from the <a href=\"https://icerm.brown.edu/program/hot_topics_workshop/htw-25-aftwm\">Autoformalization for the Working Mathematician</a> workshop).</li>\n</ul>\n<p>Goals:</p>\n<ul>\n<li>Evaluate AI agents on a useful task for the working/formalizing mathematician: filling in Prop-valued sorries in real Lean repositories, under real-world conditions.</li>\n<li>Minimize the gap between benchmark performance and real world use (e.g. one should be able to run an agent overnight to attempt to fill sorries in a specific repository)</li>\n</ul>\n<p>We were much inspired by Jason Rute's talk on <a href=\"https://www.youtube.com/watch?v=Yr8dzfVkeHg\">The Last Mile</a>, and by <a href=\"https://cmu-l3.github.io/minictx/\">miniCTX</a>, <a href=\"https://arxiv.org/abs/2410.06209\">LeanAgent</a> and <a href=\"https://www.swebench.com/\">SWE-bench</a>.</p>\n<div class=\"youtube-video message_inline_image\"><a data-id=\"Yr8dzfVkeHg\" href=\"https://www.youtube.com/watch?v=Yr8dzfVkeHg\"><img src=\"https://uploads.zulipusercontent.net/b6f6457a0ce3de21445be6f2de56ad6060528140/68747470733a2f2f692e7974696d672e636f6d2f76692f597238647a66566b6548672f6d7164656661756c742e6a7067\"></a></div><p>We currently maintain a <em><a href=\"https://github.com/SorryDB/sorrydb-data\">nightly updated index</a></em> of <code>Prop</code>-valued sorries in public repositories. This is being scaled up to eventually cover all repositories listed at <a href=\"https://reservoir.lean-lang.org/\">Reservoir</a>.</p>\n<p>We have implemented two <em>naive agents</em>, which take as input a list of sorry indices, and attempt to replace the sorries with valid proof strings. The first simply attempts \"rfl\", and the second asks an LLM for a one-shot whole-proof attempt. A third which uses an LLM to find a proof in tactic-by-tactic mode is planned. These are meant as templates—not competitive entries—designed to make building new agents as easy as possible. See <a href=\"https://github.com/SorryDB/SorryDB/tree/master/sorrydb/agents\">source code</a> and <a href=\"https://github.com/SorryDB/SorryDB/blob/master/doc/AGENTS.md\">documentation</a>. </p>\n<p>The infrastructure is now mature enough that it makes sense to implement a few <em>serious agents</em>—e.g., porting existing theorem-proving models to this setup. <strong>Suggestions and contributions are very welcome!</strong> We’re happy to discuss what’s involved.</p>\n<p>Our next target: a simple <em>sorry server</em> to automatically select recent sorries, serve them to agents via an API, verify solutions, and maintain an ELO-style ranking.</p>\n<p>Finally, a few comments on data policy, based on the <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/Incentives.20.26.20sorry-filling.20leaderboard/with/501641915\">previous discussion</a>:</p>\n<ul>\n<li>we will only index repositories from <a href=\"https://reservoir.lean-lang.org/\">Reservoir</a> (in particular those have an <a href=\"https://reservoir.lean-lang.org/inclusion-criteria\">open source licence</a>).</li>\n<li>owners can opt-out from having their repository indexed (just send us a message)</li>\n<li>we will never send unsolicited automated pull requests or similar, any such future feature will be opt-in.</li>\n</ul>\n<p>For more information, see <a href=\"https://github.com/SorryDB/SorryDB\">SorryDB on GitHub</a>, and the <a href=\"https://github.com/SorryDB/SorryDB/tree/master/doc\">docs</a>. Feedback is much appreciated!</p>",
        "id": 518068190,
        "sender_full_name": "Lenny Taelman",
        "timestamp": 1747229739
    },
    {
        "content": "<p>Hi, have you considered running on my repo (for various values of \"my\")? You mentioned in your talk that it only handles recent sorries, but the cutoff was something like 2 weeks which I find to be <em>very</em> short and misses out on a lot of easy sorries that are just dormant.</p>",
        "id": 518188760,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1747272568
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"479731\">@Lenny Taelman</span> Thanks for the update! This looks great, and I am excited to play around with building bots. I had a few questions:</p>\n<ul>\n<li>For the data infrastructure, what is the typical runtime for the sorry data scraping and indexing process? What is the typical runtime when starting from scratch versus updating repositories that you have already indexed? </li>\n<li>How do you handle repositories with differing Lean versions? When I was writing <a href=\"https://www.leanexplore.com/\">LeanExplore</a>, this became a problem, but I can imagine workarounds in your case.</li>\n<li>Are you going to limit the ELO sorry leaderboard to specific repositories? Because I can see this being problematic if applied to repositories with lots of improper usage of axioms and partial / unsafe declarations.</li>\n</ul>",
        "id": 518213337,
        "sender_full_name": "Justin Asher",
        "timestamp": 1747289291
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110049\">Mario Carneiro</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/SorryDB.20project/near/518188760\">said</a>:</p>\n<blockquote>\n<p>Hi, have you considered running on my repo (for various values of \"my\")? You mentioned in your talk that it only handles recent sorries, but the cutoff was something like 2 weeks which I find to be <em>very</em> short and misses out on a lot of easy sorries that are just dormant.</p>\n</blockquote>\n<p>Indeed that could also be part of 'scaling up'. We visit any repository that has been updated since we last visited, or if never visited if it has been updated since a certain cutoff date. Having this cutoff date at -\\infty would just incur an extra cost for the initial run.  The current update runs in (order of magnitude) 1 hour, so this should be feasible. <span class=\"user-mention\" data-user-id=\"699684\">@Austin Letson</span> can give you more precise figures for the cutoff and runtime. </p>\n<p>The focus for now has been on establishing that there is a continuous supply of fresh sorries.</p>",
        "id": 518215029,
        "sender_full_name": "Lenny Taelman",
        "timestamp": 1747290123
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"780541\">Justin Asher</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/SorryDB.20project/near/518213337\">said</a>:</p>\n<blockquote>\n<ul>\n<li>How do you handle repositories with differing Lean versions? When I was writing <a href=\"https://www.leanexplore.com/\">LeanExplore</a>, this became a problem, but I can imagine workarounds in your case</li>\n</ul>\n</blockquote>\n<p>We record the Lean version as part of the indexing. (And use a matching version of REPL to analyse the sorry). In particular, any 'agent' that will compete will need to be able to deal with varying (and recent) Lean versions. I consider this a fundamental aspect of the 'real-world conditions' alluded to above.</p>",
        "id": 518238137,
        "sender_full_name": "Lenny Taelman",
        "timestamp": 1747297793
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"780541\">Justin Asher</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/SorryDB.20project/near/518213337\">said</a>:</p>\n<blockquote>\n<ul>\n<li>Are you going to limit the ELO sorry leaderboard to specific repositories? Because I can see this being problematic if applied to repositories with lots of improper usage of axioms and partial / unsafe declarations.</li>\n</ul>\n</blockquote>\n<p>This will always require a bit of monitoring, but so far the vast majority of sorries we see are honest mathematical statements. In any case, since this is meant to be a continuously-running competition, it is easy to declare some sorries 'invalid' after the fact, and remove them retroactively from the computation of the ELO rating.</p>\n<p>A little bit of unchecked noise should be ok, as long as the rules are the same for everyone and the weird or irrelevant sorries do not dominate the landscape.</p>",
        "id": 518238988,
        "sender_full_name": "Lenny Taelman",
        "timestamp": 1747297979
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"479731\">Lenny Taelman</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/SorryDB.20project/near/518215029\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"110049\">Mario Carneiro</span> <a href=\"#narrow/channel/219941-Machine-Learning-for-Theorem-Proving/topic/SorryDB.20project/near/518188760\">said</a>:</p>\n<blockquote>\n<p>Hi, have you considered running on my repo (for various values of \"my\")? You mentioned in your talk that it only handles recent sorries, but the cutoff was something like 2 weeks which I find to be <em>very</em> short and misses out on a lot of easy sorries that are just dormant.</p>\n</blockquote>\n<p>Indeed that could also be part of 'scaling up'. We visit any repository that has been updated since we last visited, or if never visited if it has been updated since a certain cutoff date. Having this cutoff date at -\\infty would just incur an extra cost for the initial run.  The current update runs in (order of magnitude) 1 hour, so this should be feasible. <span class=\"user-mention silent\" data-user-id=\"699684\">Austin Letson</span> can give you more precise figures for the cutoff and runtime. </p>\n<p>The focus for now has been on establishing that there is a continuous supply of fresh sorries.</p>\n</blockquote>\n<p>Re update runtime: The runtime of the update varies a lot based on which repos have been updated that day. As Lenny said, 1 hour is a good estimate. We are working on creating aggregated stats for runtime, and repo specific processing time. </p>\n<p>Re cutoff date: Currently the cut off date is 2025-04-01. I will stamp that this is the cutoff date for any changes to the git repo. If any branch in the git repo has a commit after the cutoff date then we will index all sorries on that branch. For example if there is a lean version bump, then we will index all sorries on the branch with the bump, not just the sorries created after 2025-04-01. Note, when we incorporate more of reservoir into the database, we going to move this date back significantly.</p>",
        "id": 519092425,
        "sender_full_name": "Austin Letson",
        "timestamp": 1747657253
    },
    {
        "content": "<p>To <span class=\"user-mention\" data-user-id=\"110049\">@Mario Carneiro</span>'s point, I think we still want to index sorries from dormant repos. There are few possibilities on how to do this. For example:</p>\n<ul>\n<li>Extend the cut off date back to the release of Lean4. This would essentially index sorries on every branch of every repository in Reservoir.</li>\n<li>Keep a relatively recent cut off date, but index the default git branch for every repo in reservoir, even if the default branch wasn't updated before the cutoff.</li>\n<li>Incorporate a Lean version into the cut off criteria, e.g., index all branches with Lean version &gt;= 4.9. Since we are limited by the versions that REPL supports, this might be inevitable. </li>\n</ul>\n<p>I am curious to hear from others who have maintained long running Lean projects and/or dormant Lean projects on what they think is the best approach.</p>",
        "id": 519097661,
        "sender_full_name": "Austin Letson",
        "timestamp": 1747658406
    },
    {
        "content": "<p>if you push back to -infty then it will inevitably actually be a lean version cutoff in the end, which makes sense to me.</p>",
        "id": 519098545,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1747658590
    },
    {
        "content": "<p>Analogously, I don't think anyone is interested in training language models to write Python 2.2 code</p>",
        "id": 519099004,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1747658693
    },
    {
        "content": "<p>We are still accepting applications for the SorryDB Hackathon in Amsterdam, October 7th - 10th, 2025! For more details see <a href=\"#narrow/channel/113486-announce/topic/SorryDB.20Hackathon/with/537817717\">the initial announcement</a>.</p>\n<p>If you are interested please fill out the application <a href=\"https://docs.google.com/forms/d/e/1FAIpQLSe9VN-K4_r7IZdpDYCyK7C9h6xnEM0853K3gR3vUdgc8uIwbA/viewform?pli=1\">here</a>.</p>",
        "id": 539975666,
        "sender_full_name": "Austin Letson",
        "timestamp": 1758103598
    }
]