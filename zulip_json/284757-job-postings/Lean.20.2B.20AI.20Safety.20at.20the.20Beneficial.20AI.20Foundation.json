[
    {
        "content": "<p>A description: <a href=\"https://www.beneficialaifoundation.org/jobs\">https://www.beneficialaifoundation.org/jobs</a></p>\n<p>The link: <a href=\"https://docs.google.com/forms/d/1irecYvgyrSR-5r8hN8qAXumheEuz02TtRgFp-QxYheY/viewform?edit_requested=true\">https://docs.google.com/forms/d/1irecYvgyrSR-5r8hN8qAXumheEuz02TtRgFp-QxYheY/viewform?edit_requested=true</a></p>\n<hr>\n<p>We invite the interested:</p>\n<p>This position involves working with me, Max Tegmark, and others on provable AI safety via formal verification, as described <a href=\"https://arxiv.org/abs/2309.01933\">here</a> (a high-level introduction is given in the 2nd half of this <a href=\"https://www.ted.com/talks/max_tegmark_how_to_keep_ai_under_control?language=en\">TED talk</a>).  The position can be either remote or in the Bay Area/Cambridge, Massachusetts (MIT).</p>\n<p>The ideal candidate:</p>\n<ul>\n<li>\n<p>Wants to ensure that powerful AI systems stay under human control</p>\n</li>\n<li>\n<p>Concerned that AGI is not many decades away,  and that current AI safety approaches may be inadequate for such a transformative technology</p>\n</li>\n<li>\n<p>Experience with both formal verification and machine learning</p>\n</li>\n</ul>\n<p>Annual compensation:</p>\n<p>$70,000—$250,000 USD depending on experience</p>",
        "id": 517164997,
        "sender_full_name": "Alok Singh",
        "timestamp": 1746814426
    }
]