[
    {
        "content": "<p>My main takeaway from <a href=\"https://doi.org/10.1007/978-3-662-44199-2_3\">Flyspecking Flyspeck</a> by Mark Adams is that it's important, for auditing purposes, to be able to export a proof object file and validate that file using a separate piece of software. Is this a capability that Lean 4 has? If so, are there step-by-step instructions somewhere, explaining how to do this?</p>\n<p>It seems to me that even this kind of \"independent\" check might not be completely independent. For example, it would certainly be tempting to use the same version of GMP during the audit as during the original proof. What other libraries besides GMP might one worry about?</p>\n<p>On a slightly different but related note, suppose I formulate and prove a theorem, and I carefully check all the definitions in mathlib that I'm relying on, to convince myself that they mean what I think they mean. Suppose that I worry that mathlib might evolve in such a way that my theorem is still correct, but no longer proves exactly what I think it proves. Is there a mechanism by which I can \"lock in\" a particular version of mathlib (or the relevant portions of mathlib) along with my theorem, to preclude this kind of \"definition drift\"? More generally, what community standards are in place to minimize the possibility of definition drift in mathlib?</p>",
        "id": 553366459,
        "sender_full_name": "Timothy Chow",
        "timestamp": 1762171901
    },
    {
        "content": "<p>You can extract with: <a href=\"https://github.com/leanprover/lean4export\">https://github.com/leanprover/lean4export</a> and feed it to third party kernels (or indeed also the kernel itself again), such as <a href=\"https://github.com/ammkrn/nanoda_lib\">https://github.com/ammkrn/nanoda_lib</a></p>",
        "id": 553371563,
        "sender_full_name": "Henrik BÃ¶ving",
        "timestamp": 1762173610
    },
    {
        "content": "<p>More information about (external) type checking can be found here: <a href=\"https://ammkrn.github.io/type_checking_in_lean4/\">https://ammkrn.github.io/type_checking_in_lean4/</a></p>",
        "id": 553380567,
        "sender_full_name": "Floris van Doorn",
        "timestamp": 1762176468
    },
    {
        "content": "<p>Definition drift is a potential issue, since definitions do get changed in Mathlib. The review cycle and Mathlib standards will usually ensure that a definition doesn't just change to a mathematically meaningfully different definition, but in edge cases this could be a problem. </p>\n<p>That said: every Lean project completely specifies which version of Mathlib it is built with, and (unless you update it), it will stay on that Mathlib version.</p>",
        "id": 553381632,
        "sender_full_name": "Floris van Doorn",
        "timestamp": 1762176778
    },
    {
        "content": "<p>Here's a related question. How often does it happen that a proof that works perfectly fine with one version of mathlib breaks with a newer version of mathlib? I can think of various reasons why this might happen. Definitions might be eliminated entirely, or at least changed materially. It could also be that powerful tactics such as <code>grind</code> don't increase in power monotonically, but stop being able to prove things that they used to be able to prove.</p>\n<p>Does this sort of thing happen much in practice? Are there other reasons why a proof might break when mathlib is upgraded?</p>",
        "id": 554518233,
        "sender_full_name": "Timothy Chow",
        "timestamp": 1762644015
    },
    {
        "content": "<p>Very common, yes</p>",
        "id": 554518315,
        "sender_full_name": "Ruben Van de Velde",
        "timestamp": 1762644095
    },
    {
        "content": "<p>If you filter for commits bumping the Lean toolchain and/or look at things marked with <code>#adaptation_note</code> these are not too hard to track down.</p>",
        "id": 554518383,
        "sender_full_name": "Chris Henson",
        "timestamp": 1762644153
    },
    {
        "content": "<p>Things getting renamed are common, for example</p>",
        "id": 554518395,
        "sender_full_name": "Ruben Van de Velde",
        "timestamp": 1762644167
    },
    {
        "content": "<p>Files being moved around, tactics changing (typically becoming stronger)</p>",
        "id": 554518457,
        "sender_full_name": "Ruben Van de Velde",
        "timestamp": 1762644223
    },
    {
        "content": "<p>Oh I misunderstood, I was talking about changes in Lean itself. A different issue, but still somewhat relevant.</p>",
        "id": 554518471,
        "sender_full_name": "Chris Henson",
        "timestamp": 1762644238
    },
    {
        "content": "<p>New linters, if you have those turned on</p>",
        "id": 554518495,
        "sender_full_name": "Ruben Van de Velde",
        "timestamp": 1762644262
    },
    {
        "content": "<p>Hypotheses being weakened, as well</p>",
        "id": 554518653,
        "sender_full_name": "Ruben Van de Velde",
        "timestamp": 1762644410
    },
    {
        "content": "<p>Can a tactic becoming stronger cause a proof to break? It didn't occur to me that that could happen, but maybe it could?</p>",
        "id": 554531300,
        "sender_full_name": "Timothy Chow",
        "timestamp": 1762659495
    },
    {
        "content": "<p>Well yes, for example if it finishes the proof earlier, you get a \"no goals to be solved\" error. A more complex case that I hit recently was with <code>field_simp</code> gaining support for inequalities, where the rest of the proof assumed it didn't</p>",
        "id": 554541159,
        "sender_full_name": "Ruben Van de Velde",
        "timestamp": 1762671986
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"478409\">Timothy Chow</span> <a href=\"#narrow/channel/270676-lean4/topic/Flyspecking.20Flyspeck/near/554518233\">said</a>:</p>\n<blockquote>\n<p>Here's a related question. How often does it happen that a proof that works perfectly fine with one version of mathlib breaks with a newer version of mathlib?</p>\n</blockquote>\n<p>Click on a few of these PRs (bumps to mathlib in the FLT project) to see things going wrong:<br>\n<a href=\"https://github.com/ImperialCollegeLondon/FLT/pulls?q=is%3Apr+is%3Aclosed+bump\">https://github.com/ImperialCollegeLondon/FLT/pulls?q=is%3Apr+is%3Aclosed+bump</a> . Ignore the changes to system files (these are typically at the bottom) but observe that there's just general noise as things get upstreamed (e.g. someone defines X or proves X and dumps it in FLT, and then someone moves it up to mathlib and during the process the name changes and/or the order of, or number of, inputs changes, and then things break). More complicated to fix are when the behaviour of <code>simp</code> changes.</p>",
        "id": 554768514,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1762800056
    },
    {
        "content": "<p>Yeah, though issues with upstreaming code tend to only happen if you (or one of your contributors) actively make them happen</p>",
        "id": 554777588,
        "sender_full_name": "Ruben Van de Velde",
        "timestamp": 1762803584
    }
]