[
    {
        "content": "<p>Today I wanted to get cached build of mathlib4 and got struck on <code>curl</code> version. On Ubuntu 20.04, the version of curl is 7.68 but <code>lean exe cache</code> needs 7.69 and above.</p>\n<p>Googling for \"update curl ubuntu\" gives you this <a href=\"https://yannmjl.medium.com/how-to-manually-update-curl-on-ubuntu-server-899476062ad6\">guide</a> which downloads sources, complies and install them. Other guides on how to update curl compile the code too! This is not beginner friendly at all. </p>\n<p>Talking briefly to Mario about this. Apparently this is because new version of curl supports parallelization. I would suggest to fallback to old version of curl. Non parallelized curl would be still faster then compiling mathlib.</p>\n<p>I think Ubuntu 20.04 is relatively new and popular, so fixing this would be nice.</p>",
        "id": 344029051,
        "sender_full_name": "Tomas Skrivan",
        "timestamp": 1679587867
    },
    {
        "content": "<p>AFAIR it is <em>extremely</em> slow without parallelization, to the point where I wondered whether building from scratch wouldn't be faster</p>",
        "id": 344030379,
        "sender_full_name": "Sebastian Ullrich",
        "timestamp": 1679588143
    },
    {
        "content": "<p>Relevant discussion: <a href=\"#narrow/stream/287929-mathlib4/topic/.60lake.20exe.20cache.60.20curl.20version\">https://leanprover.zulipchat.com/#narrow/stream/287929-mathlib4/topic/.60lake.20exe.20cache.60.20curl.20version</a></p>",
        "id": 344030400,
        "sender_full_name": "YaÃ«l Dillies",
        "timestamp": 1679588147
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110024\">Sebastian Ullrich</span> <a href=\"#narrow/stream/270676-lean4/topic/curl.20version.20on.20Ubuntu.2020.2E04/near/344030379\">said</a>:</p>\n<blockquote>\n<p>AFAIR it is <em>extremely</em> slow without parallelization, to the point where I wondered whether building from scratch wouldn't be faster</p>\n</blockquote>\n<p>Is it possible to parallelize inside Lean rather than letting curl do its parallelization? Maybe this helps overcome or work around the issues with Curl's parallelization in version 7.68 and below?</p>",
        "id": 344077656,
        "sender_full_name": "Shreyas Srinivas",
        "timestamp": 1679598462
    },
    {
        "content": "<p>Only experimentation can tell... I wouldn't know beforehand</p>",
        "id": 344078987,
        "sender_full_name": "Arthur Paulino",
        "timestamp": 1679598785
    },
    {
        "content": "<p>I would imagine that curl will do a much better job of parallelism than what we can do in Lean</p>",
        "id": 344082297,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1679599634
    },
    {
        "content": "<p>yes, but only if the flag actually exists!</p>",
        "id": 344082476,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1679599679
    },
    {
        "content": "<p>the issue here is that many people don't have a curl that supports the option we want to use</p>",
        "id": 344082585,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1679599700
    },
    {
        "content": "<p>If we have a reliable way to get new curl installed on machines that's fine, but we clearly don't want end users to have to install curl from source</p>",
        "id": 344082798,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1679599762
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110038\">Kevin Buzzard</span> <a href=\"#narrow/stream/287929-mathlib4/topic/lake.20get-cache/near/319641701\">said</a>:</p>\n<blockquote>\n<p><a href=\"https://www.linuxcapable.com/how-to-install-upgrade-curl-on-ubuntu-20-04-lts/\">https://www.linuxcapable.com/how-to-install-upgrade-curl-on-ubuntu-20-04-lts/</a> fixed the problem for me, although I'm now running curl as modified by some random person on the internet</p>\n</blockquote>\n<p>was one option</p>",
        "id": 344083783,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1679600014
    },
    {
        "content": "<p>Clicking on the \"upgrade to 22.04?\" button is another one</p>",
        "id": 344106028,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1679607256
    },
    {
        "content": "<p>University computers are a concern though, since students don't have SU privileges</p>",
        "id": 344106866,
        "sender_full_name": "Arthur Paulino",
        "timestamp": 1679607590
    },
    {
        "content": "<p>Not to mention, upgrading a distro can break a lot of other things</p>",
        "id": 344110289,
        "sender_full_name": "Shreyas Srinivas",
        "timestamp": 1679608964
    },
    {
        "content": "<p>Also, it doesn't help all the Ubuntu derived distributions</p>",
        "id": 344110411,
        "sender_full_name": "Shreyas Srinivas",
        "timestamp": 1679609021
    },
    {
        "content": "<p>I think we could do worse than providing a statically linked recent version of curl per platform and download that (for which older curl is sufficient).</p>\n<div class=\"codehilite\" data-code-language=\"Bash Session\"><pre><span></span><code><span class=\"gp\">$ </span>nix<span class=\"w\"> </span>build<span class=\"w\"> </span>github:NixOS/nixpkgs/nixos-unstable#pkgsStatic.curl\n<span class=\"gp\">$ </span>file<span class=\"w\"> </span>./result-bin/bin/curl\n<span class=\"go\">./result-bin/bin/curl: ELF 64-bit LSB executable, x86-64, version 1 (SYSV), statically linked, BuildID[sha1]=ee11a4cbde03a128ffa2c03b810d7c9d287f0506, not stripped</span>\n<span class=\"gp\">$ </span>./result-bin/bin/curl<span class=\"w\"> </span>--version\n<span class=\"go\">curl 7.88.1 (x86_64-unknown-linux-musl) libcurl/7.88.1 OpenSSL/3.0.8 zlib/1.2.13 zstd/1.5.4 libidn2/2.3.2 libssh2/1.10.0 nghttp2/1.51.0</span>\n<span class=\"go\">Release-Date: 2023-02-20</span>\n<span class=\"go\">Protocols: dict file ftp ftps gopher gophers http https imap imaps mqtt pop3 pop3s rtsp scp sftp smb smbs smtp smtps telnet tftp</span>\n<span class=\"go\">Features: alt-svc AsynchDNS HSTS HTTP2 HTTPS-proxy IDN IPv6 Largefile libz NTLM NTLM_WB SSL threadsafe TLS-SRP UnixSockets zstd</span>\n</code></pre></div>",
        "id": 344181294,
        "sender_full_name": "Sebastian Ullrich",
        "timestamp": 1679643765
    },
    {
        "content": "<p>If your Linux curl is too old, please give <a href=\"https://github.com/leanprover-community/mathlib4/pull/3097\">https://github.com/leanprover-community/mathlib4/pull/3097</a> a try</p>",
        "id": 344473802,
        "sender_full_name": "Sebastian Ullrich",
        "timestamp": 1679746078
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"451983\">Arthur Paulino</span> <a href=\"#narrow/stream/270676-lean4/topic/curl.20version.20on.20Ubuntu.2020.2E04/near/344078987\">said</a>:</p>\n<blockquote>\n<p>Only experimentation can tell... I wouldn't know beforehand</p>\n</blockquote>\n<p>Using <code>IO.asTask</code> to parallelize in Lean, rather than in curl, takes:</p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"bp\">%</span> <span class=\"n\">time</span> <span class=\"n\">lake</span> <span class=\"n\">exe</span> <span class=\"n\">cache</span> <span class=\"n\">get</span><span class=\"bp\">!</span>\n<span class=\"n\">Attempting</span> <span class=\"n\">to</span> <span class=\"n\">download</span> <span class=\"mi\">1876</span> <span class=\"n\">file</span><span class=\"o\">(</span><span class=\"n\">s</span><span class=\"o\">)</span>\n<span class=\"n\">Decompressing</span> <span class=\"mi\">1875</span> <span class=\"n\">file</span><span class=\"o\">(</span><span class=\"n\">s</span><span class=\"o\">)</span>\n<span class=\"n\">lake</span> <span class=\"n\">exe</span> <span class=\"n\">cache</span> <span class=\"n\">get</span><span class=\"bp\">!</span>  <span class=\"mi\">57</span><span class=\"bp\">.</span><span class=\"mi\">12</span><span class=\"n\">s</span> <span class=\"n\">user</span> <span class=\"mi\">97</span><span class=\"bp\">.</span><span class=\"mi\">32</span><span class=\"n\">s</span> <span class=\"n\">system</span> <span class=\"mi\">85</span><span class=\"bp\">%</span> <span class=\"n\">cpu</span> <span class=\"mi\">3</span><span class=\"o\">:</span><span class=\"mi\">00</span><span class=\"bp\">.</span><span class=\"mi\">54</span> <span class=\"n\">total</span>\n</code></pre></div>\n<p>which for me is barely slower than the current implementation using <code>--parallel</code>:</p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"bp\">%</span> <span class=\"n\">time</span> <span class=\"n\">lake</span> <span class=\"n\">exe</span> <span class=\"n\">cache</span> <span class=\"n\">get</span><span class=\"bp\">!</span>\n<span class=\"n\">Attempting</span> <span class=\"n\">to</span> <span class=\"n\">download</span> <span class=\"mi\">1876</span> <span class=\"n\">file</span><span class=\"o\">(</span><span class=\"n\">s</span><span class=\"o\">)</span>\n<span class=\"n\">Decompressing</span> <span class=\"mi\">1876</span> <span class=\"n\">file</span><span class=\"o\">(</span><span class=\"n\">s</span><span class=\"o\">)</span>\n<span class=\"n\">lake</span> <span class=\"n\">exe</span> <span class=\"n\">cache</span> <span class=\"n\">get</span><span class=\"bp\">!</span>  <span class=\"mi\">28</span><span class=\"bp\">.</span><span class=\"mi\">48</span><span class=\"n\">s</span> <span class=\"n\">user</span> <span class=\"mi\">48</span><span class=\"bp\">.</span><span class=\"mi\">23</span><span class=\"n\">s</span> <span class=\"n\">system</span> <span class=\"mi\">47</span><span class=\"bp\">%</span> <span class=\"n\">cpu</span> <span class=\"mi\">2</span><span class=\"o\">:</span><span class=\"mi\">41</span><span class=\"bp\">.</span><span class=\"mi\">21</span> <span class=\"n\">total</span>\n</code></pre></div>",
        "id": 345084791,
        "sender_full_name": "Scott Morrison",
        "timestamp": 1679998782
    },
    {
        "content": "<p>I can make a PR with my code as a fallback if we haven't obtained a suitable curl, but I'd want someone with more curl-fu to check my flags.</p>",
        "id": 345086563,
        "sender_full_name": "Scott Morrison",
        "timestamp": 1679999209
    },
    {
        "content": "<p>I think we've effectively solved the problem, at least on Linux. I'm surprised though it's so slow for you, is it simply your downstream?</p>",
        "id": 345087077,
        "sender_full_name": "Sebastian Ullrich",
        "timestamp": 1679999360
    },
    {
        "content": "<p>I had to upgrade curl on my macos system to satisfy <code>cache</code>, so I think more general solutions are still worthwhile.</p>",
        "id": 345088789,
        "sender_full_name": "Scott Morrison",
        "timestamp": 1679999883
    },
    {
        "content": "<p>I'm not sure why it is so slow, but it is certainly painful. :-) Not sure whether to blame azure in australia, my ISP, or something else.</p>",
        "id": 345088961,
        "sender_full_name": "Scott Morrison",
        "timestamp": 1679999926
    },
    {
        "content": "<p><a href=\"https://github.com/leanprover-community/mathlib4/pull/3146\">!4#3146</a>, no problem if it is discarded.</p>",
        "id": 345090888,
        "sender_full_name": "Scott Morrison",
        "timestamp": 1680000426
    },
    {
        "content": "<p>What about reliability? Users might end up in cycles of <code>cache get!</code> if downloads fail too often</p>",
        "id": 345120050,
        "sender_full_name": "Arthur Paulino",
        "timestamp": 1680007369
    },
    {
        "content": "<p>So far in testing I don't seem to have had any failures. What could be done to improve reliability? Why would we expect it to be worse with Task parallelization rather than curl parallelization?</p>",
        "id": 345238105,
        "sender_full_name": "Scott Morrison",
        "timestamp": 1680036210
    },
    {
        "content": "<p>Unfortunately I don't know <code>curl</code> well enough to give satisfying answers. I can only raise concerns</p>",
        "id": 345238592,
        "sender_full_name": "Arthur Paulino",
        "timestamp": 1680036386
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110087\">Scott Morrison</span> <a href=\"#narrow/stream/270676-lean4/topic/curl.20version.20on.20Ubuntu.2020.2E04/near/345238105\">said</a>:</p>\n<blockquote>\n<p>So far in testing I don't seem to have had any failures. What could be done to improve reliability? Why would we expect it to be worse with Task parallelization rather than curl parallelization?</p>\n</blockquote>\n<p>So, just from a protocol POV HTTP 2 is actually fully capable of having multiple streams encoded in the same TCP connection which I would expect curl abuses for task parallelization. If you instead have multiple curl tasks they have to open seperate TCP connections for seperate HTTP 2 connections and each of those connections need to carry their meta data with them. Now, the meta data should (hopefully) not be too significant but I would expect that there is a measurable difference in multiple curls vs 1 curl doing multi tasking on its own assuming an HTTP 2 connection.</p>",
        "id": 345239456,
        "sender_full_name": "Henrik BÃ¶ving",
        "timestamp": 1680036740
    },
    {
        "content": "<p>Right, the difference in time was noticeable. But we're wondering if parallel tasks would be any riskier in terms of failing to download (aside from the fact that a longer download is intrinsically riskier in terms of failure)</p>",
        "id": 345244025,
        "sender_full_name": "Arthur Paulino",
        "timestamp": 1680038587
    },
    {
        "content": "<p>Its all TCP based anyways so there is no reason to fear failures from a protocol POV again. The only reason I could see for your downloads to fail would be if Azure would decide to rate limit you because it feels like you having so many connections open might count as a DoS attack but I would hope that rate limiting on azure blobs is configurable to a point where this is not the case</p>",
        "id": 345244584,
        "sender_full_name": "Henrik BÃ¶ving",
        "timestamp": 1680038837
    },
    {
        "content": "<p>This presumes that old curl doesn't have other bugs that cause a download to fail; given the problem in the first place was that <code>--parallel</code> had a bug, this may or may not be a safe assumption.</p>",
        "id": 345278068,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1680055685
    },
    {
        "content": "<p>I think Sebastian noticed that the Azure blob storage doesn't do HTTP/2.  I think he got a nice speedup when trying out HTTP/2 with the CDN.</p>",
        "id": 345279741,
        "sender_full_name": "Gabriel Ebner",
        "timestamp": 1680056910
    },
    {
        "content": "<p>Here's the URL in case somebody wants to make a PR: <a href=\"https://lakecache-gjhdfybgcpf9dpfr.z01.azurefd.net/mathlib4/f/18296616905743833141.tar.gz\">https://lakecache-gjhdfybgcpf9dpfr.z01.azurefd.net/mathlib4/f/18296616905743833141.tar.gz</a></p>",
        "id": 345279765,
        "sender_full_name": "Gabriel Ebner",
        "timestamp": 1680056940
    },
    {
        "content": "<p>I tried the CDN earlier today and didn't see any speed-up. :-(</p>",
        "id": 345286084,
        "sender_full_name": "Scott Morrison",
        "timestamp": 1680061291
    },
    {
        "content": "<p>In fact, it was slightly slower. (For me a <code>cache get!</code> takes about three minutes.)</p>",
        "id": 345286166,
        "sender_full_name": "Scott Morrison",
        "timestamp": 1680061324
    },
    {
        "content": "<p>I should've put the cache in Australia instead of Ohio. <span aria-label=\"rofl\" class=\"emoji emoji-1f923\" role=\"img\" title=\"rofl\">:rofl:</span></p>",
        "id": 345286459,
        "sender_full_name": "Gabriel Ebner",
        "timestamp": 1680061556
    },
    {
        "content": "<p>Was it just slower the first time though?  Did it get faster if you tried <code>cache get!</code> a second time?</p>",
        "id": 345286544,
        "sender_full_name": "Gabriel Ebner",
        "timestamp": 1680061588
    },
    {
        "content": "<p>That was my impression with the mathlib3 cache at least.</p>",
        "id": 345286597,
        "sender_full_name": "Gabriel Ebner",
        "timestamp": 1680061606
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"395550\">Henrik BÃ¶ving</span> <a href=\"#narrow/stream/270676-lean4/topic/curl.20version.20on.20Ubuntu.2020.2E04/near/345244584\">said</a>:</p>\n<blockquote>\n<p>Its all TCP based anyways</p>\n</blockquote>\n<p>Up until Azure CDN support HTTP/3 :) ... but yes, I was surprised to find that protocol overhead apparently is negligible (when querying actually existent files) (and <code>--parallel</code> still seems to help even when using HTTP/2). It's all about the raw speed of the connection on both ends, and everywhere in between</p>",
        "id": 345323968,
        "sender_full_name": "Sebastian Ullrich",
        "timestamp": 1680077427
    },
    {
        "content": "<p>Unfortunately the CDN is still just as slow as the original, for me, even after repeat invocations.</p>",
        "id": 345349820,
        "sender_full_name": "Scott Morrison",
        "timestamp": 1680083935
    },
    {
        "content": "<p>How long is <code>lake exe cache get!</code> taking for others?</p>",
        "id": 345349863,
        "sender_full_name": "Scott Morrison",
        "timestamp": 1680083948
    },
    {
        "content": "<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"bp\">$</span> <span class=\"n\">time</span> <span class=\"n\">lake</span> <span class=\"n\">exe</span> <span class=\"n\">cache</span> <span class=\"n\">get</span><span class=\"bp\">!</span>\n<span class=\"n\">Attempting</span> <span class=\"n\">to</span> <span class=\"n\">download</span> <span class=\"mi\">1895</span> <span class=\"n\">file</span><span class=\"o\">(</span><span class=\"n\">s</span><span class=\"o\">)</span>\n<span class=\"n\">Decompressing</span> <span class=\"mi\">1895</span> <span class=\"n\">file</span><span class=\"o\">(</span><span class=\"n\">s</span><span class=\"o\">)</span>\n\n<span class=\"n\">________________________________________________________</span>\n<span class=\"n\">Executed</span> <span class=\"k\">in</span>  <span class=\"mi\">178</span><span class=\"bp\">.</span><span class=\"mi\">09</span> <span class=\"n\">secs</span>    <span class=\"n\">fish</span>           <span class=\"n\">external</span>\n   <span class=\"n\">usr</span> <span class=\"n\">time</span>   <span class=\"mi\">20</span><span class=\"bp\">.</span><span class=\"mi\">99</span> <span class=\"n\">secs</span>    <span class=\"mi\">0</span><span class=\"bp\">.</span><span class=\"mi\">00</span> <span class=\"n\">micros</span>   <span class=\"mi\">20</span><span class=\"bp\">.</span><span class=\"mi\">99</span> <span class=\"n\">secs</span>\n   <span class=\"n\">sys</span> <span class=\"n\">time</span>   <span class=\"mi\">19</span><span class=\"bp\">.</span><span class=\"mi\">61</span> <span class=\"n\">secs</span>  <span class=\"mi\">374</span><span class=\"bp\">.</span><span class=\"mi\">00</span> <span class=\"n\">micros</span>   <span class=\"mi\">19</span><span class=\"bp\">.</span><span class=\"mi\">60</span> <span class=\"n\">secs</span>\n</code></pre></div>",
        "id": 345354845,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1680085314
    },
    {
        "content": "<p>that is for downloading today's mathlib master</p>",
        "id": 345354950,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1680085338
    },
    {
        "content": "<p>run no. 2 is indeed a bit faster:</p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"n\">Executed</span> <span class=\"k\">in</span>  <span class=\"mi\">133</span><span class=\"bp\">.</span><span class=\"mi\">16</span> <span class=\"n\">secs</span>    <span class=\"n\">fish</span>           <span class=\"n\">external</span>\n   <span class=\"n\">usr</span> <span class=\"n\">time</span>   <span class=\"mi\">20</span><span class=\"bp\">.</span><span class=\"mi\">35</span> <span class=\"n\">secs</span>  <span class=\"mi\">609</span><span class=\"bp\">.</span><span class=\"mi\">00</span> <span class=\"n\">micros</span>   <span class=\"mi\">20</span><span class=\"bp\">.</span><span class=\"mi\">35</span> <span class=\"n\">secs</span>\n   <span class=\"n\">sys</span> <span class=\"n\">time</span>   <span class=\"mi\">17</span><span class=\"bp\">.</span><span class=\"mi\">46</span> <span class=\"n\">secs</span>    <span class=\"mi\">0</span><span class=\"bp\">.</span><span class=\"mi\">00</span> <span class=\"n\">micros</span>   <span class=\"mi\">17</span><span class=\"bp\">.</span><span class=\"mi\">46</span> <span class=\"n\">secs</span>\n</code></pre></div>",
        "id": 345355915,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1680085604
    },
    {
        "content": "<p>Would it be crazy to use a protocol designed for synchronization (e.g., rsync or whatever <code>azcopy sync</code> uses)?</p>",
        "id": 345388207,
        "sender_full_name": "Mauricio Collares",
        "timestamp": 1680093502
    },
    {
        "content": "<p>Does windows have rsync type of stuff nowadays?</p>",
        "id": 345399395,
        "sender_full_name": "Henrik BÃ¶ving",
        "timestamp": 1680096150
    },
    {
        "content": "<p>Oh, wow.  I didn't realize it was that slow for other people.  (It would be great though if we had numbers for just the downloading part instead of downloading+unpacking combined.)</p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"bp\">$</span> <span class=\"n\">time</span> <span class=\"n\">lake</span> <span class=\"n\">exe</span> <span class=\"n\">cache</span> <span class=\"n\">get</span><span class=\"bp\">!</span>\n<span class=\"n\">Attempting</span> <span class=\"n\">to</span> <span class=\"n\">download</span> <span class=\"mi\">1898</span> <span class=\"n\">file</span><span class=\"o\">(</span><span class=\"n\">s</span><span class=\"o\">)</span>\n<span class=\"n\">Decompressing</span> <span class=\"mi\">1898</span> <span class=\"n\">file</span><span class=\"o\">(</span><span class=\"n\">s</span><span class=\"o\">)</span>\n\n<span class=\"n\">________________________________________________________</span>\n<span class=\"n\">Executed</span> <span class=\"k\">in</span>   <span class=\"mi\">13</span><span class=\"bp\">.</span><span class=\"mi\">72</span> <span class=\"n\">secs</span>    <span class=\"n\">fish</span>           <span class=\"n\">external</span>\n   <span class=\"n\">usr</span> <span class=\"n\">time</span>   <span class=\"mi\">10</span><span class=\"bp\">.</span><span class=\"mi\">96</span> <span class=\"n\">secs</span>    <span class=\"mi\">0</span><span class=\"bp\">.</span><span class=\"mi\">00</span> <span class=\"n\">micros</span>   <span class=\"mi\">10</span><span class=\"bp\">.</span><span class=\"mi\">96</span> <span class=\"n\">secs</span>\n   <span class=\"n\">sys</span> <span class=\"n\">time</span>   <span class=\"mi\">24</span><span class=\"bp\">.</span><span class=\"mi\">94</span> <span class=\"n\">secs</span>  <span class=\"mi\">351</span><span class=\"bp\">.</span><span class=\"mi\">00</span> <span class=\"n\">micros</span>   <span class=\"mi\">24</span><span class=\"bp\">.</span><span class=\"mi\">94</span> <span class=\"n\">secs</span>\n</code></pre></div>",
        "id": 345468256,
        "sender_full_name": "Gabriel Ebner",
        "timestamp": 1680110225
    },
    {
        "content": "<blockquote>\n<p>Would it be crazy to use a protocol designed for synchronization (e.g., rsync or whatever <code>azcopy sync</code> uses)?</p>\n</blockquote>\n<p>I don't think <code>rsync</code> works that well if you have a huge list of small files you want to download (instead of a whole directory).  And I believe <code>azcopy sync</code> uses the same HTTP endpoints that we access via <code>curl</code>.</p>",
        "id": 345468741,
        "sender_full_name": "Gabriel Ebner",
        "timestamp": 1680110369
    },
    {
        "content": "<p>I'd also caution you not to expect any miracles.  All olean caches for mathlib combined are 445 megabytes right now (which is what you test with <code>lake exe cache get!</code>).  Divide this by your connection speed, and you get a lower bound on how quickly you can get them.</p>",
        "id": 345470084,
        "sender_full_name": "Gabriel Ebner",
        "timestamp": 1680110715
    },
    {
        "content": "<p>Doing this back-of-the-envelope calculation, all the results posted here give connection speeds between 30 and 500 mbit/s.  Which is perfectly reasonable, and I don't think we can improve it much using only protocol changes.  The unfortunate truth is that Lean 4 oleans are an order of magnitude more voluminous than their Lean 3 counterparts.</p>",
        "id": 345473919,
        "sender_full_name": "Gabriel Ebner",
        "timestamp": 1680111603
    },
    {
        "content": "<p>I've heard this a few times (oleans getting much bigger) - is that considered an issue that might see improvements in the future or should we assume it's going to remain the case?</p>",
        "id": 345474838,
        "sender_full_name": "Ruben Van de Velde",
        "timestamp": 1680111852
    },
    {
        "content": "<p>Also, are they amenable to compression, either individually or as a group?</p>",
        "id": 345474968,
        "sender_full_name": "Ruben Van de Velde",
        "timestamp": 1680111893
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110043\">Gabriel Ebner</span> <a href=\"#narrow/stream/270676-lean4/topic/curl.20version.20on.20Ubuntu.2020.2E04/near/345473919\">said</a>:</p>\n<blockquote>\n<p>Doing this back-of-the-envelope calculation, all the results posted here give connection speeds between 30 and 500 mbit/s.  Which is perfectly reasonable, and I don't think we can improve it much using only protocol changes.  The unfortunate truth is that Lean 4 oleans are an order of magnitude more voluminous than their Lean 3 counterparts.</p>\n</blockquote>\n<p>This is a really big problem when teaching, giving tutorials, or any other time that you ask new users to install Lean 4 and mathlib4.</p>",
        "id": 345475037,
        "sender_full_name": "Floris van Doorn",
        "timestamp": 1680111911
    },
    {
        "content": "<blockquote>\n<p>Also, are they amenable to compression, either individually or as a group?</p>\n</blockquote>\n<p>We're already compressing them, they'd be 1.4 gigabytes otherwise.</p>",
        "id": 345475786,
        "sender_full_name": "Gabriel Ebner",
        "timestamp": 1680112129
    },
    {
        "content": "<blockquote>\n<p>This is a really big problem when teaching, giving tutorials, or any other time that you ask new users to install Lean 4 and mathlib4.</p>\n</blockquote>\n<p>I can imagine this is expecially bad if a room full of 25 people, with mediocre wifi, all need to download 500mb each at the start of a tutorial</p>",
        "id": 345478749,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1680112839
    },
    {
        "content": "<p>Perhaps this is an argument for more heavily leaning on vscode remote development for teaching, be it via code-spaces, gitpod, or remote access to university servers</p>",
        "id": 345479027,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1680112910
    },
    {
        "content": "<p>Maybe I'll have to write a script the pre-emptively checks out modified branches from github and pulls the oleans, that runs while I'm getting my breakfast. :-)</p>",
        "id": 345521035,
        "sender_full_name": "Scott Morrison",
        "timestamp": 1680126262
    },
    {
        "content": "<p>(I realise this is probably a bad idea, misusing our azure resources.)</p>",
        "id": 345521061,
        "sender_full_name": "Scott Morrison",
        "timestamp": 1680126280
    },
    {
        "content": "<p>You have my official permission to do that. <span aria-label=\"smile\" class=\"emoji emoji-1f642\" role=\"img\" title=\"smile\">:smile:</span>. Just don't do <code>get!</code>. Your productivity is worth more than our Azure bills.  Besides, you're not downloading anything twice.  The branches probably share a lot of common Orleans.</p>",
        "id": 345526212,
        "sender_full_name": "Gabriel Ebner",
        "timestamp": 1680128884
    },
    {
        "content": "<p>How much of a concern is storing and re-downloading identical but differently named olean tars yet? I'm assuming not all that much at this point because people most work on mathlib4 leaves, invalidating few existing modules, and we do not update Lean or other dependencies that often either. But as soon as either of these changes, I believe we should take a serious look at moving towards a content-addressed storage model to potentially save massive amounts of bandwidth. Which could be as simple as replacing the current <code>&lt;input-hash&gt;.tar.gz</code> with a symlink-like text file <code>&lt;input-hash&gt;</code> that contains <code>&lt;output-hash.tar.gz&gt;</code>.</p>",
        "id": 345586343,
        "sender_full_name": "Sebastian Ullrich",
        "timestamp": 1680161568
    },
    {
        "content": "<p>Just to state the maybe-obvious, no work has been done on optimizing the size of Lean 4 .oleans yet, or analyses on the size difference to Lean 3 .oleans. Similarly, we might not be doing a good job yet at avoiding to perturb a .olean's contents on upstream changes, which would affect the efficiency of such a content address model.</p>",
        "id": 345590271,
        "sender_full_name": "Sebastian Ullrich",
        "timestamp": 1680162679
    },
    {
        "content": "<p>The Lean 4 oleans are basically mmapped to build the in-memory environment, right?<br>\nSo if we want to keep doing that, there would be some constraints on the format/size?</p>",
        "id": 345591346,
        "sender_full_name": "Reid Barton",
        "timestamp": 1680162980
    },
    {
        "content": "<p>Yes, the overhead of that is one of the unclear parts. But in theory, the cache could use a completely different representation that we transform from after unpacking, so it would only be disk space and unpacking overhead.</p>",
        "id": 345593314,
        "sender_full_name": "Sebastian Ullrich",
        "timestamp": 1680163489
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110024\">Sebastian Ullrich</span> <a href=\"#narrow/stream/270676-lean4/topic/curl.20version.20on.20Ubuntu.2020.2E04/near/345590271\">said</a>:</p>\n<blockquote>\n<p>Just to state the maybe-obvious, no work has been done on optimizing the size of Lean 4 .oleans yet, or analyses on the size</p>\n</blockquote>\n<p>Now we know a little bit more</p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"n\">array</span>        <span class=\"mi\">526</span><span class=\"bp\">.</span><span class=\"mi\">661</span> <span class=\"o\">(</span>   <span class=\"mi\">1</span><span class=\"bp\">%</span><span class=\"o\">)</span>      <span class=\"mi\">42</span><span class=\"bp\">.</span><span class=\"mi\">704</span><span class=\"bp\">.</span><span class=\"mi\">504</span><span class=\"n\">B</span> <span class=\"o\">(</span>   <span class=\"mi\">3</span><span class=\"bp\">%</span><span class=\"o\">)</span>\n<span class=\"n\">string</span>     <span class=\"mi\">1</span><span class=\"bp\">.</span><span class=\"mi\">148</span><span class=\"bp\">.</span><span class=\"mi\">716</span> <span class=\"o\">(</span>   <span class=\"mi\">3</span><span class=\"bp\">%</span><span class=\"o\">)</span>      <span class=\"mi\">53</span><span class=\"bp\">.</span><span class=\"mi\">699</span><span class=\"bp\">.</span><span class=\"mi\">609</span><span class=\"n\">B</span> <span class=\"o\">(</span>   <span class=\"mi\">4</span><span class=\"bp\">%</span><span class=\"o\">)</span>\n<span class=\"n\">bignum</span>             <span class=\"mi\">1</span> <span class=\"o\">(</span>   <span class=\"mi\">0</span><span class=\"bp\">%</span><span class=\"o\">)</span>              <span class=\"mi\">40</span><span class=\"n\">B</span> <span class=\"o\">(</span>   <span class=\"mi\">0</span><span class=\"bp\">%</span><span class=\"o\">)</span>\n<span class=\"n\">ctor</span>      <span class=\"mi\">35</span><span class=\"bp\">.</span><span class=\"mi\">000</span><span class=\"bp\">.</span><span class=\"mi\">295</span> <span class=\"o\">(</span>  <span class=\"mi\">95</span><span class=\"bp\">%</span><span class=\"o\">)</span>    <span class=\"mi\">1</span><span class=\"bp\">.</span><span class=\"mi\">191</span><span class=\"bp\">.</span><span class=\"mi\">012</span><span class=\"bp\">.</span><span class=\"mi\">032</span><span class=\"n\">B</span> <span class=\"o\">(</span>  <span class=\"mi\">92</span><span class=\"bp\">%</span><span class=\"o\">)</span>\n    <span class=\"n\">tag</span> <span class=\"mi\">0</span>      <span class=\"mi\">3</span><span class=\"bp\">.</span><span class=\"mi\">962</span><span class=\"bp\">.</span><span class=\"mi\">740</span> <span class=\"o\">(</span>  <span class=\"mi\">10</span><span class=\"bp\">%</span><span class=\"o\">)</span>     <span class=\"mi\">128</span><span class=\"bp\">.</span><span class=\"mi\">823</span><span class=\"bp\">.</span><span class=\"mi\">376</span><span class=\"n\">B</span> <span class=\"o\">(</span>  <span class=\"mi\">10</span><span class=\"bp\">%</span><span class=\"o\">)</span>\n    <span class=\"n\">tag</span> <span class=\"mi\">1</span>      <span class=\"mi\">2</span><span class=\"bp\">.</span><span class=\"mi\">658</span><span class=\"bp\">.</span><span class=\"mi\">974</span> <span class=\"o\">(</span>   <span class=\"mi\">7</span><span class=\"bp\">%</span><span class=\"o\">)</span>      <span class=\"mi\">76</span><span class=\"bp\">.</span><span class=\"mi\">023</span><span class=\"bp\">.</span><span class=\"mi\">200</span><span class=\"n\">B</span> <span class=\"o\">(</span>   <span class=\"mi\">5</span><span class=\"bp\">%</span><span class=\"o\">)</span>\n    <span class=\"n\">tag</span> <span class=\"mi\">2</span>        <span class=\"mi\">943</span><span class=\"bp\">.</span><span class=\"mi\">200</span> <span class=\"o\">(</span>   <span class=\"mi\">2</span><span class=\"bp\">%</span><span class=\"o\">)</span>      <span class=\"mi\">28</span><span class=\"bp\">.</span><span class=\"mi\">268</span><span class=\"bp\">.</span><span class=\"mi\">920</span><span class=\"n\">B</span> <span class=\"o\">(</span>   <span class=\"mi\">2</span><span class=\"bp\">%</span><span class=\"o\">)</span>\n    <span class=\"n\">tag</span> <span class=\"mi\">3</span>        <span class=\"mi\">237</span><span class=\"bp\">.</span><span class=\"mi\">476</span> <span class=\"o\">(</span>   <span class=\"mi\">0</span><span class=\"bp\">%</span><span class=\"o\">)</span>       <span class=\"mi\">7</span><span class=\"bp\">.</span><span class=\"mi\">211</span><span class=\"bp\">.</span><span class=\"mi\">992</span><span class=\"n\">B</span> <span class=\"o\">(</span>   <span class=\"mi\">0</span><span class=\"bp\">%</span><span class=\"o\">)</span>\n    <span class=\"n\">tag</span> <span class=\"mi\">4</span>      <span class=\"mi\">1</span><span class=\"bp\">.</span><span class=\"mi\">019</span><span class=\"bp\">.</span><span class=\"mi\">304</span> <span class=\"o\">(</span>   <span class=\"mi\">2</span><span class=\"bp\">%</span><span class=\"o\">)</span>      <span class=\"mi\">31</span><span class=\"bp\">.</span><span class=\"mi\">936</span><span class=\"bp\">.</span><span class=\"mi\">928</span><span class=\"n\">B</span> <span class=\"o\">(</span>   <span class=\"mi\">2</span><span class=\"bp\">%</span><span class=\"o\">)</span>\n    <span class=\"n\">tag</span> <span class=\"mi\">5</span>     <span class=\"mi\">20</span><span class=\"bp\">.</span><span class=\"mi\">710</span><span class=\"bp\">.</span><span class=\"mi\">716</span> <span class=\"o\">(</span>  <span class=\"mi\">56</span><span class=\"bp\">%</span><span class=\"o\">)</span>     <span class=\"mi\">662</span><span class=\"bp\">.</span><span class=\"mi\">427</span><span class=\"bp\">.</span><span class=\"mi\">408</span><span class=\"n\">B</span> <span class=\"o\">(</span>  <span class=\"mi\">51</span><span class=\"bp\">%</span><span class=\"o\">)</span>\n    <span class=\"n\">tag</span> <span class=\"mi\">6</span>      <span class=\"mi\">2</span><span class=\"bp\">.</span><span class=\"mi\">717</span><span class=\"bp\">.</span><span class=\"mi\">678</span> <span class=\"o\">(</span>   <span class=\"mi\">7</span><span class=\"bp\">%</span><span class=\"o\">)</span>     <span class=\"mi\">125</span><span class=\"bp\">.</span><span class=\"mi\">459</span><span class=\"bp\">.</span><span class=\"mi\">136</span><span class=\"n\">B</span> <span class=\"o\">(</span>   <span class=\"mi\">9</span><span class=\"bp\">%</span><span class=\"o\">)</span>\n    <span class=\"n\">tag</span> <span class=\"mi\">7</span>      <span class=\"mi\">1</span><span class=\"bp\">.</span><span class=\"mi\">964</span><span class=\"bp\">.</span><span class=\"mi\">034</span> <span class=\"o\">(</span>   <span class=\"mi\">5</span><span class=\"bp\">%</span><span class=\"o\">)</span>      <span class=\"mi\">91</span><span class=\"bp\">.</span><span class=\"mi\">803</span><span class=\"bp\">.</span><span class=\"mi\">944</span><span class=\"n\">B</span> <span class=\"o\">(</span>   <span class=\"mi\">7</span><span class=\"bp\">%</span><span class=\"o\">)</span>\n    <span class=\"n\">tag</span> <span class=\"mi\">8</span>        <span class=\"mi\">604</span><span class=\"bp\">.</span><span class=\"mi\">649</span> <span class=\"o\">(</span>   <span class=\"mi\">1</span><span class=\"bp\">%</span><span class=\"o\">)</span>      <span class=\"mi\">33</span><span class=\"bp\">.</span><span class=\"mi\">537</span><span class=\"bp\">.</span><span class=\"mi\">784</span><span class=\"n\">B</span> <span class=\"o\">(</span>   <span class=\"mi\">2</span><span class=\"bp\">%</span><span class=\"o\">)</span>\n    <span class=\"n\">tag</span> <span class=\"mi\">9</span>         <span class=\"mi\">17</span><span class=\"bp\">.</span><span class=\"mi\">037</span> <span class=\"o\">(</span>   <span class=\"mi\">0</span><span class=\"bp\">%</span><span class=\"o\">)</span>         <span class=\"mi\">408</span><span class=\"bp\">.</span><span class=\"mi\">888</span><span class=\"n\">B</span> <span class=\"o\">(</span>   <span class=\"mi\">0</span><span class=\"bp\">%</span><span class=\"o\">)</span>\n    <span class=\"n\">tag</span> <span class=\"mi\">10</span>        <span class=\"mi\">81</span><span class=\"bp\">.</span><span class=\"mi\">597</span> <span class=\"o\">(</span>   <span class=\"mi\">0</span><span class=\"bp\">%</span><span class=\"o\">)</span>       <span class=\"mi\">2</span><span class=\"bp\">.</span><span class=\"mi\">823</span><span class=\"bp\">.</span><span class=\"mi\">552</span><span class=\"n\">B</span> <span class=\"o\">(</span>   <span class=\"mi\">0</span><span class=\"bp\">%</span><span class=\"o\">)</span>\n    <span class=\"n\">tag</span> <span class=\"mi\">11</span>        <span class=\"mi\">77</span><span class=\"bp\">.</span><span class=\"mi\">122</span> <span class=\"o\">(</span>   <span class=\"mi\">0</span><span class=\"bp\">%</span><span class=\"o\">)</span>       <span class=\"mi\">2</span><span class=\"bp\">.</span><span class=\"mi\">182</span><span class=\"bp\">.</span><span class=\"mi\">864</span><span class=\"n\">B</span> <span class=\"o\">(</span>   <span class=\"mi\">0</span><span class=\"bp\">%</span><span class=\"o\">)</span>\n    <span class=\"n\">tag</span> <span class=\"mi\">12</span>         <span class=\"mi\">5</span><span class=\"bp\">.</span><span class=\"mi\">768</span> <span class=\"o\">(</span>   <span class=\"mi\">0</span><span class=\"bp\">%</span><span class=\"o\">)</span>         <span class=\"mi\">104</span><span class=\"bp\">.</span><span class=\"mi\">040</span><span class=\"n\">B</span> <span class=\"o\">(</span>   <span class=\"mi\">0</span><span class=\"bp\">%</span><span class=\"o\">)</span>\n<span class=\"n\">total</span>     <span class=\"mi\">36</span><span class=\"bp\">.</span><span class=\"mi\">675</span><span class=\"bp\">.</span><span class=\"mi\">673</span> <span class=\"o\">(</span> <span class=\"mi\">100</span><span class=\"bp\">%</span><span class=\"o\">)</span>    <span class=\"mi\">1</span><span class=\"bp\">.</span><span class=\"mi\">287</span><span class=\"bp\">.</span><span class=\"mi\">416</span><span class=\"bp\">.</span><span class=\"mi\">185</span><span class=\"n\">B</span> <span class=\"o\">(</span> <span class=\"mi\">100</span><span class=\"bp\">%</span><span class=\"o\">)</span>\n\n<span class=\"n\">shared</span> <span class=\"n\">pointers</span>   <span class=\"mi\">39</span><span class=\"bp\">.</span><span class=\"mi\">796</span><span class=\"bp\">.</span><span class=\"mi\">971</span> <span class=\"o\">(</span>  <span class=\"mi\">52</span><span class=\"bp\">%</span><span class=\"o\">)</span>\n<span class=\"n\">lake</span> <span class=\"n\">exe</span> <span class=\"n\">oleanparser</span> <span class=\"bp\">~/</span><span class=\"n\">lean</span><span class=\"bp\">/</span><span class=\"n\">mathlib4</span><span class=\"bp\">/</span><span class=\"n\">build</span><span class=\"bp\">/**/*.</span><span class=\"n\">olean</span> <span class=\"c1\">--stats  46.29s user 0.62s system 99% cpu 47.127 total</span>\n</code></pre></div>\n<p>No low-hanging fruits like \"we included 10MB of strings or empty arrays\" unfortunately. For constructors, the vast majority of objects and bytes, there is no direct type information available, but given that <code>Expr.app</code> has constructor index 5, it's fair to guess that these are mostly <code>Expr</code> objects, which of course is information we cannot directly avoid storing in <em>some</em> form usually.</p>",
        "id": 346228046,
        "sender_full_name": "Sebastian Ullrich",
        "timestamp": 1680368367
    },
    {
        "content": "<p>Not that I'm saying that the .olean format is particularly efficient for storing <code>Expr.app</code>s: we have 8 bytes of object header followed by two 8 byte pointers followed by another 8 bytes of <code>Expr.Data</code> cache. In principle, this information could be packed much more tightly for transporting (which would not even have to be part of core).</p>",
        "id": 346228684,
        "sender_full_name": "Sebastian Ullrich",
        "timestamp": 1680368611
    },
    {
        "content": "<p>Compression achieves some of that space savings automatically, right?</p>",
        "id": 346228840,
        "sender_full_name": "Reid Barton",
        "timestamp": 1680368662
    },
    {
        "content": "<p>I assume there should be quite a lot of sharing among Exprs?</p>",
        "id": 346229087,
        "sender_full_name": "Reid Barton",
        "timestamp": 1680368757
    },
    {
        "content": "<p>We know compression helps quite a bit, but I couldn't say how it would affect such manual optimizations. The redundant headers are probably great for compression, but the cached metadata is more variable.</p>",
        "id": 346229460,
        "sender_full_name": "Sebastian Ullrich",
        "timestamp": 1680368891
    },
    {
        "content": "<p>There are about twice as many pointers as there are objects because of sharing, yes, that's the 52%</p>",
        "id": 346229517,
        "sender_full_name": "Sebastian Ullrich",
        "timestamp": 1680368918
    },
    {
        "content": "<p>It is unclear how to make a more detailed analysis; here is a breakdown of the environment extensions and the constants used by the old compiler for the largest two mathlib4 files</p>\n<div class=\"codehilite\" data-code-language=\"Bash Session\"><pre><span></span><code><span class=\"gp\">$ </span>oleanparser<span class=\"w\"> </span>--env-stats<span class=\"w\"> </span>build/lib/Mathlib/LinearAlgebra/TensorProduct.olean\n<span class=\"go\">objects reachable from</span>\n<span class=\"go\">     282.073 (  72%) old compiler constants</span>\n<span class=\"go\">      36.710 (   9%) Lean.IR.declMapExt</span>\n<span class=\"go\">       9.863 (   2%) Lean.Compiler.LCNF.baseExt</span>\n<span class=\"go\">       6.484 (   1%) Lean.IR.UnreachableBranches.functionSummariesExt</span>\n<span class=\"go\">       5.218 (   1%) Lean.Meta.simpExtension</span>\n<span class=\"go\">       3.786 (   0%) Lean.declRangeExt</span>\n<span class=\"go\">       2.901 (   0%) Lean.Compiler.LCNF.monoExt</span>\n<span class=\"go\">       2.731 (   0%) Lean.namespacesExt</span>\n<span class=\"go\">         649 (   0%) Mathlib.Prelude.Rename.renameExtension</span>\n<span class=\"go\">         588 (   0%) Lean.Compiler.specExtension</span>\n<span class=\"go\">         394 (   0%) Lean.Meta.instanceExtension</span>\n<span class=\"go\">         347 (   0%) Lean.Compiler.LCNF.specExtension</span>\n<span class=\"go\">         169 (   0%) Lean.Compiler.LCNF.UnreachableBranches.functionSummariesExt</span>\n<span class=\"go\">         169 (   0%) Lean.docStringExt</span>\n<span class=\"go\">          67 (   0%) Std.Tactic.Lint.stdLinterExt</span>\n<span class=\"go\">          61 (   0%) Lean.Meta.globalInstanceExtension</span>\n<span class=\"go\">          50 (   0%) Lean.Parser.parserExtension</span>\n<span class=\"go\">          49 (   0%) Lean.Meta.Match.Extension.extension</span>\n<span class=\"go\">          41 (   0%) Lean.protectedExt</span>\n<span class=\"go\">          29 (   0%) Lean.reducibilityAttrs</span>\n<span class=\"go\">          27 (   0%) Lean.Elab.macroAttribute</span>\n<span class=\"go\">          24 (   0%) Lean.Compiler.inlineAttrs</span>\n<span class=\"go\">          15 (   0%) Lean.structureExt</span>\n<span class=\"go\">          13 (   0%) Lean.projectionFnInfoExt</span>\n<span class=\"go\">          13 (   0%) Lean.PrettyPrinter.Delaborator.appUnexpanderAttribute</span>\n<span class=\"go\">          13 (   0%) Lean.auxRecExt</span>\n<span class=\"go\">          11 (   0%) Lean.moduleDocExt</span>\n<span class=\"go\">           7 (   0%) Lean.classExtension</span>\n<span class=\"go\">           7 (   0%) Lean.noConfusionExt</span>\n<span class=\"go\">           7 (   0%) Lean.Server.Completion.completionBlackListExt</span>\n<span class=\"go\">           5 (   0%) Lean.Elab.Term.elabAsElim</span>\n<span class=\"gp\">$ </span>oleanparser<span class=\"w\"> </span>--env-stats<span class=\"w\"> </span>build/lib/Mathlib/Tactic/Ring/Basic.olean\n<span class=\"go\">objects reachable from</span>\n<span class=\"go\">     200.570 (  62%) Lean.IR.declMapExt</span>\n<span class=\"go\">     117.781 (  36%) old compiler constants</span>\n<span class=\"go\">      49.448 (  15%) Lean.Compiler.LCNF.baseExt</span>\n<span class=\"go\">      41.720 (  13%) Lean.Compiler.LCNF.monoExt</span>\n<span class=\"go\">       7.280 (   2%) Lean.Elab.Structural.eqnInfoExt</span>\n<span class=\"go\">       3.238 (   1%) Lean.declRangeExt</span>\n<span class=\"go\">       2.793 (   0%) Lean.IR.UnreachableBranches.functionSummariesExt</span>\n<span class=\"go\">       1.036 (   0%) Lean.namespacesExt</span>\n<span class=\"go\">         940 (   0%) Lean.Compiler.specExtension</span>\n<span class=\"go\">         842 (   0%) Lean.Meta.simpExtension</span>\n<span class=\"go\">         790 (   0%) Lean.Compiler.LCNF.UnreachableBranches.functionSummariesExt</span>\n<span class=\"go\">         693 (   0%) Lean.Compiler.LCNF.Specialize.specCacheExt</span>\n<span class=\"go\">         494 (   0%) Lean.Meta.Match.Extension.extension</span>\n<span class=\"go\">         329 (   0%) Lean.Compiler.inlineAttrs</span>\n<span class=\"go\">         304 (   0%) Lean.docStringExt</span>\n<span class=\"go\">         196 (   0%) Lean.Meta.instanceExtension</span>\n<span class=\"go\">         189 (   0%) Lean.reducibilityAttrs</span>\n<span class=\"go\">          92 (   0%) Lean.structureExt</span>\n<span class=\"go\">          77 (   0%) Lean.projectionFnInfoExt</span>\n<span class=\"go\">          69 (   0%) Lean.protectedExt</span>\n<span class=\"go\">          67 (   0%) Std.Tactic.Lint.stdLinterExt</span>\n<span class=\"go\">          51 (   0%) Lean.Parser.parserExtension</span>\n<span class=\"go\">          48 (   0%) Lean.Meta.globalInstanceExtension</span>\n<span class=\"go\">          45 (   0%) Lean.auxRecExt</span>\n<span class=\"go\">          37 (   0%) Lean.Server.Completion.completionBlackListExt</span>\n<span class=\"go\">          29 (   0%) Lean.noConfusionExt</span>\n<span class=\"go\">          23 (   0%) Lean.regularInitAttr</span>\n<span class=\"go\">          13 (   0%) Lean.Elab.macroAttribute</span>\n<span class=\"go\">          13 (   0%) Lean.Elab.Tactic.tacticElabAttribute</span>\n<span class=\"go\">          11 (   0%) Lean.moduleDocExt</span>\n</code></pre></div>\n<p>(note that these categories are not necessarily disjoint with each other and the rest of the environment because of sharing)<br>\nFor TensorProduct there is some unfortunate code duplication from specialization in the old compiler, but the new compiler looks much better.<br>\nCuriously there are some smaller files where the analysis takes much longer despite the reachable objects closures being smaller, so I don't have number for all of mathlib4 yet.</p>",
        "id": 346253220,
        "sender_full_name": "Sebastian Ullrich",
        "timestamp": 1680382377
    },
    {
        "content": "<p>Do you try somehow (maybe by a collection step before writing out the data) to ensure some degree of locality for the pointers?</p>",
        "id": 346254631,
        "sender_full_name": "Reid Barton",
        "timestamp": 1680383323
    },
    {
        "content": "<p>Yes of course, there are no gaps between objects except for 8-byte alignment. And everything is maximally shared.</p>",
        "id": 346255205,
        "sender_full_name": "Sebastian Ullrich",
        "timestamp": 1680383756
    },
    {
        "content": "<p>I mean, if you have part of the data that is structured like a linked list, then the consecutive elements in the list should appear consecutively in memory, as far as is possible</p>",
        "id": 346256162,
        "sender_full_name": "Reid Barton",
        "timestamp": 1680384406
    },
    {
        "content": "<p>Ah, the post-order traversal with sharing naturally leads to some locality, but otherwise the system has no idea about what kind of data it is writing to disk</p>",
        "id": 346257054,
        "sender_full_name": "Sebastian Ullrich",
        "timestamp": 1680385119
    },
    {
        "content": "<p>In a custom transport format it might even make sense to implement n-ary applications even if it destroys some sharing</p>",
        "id": 346257185,
        "sender_full_name": "Sebastian Ullrich",
        "timestamp": 1680385219
    }
]