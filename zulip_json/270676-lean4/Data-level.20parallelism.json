[
    {
        "content": "<p>Is there anything out there for data-level parallelism? E.g. some kind of parallel map (map/reduce style) or similar? The way I've found so far is to use <code>Task</code>, which from <a href=\"#narrow/stream/270676-lean4/topic/Another.20IO.20Task.20question\">this discussion</a> sounds like it would be a lot of overhead to spawn a new task for every single computation in a <code>map</code>.</p>",
        "id": 291835439,
        "sender_full_name": "Andrés Goens",
        "timestamp": 1659526537
    },
    {
        "content": "<p>That's a pretty long thread, can you be more specific?</p>",
        "id": 291835991,
        "sender_full_name": "Sebastian Ullrich",
        "timestamp": 1659526819
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110024\">Sebastian Ullrich</span> <a href=\"#narrow/stream/270676-lean4/topic/Data-level.20parallelism/near/291835991\">said</a>:</p>\n<blockquote>\n<p>That's a pretty long thread, can you be more specific?</p>\n</blockquote>\n<p>Haha, indeed it is! I can try to be more specific: From the discussion it seems that if we have n <code>Task</code>s, then the runtime system will spawn <code>n</code> worker threads. My first thought was (without testing it though) that this would not be very efficient if we wanted to run a computation (like a <code>map</code>) on a very large <code>Array</code>, as the overhead of spawning a new thread for every value would not be worth it. Is that wrong, e.g. does the runtime system not spawn OS threads for that but rather be much more lightweight and it might be worth it?</p>\n<p>There's obviously other ways around this otherwise, like splitting the computation manually into m <code>Task</code>s, but I wanted to ask if there was any code out there that had done something like this</p>",
        "id": 291836979,
        "sender_full_name": "Andrés Goens",
        "timestamp": 1659527382
    },
    {
        "content": "<p>That's not true, non-dedicated tasks (the default) are backed by a thread pool bounded by the number of hardware threads</p>",
        "id": 291837297,
        "sender_full_name": "Sebastian Ullrich",
        "timestamp": 1659527543
    },
    {
        "content": "<p>for the collections library, I plan to implement parallelized versions of map/whatever that chunk the data appropriately to minimize the overhead; I think even with a dedicated thread pool you'd want some granularity</p>",
        "id": 291841879,
        "sender_full_name": "James Gallicchio",
        "timestamp": 1659530054
    },
    {
        "content": "<p>(but, very happy to hear that the overhead will not be the same as spawning a system thread)</p>",
        "id": 291841954,
        "sender_full_name": "James Gallicchio",
        "timestamp": 1659530097
    },
    {
        "content": "<p>Curious: is there a <code>Channel</code> abstraction to go with <code>Task</code>?</p>",
        "id": 291850103,
        "sender_full_name": "Yuri de Wit",
        "timestamp": 1659533685
    },
    {
        "content": "<p>For future reference, I did some experimenting/measuring around and the performance is pretty decent even for a lot of threads and small-ish computation! Here's a version of this naive parallel map that I described</p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"kd\">def</span> <span class=\"n\">parallelMap</span> <span class=\"o\">:</span> <span class=\"o\">(</span><span class=\"n\">α</span> <span class=\"bp\">→</span> <span class=\"n\">β</span><span class=\"o\">)</span> <span class=\"bp\">→</span> <span class=\"n\">Array</span> <span class=\"n\">α</span> <span class=\"bp\">→</span> <span class=\"n\">IO</span> <span class=\"o\">(</span><span class=\"n\">Array</span> <span class=\"n\">β</span><span class=\"o\">)</span>\n  <span class=\"bp\">|</span> <span class=\"n\">f</span><span class=\"o\">,</span> <span class=\"n\">as</span> <span class=\"bp\">=&gt;</span>\n  <span class=\"k\">let</span> <span class=\"n\">ts</span> <span class=\"o\">:=</span> <span class=\"n\">as.map</span> <span class=\"bp\">λ</span> <span class=\"n\">a</span> <span class=\"bp\">=&gt;</span> <span class=\"n\">Task.spawn</span> <span class=\"o\">(</span><span class=\"bp\">λ</span> <span class=\"n\">_</span> <span class=\"bp\">=&gt;</span> <span class=\"n\">f</span> <span class=\"n\">a</span><span class=\"o\">)</span><span class=\"bp\">;</span>\n  <span class=\"k\">let</span> <span class=\"n\">rs</span> <span class=\"o\">:=</span> <span class=\"n\">ts.map</span> <span class=\"n\">Task.get</span><span class=\"bp\">;</span>\n<span class=\"n\">return</span> <span class=\"n\">rs</span>\n</code></pre></div>\n<p>Using that I tested the following setup on an x86 machine with 24 HW threads and compared the two variants:</p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"kd\">def</span> <span class=\"n\">someComputation</span> <span class=\"o\">:</span> <span class=\"n\">Nat</span> <span class=\"bp\">→</span> <span class=\"n\">Nat</span>\n <span class=\"bp\">|</span> <span class=\"n\">n</span> <span class=\"bp\">=&gt;</span> <span class=\"n\">List.range</span> <span class=\"n\">n</span> <span class=\"bp\">|&gt;.</span><span class=\"n\">foldl</span> <span class=\"o\">(</span><span class=\"n\">init</span> <span class=\"o\">:=</span> <span class=\"mi\">42</span><span class=\"o\">)</span> <span class=\"o\">(</span><span class=\"bp\">λ</span> <span class=\"n\">x</span> <span class=\"n\">y</span> <span class=\"bp\">=&gt;</span> <span class=\"o\">(</span><span class=\"n\">x</span><span class=\"bp\">+</span><span class=\"mi\">1</span><span class=\"o\">)</span> <span class=\"bp\">*</span> <span class=\"o\">(</span><span class=\"n\">y</span><span class=\"bp\">+</span><span class=\"mi\">1</span><span class=\"o\">))</span>\n\n<span class=\"kd\">def</span> <span class=\"n\">main</span> <span class=\"o\">:</span> <span class=\"n\">IO</span> <span class=\"n\">Unit</span> <span class=\"o\">:=</span> <span class=\"k\">do</span>\n  <span class=\"k\">let</span> <span class=\"n\">foo</span> <span class=\"o\">:=</span> <span class=\"n\">List.range</span> <span class=\"mi\">10000</span> <span class=\"bp\">|&gt;.</span><span class=\"n\">toArray</span> <span class=\"bp\">|&gt;.</span><span class=\"n\">map</span> <span class=\"n\">someComputation</span>\n  <span class=\"c\">/-</span><span class=\"cm\"></span>\n<span class=\"cm\">  real  1m21.293s</span>\n<span class=\"cm\">  user  1m21.244s</span>\n<span class=\"cm\">  sys   0m0.036s</span>\n<span class=\"cm\">  -/</span>\n  <span class=\"k\">let</span> <span class=\"n\">foo</span> <span class=\"bp\">&lt;-</span> <span class=\"n\">List.range</span> <span class=\"mi\">10000</span> <span class=\"bp\">|&gt;.</span><span class=\"n\">toArray</span> <span class=\"bp\">|&gt;</span> <span class=\"n\">parallelMap</span> <span class=\"n\">someComputation</span>\n  <span class=\"c\">/-</span><span class=\"cm\"></span>\n<span class=\"cm\">  real  0m6.240s</span>\n<span class=\"cm\">  user  2m22.260s</span>\n<span class=\"cm\">  sys   0m0.372s</span>\n<span class=\"cm\">  -/</span>\n  <span class=\"n\">IO.println</span> <span class=\"n\">s</span><span class=\"bp\">!</span><span class=\"s2\">\"res: {foo.size}\"</span>\n</code></pre></div>\n<p>That's a speedup of almost 14x (in a 24 thread machine, for this compute-bound problem we can probably think of HW threads as cores), which is surprisingly good.  Or put differently, there's factor ~1.7 in terms of CPU (user) time, which for this embarrassingly parallel problem should roughly correspond to the thread overhead (of ~70%).  With a nicely chunked version like <span class=\"user-mention\" data-user-id=\"407274\">@James Gallicchio</span> 's upcoming one this should be even better <span aria-label=\"wink\" class=\"emoji emoji-1f609\" role=\"img\" title=\"wink\">:wink:</span></p>",
        "id": 291882928,
        "sender_full_name": "Andrés Goens",
        "timestamp": 1659547173
    },
    {
        "content": "<p>Would it be possible to have <code>parallelMap</code> outside of <code>IO</code> monad? And other parallel algorithms too? If you are careful, you can make sure they are fully deterministic i.e. the result does not depend on the order of thread execution.</p>",
        "id": 291979742,
        "sender_full_name": "Tomas Skrivan",
        "timestamp": 1659602337
    },
    {
        "content": "<p>It does look like the code is using the monad for <code>return</code> only :) ...</p>",
        "id": 291979891,
        "sender_full_name": "Sebastian Ullrich",
        "timestamp": 1659602415
    },
    {
        "content": "<p>For the sake of completeness, the main optimization we're currently missing regarding task overhead is local queues with work stealing. All scheduling inside the current thread pool goes through a big global mutex.</p>",
        "id": 291980128,
        "sender_full_name": "Sebastian Ullrich",
        "timestamp": 1659602604
    },
    {
        "content": "<p>Oh, I've no idea why I thought <code>Task</code> lived in <code>IO</code>,  just dropping them works indeed, thanks for that observation!</p>",
        "id": 291980141,
        "sender_full_name": "Andrés Goens",
        "timestamp": 1659602619
    },
    {
        "content": "<p>Ohh I also thought that <code>Task</code> lives in <code>IO</code> :)</p>",
        "id": 291980392,
        "sender_full_name": "Tomas Skrivan",
        "timestamp": 1659602773
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"463095\">Yuri de Wit</span> <a href=\"#narrow/stream/270676-lean4/topic/Data-level.20parallelism/near/291850103\">said</a>:</p>\n<blockquote>\n<p>Curious: is there a <code>Channel</code> abstraction to go with <code>Task</code>?</p>\n</blockquote>\n<p>Soon.. <a href=\"https://github.com/gebner/lean4/blob/10983d956cca532fcd3bdd6e7cd30ee1b87532de/src/Lean/Mutex.lean\">https://github.com/gebner/lean4/blob/10983d956cca532fcd3bdd6e7cd30ee1b87532de/src/Lean/Mutex.lean</a></p>",
        "id": 291984410,
        "sender_full_name": "Gabriel Ebner",
        "timestamp": 1659605484
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"110043\">@Gabriel Ebner</span> re: <code>Mutex.lean</code>, a notice a few patterns (?) I don't understand.</p>\n<p>Consider:</p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"kn\">private</span> <span class=\"n\">opaque</span> <span class=\"n\">BaseMutexImpl</span> <span class=\"o\">:</span> <span class=\"n\">NonemptyType.</span><span class=\"o\">{</span><span class=\"mi\">0</span><span class=\"o\">}</span>\n\n<span class=\"kd\">def</span> <span class=\"n\">BaseMutex</span> <span class=\"o\">:</span> <span class=\"kt\">Type</span> <span class=\"o\">:=</span> <span class=\"n\">BaseMutexImpl.type</span>\n</code></pre></div>\n<ol>\n<li>What is <code>BaseMutexImpl.type</code>? It seems that elaboration is adding this to the environment when using opaque, but why?</li>\n<li>Why the indirection from <code>BaseMutex</code> to <code>BaseMutexImpl.type</code>? The same is used in Condvar.</li>\n<li>I see that BaseMutexImpl is generated as a lean_box(0): is this just so it can be threaded through the API calls like \"World\" is in main?</li>\n</ol>\n<p>(sorry for the tangent in this thread)</p>",
        "id": 292031343,
        "sender_full_name": "Yuri de Wit",
        "timestamp": 1659630207
    },
    {
        "content": "<p>That's just the boilerplate required for FFI types.  What <code>opaque BaseMutexImpl : NonemptyType</code> does is declare a constant of type <code>{ α : Type // Nonempty α }</code>, i.e. a type about which we only know a single thing, namely that it is nonempty.  (We need this so that we can declare <code>opaque BaseMutex.new : BaseIO BaseMutex</code> later: for consistency Lean needs to check that <code>BaseIO BaseMutex</code> is nonempty, which is only true if <code>BaseMutex</code> is nonempty.)</p>",
        "id": 292046032,
        "sender_full_name": "Gabriel Ebner",
        "timestamp": 1659635354
    },
    {
        "content": "<p>The reason why we don't write <code>opaque BaseMutex : NonemptyType</code> is because we don't want to see/type <code>BaseMutex.type</code> afterwards.</p>",
        "id": 292046089,
        "sender_full_name": "Gabriel Ebner",
        "timestamp": 1659635385
    },
    {
        "content": "<blockquote>\n<p>I see that BaseMutexImpl is generated as a lean_box(0)</p>\n</blockquote>\n<p>This is true for every type, and it's called erasure.  For example if you write <code>def foo := (Nat, 42)</code> then the first component will also be the scalar value 0 (which is generated with the C code <code>lean_box(0)</code>).</p>",
        "id": 292046369,
        "sender_full_name": "Gabriel Ebner",
        "timestamp": 1659635521
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110043\">Gabriel Ebner</span> <a href=\"#narrow/stream/270676-lean4/topic/Data-level.20parallelism/near/292046369\">said</a>:</p>\n<blockquote>\n<blockquote>\n<p>I see that BaseMutexImpl is generated as a lean_box(0)</p>\n</blockquote>\n<p>This is true for every type, and it's called erasure.  For example if you write <code>def foo := (Nat, 42)</code> then the first component will also be the scalar value 0 (which is generated with the C code <code>lean_box(0)</code>).</p>\n</blockquote>\n<p>Ok. So there is still a tuple with two slots at runtime. It is just that the first one will be lean_object(0)? I was naively assuming that erasure meant that it would completely disappear from the runtime (e.g. a function with 2 parameters where one param is erased would become a function with 1 parameter at runtime).</p>",
        "id": 292047349,
        "sender_full_name": "Yuri de Wit",
        "timestamp": 1659635976
    },
    {
        "content": "<p>No, the memory representation of an inductive does not depend on the parameter (<code>Prod α β</code> has the same memory representation no matter what <code>α</code> and <code>β</code> are).  Otherwise you'd run into huge and ugly issues with polymorphism.  (Should <code>def blah : α × β → α</code> be compiled differently depending on <code>α</code>/<code>β</code>, or get a flag?  And what about <code>def hmm : (α : Type) × (α × Nat) → Nat := fun ⟨_, _, n⟩ =&gt; n</code>?)</p>",
        "id": 292048566,
        "sender_full_name": "Gabriel Ebner",
        "timestamp": 1659636540
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"315434\">Andrés Goens</span> <a href=\"#narrow/stream/270676-lean4/topic/Data-level.20parallelism/near/291882928\">said</a>:</p>\n<blockquote>\n<p>For future reference, I did some experimenting/measuring around and the performance is pretty decent even for a lot of threads and small-ish computation! Here's a version of this naive parallel map that I described</p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"kd\">def</span> <span class=\"n\">parallelMap</span> <span class=\"o\">:</span> <span class=\"o\">(</span><span class=\"n\">α</span> <span class=\"bp\">→</span> <span class=\"n\">β</span><span class=\"o\">)</span> <span class=\"bp\">→</span> <span class=\"n\">Array</span> <span class=\"n\">α</span> <span class=\"bp\">→</span> <span class=\"n\">IO</span> <span class=\"o\">(</span><span class=\"n\">Array</span> <span class=\"n\">β</span><span class=\"o\">)</span>\n  <span class=\"bp\">|</span> <span class=\"n\">f</span><span class=\"o\">,</span> <span class=\"n\">as</span> <span class=\"bp\">=&gt;</span>\n  <span class=\"k\">let</span> <span class=\"n\">ts</span> <span class=\"o\">:=</span> <span class=\"n\">as.map</span> <span class=\"bp\">λ</span> <span class=\"n\">a</span> <span class=\"bp\">=&gt;</span> <span class=\"n\">Task.spawn</span> <span class=\"o\">(</span><span class=\"bp\">λ</span> <span class=\"n\">_</span> <span class=\"bp\">=&gt;</span> <span class=\"n\">f</span> <span class=\"n\">a</span><span class=\"o\">)</span><span class=\"bp\">;</span>\n  <span class=\"k\">let</span> <span class=\"n\">rs</span> <span class=\"o\">:=</span> <span class=\"n\">ts.map</span> <span class=\"n\">Task.get</span><span class=\"bp\">;</span>\n<span class=\"n\">return</span> <span class=\"n\">rs</span>\n</code></pre></div>\n<p>Using that I tested the following setup on an x86 machine with 24 HW threads and compared the two variants:</p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"kd\">def</span> <span class=\"n\">someComputation</span> <span class=\"o\">:</span> <span class=\"n\">Nat</span> <span class=\"bp\">→</span> <span class=\"n\">Nat</span>\n <span class=\"bp\">|</span> <span class=\"n\">n</span> <span class=\"bp\">=&gt;</span> <span class=\"n\">List.range</span> <span class=\"n\">n</span> <span class=\"bp\">|&gt;.</span><span class=\"n\">foldl</span> <span class=\"o\">(</span><span class=\"n\">init</span> <span class=\"o\">:=</span> <span class=\"mi\">42</span><span class=\"o\">)</span> <span class=\"o\">(</span><span class=\"bp\">λ</span> <span class=\"n\">x</span> <span class=\"n\">y</span> <span class=\"bp\">=&gt;</span> <span class=\"o\">(</span><span class=\"n\">x</span><span class=\"bp\">+</span><span class=\"mi\">1</span><span class=\"o\">)</span> <span class=\"bp\">*</span> <span class=\"o\">(</span><span class=\"n\">y</span><span class=\"bp\">+</span><span class=\"mi\">1</span><span class=\"o\">))</span>\n\n<span class=\"kd\">def</span> <span class=\"n\">main</span> <span class=\"o\">:</span> <span class=\"n\">IO</span> <span class=\"n\">Unit</span> <span class=\"o\">:=</span> <span class=\"k\">do</span>\n  <span class=\"k\">let</span> <span class=\"n\">foo</span> <span class=\"o\">:=</span> <span class=\"n\">List.range</span> <span class=\"mi\">10000</span> <span class=\"bp\">|&gt;.</span><span class=\"n\">toArray</span> <span class=\"bp\">|&gt;.</span><span class=\"n\">map</span> <span class=\"n\">someComputation</span>\n  <span class=\"c\">/-</span>\n<span class=\"cm\">  real  1m21.293s</span>\n<span class=\"cm\">  user  1m21.244s</span>\n<span class=\"cm\">  sys   0m0.036s</span>\n<span class=\"cm\">  -/</span>\n  <span class=\"k\">let</span> <span class=\"n\">foo</span> <span class=\"bp\">&lt;-</span> <span class=\"n\">List.range</span> <span class=\"mi\">10000</span> <span class=\"bp\">|&gt;.</span><span class=\"n\">toArray</span> <span class=\"bp\">|&gt;</span> <span class=\"n\">parallelMap</span> <span class=\"n\">someComputation</span>\n  <span class=\"c\">/-</span>\n<span class=\"cm\">  real  0m6.240s</span>\n<span class=\"cm\">  user  2m22.260s</span>\n<span class=\"cm\">  sys   0m0.372s</span>\n<span class=\"cm\">  -/</span>\n  <span class=\"n\">IO.println</span> <span class=\"n\">s</span><span class=\"bp\">!</span><span class=\"s2\">\"res: {foo.size}\"</span>\n</code></pre></div>\n<p>That's a speedup of almost 14x (in a 24 thread machine, for this compute-bound problem we can probably think of HW threads as cores), which is surprisingly good.  Or put differently, there's factor ~1.7 in terms of CPU (user) time, which for this embarrassingly parallel problem should roughly correspond to the thread overhead (of ~70%).  With a nicely chunked version like <span class=\"user-mention silent\" data-user-id=\"407274\">James Gallicchio</span> 's upcoming one this should be even better <span aria-label=\"wink\" class=\"emoji emoji-1f609\" role=\"img\" title=\"wink\">:wink:</span></p>\n</blockquote>\n<p>I tried a variation of this program and discovered a bug in the current build (<a href=\"https://github.com/leanprover/lean4/issues/2208\">https://github.com/leanprover/lean4/issues/2208</a>). But it's exciting to see how well Lean's parallelism scales (on 128 threads) when it happens.</p>",
        "id": 356235443,
        "sender_full_name": "Phil Nguyen",
        "timestamp": 1683360401
    },
    {
        "content": "<p>How feasible would it be to write a parallel map that splits the array into chunks and runs map on each chunk in a separate thread?</p>\n<p>This should be done inplace, when you allow for copying then it is easy to implement.</p>",
        "id": 356330268,
        "sender_full_name": "Tomas Skrivan",
        "timestamp": 1683387397
    },
    {
        "content": "<p>I don't think it is possible without a C wrapper. All in-place array ops require that the array is unshared and owned by the calling thread</p>",
        "id": 356331211,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1683387736
    },
    {
        "content": "<p>Yeah that is what I thought. I just wondering if there is some unsafe hackery that would allow me to get around it.</p>",
        "id": 356332395,
        "sender_full_name": "Tomas Skrivan",
        "timestamp": 1683388109
    },
    {
        "content": "<p>I wouldn't recommend it, any unsafe hackery on the lean side would have to play well with the reference counting system and I don't think this application can</p>",
        "id": 356333064,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1683388324
    },
    {
        "content": "<p>better to do the unsafe hackery in C</p>",
        "id": 356333096,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1683388342
    },
    {
        "content": "<p>(at least, until we have linear type annotations in Lean <span aria-label=\"wink\" class=\"emoji emoji-1f609\" role=\"img\" title=\"wink\">:wink:</span>)</p>",
        "id": 356333179,
        "sender_full_name": "James Gallicchio",
        "timestamp": 1683388370
    },
    {
        "content": "<p>I'm not sure that would help, the array is actually shared here</p>",
        "id": 356333252,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1683388399
    },
    {
        "content": "<p>this is like trying to implement <code>split_at_mut</code> in safe rust</p>",
        "id": 356333312,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1683388418
    },
    {
        "content": "<p>the only thing that is preventing things from crashing and burning is the promise that the threads will not reach outside of their subarray (despite having access to do so)</p>",
        "id": 356333522,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1683388474
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110049\">Mario Carneiro</span> <a href=\"#narrow/stream/270676-lean4/topic/Data-level.20parallelism/near/356333522\">said</a>:</p>\n<blockquote>\n<p>the only thing that is preventing things from crashing and burning is the promise that the threads will not reach outside of their subarray (despite having access to do so)</p>\n</blockquote>\n<p>but we can enforce the bounds with some dependent type hackery, no? The underlying array type can be an array pointer along with a predicate on the indices that says whether you own each element; the <code>get</code> method requires proof you own the index; there's a <code>split</code> and <code>join</code> that are no-ops but which ensure you split/join ownership safely</p>",
        "id": 356334273,
        "sender_full_name": "James Gallicchio",
        "timestamp": 1683388745
    },
    {
        "content": "<p>(I will read about split_at_mut in rust, though)</p>",
        "id": 356334385,
        "sender_full_name": "James Gallicchio",
        "timestamp": 1683388791
    },
    {
        "content": "<blockquote>\n<p>but we can enforce the bounds with some dependent type hackery, no?</p>\n</blockquote>\n<p>Yes, but the dependent type system doesn't play well with the refcount reasoning (exactly because we don't have a linear type system)</p>",
        "id": 356334713,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1683388888
    },
    {
        "content": "<p>it's not obvious to me how you would type the functions even if there were linear annotations though</p>",
        "id": 356334839,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1683388926
    },
    {
        "content": "<blockquote>\n<p>along with a predicate on the indices that says whether you own each element</p>\n</blockquote>\n<p>ownership isn't a predicate, because it has to be linear and proofs of predicates can be copied</p>",
        "id": 356334951,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1683388983
    },
    {
        "content": "<p>I was thinking about having a monad parameterized by the index bounds  of each subarray and providing setting and getting elements. You would not have an access to any Array/Subarray object.</p>",
        "id": 356334962,
        "sender_full_name": "Tomas Skrivan",
        "timestamp": 1683388986
    },
    {
        "content": "<p>and then the primitive would be to combine two such monadic computations if their bounds are contiguous/disjoint?</p>",
        "id": 356335508,
        "sender_full_name": "James Gallicchio",
        "timestamp": 1683389092
    },
    {
        "content": "<p>I think you could do it with a wrapper around <code>Array</code> written in C (which acquires unique access to the array on construction), and you can call a function to split it into pieces (handles to the same array object but with known subarray bounds), and each piece is separately ref-counted and can do in-place mutation when the piece is uniquely owned</p>",
        "id": 356335719,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1683389172
    },
    {
        "content": "<p>I was thinking more of parallelMap that splits array into chunks and you can modify each chunk by providing a function in that monad.</p>",
        "id": 356335753,
        "sender_full_name": "Tomas Skrivan",
        "timestamp": 1683389184
    },
    {
        "content": "<p><code>parallelMap</code> is the high level interface, which could be built on top</p>",
        "id": 356335840,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1683389211
    },
    {
        "content": "<p>Maybe I should have said <code>parallelMapChunk</code> or something like that.</p>",
        "id": 356336016,
        "sender_full_name": "Tomas Skrivan",
        "timestamp": 1683389269
    },
    {
        "content": "<p>here's a plausible interface:</p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"sd\">/-- A slice of an array, similar to `Subarray A` but more opaque -/</span>\n<span class=\"n\">opaque</span> <span class=\"n\">ArrayChunk</span> <span class=\"o\">(</span><span class=\"n\">A</span> <span class=\"o\">:</span> <span class=\"kt\">Type</span> <span class=\"n\">u</span><span class=\"o\">)</span> <span class=\"o\">:</span> <span class=\"kt\">Type</span> <span class=\"n\">u</span>\n<span class=\"sd\">/-- Consumes the array and returns an `ArrayChunk` spanning the whole array -/</span>\n<span class=\"n\">opaque</span> <span class=\"n\">ArrayChunk.mk</span> <span class=\"o\">:</span> <span class=\"n\">Array</span> <span class=\"n\">A</span> <span class=\"bp\">-&gt;</span> <span class=\"n\">ArrayChunk</span> <span class=\"n\">A</span>\n<span class=\"sd\">/-- The number of elements in this chunk -/</span>\n<span class=\"n\">opaque</span> <span class=\"n\">ArrayChunk.size</span> <span class=\"o\">:</span> <span class=\"n\">ArrayChunk</span> <span class=\"n\">A</span> <span class=\"bp\">-&gt;</span> <span class=\"n\">Nat</span>\n<span class=\"sd\">/-- Consumes the `ArrayChunk` and returns pieces split at index `n` -/</span>\n<span class=\"n\">opaque</span> <span class=\"n\">ArrayChunk.splitAt</span> <span class=\"o\">(</span><span class=\"n\">n</span> <span class=\"o\">:</span> <span class=\"n\">Nat</span><span class=\"o\">)</span> <span class=\"o\">:</span> <span class=\"n\">ArrayChunk</span> <span class=\"n\">A</span> <span class=\"bp\">-&gt;</span> <span class=\"n\">ArrayChunk</span> <span class=\"n\">A</span> <span class=\"bp\">×</span> <span class=\"n\">ArrayChunk</span> <span class=\"n\">A</span>\n<span class=\"sd\">/-- Return the element at index `i`-/</span>\n<span class=\"n\">opaque</span> <span class=\"n\">ArrayChunk.get</span> <span class=\"o\">(</span><span class=\"n\">a</span> <span class=\"o\">:</span> <span class=\"n\">ArrayChunk</span> <span class=\"n\">A</span><span class=\"o\">)</span> <span class=\"o\">(</span><span class=\"n\">i</span> <span class=\"o\">:</span> <span class=\"n\">Nat</span><span class=\"o\">)</span> <span class=\"o\">(</span><span class=\"n\">h</span> <span class=\"o\">:</span> <span class=\"n\">i</span> <span class=\"bp\">&lt;</span> <span class=\"n\">a.size</span><span class=\"o\">)</span> <span class=\"o\">:</span> <span class=\"n\">A</span>\n<span class=\"sd\">/-- Set the element at index `i` -/</span>\n<span class=\"n\">opaque</span> <span class=\"n\">ArrayChunk.set</span> <span class=\"o\">(</span><span class=\"n\">a</span> <span class=\"o\">:</span> <span class=\"n\">ArrayChunk</span> <span class=\"n\">A</span><span class=\"o\">)</span> <span class=\"o\">(</span><span class=\"n\">i</span> <span class=\"o\">:</span> <span class=\"n\">Nat</span><span class=\"o\">)</span> <span class=\"o\">(</span><span class=\"n\">h</span> <span class=\"o\">:</span> <span class=\"n\">i</span> <span class=\"bp\">&lt;</span> <span class=\"n\">a.size</span><span class=\"o\">)</span> <span class=\"o\">(</span><span class=\"n\">v</span> <span class=\"o\">:</span> <span class=\"n\">A</span><span class=\"o\">)</span> <span class=\"o\">:</span> <span class=\"n\">ArrayChunk</span> <span class=\"n\">A</span>\n</code></pre></div>\n<p>You could also make <code>ArrayChunk A</code> a <code>structure</code> around <code>List A</code> for proving purposes (and extern implement all the ops similarly to arrays)</p>",
        "id": 356336953,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1683389593
    },
    {
        "content": "<p>you actually don't need anything here to be monadic</p>",
        "id": 356337053,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1683389632
    },
    {
        "content": "<p>Nice, but it is not clear to me when would you clean up the original array. Is the last <code>ArrayChunk</code> standing responsible for cleaning upt the original array? How would they keep track of that?</p>",
        "id": 356339972,
        "sender_full_name": "Tomas Skrivan",
        "timestamp": 1683390797
    },
    {
        "content": "<p>it would, and you can also have another function for getting the array back</p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"n\">opaque</span> <span class=\"n\">ArrayChunk.toArray</span> <span class=\"o\">:</span> <span class=\"n\">ArrayChunk</span> <span class=\"n\">A</span> <span class=\"bp\">-&gt;</span> <span class=\"n\">Array</span> <span class=\"n\">A</span>\n</code></pre></div>",
        "id": 356340088,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1683390843
    },
    {
        "content": "<p>all the <code>ArrayChunk</code> pieces are holding on to refs of the <code>Array</code>, so it gets cleaned up by the usual refcounting approach</p>",
        "id": 356340196,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1683390879
    },
    {
        "content": "<p>the unsafe hackery is that <code>ArrayChunk.set</code> does a destructive update of the array if the <code>ArrayChunk</code> itself is unshared, not the <code>Array</code> it is holding a reference to</p>",
        "id": 356340359,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1683390937
    },
    {
        "content": "<p>the invariant is that the array in an <code>ArrayChunk</code> only has direct references within other <code>ArrayChunk</code>s, no one can get access to it directly</p>",
        "id": 356340517,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1683390991
    },
    {
        "content": "<p>And <code>ArrayChunk.mk</code> ensures that the ref count is one or it makes a copy, right?</p>",
        "id": 356340524,
        "sender_full_name": "Tomas Skrivan",
        "timestamp": 1683390993
    },
    {
        "content": "<p>exactly</p>",
        "id": 356340546,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1683390998
    },
    {
        "content": "<p>same thing for <code>ArrayChunk.toArray</code>: it ensures the chunk is unshared and also covers the whole array, or else it copies the slice into a new array</p>",
        "id": 356340632,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1683391043
    },
    {
        "content": "<p>This is a bit unclear to me. Take an array, split it into bunch of chunks, modify those. Then how do I recover the original array? Do I need destroy all but one chunk and call <code>toArray</code> on that chunk?</p>",
        "id": 356341121,
        "sender_full_name": "Tomas Skrivan",
        "timestamp": 1683391223
    },
    {
        "content": "<p>I was thinking about that. I think you need to hold on to the first chunk, but this will break linearity for the pieces. To fix this the chunk should hold a \"disabled\" flag which is set when you call <code>splitAt</code> on it; after that point destructive updates are not allowed if you use <code>set</code> on it (since ownership of this chunk has been given away to the pieces)</p>",
        "id": 356341486,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1683391388
    },
    {
        "content": "<p>even after the main chunk has been disabled, you can still use <code>toArray</code> destructively (once all the child chunks are cleaned up) because you can look at the refcount of the array itself to see that there are no other <code>ArrayChunk</code>s floating around</p>",
        "id": 356341787,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1683391515
    },
    {
        "content": "<p>What if <code>ArrayChunk.mk</code> would also return  <code>OpaqueArray</code> which has only one method <code>toArray</code> used to recover the original array. To me that sounds a bit cleaner then setting up some flags.</p>",
        "id": 356342245,
        "sender_full_name": "Tomas Skrivan",
        "timestamp": 1683391692
    },
    {
        "content": "<p>actually you need the flags in all the chunks because you can hold on to any chunk after calling <code>splitAt</code></p>",
        "id": 356342570,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1683391819
    },
    {
        "content": "<p>so the top level chunk isn't exactly being special cased here</p>",
        "id": 356342716,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1683391890
    },
    {
        "content": "<p>alternatively, have an API that doesn't let you split an array more than one time :P</p>",
        "id": 356342773,
        "sender_full_name": "James Gallicchio",
        "timestamp": 1683391913
    },
    {
        "content": "<p>Ohh I see the problem</p>",
        "id": 356342779,
        "sender_full_name": "Tomas Skrivan",
        "timestamp": 1683391917
    },
    {
        "content": "<p>except that <code>toArray</code> on a chunk only works destructively if that chunk owns the whole array</p>",
        "id": 356342786,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1683391919
    },
    {
        "content": "<p>but you could conceivably <code>splitAt 0</code> and then use one of the children, seems a bit niche though</p>",
        "id": 356342877,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1683391942
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110049\">Mario Carneiro</span> <a href=\"#narrow/stream/270676-lean4/topic/Data-level.20parallelism/near/356342786\">said</a>:</p>\n<blockquote>\n<p>except that <code>toArray</code> on a chunk only works destructively if that chunk owns the whole array</p>\n</blockquote>\n<p>Does that mean the ref counter of the whole array is one? Or you mean something else?</p>",
        "id": 356343130,
        "sender_full_name": "Tomas Skrivan",
        "timestamp": 1683392056
    },
    {
        "content": "<p>two things: the ref counter of the array is one, and also the chunk's bounds (it holds a <code>start</code> and <code>stop</code>, or maybe <code>start</code> and <code>size</code>) match those of the array</p>",
        "id": 356343223,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1683392110
    },
    {
        "content": "<p>I don't see why can't you use any chunk</p>",
        "id": 356343282,
        "sender_full_name": "Tomas Skrivan",
        "timestamp": 1683392148
    },
    {
        "content": "<p>The chunk only \"knows\" about its subarray at the logical level. If we were modeling it in lean it would be <code>List A</code> where the list is just that subslice of the original array</p>",
        "id": 356343435,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1683392208
    },
    {
        "content": "<p>so it can't reconstruct the original array unless it has all the elements</p>",
        "id": 356343477,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1683392232
    },
    {
        "content": "<p>it can reconstruct its slice, but that's a copy</p>",
        "id": 356343502,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1683392242
    },
    {
        "content": "<p>I think this is a requirement, because those other parts of the array can change concurrently</p>",
        "id": 356343624,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1683392286
    },
    {
        "content": "<p>Right, makes sense. </p>\n<p>Wait,  will <code>toArray</code> have to block the thread until the ref counter goes down to one?</p>",
        "id": 356344846,
        "sender_full_name": "Tomas Skrivan",
        "timestamp": 1683392772
    },
    {
        "content": "<p>Otherwise it might still be modified concurrently and you can't make a sensible copy out of it.</p>",
        "id": 356344962,
        "sender_full_name": "Tomas Skrivan",
        "timestamp": 1683392831
    },
    {
        "content": "<p>Oh good point</p>",
        "id": 356345273,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1683392970
    },
    {
        "content": "<p>actually I think you need to collect the child chunks with some kind of <code>join</code> operator</p>",
        "id": 356345469,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1683393059
    },
    {
        "content": "<p>because as far as lean is concerned the value of the original chunk can't change if you just try to use it directly</p>",
        "id": 356345653,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1683393147
    },
    {
        "content": "<p>A slightly simpler but more limiting interface would be a callback, where the child chunks are passed to the callback and collected once it is done</p>",
        "id": 356346006,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1683393319
    },
    {
        "content": "<p>How would the type signature of that look like?</p>",
        "id": 356346122,
        "sender_full_name": "Tomas Skrivan",
        "timestamp": 1683393368
    },
    {
        "content": "<p>which one? <code>join</code> would just be <code>ArrayChunk A -&gt; ArrayChunk A -&gt; ArrayChunk A</code> but with a somewhat complicated condition for when the joining is legal (not requiring a copy)</p>",
        "id": 356348222,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1683394426
    },
    {
        "content": "<p>And the callback?</p>",
        "id": 356348336,
        "sender_full_name": "Tomas Skrivan",
        "timestamp": 1683394468
    },
    {
        "content": "<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"n\">withSplitAt</span> <span class=\"o\">:</span> <span class=\"n\">ArrayChunk</span> <span class=\"n\">A</span> <span class=\"bp\">-&gt;</span> <span class=\"n\">Nat</span> <span class=\"bp\">-&gt;</span> <span class=\"o\">(</span><span class=\"n\">ArrayChunk</span> <span class=\"n\">A</span> <span class=\"bp\">-&gt;</span> <span class=\"n\">ArrayChunk</span> <span class=\"n\">A</span> <span class=\"bp\">-&gt;</span> <span class=\"n\">B</span><span class=\"o\">)</span> <span class=\"bp\">-&gt;</span> <span class=\"n\">B</span>\n</code></pre></div>",
        "id": 356348429,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1683394512
    },
    {
        "content": "<p>But can't you return those chunks in <code>B</code> and cause problems?</p>",
        "id": 356348605,
        "sender_full_name": "Tomas Skrivan",
        "timestamp": 1683394589
    },
    {
        "content": "<p>basically any \"invalid\" use will cause lots of copies but no logical breakage</p>",
        "id": 356348661,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1683394615
    },
    {
        "content": "<p>with the callback version you don't need the \"disabled\" flags, since <code>withSplitAt</code> will consume the chunk. If you try to hold on to it then a copy is made</p>",
        "id": 356348973,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1683394769
    },
    {
        "content": "<p>actually the callback version doesn't solve the collection problem, you still need the new values of the chunks to be passed back in or else it is logically impossible for the array's value to depend on the new value of the chunks (you will just have an unused chunk variable after the modification and nowhere to put it)</p>",
        "id": 356349577,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1683395048
    }
]