[
    {
        "content": "<p>I'm working on improving my Lean 4 autograder for Gradescope (based on code by <span class=\"user-mention\" data-user-id=\"552229\">@Vanessa Rodrigues</span> and <span class=\"user-mention\" data-user-id=\"110043\">@Gabriel Ebner</span> ). The big-picture structure of the autograder is this. We have a course project with a whole bunch of files. A student edits  one file, <code>HW.lean</code>, and upload it to the autograder. The autograder has the full course project including the original <code>HW.lean</code>, which has some problems tagged as exercises. It creates two environments, one with the original <code>HW.lean</code> and one with the student's version, and checks that the tagged declarations exist in the student's version and do not contain sorry or extra axioms.</p>\n<p>The problem is, if the student's submission doesn't compile, we can't create the second environment -- the import fails and the grade is a 0. This is confusing in the case, for example, where a student has finished 9/10 of their proof obligations. If they submit a file with one unfinished proof they don't get credit for the 9 they did finish. In VSCode it looks like the file \"works\" except for the one issue. This spring I tried to train students to always <code>sorry</code> incomplete proofs. This works but isn't foolproof, it can be easy to miss especially if an incomplete proof has multiple goals left.</p>\n<p>Is there any way to do a \"soft\" import of the submitted file, that works more like a file with errors in the editor, where incomplete proofs are <code>sorry</code>ed?</p>",
        "id": 388342958,
        "sender_full_name": "Rob Lewis",
        "timestamp": 1693493713
    },
    {
        "content": "<p>Don't use an import, process the file directly to get an environment</p>",
        "id": 388343168,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1693493776
    },
    {
        "content": "<p>that is, do it like the server would</p>",
        "id": 388343232,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1693493794
    },
    {
        "content": "<p>This part of the autograder came from Vanessa's original script, so I'm not as clear on the details. Right now it's using <a href=\"https://github.com/robertylewis/lean4-autograder-main/blob/master/Main.lean#L93\"><code>importModules</code></a> to produce the environment. When you say \"process the file directly,\" is there a different function to drop in here?</p>",
        "id": 388345387,
        "sender_full_name": "Rob Lewis",
        "timestamp": 1693494395
    },
    {
        "content": "<p>(This is an older version of the autograder, our updates are in a private repo, but we haven't changed anything relevant to this question)</p>",
        "id": 388345546,
        "sender_full_name": "Rob Lewis",
        "timestamp": 1693494448
    },
    {
        "content": "<p>I don't know what Mario has in mind precisely, but I suppose you could compile the file with <a href=\"https://leanprover-community.github.io/mathlib4_docs/find/?pattern=Lean.Elab.IO.processCommands#doc\">docs#Lean.Elab.IO.processCommands</a> . I did something similar in the auto-grading tool I made here: <a href=\"https://github.com/adamtopaz/lean_grader\">https://github.com/adamtopaz/lean_grader</a></p>",
        "id": 388348927,
        "sender_full_name": "Adam Topaz",
        "timestamp": 1693495398
    },
    {
        "content": "<p>Oh, interesting. Does your grader handle the case where some proofs are incomplete?</p>",
        "id": 388349438,
        "sender_full_name": "Rob Lewis",
        "timestamp": 1693495553
    },
    {
        "content": "<p>no, it's very rudimentary -- it just checks whether a term <code>solution</code> exists in the file <code>Solution.lean</code>, that it doesn't use axioms, and that the hash of the type of <code>solution</code> matches what's provided as an argument.</p>",
        "id": 388349655,
        "sender_full_name": "Adam Topaz",
        "timestamp": 1693495609
    },
    {
        "content": "<p>But to obtain <code>solution</code> from the environment it doesn't import anything, but rather actually compile the <code>Solution.lean</code> file.</p>",
        "id": 388349836,
        "sender_full_name": "Adam Topaz",
        "timestamp": 1693495662
    },
    {
        "content": "<p>Here's the precise line where the environment is obtained: <a href=\"https://github.com/adamtopaz/lean_grader/blob/78fdff947d45a161412debce6e1fa2779b5d628a/Main.lean#L18\">https://github.com/adamtopaz/lean_grader/blob/78fdff947d45a161412debce6e1fa2779b5d628a/Main.lean#L18</a></p>",
        "id": 388350144,
        "sender_full_name": "Adam Topaz",
        "timestamp": 1693495738
    },
    {
        "content": "<p>Oh, cool -- I think that does work the way I need. Thanks very much!</p>",
        "id": 388350991,
        "sender_full_name": "Rob Lewis",
        "timestamp": 1693495967
    },
    {
        "content": "<p>Ha, I just noticed <a href=\"https://leanprover-community.github.io/mathlib4_docs/find/?pattern=Lean.Elab.process#doc\">docs#Lean.Elab.process</a> which should work just as well</p>",
        "id": 388351018,
        "sender_full_name": "Adam Topaz",
        "timestamp": 1693495977
    },
    {
        "content": "<p>Yes, what Adam is suggesting is what I meant</p>",
        "id": 388373148,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1693502275
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"110596\">@Rob Lewis</span> you might like the frontend wrapper at <a href=\"https://github.com/semorrison/lean-training-data/blob/master/TrainingData/Frontend.lean\">https://github.com/semorrison/lean-training-data/blob/master/TrainingData/Frontend.lean</a>. It gives you the <code>Environment</code> before and after every command, along with error messages (also syntax, source, info trees).</p>",
        "id": 388421630,
        "sender_full_name": "Scott Morrison",
        "timestamp": 1693525063
    },
    {
        "content": "<p>I'd like to upstream somewhere a nice frontend library that covers most people's needs. I'm not sure where that should actually be --- maybe just a top level library, or downstream of Std if that's helpful.</p>",
        "id": 388421780,
        "sender_full_name": "Scott Morrison",
        "timestamp": 1693525174
    },
    {
        "content": "<p>Thanks Scott, we'll take a look at that too -- I'm not sure we need something that fine-grained yet, but we might in the future</p>",
        "id": 388432954,
        "sender_full_name": "Rob Lewis",
        "timestamp": 1693530670
    },
    {
        "content": "<p>Once our autograder is more polished we'll make it public. It's a little more complex than Adam's, but tied to Gradescope instead of Github Classrooms</p>",
        "id": 388433112,
        "sender_full_name": "Rob Lewis",
        "timestamp": 1693530738
    }
]