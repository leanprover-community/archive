[
    {
        "content": "<p>I assume the basic <code>Float</code> type is the binary64 format but <code>Float.lean</code> doesn't tell me much about what exactly it is or how it works. Are IEEE 754 floats and float arithmetic implemented in pure Lean somewhere?</p>\n<p>Disclaimer: I'm still new to Lean. I did try to find the docs but the page for Float is blank (<a href=\"https://lean-lang.org/lean4/doc/float.html\">https://lean-lang.org/lean4/doc/float.html</a>)</p>",
        "id": 395452257,
        "sender_full_name": "Alex Sweeney",
        "timestamp": 1696710159
    },
    {
        "content": "<p><code>Float</code> is an opaque type from lean's perspective, but yes it is in fact IEEE 754 binary64</p>",
        "id": 395452736,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1696710611
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"110049\">@Mario Carneiro</span> As far as I can tell opaque is a way to define something that's unknown to the type checker. Is this so it can use C's float math for performance reasons? Or they just didn't want to reinvent floats in Lean? Basically I think it would be neat to prove things about IEEE 754 floats and I'm a little confused why it seems nobody has done it. Sounds like a fun project.</p>",
        "id": 395456067,
        "sender_full_name": "Alex Sweeney",
        "timestamp": 1696714221
    },
    {
        "content": "<p>Might be relavent: <a href=\"#narrow/stream/270676-lean4/topic/IEEE.20floats\">https://leanprover.zulipchat.com/#narrow/stream/270676-lean4/topic/IEEE.20floats</a></p>",
        "id": 395456197,
        "sender_full_name": "Andrew Yang",
        "timestamp": 1696714396
    },
    {
        "content": "<p>Yes it is for performance reasons. The compiler knows about <code>Float</code> as a primitive type and turns them into the proper C type.  I guess if you really want to you could redefine them as <code>UInt64</code> and start formalizing things about them but at the time that the current float implementation was conceived there was basically no use for theorems on it so nobody did it.</p>",
        "id": 395456271,
        "sender_full_name": "Henrik BÃ¶ving",
        "timestamp": 1696714457
    },
    {
        "content": "<p>Personally, I would be interested in formalizing (or seeing the formailzation of) something like <a href=\"https://herbie.uwplse.org/papers.html\">Herbie</a> which is about \"Automatically Improving Accuracy for Floating Point Expressions\", see also <a href=\"https://egraphs-good.github.io/egglog/?example=herbie\">here</a> for a series of rewrite rules, they are supposed to be equal for <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi mathvariant=\"double-struck\">R</mi></mrow><annotation encoding=\"application/x-tex\">\\mathbb{R}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6889em;\"></span><span class=\"mord mathbb\">R</span></span></span></span> and reach a better accuracy bound for floats. I hope to formalize not just IEEE 754 float but also emerging float types like <a href=\"https://en.wikipedia.org/wiki/Bfloat16_floating-point_format\">bfloat16</a> or <a href=\"https://browse.arxiv.org/pdf/2305.14314.pdf\">4-bit NormalFloat</a> which is supposed to be an information theoretically optimal type for quantization in the area of LLM research.</p>",
        "id": 395477650,
        "sender_full_name": "Utensil Song",
        "timestamp": 1696731818
    }
]