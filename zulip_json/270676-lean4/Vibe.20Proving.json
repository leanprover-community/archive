[
    {
        "content": "<p>Is it safe to say that, as long as you understand the final theorem you're working towards, and you manage to get something to compile with no errors and no <code>sorry</code>s/<code>admit</code>s, then it doesn't really matter what led you to your goal?</p>\n<p>I ask because GPT-5 managed to complete a proof for me, just by making small changes and correcting based on feedback from lean4 until there's no errors in a loop. While it could be refactored to be more readable/less verbose, etc. if my understanding is correct, it doesn't matter because that proof has been proved.</p>\n<p>Here's the proof:<br>\n<a href=\"https://gist.github.com/wildwestrom/9f6d45f087503c5850ccff58f0b85e27\">https://gist.github.com/wildwestrom/9f6d45f087503c5850ccff58f0b85e27</a></p>",
        "id": 537472967,
        "sender_full_name": "West",
        "timestamp": 1756905074
    },
    {
        "content": "<p>Depends on your goal. If you just want to convince lean something is true then yeah, that works. If you want to learn what you're doing, maybe not so much</p>",
        "id": 537474685,
        "sender_full_name": "Ruben Van de Velde",
        "timestamp": 1756905591
    },
    {
        "content": "<p>There's also the cost of type checking. If you, somehow, found a proof that takes 10 minutes to be checked by Lean but it could be done in 2 seconds, then I think the path you took matters</p>",
        "id": 537475131,
        "sender_full_name": "Arthur Paulino",
        "timestamp": 1756905724
    },
    {
        "content": "<p>From my point of view, yes.</p>\n<p>Set the goal (write the theorem and check all definitions it depends on to be sure they are what you think they are) and then get to a sorry-free* proof using any means necessary!</p>\n<p>Of course, if you want to contribute to Mathlib, the actual proof will matter, but for most other purposes I'll stick to a simple \"yes\".</p>\n<p>(*) I mean, a proof that depends only on these three axioms:<br>\n[propext, Classical.choice, Quot.sound]</p>",
        "id": 537475800,
        "sender_full_name": "Martin Dvořák",
        "timestamp": 1756905943
    },
    {
        "content": "<p>I intuitively understood that the function in question is infinitely differentiable (it's continuous (no sharp points, holes, asymptotes on the domain in question), and $d/dx e^x$ is $e^x$). I just didn't want to go through all the pedantic steps and figure out what I'm supposed to look for in mathlib.</p>",
        "id": 537476114,
        "sender_full_name": "West",
        "timestamp": 1756906030
    },
    {
        "content": "<p>As you could tell, I'm not experienced with lean4, but I was wondering if y'all could take a look and see if there's anything that could obviously be refactored out or simplified, for example <code>primitive_is_C_inf_on_unitInterval</code>.<br>\nI already did as much as I could wrap my head around.</p>",
        "id": 537480788,
        "sender_full_name": "West",
        "timestamp": 1756907380
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"307953\">Ruben Van de Velde</span> <a href=\"#narrow/channel/270676-lean4/topic/Vibe.20Proofing/near/537474685\">said</a>:</p>\n<blockquote>\n<p>...convince lean something is true...</p>\n</blockquote>\n<p>By the way, not sure if you meant this, but I'm not trying to convince lean of anything. If anything, I want lean to convince <em>me</em> that it's done the math right.</p>",
        "id": 537481712,
        "sender_full_name": "West",
        "timestamp": 1756907636
    },
    {
        "content": "<p>Speaking metaphorically, in the sense of writing code that lean can compile</p>",
        "id": 537483456,
        "sender_full_name": "Ruben Van de Velde",
        "timestamp": 1756908116
    },
    {
        "content": "<p>What are you using? Copilot?</p>",
        "id": 537582702,
        "sender_full_name": "(deleted)",
        "timestamp": 1756955689
    },
    {
        "content": "<p>Do you use LeanExplore?</p>",
        "id": 537582810,
        "sender_full_name": "(deleted)",
        "timestamp": 1756955772
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"511228\">Huỳnh Trần Khanh</span> <a href=\"#narrow/channel/270676-lean4/topic/Vibe.20Proofing/near/537582702\">said</a>:</p>\n<blockquote>\n<p>What are you using? Copilot?</p>\n</blockquote>\n<p>I used Cursor with <code>gpt-5-low</code> and I had generated a rule that basically describes how to debug (make a small change, see the output of the current state of the proof and the compiler, and repeat).</p>\n<p>Claude, gemini, and \"auto\" failed spectacularly every time.</p>",
        "id": 537584493,
        "sender_full_name": "West",
        "timestamp": 1756957322
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"511228\">Huỳnh Trần Khanh</span> <a href=\"#narrow/channel/270676-lean4/topic/Vibe.20Proofing/near/537582810\">said</a>:</p>\n<blockquote>\n<p>Do you use LeanExplore?</p>\n</blockquote>\n<p>Never heard of this. I'll give it a try next time I want to prove something.</p>",
        "id": 537584791,
        "sender_full_name": "West",
        "timestamp": 1756957413
    },
    {
        "content": "<p>One more thing. When using cursor, you also might benefit from removing <code>.lake</code> from <code>.gitignore</code> temporarily so it can search mathlib and other libraries directly. If you gitignore it, Cursor has more trouble grepping through the codebase. Hopefully Cursor will get better at indexing the Mathlib docs soon, last time I tried it did not work at all. Better yet if somebody makes a good MCP server.</p>",
        "id": 537585570,
        "sender_full_name": "West",
        "timestamp": 1756958127
    },
    {
        "content": "<p>Thank you. My verdict: it has potential. But the most important weakness is the model isn't able to tell whether the list of errors is complete or not.</p>",
        "id": 538076060,
        "sender_full_name": "(deleted)",
        "timestamp": 1757248680
    },
    {
        "content": "<p>So to maximize the potential of GPT-5, we need to make an MCP server that only reports errors when Lean has finished processing the file.</p>",
        "id": 538076097,
        "sender_full_name": "(deleted)",
        "timestamp": 1757248720
    },
    {
        "content": "<p>Cursor successfully proved my theorem, thus helping me earn $105.</p>",
        "id": 538076155,
        "sender_full_name": "(deleted)",
        "timestamp": 1757248780
    },
    {
        "content": "<p>The age of AI printing money for me isn't far away. It's right here.</p>",
        "id": 538076185,
        "sender_full_name": "(deleted)",
        "timestamp": 1757248814
    },
    {
        "content": "<p>Because of my greed, I made Cursor solve another problem. It didn't do that well.</p>",
        "id": 538095963,
        "sender_full_name": "(deleted)",
        "timestamp": 1757268091
    },
    {
        "content": "<p>The reasoning depth matters a lot. If the model still has to do a lot of extra reasoning beyond the provided blueprint then it's more likely to fail.</p>",
        "id": 538096529,
        "sender_full_name": "(deleted)",
        "timestamp": 1757268747
    },
    {
        "content": "<p>To prevent the model from acting on an incomplete error list, a simple #check at the end of the file is enough.</p>",
        "id": 538096735,
        "sender_full_name": "(deleted)",
        "timestamp": 1757269019
    },
    {
        "content": "<p>This may be of help: <a href=\"https://gist.github.com/wildwestrom/55f7b11b3ab821e517e0c6d1bd31a5c2\">https://gist.github.com/wildwestrom/55f7b11b3ab821e517e0c6d1bd31a5c2</a></p>\n<p>It's hit or miss with 'auto' and seems to work well with 'gpt-5-low'.</p>\n<p>I recently started using <a href=\"https://github.com/oOo0oOo/lean-lsp-mcp/issues\">this lean mcp server</a>.</p>",
        "id": 538112972,
        "sender_full_name": "West",
        "timestamp": 1757289406
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"955304\">@West</span> Woah. That's pretty cool. Is it all automated? I tried a bit of vibe proofing with the normal GPT in the browser and it just made up a load of stuff. My method was to try a top-down approach and to ask it to try and take the proposition and write it in terms of a few other unproved propositions and do that recursively.  Didn't really work though <span aria-label=\"cry\" class=\"emoji emoji-1f622\" role=\"img\" title=\"cry\">:cry:</span></p>\n<p>Do you have a screen recording of it solving your proof. That would be nice to see.</p>",
        "id": 538117796,
        "sender_full_name": "Mr Proof",
        "timestamp": 1757293940
    },
    {
        "content": "<p>It definitely needs babysitting. I probably won't make a recording either. But anyway, like I said, gpt-5 is the only family of models that work well with lean within cursor, and you really have to make sure it doesn't make changes without seeing the goal state and diagnostics.</p>",
        "id": 538118107,
        "sender_full_name": "West",
        "timestamp": 1757294281
    },
    {
        "content": "<p>P.S I like the name \"Vibe Proofing\" <span aria-label=\"copyright\" class=\"emoji emoji-00a9\" role=\"img\" title=\"copyright\">:copyright:</span>.</p>",
        "id": 538118312,
        "sender_full_name": "Mr Proof",
        "timestamp": 1757294548
    },
    {
        "content": "<p>Not a fan of the MCP server. It's too buggy.</p>",
        "id": 538161491,
        "sender_full_name": "(deleted)",
        "timestamp": 1757320183
    },
    {
        "content": "<p>Don't use it.</p>",
        "id": 538161606,
        "sender_full_name": "(deleted)",
        "timestamp": 1757320210
    },
    {
        "content": "<p>I'll just babysit Cursor and tell it to reread lints when there are more errors than what it previously fetched</p>",
        "id": 538163206,
        "sender_full_name": "(deleted)",
        "timestamp": 1757320636
    },
    {
        "content": "<p>In any case, let's work together so we can make vibe proving a better experience. We can start by sharing Cursor rules and other procedures. You can modify <a href=\"https://gist.github.com/wildwestrom/55f7b11b3ab821e517e0c6d1bd31a5c2\">mine</a> and instead of telling it to use the MCP tell it which commands to run.</p>\n<p>Also, I forgot to mention. Somewhere in the project (in a separate file or at the top of the file with your proof) it helps to add context about the problem you're working on. This primes the language model to use its math knowledge more.</p>",
        "id": 538164640,
        "sender_full_name": "West",
        "timestamp": 1757321023
    },
    {
        "content": "<p>Using LLMs for doing Lean is more a problem of having the right information (about APIs, syntax, procedures, etc.) rather than the math itself. This is because language models have math as a large part of their training data.</p>",
        "id": 538170507,
        "sender_full_name": "West",
        "timestamp": 1757322579
    },
    {
        "content": "<p>As a drive by comment, I'm reading \"vibe proofing\" as \"vibe-proofing\" as in \"making Lean resilient to AI generation\" (better error messages etc). I'd perhaps suggest \"vibe pro<em>v</em>ing\" instead as the analogy to \"vibe coding\".</p>",
        "id": 538175163,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1757323819
    },
    {
        "content": "<p>You're write. I realized it sounded kinda dumb so I changed my words before your comment.</p>\n<p><span class=\"user-mention silent\" data-user-id=\"955304\">West</span> <a href=\"#narrow/channel/270676-lean4/topic/Vibe.20Proofing/near/538164640\">said</a>:</p>\n<blockquote>\n<p>vibe proving</p>\n</blockquote>\n<p>I'll change the name of the topic.</p>",
        "id": 538179259,
        "sender_full_name": "West",
        "timestamp": 1757324986
    },
    {
        "content": "<p>I am developing this MCP. <span class=\"user-mention\" data-user-id=\"511228\">@Huỳnh Trần Khanh</span> I am sorry you had a buggy experience. You can dm me (not to pollute this thread) or open an issue, maybe we can fix some of these bugs.</p>\n<p><span class=\"user-mention\" data-user-id=\"955304\">@West</span> I would be interested in linking your instruction file in the README as an example, if you are OK with this. You can let me know, once you have a ready version...</p>",
        "id": 538185747,
        "sender_full_name": "Oliver Dressler",
        "timestamp": 1757326911
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"802311\">Oliver Dressler</span> <a href=\"#narrow/channel/270676-lean4/topic/Vibe.20Proving/near/538185747\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"955304\">West</span> I would be interested in linking your instruction file in the README as an example, if you are OK with this. You can let me know, once you have a ready version...</p>\n</blockquote>\n<p>I think it could be refined a lot more. <br>\nI just asked GPT 5 to generate it and then tweaked it.<br>\nIt could be more concise.<br>\nYou're free to use it. Let it be public domain.</p>",
        "id": 538186136,
        "sender_full_name": "West",
        "timestamp": 1757327048
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"955304\">West</span> <a href=\"#narrow/channel/270676-lean4/topic/Vibe.20Proving/near/538186136\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"802311\">Oliver Dressler</span> <a href=\"#narrow/channel/270676-lean4/topic/Vibe.20Proving/near/538185747\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"955304\">West</span> I would be interested in linking your instruction file in the README as an example, if you are OK with this. You can let me know, once you have a ready version...</p>\n</blockquote>\n<p>I think it could be refined a lot more. </p>\n</blockquote>\n<p>No hurry, I'm happy to wait a bit for some refinement then.</p>\n<p>I am aware that instructions are the missing piece for successfully using the MCP. I have been planning to start a collection of examples for a while but haven't gotten around to it.</p>\n<p>Honestly I am not a very prolific user of the MCP myself, so I am reliant on user feedback for this.</p>",
        "id": 538187075,
        "sender_full_name": "Oliver Dressler",
        "timestamp": 1757327360
    },
    {
        "content": "<p>I <strong>love</strong> this concept! </p>\n<p>I've been experimenting with a number of tasks that agents can accomplish autonomously. I've mainly been using Claude-code, as I'm a bioinformatician and it is <em>much</em> better than GPT5 at coding, but I've been trying to create prompt systems and task scopes that are both useful, and comfortably within the models' current sets of capabilities. Things that don't take all too much effort to <em>check</em> a correct solution: optimizing memory or runtime efficiency, for example. Give the same input as the old program? You should get the same output. Objective measures like runtime or maximum memory utilization can be checked by the agent as it iterates. </p>\n<p>If not given proper instructions, the agent may try to optimize the algorithm.. well.. robotically: redesign entire algorithm so input for n&lt;500 is <em>much</em> faster (n&lt;500 already only took 10 seconds). Or, it may find vestigial code in a large repository, and try to optimize that (not having profiled the code to figure out what gets run, and where execution actually hangs).</p>\n<p>It's this journey that has brought me to Lean: my undergrad degrees were math and physics (although I admittedly.. barely <em>survived</em> Real Analysis), so I was <em>fascinated</em> to learn of a compilable, verifiable language for math proofs.</p>\n<p>I have both cursor and ChatGPT Pro subscriptions, so I am able to try a <em>lot</em> of things here. I also have access to a powerful VM: an Ubuntu 22.04 KVM virtual machine configured with 190 virtual cores and ~380GB of RAM, running on a Dell PowerEdge R7525 server with two AMD EPYC 7552 48-Core Processors and 2TB total RAM, equipped with an A100 GPU with 40Gb memory.</p>\n<p>I am, however, entirely new to Lean itself (and my proof abilities are <em>very</em> rusty). My research interests in this area do lie specifically in the <em>automation</em> of agentic AI contribution to scientific endeavors. This has proven difficult for broad tasks, but easier for those with limited scope. Directive sets like the ones you posted, @West:</p>\n<p><span class=\"user-mention silent\" data-user-id=\"955304\">West</span> <a href=\"#narrow/channel/270676-lean4/topic/Vibe.20Proving/near/538112972\">said</a>:</p>\n<blockquote>\n<p><a href=\"https://gist.github.com/wildwestrom/55f7b11b3ab821e517e0c6d1bd31a5c2\">https://gist.github.com/wildwestrom/55f7b11b3ab821e517e0c6d1bd31a5c2</a></p>\n</blockquote>\n<p>are of the <em>utmost</em> importance in this area, in my opinion. I don't like calling what we are doing \"vibes\": vibes imply you have <em>no</em> clue what the thing is spitting back out at you. That's not the case here: we're not humanities majors coding a website to do ML on polymer prediction, or something we have no clue about. I prefer to call (at least, the current state of) this \"Nanny-coding\" (or \"Nanny-proving\" in this case): We are \"babysitting\" the results.</p>\n<p>To that end, and.. given my limited confidence in the mathematical abilities I've retained over the last 8 years of not using them.. What do you think is a good place to start? Is there a nice, 'bite-sized' set of proofs you can direct me to? Are you willing to look at the results, and see if they can be integrated into the community?</p>\n<p>How will I know <em>for sure</em> the agent has gotten the correct answer(s)? Are there common ways it will attempt to 'evade'? Are there definitive 'test harnesses' I can apply? Asserting the beginning, and end of the proof perhaps, in some way? In coding I'm able to directly test the output of an algorithm, or at least construct a set of tests with known inputs and outputs. I initially thought that vibe-, or Nanny-<em>proving</em> wouldn't be possible, for lack of verifiability. </p>\n<p>As the models continue to expand their sets of capabilities, I think it's <em>very</em> important we work out some of these things <em>now</em>. <em>Even if</em> these things were <em>already</em> of \"genius, PhD-level\" intelligence, we would <em>still</em> need a verifiable check on machine outputs, and likely, providing a precise directives document with best practices would <em>still</em> produce better output.</p>\n<p>Sorry for the essay!</p>",
        "id": 538218352,
        "sender_full_name": "Rye Howard-Stone",
        "timestamp": 1757336177
    },
    {
        "content": "<p>What's important is that you know just enough Lean and mathlib to make sure you (or somebody) can understand exactly what your final theorem is asserting. Only then can you let the AI take over, otherwise it's meaningless.</p>",
        "id": 538220027,
        "sender_full_name": "West",
        "timestamp": 1757336538
    },
    {
        "content": "<p>I guess that's what I'm asking: can't we set <em>up</em> the assertions at the end? Does the language permit some form of 'test harness'? Rather than writing the proof, specify the inputs and outputs?</p>",
        "id": 538220433,
        "sender_full_name": "Rye Howard-Stone",
        "timestamp": 1757336618
    },
    {
        "content": "<p>You must be new to the language. Yes, if you just write your assertion (<code>lemma</code> or <code>theorem</code>) and put <code>sorry</code> or <code>admit</code> you're basically telling Lean \"just trust me bro\" and you can work on something else without the compiler complaining too much. It's useful for when you know something is true but you can't figure out how to code it out yet.</p>",
        "id": 538224257,
        "sender_full_name": "West",
        "timestamp": 1757337510
    },
    {
        "content": "<p>I am, very! Got it, the language itself is sort of the test harness. So, a set of 'bite-sized' potential proofs for contribution might be things that have been left as <code>sorry</code> or <code>admit</code> in existing mathlib4 proofs?</p>",
        "id": 538225660,
        "sender_full_name": "Rye Howard-Stone",
        "timestamp": 1757337840
    },
    {
        "content": "<p><code>mathlib4</code> has no <code>sorry</code> or <code>admit</code>, that's one of the rules.</p>",
        "id": 538226808,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1757338116
    },
    {
        "content": "<p>Gotcha! Sensible rule. So, where would you suggest starting? Any, 'low-hanging fruit' to test the ability of an automated system? The process of verifying that the <em>statement</em> of a proof is correct is not nearly as hard as actually <em>proving</em> it (I'm sure there's a counterexample, but for most things). Is there a DB or collection somewhere of <em>statements</em> of Lean proofs, yet to be formalized?</p>",
        "id": 538228338,
        "sender_full_name": "Rye Howard-Stone",
        "timestamp": 1757338474
    },
    {
        "content": "<p>Lean 4 annotation firms. Look into them. Project Numina is one. You get to solve problems.</p>",
        "id": 538229490,
        "sender_full_name": "(deleted)",
        "timestamp": 1757338770
    },
    {
        "content": "<p>Oh <em>my</em> that is a fascinating project!! Thank you! All these communities are clearly on the cusp of great things!</p>\n<p>My thinking is that, re:</p>\n<p><span class=\"user-mention silent\" data-user-id=\"451983\">Arthur Paulino</span> <a href=\"#narrow/channel/270676-lean4/topic/Vibe.20Proving/near/537475131\">said</a>:</p>\n<blockquote>\n<p>There's also the cost of type checking. If you, somehow, found a proof that takes 10 minutes to be checked by Lean but it could be done in 2 seconds, then I think the path you took matters</p>\n</blockquote>\n<p>That's fundamentally back to the 'efficiency' problem. If a human verifies the statement of the problem, and an AI is able to come up with <em>some</em> correct solution, it can then be <em>profiled</em> for type checking behavior -- and, optimized agentically. Type checking cost is itself an objective measure, right? Treat the inefficient 'first pass' as the 'ground truth', and optimize from there.</p>",
        "id": 538230984,
        "sender_full_name": "Rye Howard-Stone",
        "timestamp": 1757339164
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"511228\">Huỳnh Trần Khanh</span> <a href=\"#narrow/channel/270676-lean4/topic/Vibe.20Proving/near/538229490\">said</a>:</p>\n<blockquote>\n<p>Lean 4 annotation firms. Look into them. Project Numina is one. You get to solve problems.</p>\n</blockquote>\n<p>If these employers are paying for human-written Lean data to train AIs, I don't think they are going to be very happy about you giving them AI generated data</p>",
        "id": 538234050,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1757339931
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"957416\">Rye Howard-Stone</span> <a href=\"#narrow/channel/270676-lean4/topic/Vibe.20Proving/near/538228338\">said</a>:</p>\n<blockquote>\n<p>Gotcha! Sensible rule. So, where would you suggest starting? Any, 'low-hanging fruit' to test the ability of an automated system? The process of verifying that the <em>statement</em> of a proof is correct is not nearly as hard as actually <em>proving</em> it (I'm sure there's a counterexample, but for most things). Is there a DB or collection somewhere of <em>statements</em> of Lean proofs, yet to be formalized?</p>\n</blockquote>\n<p>You might be interested in <a href=\"https://github.com/SorryDB/SorryDB\">https://github.com/SorryDB/SorryDB</a> but I'm not promising any low-hanging fruit. </p>\n<p>The process of verifying that the statement of a theorem is correct is something which I would not trust a machine to do; the process of verifying that a Lean proof of a theorem is correct is absolutely something I would trust a machine to do, indeed that's one thing Lean does.</p>",
        "id": 538234094,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1757339940
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"310045\">Eric Wieser</span> <a href=\"#narrow/channel/270676-lean4/topic/Vibe.20Proving/near/538234050\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"511228\">Huỳnh Trần Khanh</span> <a href=\"#narrow/channel/270676-lean4/topic/Vibe.20Proving/near/538229490\">said</a>:</p>\n<blockquote>\n<p>Lean 4 annotation firms. Look into them. Project Numina is one. You get to solve problems.</p>\n</blockquote>\n<p>If these employers are paying for human-written Lean data to train AIs, I don't think they are going to be very happy about you giving them AI generated data</p>\n</blockquote>\n<p>They actively encourage it actually. The only rule is the code compiles.</p>",
        "id": 538234492,
        "sender_full_name": "(deleted)",
        "timestamp": 1757340034
    },
    {
        "content": "<p>Interesting!</p>",
        "id": 538234611,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1757340060
    },
    {
        "content": "<blockquote>\n<p>The only rule is the code compiles.</p>\n</blockquote>\n<p>Surely there is a rule also against empty files, against <code>native_decide</code> hacks, against malicious code, ...?</p>",
        "id": 538234879,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1757340122
    },
    {
        "content": "<p>Every month someone goes through all my code and reviews to check whether there's something very bad. The main thing they check is wrong theorem statements, and very egregious native_decide hacks—which have yet to appear in anyone's code. Sometimes I'm asked to review other people's code.</p>",
        "id": 538235587,
        "sender_full_name": "(deleted)",
        "timestamp": 1757340303
    },
    {
        "content": "<p>There used to be a rule against AI but then I asked for clarification and they said only AI code that doesn't work properly is banned</p>",
        "id": 538235759,
        "sender_full_name": "(deleted)",
        "timestamp": 1757340346
    },
    {
        "content": "<p>And the pay is fixed, $105 per problem. And problems are very hard. I can only manage to solve one per day.</p>",
        "id": 538236054,
        "sender_full_name": "(deleted)",
        "timestamp": 1757340416
    },
    {
        "content": "<p>Oh woah wait which one pays you lol?</p>",
        "id": 538236155,
        "sender_full_name": "Rye Howard-Stone",
        "timestamp": 1757340441
    },
    {
        "content": "<p>Project Numina pays me through ABAKA AI and Kili Technology.</p>",
        "id": 538236396,
        "sender_full_name": "(deleted)",
        "timestamp": 1757340496
    },
    {
        "content": "<p>Oh wow! Yeah I'm looking at the bottom now, where it says 'join as contributor'?</p>",
        "id": 538236472,
        "sender_full_name": "Rye Howard-Stone",
        "timestamp": 1757340511
    },
    {
        "content": "<p>Email <a href=\"mailto:maxime.michel@kili-technology.com\">maxime.michel@kili-technology.com</a> and ask him to join the project. You'll get a response on September 15th.</p>",
        "id": 538236736,
        "sender_full_name": "(deleted)",
        "timestamp": 1757340571
    },
    {
        "content": "<p>There might be other ways I'm not sure. But this is the easiest way.</p>",
        "id": 538236907,
        "sender_full_name": "(deleted)",
        "timestamp": 1757340612
    },
    {
        "content": "<p>Thank you! I <em>must</em> say -- y'all are <em>so</em> nice! A lot of other disciplines would very quickly tell the novice: 'shush, go read. The AI can't help you' and just dismiss the giant text block! I'm finding different domains and communities are reacting radically differently to AI contributions, some will <em>not</em> hear of it, others are fascinated -- the right approach, I think, is skeptical!</p>",
        "id": 538237409,
        "sender_full_name": "Rye Howard-Stone",
        "timestamp": 1757340732
    },
    {
        "content": "<p>So on Numina -- the theorems that you are trying to prove, do they <em>come</em> stated in Lean?</p>",
        "id": 538237941,
        "sender_full_name": "Rye Howard-Stone",
        "timestamp": 1757340857
    },
    {
        "content": "<p>Announcing how to set up AI to answer questions with a monetary reward is likely to lead to commoditization and thus the reward $$$ to decrease.</p>",
        "id": 538238190,
        "sender_full_name": "Yakov Pechersky",
        "timestamp": 1757340916
    },
    {
        "content": "<p>I mean hey free market</p>",
        "id": 538238276,
        "sender_full_name": "Rye Howard-Stone",
        "timestamp": 1757340939
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"957416\">Rye Howard-Stone</span> <a href=\"#narrow/channel/270676-lean4/topic/Vibe.20Proving/near/538237941\">said</a>:</p>\n<blockquote>\n<p>So on Numina -- the theorems that you are trying to prove, do they <em>come</em> stated in Lean?</p>\n</blockquote>\n<p>They're not stated in Lean. You have to translate into Lean yourself. There are human reviewers after all.</p>",
        "id": 538238383,
        "sender_full_name": "(deleted)",
        "timestamp": 1757340967
    },
    {
        "content": "<p>I'm not afraid of more people contributing. Problems will get harder, but in the long run demand will increase, as Lean gets used by more people.</p>",
        "id": 538238517,
        "sender_full_name": "(deleted)",
        "timestamp": 1757341002
    },
    {
        "content": "<p>That's why I openly talk about my methods.</p>",
        "id": 538238582,
        "sender_full_name": "(deleted)",
        "timestamp": 1757341017
    },
    {
        "content": "<p>AI is meh, I plan on using my natural stupidity as long as I can. <span aria-label=\"grinning\" class=\"emoji emoji-1f600\" role=\"img\" title=\"grinning\">:grinning:</span></p>\n<p>That probably means I don't know how to use AI correctly (probably too old). <span aria-label=\"sweat smile\" class=\"emoji emoji-1f605\" role=\"img\" title=\"sweat smile\">:sweat_smile:</span></p>",
        "id": 538239821,
        "sender_full_name": "Ilmārs Cīrulis",
        "timestamp": 1757341308
    },
    {
        "content": "<p>That's the beauty of what I've been finding out: it's our 'natural stupidity' that is <strong>best</strong> to use when accelerating ourselves with AI. That mindset ('I have the plan in my head, I know what I would do, I know how I'll check it.. it will just take a while') is <em>exactly</em> the kind of thing that is useful to codify as prompts (like West's fantastic Lean proving gist)</p>",
        "id": 538240623,
        "sender_full_name": "Rye Howard-Stone",
        "timestamp": 1757341504
    },
    {
        "content": "<p>Lol. Anyway</p>",
        "id": 538295189,
        "sender_full_name": "(deleted)",
        "timestamp": 1757357611
    },
    {
        "content": "<p>If the problem is API heavy GPT-5 with Cursor is likely to succeed</p>",
        "id": 538295237,
        "sender_full_name": "(deleted)",
        "timestamp": 1757357625
    },
    {
        "content": "<p>If the problem is reasoning heavy GPT-5 with Cursor is less likely to succeed</p>",
        "id": 538295273,
        "sender_full_name": "(deleted)",
        "timestamp": 1757357641
    },
    {
        "content": "<p>At least it's an improvement compared to Claude Code, which is unable to do anything</p>",
        "id": 538295389,
        "sender_full_name": "(deleted)",
        "timestamp": 1757357681
    },
    {
        "content": "<p>I haven't tried Cursor + GPT-5 without supplying an informal blueprint. In all previous attempts I always supplied a correct informal blueprint as a comment at the top of the file.</p>",
        "id": 538295546,
        "sender_full_name": "(deleted)",
        "timestamp": 1757357749
    },
    {
        "content": "<p>AI firms are actively monitoring the discussions here. I anticipate that they will start using GPT-5 in the future to prove some of the problems, taking them out of the problem pool.</p>",
        "id": 538295693,
        "sender_full_name": "(deleted)",
        "timestamp": 1757357816
    },
    {
        "content": "<p>I’m very happy to see Huỳnh Trần Khanh actively participating in AI collapse by feeding AI slop to AI training, please don’t let skeptics discourages you building us a better world!</p>",
        "id": 538364212,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1757401515
    },
    {
        "content": "<p>Ok I'll stop</p>",
        "id": 538364441,
        "sender_full_name": "(deleted)",
        "timestamp": 1757401613
    },
    {
        "content": "<p>But the actual work is much more complicated... I also talked about AI failing catastrophically too</p>",
        "id": 538364536,
        "sender_full_name": "(deleted)",
        "timestamp": 1757401648
    },
    {
        "content": "<p>I posted screenshots of failures on Zulip</p>",
        "id": 538364791,
        "sender_full_name": "(deleted)",
        "timestamp": 1757401776
    },
    {
        "content": "<p>I don’t think you can stop AI training on AI generated stuff and getting worse and worse. Nobody can.</p>",
        "id": 538364905,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1757401824
    },
    {
        "content": "<p>I'm really not sure here. It's just not obvious to me that an LLM driving some form of tree search, pruned via Lean feedback, cannot produce valid proof scripts, which, if incorporated in the initial training corpus will result in a stronger LLM (and hence agentic system). Indeed, it seems quite likely that this is possible --- and apparently contrary to Patrick's assertion. </p>\n<p>It's initially AI slop, but potentially it becomes something better after being rejected by Lean enough. :-)</p>\n<p>Even if you can get an LLM+Lean to get better than it started, or even better than humans, merely by running it in a closed box, it's still even more unclear how capabilities would scale with resources.</p>",
        "id": 538395835,
        "sender_full_name": "Kim Morrison",
        "timestamp": 1757411508
    },
    {
        "content": "<p>Too bad I'm not an AI engineer or an AI researcher. AI training feels like a giant game of guessing. But whatever, they want proofs, I give proofs. Some models claim to perform well on MiniF2F but end up being useless in real world usage. Some models are good enough for day-to-day use. And currently program verification doesn't get enough attention. I don't uncritically praise AI.</p>",
        "id": 538407748,
        "sender_full_name": "(deleted)",
        "timestamp": 1757415474
    },
    {
        "content": "<p>Project Numina has this tool to help everyone <del>participate in AI collapse</del> arm AI with a tool to verify Lean code: <a href=\"https://github.com/project-numina/kimina-lean-server\">https://github.com/project-numina/kimina-lean-server</a>. It is much more efficient than existing MCP servers. Try it out!</p>",
        "id": 538581466,
        "sender_full_name": "(deleted)",
        "timestamp": 1757488405
    },
    {
        "content": "<p><a href=\"/user_uploads/3121/fKdw9EOXQwiVHmQxJFdWpvJU/image.png\">image.png</a><br>\nGPT-5 has a strong tendency to cheat by adding an axiom.</p>\n<div class=\"message_inline_image\"><a href=\"/user_uploads/3121/fKdw9EOXQwiVHmQxJFdWpvJU/image.png\" title=\"image.png\"><img data-original-content-type=\"image/png\" data-original-dimensions=\"1920x1080\" src=\"/user_uploads/thumbnail/3121/fKdw9EOXQwiVHmQxJFdWpvJU/image.png/840x560.webp\"></a></div>",
        "id": 538628492,
        "sender_full_name": "(deleted)",
        "timestamp": 1757504317
    },
    {
        "content": "<p>When I task my students (scientists/engineers) to prove things, I think many of them implement forms of vibe proving. It’s not usually systematic and automated like this via Cursor, but instead involves manually chatting while copy-pasting Lean code and errors into the chat window.</p>",
        "id": 538646246,
        "sender_full_name": "Tyler Josephson ⚛️",
        "timestamp": 1757509406
    },
    {
        "content": "<p>I've tried using GPT-4o mini for Lean questions a few times but it always hallucinated. :&lt;</p>",
        "id": 538649547,
        "sender_full_name": "Jakub Nowak",
        "timestamp": 1757510264
    },
    {
        "content": "<p>I've found a middle ground that has been working nicely for me. Instead of expecting the LLM to spit out precise proofs, I ask it to structure a proof so I can deal with the details myself.</p>",
        "id": 538650106,
        "sender_full_name": "Arthur Paulino",
        "timestamp": 1757510423
    },
    {
        "content": "<p>I am agentically proving an inequality</p>",
        "id": 538651139,
        "sender_full_name": "(deleted)",
        "timestamp": 1757510697
    },
    {
        "content": "<p>My intuition: there's plenty Lean 3 code out there. And even within the Lean 4 realm, mathlib (and other libs) are alive and evolve. And, of course, Lean 4 itself is alive and evolves!</p>",
        "id": 538651147,
        "sender_full_name": "Arthur Paulino",
        "timestamp": 1757510699
    },
    {
        "content": "<p>Yeah. Good thing Cursor provides enough context about the current state of mathlib4 to GPT-5</p>",
        "id": 538651547,
        "sender_full_name": "(deleted)",
        "timestamp": 1757510802
    },
    {
        "content": "<p>Otherwise GPT-5 keeps hallucinating to death</p>",
        "id": 538651593,
        "sender_full_name": "(deleted)",
        "timestamp": 1757510815
    },
    {
        "content": "<p>This of course requires that you delete gitignore</p>",
        "id": 538651749,
        "sender_full_name": "(deleted)",
        "timestamp": 1757510849
    },
    {
        "content": "<p>Hmm. Errors are everywhere. Everything moves slowly</p>",
        "id": 538652161,
        "sender_full_name": "(deleted)",
        "timestamp": 1757510948
    },
    {
        "content": "<p>Let's see how far it goes in the end</p>",
        "id": 538652196,
        "sender_full_name": "(deleted)",
        "timestamp": 1757510954
    },
    {
        "content": "<p>Maybe all this is crap</p>",
        "id": 538652345,
        "sender_full_name": "(deleted)",
        "timestamp": 1757510991
    },
    {
        "content": "<p>And I'm now using up the context window. I'll just tell the agent to fix existing errors for now.</p>",
        "id": 538653066,
        "sender_full_name": "(deleted)",
        "timestamp": 1757511162
    },
    {
        "content": "<p>Speculation: I have a feeling someone at OpenAI did at least some amount of fine tuning so GPT-5 is able to write Lean code. GPT-5 proofs have a lot of have statements too.</p>",
        "id": 538683801,
        "sender_full_name": "(deleted)",
        "timestamp": 1757518614
    },
    {
        "content": "<p>And as I mentioned in a previous thread, Project Numina deliberately engineered their LLM to produce many have statements. This is directly confirmed by their paper.</p>",
        "id": 538683969,
        "sender_full_name": "(deleted)",
        "timestamp": 1757518659
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"955304\">West</span> <a href=\"#narrow/channel/270676-lean4/topic/Vibe.20Proving/near/537472967\">said</a>:</p>\n<blockquote>\n<p>Is it safe to say that, as long as you understand the final theorem you're working towards, and you manage to get something to compile with no errors and no <code>sorry</code>s/<code>admit</code>s, then it doesn't really matter what led you to your goal?</p>\n</blockquote>\n<p>I'd dare to say the style of the proof does matter a lot for _proof maintenance_.</p>\n<p>If your proof is a one-shot thing, it shouldn't indeed matter.</p>\n<p>Maybe <a href=\"https://openreview.net/forum?id=dWsdJAXjQD\">this paper</a> is of your interest.</p>",
        "id": 538701445,
        "sender_full_name": "Emilio Jesús Gallego Arias",
        "timestamp": 1757524015
    },
    {
        "content": "<p>Proof maintenance becomes easy when AI can write the proofs, making it cheaper to make a new proof when underlying definitions change</p>",
        "id": 538704842,
        "sender_full_name": "(deleted)",
        "timestamp": 1757525210
    },
    {
        "content": "<p>This is what Certified Programming with Dependent Types says... wait it doesn't mention AI, just automation in general</p>",
        "id": 538704923,
        "sender_full_name": "(deleted)",
        "timestamp": 1757525238
    },
    {
        "content": "<p>It all becomes easily defensible if you assume you have the ideal AI system</p>",
        "id": 538706249,
        "sender_full_name": "Arthur Paulino",
        "timestamp": 1757525684
    },
    {
        "content": "<p>Which doesn't exist. That's why I get paid.</p>",
        "id": 538708712,
        "sender_full_name": "(deleted)",
        "timestamp": 1757526591
    },
    {
        "content": "<p>Sorry. Looks like this thing isn't as magical as I thought. Good thing it helped me earn $105. Now it isn't very helpful anymore. Gemini Deep Think is the most helpful tool I've used, nothing else has come close.</p>",
        "id": 538827724,
        "sender_full_name": "(deleted)",
        "timestamp": 1757588405
    },
    {
        "content": "<p>Sorry to disappoint. AI collapse hasn't happened yet.</p>",
        "id": 538827803,
        "sender_full_name": "(deleted)",
        "timestamp": 1757588432
    },
    {
        "content": "<p>I guess the most important thing I need to improve is my brain. I shouldn't search for the next magical AI tool.</p>",
        "id": 538827985,
        "sender_full_name": "(deleted)",
        "timestamp": 1757588501
    },
    {
        "content": "<p>May I state my personal opinion. Every time a person claims they managed to hook Lean and some lemma search tools up to a general purpose LLM it always turns out to be less useful than expected.</p>",
        "id": 538837731,
        "sender_full_name": "(deleted)",
        "timestamp": 1757591698
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110031\">Patrick Massot</span> <a href=\"#narrow/channel/270676-lean4/topic/Vibe.20Proving/near/538364905\">said</a>:</p>\n<blockquote>\n<p>I don’t think you can stop AI training on AI generated stuff and getting worse and worse. Nobody can.</p>\n</blockquote>\n<p>I see a lot of missconceptions like this about AI. and it's quite the opposite. AI trained on pure RL becomes better and better, when there is no human in the loop. <br>\nAI learning by itself using it's own learned synthetic data makes the AI better. And you can do RL on lean thanks to lean feedback.<br>\nI'm pretty sure we'll see superhuman AI on lean proofs very soon thanks to this RL process.<br>\nHallucinations you currently see on LLMs will vanish when the new insights from OpenAI on why they hallucinate so much are applied as the new training process standards.</p>",
        "id": 539038828,
        "sender_full_name": "Alfredo Moreira-Rosa",
        "timestamp": 1757675803
    },
    {
        "content": "<p>Here the paper on the OpenaI insights :<br>\n<a href=\"https://arxiv.org/abs/2509.04664\">https://arxiv.org/abs/2509.04664</a></p>",
        "id": 539039470,
        "sender_full_name": "Alfredo Moreira-Rosa",
        "timestamp": 1757676047
    },
    {
        "content": "<p>My impression is that a lot of AI trained on AI is carefully controlled by the researchers building the system, such that they're aware of the loopbacks. If they're paying specifically for human expert data, and unknowingly end up with AI output from a competing system, then probably 1) it is harder to design a stable training system, and 2) this might put them at legal risk if the other AI system prohibits training on its outputs.</p>",
        "id": 539041323,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1757676684
    },
    {
        "content": "<p>Yes, feedback is a game changer. Quite literally.<br>\nThat's how AlphaGo eventually beat Lee Sedol. Because the computer can play against itself a number of times in an hour no human can come even close in a lifetime.</p>\n<p>One challenge is designing the heuristic for how close you think you are from enclosing a proof goal. A dummy heuristic is \"return 1 if the goal is closed and 0 otherwise\".</p>",
        "id": 539062531,
        "sender_full_name": "Arthur Paulino",
        "timestamp": 1757682914
    },
    {
        "content": "<p>The AI community has yet to devise another heuristic</p>",
        "id": 539063063,
        "sender_full_name": "(deleted)",
        "timestamp": 1757683056
    },
    {
        "content": "<p>It's very widely used</p>",
        "id": 539063094,
        "sender_full_name": "(deleted)",
        "timestamp": 1757683065
    },
    {
        "content": "<p>It makes sense to be conservative. If you have a bad heuristic, you can waste a lot of money and time training a system with wrong rewards</p>",
        "id": 539065987,
        "sender_full_name": "Arthur Paulino",
        "timestamp": 1757683793
    },
    {
        "content": "<p>Hmm, there are interesting safe ideas like punishing the proof context size, proof size and number of theorems used to reward succinct and self-contained proofs as a proxy for \"I know what I'm doing\"</p>",
        "id": 539068138,
        "sender_full_name": "Arthur Paulino",
        "timestamp": 1757684310
    }
]