[
    {
        "content": "<p>I just run <code>lake build</code> on math lib and realized that my system is 50% idle using only 8 out of 16 threads. I would be surprised if mathlib has only 5-8 parallel build opportunities. Hence, I wonder if there is a way to ask lake to use more threads ?</p>",
        "id": 397255612,
        "sender_full_name": "Tobias Grosser",
        "timestamp": 1697616176
    },
    {
        "content": "<p>Hmm, that is strange. I peak at much higher than 800%, and average about 1400% over the whole build.</p>",
        "id": 397261280,
        "sender_full_name": "Scott Morrison",
        "timestamp": 1697618362
    },
    {
        "content": "<p>Early and late in mathlib it is constrained by available jobs.</p>",
        "id": 397261332,
        "sender_full_name": "Scott Morrison",
        "timestamp": 1697618385
    },
    {
        "content": "<p>(Reducing unnecessary imports presumably has some marginal impact on this.)</p>",
        "id": 397261434,
        "sender_full_name": "Scott Morrison",
        "timestamp": 1697618409
    },
    {
        "content": "<p>I just run a full 'lake clean; time lake build' run and get the following output:<br>\n  lake build  22191.10s user 738.37s system 1660% cpu 23:00.82 total</p>\n<p>However, when I look at <code>top</code>, the system is consistently 10-50% idle. I am considering buying a high threadcount machine and am really not sure if that would speedup the builds.</p>",
        "id": 397268630,
        "sender_full_name": "Tobias Grosser",
        "timestamp": 1697621011
    },
    {
        "content": "<p>I would like to run lake single-threaded to see how much speedup going from 1 to 16 cores gives. Is there such an option for lake?</p>",
        "id": 397268700,
        "sender_full_name": "Tobias Grosser",
        "timestamp": 1697621041
    },
    {
        "content": "<p>I don't recall how <span class=\"user-mention\" data-user-id=\"110024\">@Sebastian Ullrich</span> made <a href=\"#narrow/stream/287929-mathlib4/topic/port.20benchmark/near/375478320\">this chart</a> but it apparently has a way to also simulate a build with maximum parallelism.</p>",
        "id": 397342679,
        "sender_full_name": "Jireh Loreaux",
        "timestamp": 1697644548
    },
    {
        "content": "<p>This answer is <a href=\"#narrow/stream/287929-mathlib4/topic/port.20benchmark/near/320765625\">here</a>, but he doesn't recommend nixprof for outside use, at least at the time of that message, and it doesn't look like the repo has been updated much since then.</p>",
        "id": 397343917,
        "sender_full_name": "Jireh Loreaux",
        "timestamp": 1697644948
    },
    {
        "content": "<p>Thank you, that is interesting.</p>",
        "id": 397344635,
        "sender_full_name": "Tobias Grosser",
        "timestamp": 1697645145
    },
    {
        "content": "<p>I've often seen it be IO-limited rather than CPU limited.</p>",
        "id": 397345831,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1697645578
    },
    {
        "content": "<p>DRAM bandwidth?</p>",
        "id": 397346430,
        "sender_full_name": "Tobias Grosser",
        "timestamp": 1697645800
    },
    {
        "content": "<p>Eric, the IO should be small right? Or do you mean writing <code>olean</code>s? I guess that could be potentially significant.</p>",
        "id": 397347739,
        "sender_full_name": "Jireh Loreaux",
        "timestamp": 1697646294
    },
    {
        "content": "<p>Some combination of writing oleans and paging between all the memory-mapped oleans</p>",
        "id": 397348347,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1697646562
    },
    {
        "content": "<blockquote>\n<p>and realized that my system is 50% idle using only 8 out of 16 threads.</p>\n</blockquote>\n<p>Is it possible that there's a setting somewhere  like<code>make -j8</code> that is restricting parallelism by default to avoid surprising the user?</p>",
        "id": 397348521,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1697646622
    },
    {
        "content": "<p>I wanted to play with the -j option, but I cannot find how to control the thread level parallelism with lake.</p>",
        "id": 397349647,
        "sender_full_name": "Tobias Grosser",
        "timestamp": 1697647073
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"122318\">@Tobias Grosser</span> There isn't a way to do this from Lake, because Lean does not provide a API-based thread control mechanism. However, there is a program wide limiting mechanism available through <code>LEAN_NUM_THREADS</code> (as mentioned <a href=\"#narrow/stream/270676-lean4/topic/How.20to.20limit.20the.20number.20of.20concurrent.20tasks.3F/near/362908862\">here</a>)</p>",
        "id": 397357167,
        "sender_full_name": "Mac Malone",
        "timestamp": 1697650184
    },
    {
        "content": "<p>This is what I was looking for. I give this a shot.</p>",
        "id": 397359766,
        "sender_full_name": "Tobias Grosser",
        "timestamp": 1697651451
    },
    {
        "content": "<p>I just redid the experiment on a 56 core 12 thread machine with today's mathlib:</p>\n<p>real    16m23.110s<br>\nuser    253m2.379s<br>\nsys     14m39.441s</p>\n<p>So we get about 16 x speedup on a 56 core system. With perfect scaling we should be at 5 m roughly. I guess the issue is that lean/lake cannot yet extract sufficient parallelism from mathlib. Interesting.</p>",
        "id": 401449115,
        "sender_full_name": "Tobias Grosser",
        "timestamp": 1699659448
    },
    {
        "content": "<p>In-file parallelism (coming!) will help here.</p>\n<p>Disentangling the mathlib import tree can help as well. (i.e. locate moments when relatively few files are compiling simultaneously, and then try and reduce import dependencies on those).</p>\n<p>It might also be possible, but only with a substantial change to Lake, to prioritize compiling those files with the most downstream dependents. This would mean that during the phases when we are CPU bound rather than import bound, we work on the files which will open up more tasks.</p>",
        "id": 401454297,
        "sender_full_name": "Scott Morrison",
        "timestamp": 1699663100
    },
    {
        "content": "<p>I think an automatic tool that showed where the import graph bottlenecks were would be great.</p>",
        "id": 401454362,
        "sender_full_name": "Scott Morrison",
        "timestamp": 1699663144
    },
    {
        "content": "<p>I'm not really sure what the spec of such a tool would be.</p>",
        "id": 401454563,
        "sender_full_name": "Scott Morrison",
        "timestamp": 1699663245
    },
    {
        "content": "<p>Or whether it should try to run \"live\", or if we should record the build times of each file and then do an offline analysis assuming infinite parallelism.</p>",
        "id": 401454619,
        "sender_full_name": "Scott Morrison",
        "timestamp": 1699663277
    },
    {
        "content": "<p>Even just producing a flame graph, and looking for the files that \"finish at the bottom of a trough\" would be a great start.</p>",
        "id": 401454796,
        "sender_full_name": "Scott Morrison",
        "timestamp": 1699663371
    },
    {
        "content": "<p>(i.e. files which, when finished, allow more cores to start working)</p>",
        "id": 401454825,
        "sender_full_name": "Scott Morrison",
        "timestamp": 1699663388
    },
    {
        "content": "<p>Then you would try to move those files earlier / split them / reduce dependencies on them.</p>",
        "id": 401454861,
        "sender_full_name": "Scott Morrison",
        "timestamp": 1699663409
    },
    {
        "content": "<p>One place that anecdata suggests is a bottleneck is <code>Mathlib.Analysis.Calculus.ContDiff</code>. I often see a build get stuck there, and immediately afterwards there are lots of things that can be compiled.</p>",
        "id": 401478827,
        "sender_full_name": "Scott Morrison",
        "timestamp": 1699678431
    },
    {
        "content": "<p>It is almost 3000 lines long.</p>",
        "id": 401478836,
        "sender_full_name": "Scott Morrison",
        "timestamp": 1699678440
    },
    {
        "content": "<p>And the import <code>Mathlib.Analysis.NormedSpace.FiniteDimension</code> is not needed until almost 2000 lines in, so I think there is an obvious split there.</p>",
        "id": 401478890,
        "sender_full_name": "Scott Morrison",
        "timestamp": 1699678476
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110087\">Scott Morrison</span> <a href=\"#narrow/stream/270676-lean4/topic/Lake.20parallel.20builds/near/401454297\">said</a>:</p>\n<blockquote>\n<p>In-file parallelism (coming!) will help here.</p>\n</blockquote>\n<p>I guess that's a good piece to the answer. Happy to beta-test.</p>",
        "id": 401549986,
        "sender_full_name": "Tobias Grosser",
        "timestamp": 1699745834
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110087\">Scott Morrison</span> <a href=\"#narrow/stream/270676-lean4/topic/Lake.20parallel.20builds/near/401454796\">said</a>:</p>\n<blockquote>\n<p>Even just producing a flame graph, and looking for the files that \"finish at the bottom of a trough\" would be a great start.</p>\n</blockquote>\n<p>A flame graph isn't really the right thing here, I believe we want a gantt chart. Although I don't think we can just do this nicely outside of lake I believe? It would probably have to be part of lake itself.</p>",
        "id": 401553138,
        "sender_full_name": "Henrik BÃ¶ving",
        "timestamp": 1699748677
    },
    {
        "content": "<p>If we just want to do longest pole analysis, the data we already have on the speed center, combined with a dependency graph, should do the trick</p>",
        "id": 401556745,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1699750862
    },
    {
        "content": "<p>I've previously (mathlib3 days) done longest pole analysis, but I did it in Mathematica.</p>",
        "id": 401563001,
        "sender_full_name": "Scott Morrison",
        "timestamp": 1699755093
    },
    {
        "content": "<p>Is there a way to get all of the file build times for a commit from <a href=\"http://speed.lean-fro.org/mathlib4/run-detail/137c79fb-447e-4e1f-b773-df3a1d85c5af\">speedcentre</a> without scraping pages?</p>",
        "id": 401563368,
        "sender_full_name": "Scott Morrison",
        "timestamp": 1699755414
    },
    {
        "content": "<p>Also, the speed center only reports per-file instruction counts, rather than wall-clock. But perhaps instruction count is a good enough proxy?</p>",
        "id": 401563605,
        "sender_full_name": "Scott Morrison",
        "timestamp": 1699755621
    },
    {
        "content": "<p><a href=\"http://speed.lean-fro.org/mathlib4/api/run/137c79fb-447e-4e1f-b773-df3a1d85c5af?all_values=true\">http://speed.lean-fro.org/mathlib4/api/run/137c79fb-447e-4e1f-b773-df3a1d85c5af?all_values=true</a> seems to do it, although you still need to do the commit sha --&gt; velcom id lookup.</p>",
        "id": 401563766,
        "sender_full_name": "Scott Morrison",
        "timestamp": 1699755766
    },
    {
        "content": "<p>I couldn't resist:</p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"bp\">%</span> <span class=\"n\">lake</span> <span class=\"n\">exe</span> <span class=\"n\">pole</span>\n<span class=\"n\">Mathlib</span> <span class=\"mi\">8581</span>\n<span class=\"n\">Mathlib.AlgebraicGeometry.Morphisms.FiniteType</span> <span class=\"mi\">8567</span>\n<span class=\"n\">Mathlib.AlgebraicGeometry.Morphisms.RingHomProperties</span> <span class=\"mi\">8557</span>\n<span class=\"n\">Mathlib.AlgebraicGeometry.Morphisms.Basic</span> <span class=\"mi\">6582</span>\n<span class=\"n\">Mathlib.AlgebraicGeometry.Pullbacks</span> <span class=\"mi\">6497</span>\n<span class=\"n\">Mathlib.AlgebraicGeometry.AffineScheme</span> <span class=\"mi\">6350</span>\n<span class=\"n\">Mathlib.AlgebraicGeometry.Restrict</span> <span class=\"mi\">5438</span>\n<span class=\"n\">Mathlib.AlgebraicGeometry.OpenImmersion</span> <span class=\"mi\">5182</span>\n<span class=\"n\">Mathlib.AlgebraicGeometry.Scheme</span> <span class=\"mi\">5106</span>\n<span class=\"n\">Mathlib.AlgebraicGeometry.Spec</span> <span class=\"mi\">5067</span>\n<span class=\"n\">Mathlib.AlgebraicGeometry.StructureSheaf</span> <span class=\"mi\">4936</span>\n<span class=\"n\">Mathlib.AlgebraicGeometry.PrimeSpectrum.Basic</span> <span class=\"mi\">4689</span>\n<span class=\"n\">Mathlib.RingTheory.Ideal.Over</span> <span class=\"mi\">4645</span>\n<span class=\"n\">Mathlib.RingTheory.Localization.Integral</span> <span class=\"mi\">4578</span>\n<span class=\"n\">Mathlib.RingTheory.Algebraic</span> <span class=\"mi\">4517</span>\n<span class=\"n\">Mathlib.RingTheory.IntegralClosure</span> <span class=\"mi\">4445</span>\n<span class=\"n\">Mathlib.LinearAlgebra.Matrix.Charpoly.LinearMap</span> <span class=\"mi\">4269</span>\n<span class=\"n\">Mathlib.LinearAlgebra.Matrix.Charpoly.Coeff</span> <span class=\"mi\">4228</span>\n<span class=\"n\">Mathlib.LinearAlgebra.Matrix.Charpoly.Basic</span> <span class=\"mi\">4133</span>\n<span class=\"n\">Mathlib.RingTheory.PolynomialAlgebra</span> <span class=\"mi\">4112</span>\n<span class=\"n\">Mathlib.RingTheory.MatrixAlgebra</span> <span class=\"mi\">4041</span>\n<span class=\"n\">Mathlib.RingTheory.TensorProduct</span> <span class=\"mi\">3990</span>\n<span class=\"n\">Mathlib.LinearAlgebra.FiniteDimensional</span> <span class=\"mi\">3680</span>\n<span class=\"n\">Mathlib.LinearAlgebra.FreeModule.Finite.Rank</span> <span class=\"mi\">3535</span>\n<span class=\"n\">Mathlib.LinearAlgebra.Finrank</span> <span class=\"mi\">3509</span>\n<span class=\"n\">Mathlib.LinearAlgebra.Dimension</span> <span class=\"mi\">3458</span>\n<span class=\"n\">Mathlib.LinearAlgebra.InvariantBasisNumber</span> <span class=\"mi\">3320</span>\n<span class=\"n\">Mathlib.RingTheory.PrincipalIdealDomain</span> <span class=\"mi\">3287</span>\n<span class=\"n\">Mathlib.RingTheory.UniqueFactorizationDomain</span> <span class=\"mi\">3258</span>\n<span class=\"n\">Mathlib.RingTheory.Noetherian</span> <span class=\"mi\">3033</span>\n<span class=\"n\">Mathlib.RingTheory.Nilpotent</span> <span class=\"mi\">2902</span>\n<span class=\"n\">Mathlib.LinearAlgebra.Matrix.ToLin</span> <span class=\"mi\">2868</span>\n<span class=\"n\">Mathlib.Algebra.Algebra.Subalgebra.Tower</span> <span class=\"mi\">2533</span>\n<span class=\"n\">Mathlib.Algebra.Algebra.Subalgebra.Basic</span> <span class=\"mi\">2512</span>\n<span class=\"n\">Mathlib.RingTheory.Ideal.Operations</span> <span class=\"mi\">2331</span>\n<span class=\"n\">Mathlib.LinearAlgebra.Basis.Bilinear</span> <span class=\"mi\">2144</span>\n<span class=\"n\">Mathlib.LinearAlgebra.Basis</span> <span class=\"mi\">2128</span>\n<span class=\"n\">Mathlib.LinearAlgebra.LinearIndependent</span> <span class=\"mi\">1980</span>\n<span class=\"n\">Mathlib.LinearAlgebra.Prod</span> <span class=\"mi\">1853</span>\n<span class=\"n\">Mathlib.Algebra.Algebra.Prod</span> <span class=\"mi\">1762</span>\n<span class=\"n\">Mathlib.Algebra.Algebra.Hom</span> <span class=\"mi\">1751</span>\n<span class=\"n\">Mathlib.Algebra.Algebra.Basic</span> <span class=\"mi\">1685</span>\n<span class=\"n\">Mathlib.LinearAlgebra.Basic</span> <span class=\"mi\">1612</span>\n<span class=\"n\">Mathlib.Data.Finsupp.Basic</span> <span class=\"mi\">1425</span>\n<span class=\"n\">Mathlib.Algebra.BigOperators.Finsupp</span> <span class=\"mi\">1347</span>\n<span class=\"n\">Mathlib.Algebra.BigOperators.Fin</span> <span class=\"mi\">1277</span>\n<span class=\"n\">Mathlib.Data.Fintype.Fin</span> <span class=\"mi\">1243</span>\n<span class=\"n\">Mathlib.Data.Fin.Interval</span> <span class=\"mi\">1238</span>\n<span class=\"n\">Mathlib.Data.Nat.Interval</span> <span class=\"mi\">1228</span>\n<span class=\"n\">Mathlib.Data.Finset.LocallyFinite</span> <span class=\"mi\">1218</span>\n<span class=\"n\">Mathlib.Order.LocallyFinite</span> <span class=\"mi\">1182</span>\n<span class=\"n\">Mathlib.Data.Finset.Preimage</span> <span class=\"mi\">1148</span>\n<span class=\"n\">Mathlib.Algebra.BigOperators.Basic</span> <span class=\"mi\">1142</span>\n<span class=\"n\">Mathlib.Data.Finset.Powerset</span> <span class=\"mi\">1039</span>\n<span class=\"n\">Mathlib.Data.Finset.Lattice</span> <span class=\"mi\">1028</span>\n<span class=\"n\">Mathlib.Data.Finset.Prod</span> <span class=\"mi\">963</span>\n<span class=\"n\">Mathlib.Data.Finset.Card</span> <span class=\"mi\">944</span>\n<span class=\"n\">Mathlib.Data.Finset.Image</span> <span class=\"mi\">928</span>\n<span class=\"n\">Mathlib.Data.Finset.Basic</span> <span class=\"mi\">904</span>\n<span class=\"n\">Mathlib.Data.Multiset.FinsetOps</span> <span class=\"mi\">824</span>\n<span class=\"n\">Mathlib.Data.Multiset.Dedup</span> <span class=\"mi\">817</span>\n<span class=\"n\">Mathlib.Data.Multiset.Nodup</span> <span class=\"mi\">812</span>\n<span class=\"n\">Mathlib.Data.Multiset.Bind</span> <span class=\"mi\">806</span>\n<span class=\"n\">Mathlib.Algebra.BigOperators.Multiset.Basic</span> <span class=\"mi\">792</span>\n<span class=\"n\">Mathlib.Data.Multiset.Basic</span> <span class=\"mi\">769</span>\n<span class=\"n\">Mathlib.Data.List.Perm</span> <span class=\"mi\">699</span>\n<span class=\"n\">Mathlib.Data.List.Dedup</span> <span class=\"mi\">660</span>\n<span class=\"n\">Mathlib.Data.List.Nodup</span> <span class=\"mi\">654</span>\n<span class=\"n\">Mathlib.Data.List.Lattice</span> <span class=\"mi\">642</span>\n<span class=\"n\">Mathlib.Data.List.Count</span> <span class=\"mi\">635</span>\n<span class=\"n\">Mathlib.Data.List.BigOperators.Basic</span> <span class=\"mi\">630</span>\n<span class=\"n\">Mathlib.Data.List.Forall2</span> <span class=\"mi\">602</span>\n<span class=\"n\">Mathlib.Data.List.Infix</span> <span class=\"mi\">587</span>\n<span class=\"n\">Mathlib.Data.List.Basic</span> <span class=\"mi\">578</span>\n<span class=\"n\">Mathlib.Data.Nat.Order.Basic</span> <span class=\"mi\">506</span>\n<span class=\"n\">Mathlib.Algebra.Order.Ring.Canonical</span> <span class=\"mi\">491</span>\n<span class=\"n\">Mathlib.Algebra.Order.Ring.Defs</span> <span class=\"mi\">484</span>\n<span class=\"n\">Mathlib.Algebra.Order.Group.Defs</span> <span class=\"mi\">441</span>\n<span class=\"n\">Mathlib.Order.Hom.Basic</span> <span class=\"mi\">408</span>\n<span class=\"n\">Mathlib.Order.WithBot</span> <span class=\"mi\">384</span>\n<span class=\"n\">Mathlib.Order.BoundedOrder</span> <span class=\"mi\">362</span>\n<span class=\"n\">Mathlib.Data.Option.Basic</span> <span class=\"mi\">352</span>\n</code></pre></div>",
        "id": 401570302,
        "sender_full_name": "Scott Morrison",
        "timestamp": 1699761091
    },
    {
        "content": "<p>This displays the cumulative instructions (in billions) assuming infinite parallelism.</p>",
        "id": 401570635,
        "sender_full_name": "Scott Morrison",
        "timestamp": 1699761359
    },
    {
        "content": "<p>You can also use <code>--to</code>, for the longest pole to your favourite target:</p>",
        "id": 401570687,
        "sender_full_name": "Scott Morrison",
        "timestamp": 1699761380
    },
    {
        "content": "<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"bp\">%</span> <span class=\"n\">lake</span> <span class=\"n\">exe</span> <span class=\"n\">pole</span> <span class=\"c1\">--to Mathlib.Analysis.Calculus.ContDiff.Basic</span>\n<span class=\"n\">Mathlib.Analysis.Calculus.ContDiff.Basic</span> <span class=\"mi\">5850</span>\n<span class=\"n\">Mathlib.Analysis.Calculus.ContDiff.Defs</span> <span class=\"mi\">5418</span>\n<span class=\"n\">Mathlib.Analysis.Calculus.FDeriv.Mul</span> <span class=\"mi\">5029</span>\n<span class=\"n\">Mathlib.Analysis.Calculus.FDeriv.Bilinear</span> <span class=\"mi\">4715</span>\n<span class=\"n\">Mathlib.Analysis.Calculus.FDeriv.Prod</span> <span class=\"mi\">4678</span>\n<span class=\"n\">Mathlib.Analysis.Calculus.FDeriv.Linear</span> <span class=\"mi\">4594</span>\n<span class=\"n\">Mathlib.Analysis.NormedSpace.BoundedLinearMaps</span> <span class=\"mi\">4579</span>\n<span class=\"n\">Mathlib.Analysis.NormedSpace.Multilinear</span> <span class=\"mi\">4491</span>\n<span class=\"n\">Mathlib.Analysis.NormedSpace.OperatorNorm</span> <span class=\"mi\">3793</span>\n<span class=\"n\">Mathlib.Analysis.LocallyConvex.WithSeminorms</span> <span class=\"mi\">3105</span>\n<span class=\"n\">Mathlib.Topology.Algebra.Equicontinuity</span> <span class=\"mi\">2953</span>\n<span class=\"n\">Mathlib.Topology.Algebra.UniformConvergence</span> <span class=\"mi\">2941</span>\n<span class=\"n\">Mathlib.Analysis.LocallyConvex.Bounded</span> <span class=\"mi\">2909</span>\n<span class=\"n\">Mathlib.Analysis.Seminorm</span> <span class=\"mi\">2877</span>\n<span class=\"n\">Mathlib.Analysis.LocallyConvex.Basic</span> <span class=\"mi\">2682</span>\n<span class=\"n\">Mathlib.Analysis.NormedSpace.Basic</span> <span class=\"mi\">2646</span>\n<span class=\"n\">Mathlib.Analysis.Normed.MulAction</span> <span class=\"mi\">2600</span>\n<span class=\"n\">Mathlib.Analysis.Normed.Field.Basic</span> <span class=\"mi\">2584</span>\n<span class=\"n\">Mathlib.Algebra.Algebra.Subalgebra.Basic</span> <span class=\"mi\">2512</span>\n<span class=\"n\">Mathlib.RingTheory.Ideal.Operations</span> <span class=\"mi\">2331</span>\n<span class=\"n\">Mathlib.LinearAlgebra.Basis.Bilinear</span> <span class=\"mi\">2144</span>\n<span class=\"n\">Mathlib.LinearAlgebra.Basis</span> <span class=\"mi\">2128</span>\n<span class=\"n\">Mathlib.LinearAlgebra.LinearIndependent</span> <span class=\"mi\">1980</span>\n<span class=\"n\">Mathlib.LinearAlgebra.Prod</span> <span class=\"mi\">1853</span>\n<span class=\"n\">Mathlib.Algebra.Algebra.Prod</span> <span class=\"mi\">1762</span>\n<span class=\"n\">Mathlib.Algebra.Algebra.Hom</span> <span class=\"mi\">1751</span>\n<span class=\"n\">Mathlib.Algebra.Algebra.Basic</span> <span class=\"mi\">1685</span>\n<span class=\"n\">Mathlib.LinearAlgebra.Basic</span> <span class=\"mi\">1612</span>\n<span class=\"n\">Mathlib.Data.Finsupp.Basic</span> <span class=\"mi\">1425</span>\n<span class=\"n\">Mathlib.Algebra.BigOperators.Finsupp</span> <span class=\"mi\">1347</span>\n<span class=\"n\">Mathlib.Algebra.BigOperators.Fin</span> <span class=\"mi\">1277</span>\n<span class=\"n\">Mathlib.Data.Fintype.Fin</span> <span class=\"mi\">1243</span>\n<span class=\"n\">Mathlib.Data.Fin.Interval</span> <span class=\"mi\">1238</span>\n<span class=\"n\">Mathlib.Data.Nat.Interval</span> <span class=\"mi\">1228</span>\n<span class=\"n\">Mathlib.Data.Finset.LocallyFinite</span> <span class=\"mi\">1218</span>\n<span class=\"n\">Mathlib.Order.LocallyFinite</span> <span class=\"mi\">1182</span>\n<span class=\"n\">Mathlib.Data.Finset.Preimage</span> <span class=\"mi\">1148</span>\n<span class=\"n\">Mathlib.Algebra.BigOperators.Basic</span> <span class=\"mi\">1142</span>\n<span class=\"n\">Mathlib.Data.Finset.Powerset</span> <span class=\"mi\">1039</span>\n<span class=\"n\">Mathlib.Data.Finset.Lattice</span> <span class=\"mi\">1028</span>\n<span class=\"n\">Mathlib.Data.Finset.Prod</span> <span class=\"mi\">963</span>\n<span class=\"n\">Mathlib.Data.Finset.Card</span> <span class=\"mi\">944</span>\n<span class=\"n\">Mathlib.Data.Finset.Image</span> <span class=\"mi\">928</span>\n<span class=\"n\">Mathlib.Data.Finset.Basic</span> <span class=\"mi\">904</span>\n<span class=\"n\">Mathlib.Data.Multiset.FinsetOps</span> <span class=\"mi\">824</span>\n<span class=\"n\">Mathlib.Data.Multiset.Dedup</span> <span class=\"mi\">817</span>\n<span class=\"n\">Mathlib.Data.Multiset.Nodup</span> <span class=\"mi\">812</span>\n<span class=\"n\">Mathlib.Data.Multiset.Bind</span> <span class=\"mi\">806</span>\n<span class=\"n\">Mathlib.Algebra.BigOperators.Multiset.Basic</span> <span class=\"mi\">792</span>\n<span class=\"n\">Mathlib.Data.Multiset.Basic</span> <span class=\"mi\">769</span>\n<span class=\"n\">Mathlib.Data.List.Perm</span> <span class=\"mi\">699</span>\n<span class=\"n\">Mathlib.Data.List.Dedup</span> <span class=\"mi\">660</span>\n<span class=\"n\">Mathlib.Data.List.Nodup</span> <span class=\"mi\">654</span>\n<span class=\"n\">Mathlib.Data.List.Lattice</span> <span class=\"mi\">642</span>\n<span class=\"n\">Mathlib.Data.List.Count</span> <span class=\"mi\">635</span>\n<span class=\"n\">Mathlib.Data.List.BigOperators.Basic</span> <span class=\"mi\">630</span>\n<span class=\"n\">Mathlib.Data.List.Forall2</span> <span class=\"mi\">602</span>\n<span class=\"n\">Mathlib.Data.List.Infix</span> <span class=\"mi\">587</span>\n<span class=\"n\">Mathlib.Data.List.Basic</span> <span class=\"mi\">578</span>\n<span class=\"n\">Mathlib.Data.Nat.Order.Basic</span> <span class=\"mi\">506</span>\n<span class=\"n\">Mathlib.Algebra.Order.Ring.Canonical</span> <span class=\"mi\">491</span>\n<span class=\"n\">Mathlib.Algebra.Order.Ring.Defs</span> <span class=\"mi\">484</span>\n<span class=\"n\">Mathlib.Algebra.Order.Group.Defs</span> <span class=\"mi\">441</span>\n<span class=\"n\">Mathlib.Order.Hom.Basic</span> <span class=\"mi\">408</span>\n<span class=\"n\">Mathlib.Order.WithBot</span> <span class=\"mi\">384</span>\n<span class=\"n\">Mathlib.Order.BoundedOrder</span> <span class=\"mi\">362</span>\n<span class=\"n\">Mathlib.Data.Option.Basic</span> <span class=\"mi\">352</span>\n</code></pre></div>",
        "id": 401570699,
        "sender_full_name": "Scott Morrison",
        "timestamp": 1699761395
    },
    {
        "content": "<p><a href=\"https://github.com/leanprover-community/mathlib4/pull/8361\">#8361</a></p>",
        "id": 401573142,
        "sender_full_name": "Scott Morrison",
        "timestamp": 1699762809
    },
    {
        "content": "<p>The second file is <code>Mathlib.AlgebraicGeometry.Morphisms.RingHomProperties</code>, which is my cue to ask for a review (or feedback) on <a href=\"https://github.com/leanprover-community/mathlib4/pull/8299\">#8299</a></p>",
        "id": 401595674,
        "sender_full_name": "Mauricio Collares",
        "timestamp": 1699780585
    },
    {
        "content": "<p>Lovely. I wonder if we could also print the 'sequential' performance, just adding up all numbers, and - for convenience -- the maximal potential speedup.</p>",
        "id": 401607191,
        "sender_full_name": "Tobias Grosser",
        "timestamp": 1699789800
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"122318\">@Tobias Grosser</span>, I've updated the output format. Rather than printing the sequential performance separately, I thought it was more useful to print the speedup factor. The current output looks like:</p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"n\">file</span>                                                    <span class=\"bp\">|</span> <span class=\"n\">instructions</span> <span class=\"bp\">|</span> <span class=\"n\">parallelism</span>\n<span class=\"c1\">------------------------------------------------------- | ------------ | -----------</span>\n<span class=\"n\">Mathlib</span>                                                 <span class=\"bp\">|</span> <span class=\"mi\">7377447</span>      <span class=\"bp\">|</span> <span class=\"n\">x18.21</span>\n<span class=\"n\">Mathlib.NumberTheory.NumberField.Units</span>                  <span class=\"bp\">|</span> <span class=\"mi\">7363973</span>      <span class=\"bp\">|</span> <span class=\"n\">x7.83</span>\n<span class=\"n\">Mathlib.NumberTheory.NumberField.CanonicalEmbedding</span>     <span class=\"bp\">|</span> <span class=\"mi\">7020425</span>      <span class=\"bp\">|</span> <span class=\"n\">x7.40</span>\n<span class=\"n\">Mathlib.NumberTheory.NumberField.Embeddings</span>             <span class=\"bp\">|</span> <span class=\"mi\">6840733</span>      <span class=\"bp\">|</span> <span class=\"n\">x7.50</span>\n<span class=\"n\">Mathlib.Analysis.Complex.Polynomial</span>                     <span class=\"bp\">|</span> <span class=\"mi\">6772681</span>      <span class=\"bp\">|</span> <span class=\"n\">x7.11</span>\n<span class=\"n\">Mathlib.Analysis.Complex.Liouville</span>                      <span class=\"bp\">|</span> <span class=\"mi\">6763172</span>      <span class=\"bp\">|</span> <span class=\"n\">x6.68</span>\n<span class=\"n\">Mathlib.Analysis.Complex.CauchyIntegral</span>                 <span class=\"bp\">|</span> <span class=\"mi\">6724325</span>      <span class=\"bp\">|</span> <span class=\"n\">x6.71</span>\n<span class=\"n\">Mathlib.MeasureTheory.Measure.Lebesgue.Complex</span>          <span class=\"bp\">|</span> <span class=\"mi\">6673273</span>      <span class=\"bp\">|</span> <span class=\"n\">x6.60</span>\n<span class=\"n\">Mathlib.MeasureTheory.Measure.Haar.InnerProductSpace</span>    <span class=\"bp\">|</span> <span class=\"mi\">6648245</span>      <span class=\"bp\">|</span> <span class=\"n\">x6.62</span>\n<span class=\"n\">Mathlib.Analysis.SpecialFunctions.Integrals</span>             <span class=\"bp\">|</span> <span class=\"mi\">6620833</span>      <span class=\"bp\">|</span> <span class=\"n\">x6.57</span>\n<span class=\"n\">Mathlib.MeasureTheory.Integral.FundThmCalculus</span>          <span class=\"bp\">|</span> <span class=\"mi\">6460684</span>      <span class=\"bp\">|</span> <span class=\"n\">x6.36</span>\n</code></pre></div>",
        "id": 401652373,
        "sender_full_name": "Scott Morrison",
        "timestamp": 1699835255
    },
    {
        "content": "<p>That's super interesting. So no need to run on more than 16 cores.</p>",
        "id": 401683944,
        "sender_full_name": "Tobias Grosser",
        "timestamp": 1699850759
    },
    {
        "content": "<p>I left a couple of comments.</p>",
        "id": 401686664,
        "sender_full_name": "Tobias Grosser",
        "timestamp": 1699851757
    },
    {
        "content": "<p>I am also a little surprised that about the following output:</p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"bp\">~/</span><span class=\"n\">Projects</span><span class=\"bp\">/</span><span class=\"n\">mathlib4</span><span class=\"bp\">$</span> <span class=\"n\">lake</span> <span class=\"n\">exe</span> <span class=\"n\">pole</span> <span class=\"bp\">|</span> <span class=\"n\">wc</span>\n    <span class=\"mi\">121</span>     <span class=\"mi\">605</span>    <span class=\"mi\">9572</span>\n<span class=\"bp\">~/</span><span class=\"n\">Projects</span><span class=\"bp\">/</span><span class=\"n\">mathlib4</span><span class=\"bp\">$</span> <span class=\"n\">find</span> <span class=\"n\">Mathlib</span> <span class=\"bp\">|</span> <span class=\"n\">wc</span>\n   <span class=\"mi\">4166</span>    <span class=\"mi\">4166</span>  <span class=\"mi\">165631</span>\n</code></pre></div>",
        "id": 401686777,
        "sender_full_name": "Tobias Grosser",
        "timestamp": 1699851793
    },
    {
        "content": "<p>Why do I get so many less modules than there are files in Mathlib. Are there really just 121 modules (after filtering leaf modules)?</p>",
        "id": 401687016,
        "sender_full_name": "Tobias Grosser",
        "timestamp": 1699851865
    },
    {
        "content": "<p>Very interesting. Overall.</p>",
        "id": 401688955,
        "sender_full_name": "Tobias Grosser",
        "timestamp": 1699852844
    },
    {
        "content": "<p>I guess the next question would be if mathlib could be structured in a way that exposes more file-level parallelism or if it is inherently coupled such that higher levels of file-level parallelism are infeasible.</p>",
        "id": 401689299,
        "sender_full_name": "Tobias Grosser",
        "timestamp": 1699853020
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"122318\">Tobias Grosser</span> <a href=\"#narrow/stream/270676-lean4/topic/Lake.20parallel.20builds/near/401687016\">said</a>:</p>\n<blockquote>\n<p>Why do I get so many less modules than there are files in Mathlib. Are there really just 121 modules (after filtering leaf modules)?</p>\n</blockquote>\n<p><code>lake exe pole</code> is only reporting the files that occur on the longest pole in Mathlib.</p>",
        "id": 401693489,
        "sender_full_name": "Scott Morrison",
        "timestamp": 1699855027
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"122318\">Tobias Grosser</span> <a href=\"#narrow/stream/270676-lean4/topic/Lake.20parallel.20builds/near/401683944\">said</a>:</p>\n<blockquote>\n<p>That's super interesting. So no need to run on more than 16 cores.</p>\n</blockquote>\n<p>Also, I think this is false. The 18x parallelism reported for <code>Mathlib</code> is the ratio of total compile time for all files (i.e. 1 core compile time) to the infinite parallelism compile time. That is: with infinitely many cores, during a build <strong>on average</strong> you will be using 18.</p>",
        "id": 401693601,
        "sender_full_name": "Scott Morrison",
        "timestamp": 1699855122
    },
    {
        "content": "<p>We know that at the beginning and end of the build you use much less: hence during the middle you will be able to use more than 18 cores!</p>",
        "id": 401693626,
        "sender_full_name": "Scott Morrison",
        "timestamp": 1699855151
    },
    {
        "content": "<p>To actually find the maximum number of useful cores we would need to construct the full Gantt diagram. That is definitely doable using the code in <code>pole</code>. In fact it's probably only another 10-20 lines of code to do this! (hint, hint :-)</p>",
        "id": 401693658,
        "sender_full_name": "Scott Morrison",
        "timestamp": 1699855199
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"122318\">Tobias Grosser</span> <a href=\"#narrow/stream/270676-lean4/topic/Lake.20parallel.20builds/near/401689299\">said</a>:</p>\n<blockquote>\n<p>I guess the next question would be if mathlib could be structured in a way that exposes more file-level parallelism or if it is inherently coupled such that higher levels of file-level parallelism are infeasible.</p>\n</blockquote>\n<p>I did look at the new longest pole after Andrew Yang's recent fix to algebraic geometry. It actually looks very plausible to my mathematical eye: you really do need (or at least want) to use those results to prove those things! Once you get down into the weeds of finiteness there are probably some more efficiencies to eek out, but not a huge amount.</p>",
        "id": 401693937,
        "sender_full_name": "Scott Morrison",
        "timestamp": 1699855285
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110087\">Scott Morrison</span> <a href=\"#narrow/stream/270676-lean4/topic/Lake.20parallel.20builds/near/401693601\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"122318\">Tobias Grosser</span> <a href=\"#narrow/stream/270676-lean4/topic/Lake.20parallel.20builds/near/401683944\">said</a>:</p>\n<blockquote>\n<p>That's super interesting. So no need to run on more than 16 cores.</p>\n</blockquote>\n<p>Also, I think this is false. The 18x parallelism reported for <code>Mathlib</code> is the ratio of total compile time for all files (i.e. 1 core compile time) to the infinite parallelism compile time. That is: with infinitely many cores, during a build <strong>on average</strong> you will be using 18.</p>\n</blockquote>\n<p>I guess approximated here a little, but given Amdahl's law this means that the low-parallelism parts dominate so even if we can be sometimes faster this won't really change the overall trend too much.</p>",
        "id": 401696208,
        "sender_full_name": "Tobias Grosser",
        "timestamp": 1699856581
    },
    {
        "content": "<p>I am still a little flabbergasted, that there is so little parallelism on the file level. Unfortunately, I have paper deadlines upcoming so cannot really dig deep, but I feel there is enough on the table that I can explore this after the deadlines.</p>",
        "id": 401696349,
        "sender_full_name": "Tobias Grosser",
        "timestamp": 1699856686
    },
    {
        "content": "<p>I think 'lake build pole' is worth merging.</p>",
        "id": 401696360,
        "sender_full_name": "Tobias Grosser",
        "timestamp": 1699856696
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110087\">Scott Morrison</span> <a href=\"#narrow/stream/270676-lean4/topic/Lake.20parallel.20builds/near/401454297\">said</a>:</p>\n<blockquote>\n<p>In-file parallelism (coming!) will help here.</p>\n</blockquote>\n<p>Is there an ETA for this?</p>",
        "id": 401696384,
        "sender_full_name": "Tobias Grosser",
        "timestamp": 1699856721
    },
    {
        "content": "<p>And are there already people committed to it or is this up-for-takers?</p>",
        "id": 401696909,
        "sender_full_name": "Tobias Grosser",
        "timestamp": 1699857031
    },
    {
        "content": "<p>This is something that Sebastian is working on, and it doesn't really make sense for anyone but him to be doing it. (There will be lots of details about this in a coming-soon roadmap.)</p>",
        "id": 401699502,
        "sender_full_name": "Scott Morrison",
        "timestamp": 1699858724
    },
    {
        "content": "<p>Perfect. Then waiting is likely the right option.</p>",
        "id": 401699535,
        "sender_full_name": "Tobias Grosser",
        "timestamp": 1699858757
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"110024\">@Sebastian Ullrich</span>, happy to help measuring things. Depending on how parallel things are, we can also try to run these things multi-node.</p>",
        "id": 401699565,
        "sender_full_name": "Tobias Grosser",
        "timestamp": 1699858788
    }
]