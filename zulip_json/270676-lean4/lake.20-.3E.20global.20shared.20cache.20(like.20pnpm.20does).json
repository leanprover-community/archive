[
    {
        "content": "<h1>Problem:</h1>\n<p>every time I need mathlib in some project I <code>cp ~/projects/lean-some-old-project-that-already-has-mathlib/.lake/packages/mathlib ~/projects/lean-my-new-project/.lake/packages/mathlib</code></p>\n<p>this creates many copies of the same mathlib</p>\n<h1>Solution:</h1>\n<p>Could <code>lake build</code> <code>ln -s $XDG_CACHE_HOME/lake/mathlib ~/projects/lean-my-new-project/.lake/packages/mathlib</code> just like <code>pnpm</code> makes links for <code>node_modules</code>?</p>",
        "id": 524112821,
        "sender_full_name": "Serhii Khoma (srghma)",
        "timestamp": 1749974424
    },
    {
        "content": "<p>It's quite complicated: every project might be using a different version of Mathlib. Who is responsible for cleaning up old ones? Deciding that they are old? etc.</p>",
        "id": 524174857,
        "sender_full_name": "Kim Morrison",
        "timestamp": 1750045979
    },
    {
        "content": "<p>Garbage collection is not new in package management. Nix has one. As long as the standard tools (lake and elan) are used to manage toolchains and dependencies, they can add enough metadata (essentially reference counting) to handle garbage collection</p>",
        "id": 524343690,
        "sender_full_name": "Shreyas Srinivas",
        "timestamp": 1750113649
    },
    {
        "content": "<p>One can even add timestamps of last access from each project and ignore references which are too old during garbage collection. This would result in more aggressive garbage collection.  Later, caches for old toolchains can be redownloaded if the corresponding projects are touched via lake again.</p>",
        "id": 524343773,
        "sender_full_name": "Shreyas Srinivas",
        "timestamp": 1750113730
    },
    {
        "content": "<p>Looking forward to your PRs, <span class=\"user-mention\" data-user-id=\"466334\">@Shreyas Srinivas</span>. :-)</p>",
        "id": 524346078,
        "sender_full_name": "Kim Morrison",
        "timestamp": 1750115405
    },
    {
        "content": "<p>A PR for this feature makes much more sense after the lake caching feature has fully landed.</p>",
        "id": 524346617,
        "sender_full_name": "Shreyas Srinivas",
        "timestamp": 1750115763
    },
    {
        "content": "<p>Currently we only have mathlib caches.</p>",
        "id": 524346643,
        "sender_full_name": "Shreyas Srinivas",
        "timestamp": 1750115772
    },
    {
        "content": "<p><del>Although on second thoughts, a mathlib cache PR might be a good place to start testing ideas.</del></p>",
        "id": 524346764,
        "sender_full_name": "Shreyas Srinivas",
        "timestamp": 1750115868
    },
    {
        "content": "<p>My proposal involves changes to elan and lake. It is best that I know whether such PRs are even welcome and in line with the FROs plans before I start writing anything. And I am exceptionally skeptical that this would be met with anything other than laughter or serious derision given the scale of proposed changes. So maybe this is a script for  a standup comedy. The idea is essentially an over-simplification of opam switches. At a bird's eye view level (not a crow, more like an eagle, altitude-wise):</p>\n<ol>\n<li>Equip elan with the ability to clone and store packages per toolchain and manage its lifecycle. This includes downloading caches, building binaries, maintaining metadata, garbage collection etc through the corresponding local lake installation. This is non-trivial work that might take a few months. But the basic idea is that elan will store all packages for a given toolchain.  </li>\n<li>Add a package metadata file (or sqlite database) with the aforementioned metadata for each package that is downloaded, per toolchain. </li>\n<li>Every time lake requests a dependency, for a project on toolchain Y, it passes on the request to elan which looks into the folder and metadata for toolchain Y. In turn elan returns a symlink for lake to use for the package and performs updates to the metadata. This is another major departure from current practice and will also require months to get right.</li>\n</ol>\n<p>The more bandaid like approach (essentially where everything is held together by coat hangers) is to do something mathlib cache specific, and modify cache to use a centralised storage, but this makes no sense if caching is arriving for all projects in a shape and form as yet unknown to the wider public.</p>",
        "id": 524351654,
        "sender_full_name": "Shreyas Srinivas",
        "timestamp": 1750119379
    },
    {
        "content": "<p>We are already onto that topic, stay tuned</p>",
        "id": 524356100,
        "sender_full_name": "Sebastian Ullrich",
        "timestamp": 1750123377
    }
]