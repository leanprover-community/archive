[
    {
        "content": "<p>Currently it seems like in order to write maximally efficient operations on arrays, one is essentially forced to write a reference implementation and an “efficient” version that uses USize for indexing (moreover these must be tied together by something unsafe such as implemented_by since the correctness here relies on something unprovable). This is obviously somewhat annoying (you have to have two roughly identical function, proving equivalence is somewhat awkward as it requires an unsafe assumption), but it also makes a very significant performance difference from my own benchmarking (which is usually the reason you’re using Arrays in the first place).</p>\n<p>One might hope that you could just do the annoying thing once (say in the implementation of fold or ForIn) and then have other functions building on arrays use these. While this is usually faster than an approach that uses Nat indexing, it’s still usually meaningfully slower than the unsafe manual recursive version.  (I think) this is because if you have compound state carried over between iterations, you end up paying the cost of allocating a tuple that’s immediately unpacked in the next iteration.</p>\n<p>I’m curious if this is a problem others have noticed. Obviously some kind of general unboxing optimization would solve this, but short of that would it be possible to automate any part of this? Perhaps if one used Fins for indexing into an Array, could the compiler tell this has to fit in a usize (at least in principle)?</p>",
        "id": 565940679,
        "sender_full_name": "cmlsharp",
        "timestamp": 1767224688
    },
    {
        "content": "<p>First of all, these <code>USize</code> optimizations are very low yield micro optimizations and don't matter in 99% of the use cases that we have. The only additional thing that happens if you don't use the <code>USize</code> version (as opposed to a properly optimized <code>Nat</code> version) is that you pay a very few additional shift instructions across an array loop which are basically for free (the relevant instructions on a modern x86 CPU have a latency of 1 cycle and a throughput of 0.5 cycles). Compared to all the other overhead that we experience, this overhead is barely noticeable in practice. Doing a single allocation in your loop is going to cost you more than the overhead combined. You will of course be able to observe it in microbenchmarks that have purely arithmetic workloads though. </p>\n<p>Somewhat amusingly using <code>Nat</code> instead of <code>USize</code> can apparently even improve performance sometimes as you can see <a href=\"https://github.com/leanprover/lean4/pull/11855#issuecomment-3703111310\">here</a> <span aria-label=\"upside down\" class=\"emoji emoji-1f643\" role=\"img\" title=\"upside down\">:upside_down:</span> not quite sure why that is.</p>\n<p>That being said one thing that does matter is that we still emit reference counting instructions for these kinds of values most of the time (this is where the properly optimized part comes into play). This is relevant because it fills up both our icache and branch predictor with the unnecessary information about the code that's just going to say we do not have to ref count anyway.  A single <code>lean_dec</code> already emits:</p>\n<div class=\"codehilite\" data-code-language=\"GAS\"><pre><span></span><code><span class=\"w\">        </span><span class=\"nf\">test</span><span class=\"w\">    </span><span class=\"no\">dil</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"mi\">1</span>\n<span class=\"w\">        </span><span class=\"nf\">jne</span><span class=\"w\">     </span><span class=\"no\">.LBB0_4</span>\n<span class=\"w\">        </span><span class=\"nf\">mov</span><span class=\"w\">     </span><span class=\"no\">eax</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"no\">dword</span><span class=\"w\"> </span><span class=\"no\">ptr</span><span class=\"w\"> </span><span class=\"p\">[</span><span class=\"no\">rdi</span><span class=\"p\">]</span>\n<span class=\"w\">        </span><span class=\"nf\">cmp</span><span class=\"w\">     </span><span class=\"no\">eax</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"mi\">2</span>\n<span class=\"w\">        </span><span class=\"nf\">jl</span><span class=\"w\">      </span><span class=\"no\">.LBB0_3</span>\n<span class=\"w\">        </span><span class=\"nf\">dec</span><span class=\"w\">     </span><span class=\"no\">eax</span>\n<span class=\"w\">        </span><span class=\"nf\">mov</span><span class=\"w\">     </span><span class=\"no\">dword</span><span class=\"w\"> </span><span class=\"no\">ptr</span><span class=\"w\"> </span><span class=\"p\">[</span><span class=\"no\">rdi</span><span class=\"p\">],</span><span class=\"w\"> </span><span class=\"no\">eax</span>\n<span class=\"w\">        </span><span class=\"nf\">ret</span>\n<span class=\"nl\">.LBB0_3:</span>\n<span class=\"w\">        </span><span class=\"nf\">test</span><span class=\"w\">    </span><span class=\"no\">eax</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"no\">eax</span>\n<span class=\"w\">        </span><span class=\"nf\">jne</span><span class=\"w\">     </span><span class=\"no\">lean_dec_ref_cold@PLT</span>\n<span class=\"nl\">.LBB0_4:</span>\n<span class=\"w\">        </span><span class=\"nf\">ret</span>\n</code></pre></div>\n<p>out of which only the first two instructions actually matter. I do have a dataflow analysis in mind  that's going to detect situations such as looping over an array and will insert the necessary information to optimize away the ref-counts. We might also be able to make use of this information to simplify arithmetic operations by one or two instructions I guess. Unfortunately that dataflow analysis is going to have to wait until we do some further refactoring work on the compiler in the upcoming quarter. I did already put some infrastructure in place to get it started though: <a href=\"https://github.com/leanprover/lean4/pull/11530\">lean4#11530</a> and <a href=\"https://github.com/leanprover/lean4/pull/11549\">lean4#11549</a>. One could take it a step up and use this information to just make <code>USize</code> out of them as well though this feels a little brittle to me. Consider a situation where our loop index is passed to another tertiary function in our loop body. We can only detect <br>\nthat the <code>USize</code> transformation is legal if either:</p>\n<ol>\n<li>the function has a <code>USize</code>-y version available as well</li>\n<li>or the function gets inlined to the point where we can detect that it is <code>USize</code>-y in our particular caller context.</li>\n</ol>\n<p>Given that very few functions will fall into category 1 but quite a few functions might fall into category 2 we might suddenly generate completely different code based on the inlining choice for this one function, that seems a bit dangerous to me.</p>\n<blockquote>\n<p>(I think) this is because if you have compound state carried over between iterations, you end up paying the cost of allocating a tuple that’s immediately unpacked in the next iteration.</p>\n</blockquote>\n<p>Could you expand on this? I don't see how this is relevant to the <code>USIze</code> optimization</p>",
        "id": 565943922,
        "sender_full_name": "Henrik Böving",
        "timestamp": 1767229641
    },
    {
        "content": "<p>Thank you for the reply! Actually upon going back and re-checking, I'm realizing that there was a flaw in my original benchmarking code that was leading me to significantly overestimate the effects of USize indexing which makes my entire question mostly irrelevant. <span aria-label=\"upside down\" class=\"emoji emoji-1f643\" role=\"img\" title=\"upside down\">:upside_down:</span></p>\n<p>I still don't fully understand why it impacted the figures I saw as much as it did, but I will investigate further.</p>",
        "id": 565948058,
        "sender_full_name": "cmlsharp",
        "timestamp": 1767236263
    },
    {
        "content": "<p>This topic was moved here from <a class=\"stream-topic\" data-stream-id=\"270676\" href=\"/#narrow/channel/270676-lean4/topic/Efficient.20array.20indexing\">#lean4 &gt; Efficient array indexing</a> by <span class=\"user-mention silent\" data-user-id=\"1006649\">cmlsharp</span>.</p>",
        "id": 565948080,
        "sender_full_name": "Notification Bot",
        "timestamp": 1767236307
    }
]