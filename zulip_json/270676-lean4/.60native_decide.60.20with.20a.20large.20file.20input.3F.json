[
    {
        "content": "<p>Hi, I am loading some LRAT proofs of unsatisfiability into the Lean environment. I wrote a little metaprogram to do so, which piggybacks on the internals of <code>bv_decide</code> (big shout out to the verified LRAT checker that now ships with Lean!)</p>\n<p>One of the steps I am doing, copied from <code>bv_decide</code>'s internals, is to insert the whole proof as a string into the environment. But for some math-by-SAT applications I am working on, we may want to import e.g. a 10GB proof file. We have a verified checker that reads the proof in line by line to avoid having the whole thing in memory.</p>\n<p>I have not actually tested putting a 10GB proof in the environment to see what happens, but my understanding is the environment is fully loaded into memory and would therefore require 10GB more memory. Let me know if it would be helpful to have an actual test here.</p>\n<p>So my question is: can this be avoided? is there a way to store the proof in the environment without it being fully loaded in memory, so it could be read line by line? is there a way to give <code>native_decide</code> access to a large file input? and if not, does anyone have advice on how I could implement such a feature?</p>\n<p>thanks!</p>",
        "id": 514187373,
        "sender_full_name": "James Gallicchio",
        "timestamp": 1745516916
    },
    {
        "content": "<p>I would say this kind of violates the whole model that we have of Lean right now. All that is needed to check a proof in the kernel is the Environment, it's literally the only input to the kernel (besides the declaration to check) and the kernel doesn't allow for IO in it's native reducibility facilities. The only thing that comes to mind that you could do here is to fake a pure interface with one that actually performs IO and then feeds the proof line by line to the checker. Though that's of course highly non recommended.</p>",
        "id": 514190453,
        "sender_full_name": "Henrik Böving",
        "timestamp": 1745517432
    },
    {
        "content": "<p>Manually creating a .olean representing <code>def input := \"the big string...\"</code> is not infeasible, see e.g. oleanparser for the reverse direction. Once you have that file, importing it should in fact work thanks to mmap. The resulting project might even pass lean4checker.</p>",
        "id": 514192992,
        "sender_full_name": "Sebastian Ullrich",
        "timestamp": 1745517775
    },
    {
        "content": "<p>But won't the 10GB string be fully in memory after reading completely through it and thus still 10GB of physical RAM comitted?</p>",
        "id": 514198673,
        "sender_full_name": "Henrik Böving",
        "timestamp": 1745518844
    },
    {
        "content": "<p>I suppose I don't actually know what \"read through\" entails for these kinds of proof checking. But the mmapped string itself should be paged out by the OS as needed, no?</p>",
        "id": 514213960,
        "sender_full_name": "Sebastian Ullrich",
        "timestamp": 1745523043
    },
    {
        "content": "<p>Right but it's only going to start doing that once it reaches the mem limit of the system, I don't know if that's desirable for this sort of application?</p>",
        "id": 514218861,
        "sender_full_name": "Henrik Böving",
        "timestamp": 1745524816
    },
    {
        "content": "<p>I think if <code>native_decide</code> will always require all arguments to be loaded into memory, there is probably no way to get the desired behavior. I will think a bit more about the \"safe IO\" by faking purity.</p>",
        "id": 514220977,
        "sender_full_name": "James Gallicchio",
        "timestamp": 1745525713
    },
    {
        "content": "<p>Remember that if you are using native_decide and using something like <code>@implemented_by</code> or <code>@extern</code> to write your own purity faking code, then that code becomes part of the trusted codebase and mistakes in that could make Lean inconsistent</p>",
        "id": 514234065,
        "sender_full_name": "Niels Voss",
        "timestamp": 1745531264
    },
    {
        "content": "<p>I'd say if you are faking IO within a pure API you are already way past that consideration point lol</p>",
        "id": 514237516,
        "sender_full_name": "Henrik Böving",
        "timestamp": 1745533258
    },
    {
        "content": "<p>I just want to make clear that this is totally not something I am recommending to do, it can cause misoptimizations and is a pretty crazy idea in general, it is merely a possibility :P</p>",
        "id": 514237930,
        "sender_full_name": "Henrik Böving",
        "timestamp": 1745533510
    },
    {
        "content": "<p>It seems like relying on your operating system paging the mmapped file could be a fine solution, and I wouldn't try anything crazy without exploring that first.</p>",
        "id": 514336890,
        "sender_full_name": "Kim Morrison",
        "timestamp": 1745574007
    }
]