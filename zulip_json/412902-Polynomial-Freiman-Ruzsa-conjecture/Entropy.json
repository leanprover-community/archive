[
    {
        "content": "<p>I have now stated most of the basic lemmas about entropy, and I have also proved most of them.</p>",
        "id": 402339002,
        "sender_full_name": "Yaël Dillies",
        "timestamp": 1700087356
    },
    {
        "content": "<p>That's great progress already!  I put in a whole bunch of stubs about Ruzsa distance and related concepts in ruzsa_distance.lean that now might be within reach now that we have at least formalizations of all the entropy lemmas. One milestone is the ruzsa triangle inequality which is the first slightly nontrivial statement about that distance.  The most advanced one is the entropic Balog-Szemeredi-Gowers lemma, which may take some time to prove as it basically uses the full suite of entropy tools.</p>",
        "id": 402345153,
        "sender_full_name": "Terence Tao",
        "timestamp": 1700090767
    },
    {
        "content": "<p>There is a spurious <code>end</code> in the latest commit</p>",
        "id": 402346755,
        "sender_full_name": "Shreyas Srinivas",
        "timestamp": 1700091781
    },
    {
        "content": "<p>in rusza_distance.lean</p>",
        "id": 402346768,
        "sender_full_name": "Shreyas Srinivas",
        "timestamp": 1700091788
    },
    {
        "content": "<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"bp\">'</span><span class=\"n\">dist_nonneg'</span> <span class=\"n\">has</span> <span class=\"n\">already</span> <span class=\"n\">been</span> <span class=\"n\">declaredLean</span> <span class=\"mi\">4</span>\n<span class=\"n\">dist_nonneg.</span><span class=\"o\">{</span><span class=\"n\">u</span><span class=\"o\">}</span> <span class=\"o\">{</span><span class=\"n\">α</span> <span class=\"o\">:</span> <span class=\"kt\">Type</span> <span class=\"n\">u</span><span class=\"o\">}</span> <span class=\"o\">[</span><span class=\"n\">inst</span><span class=\"bp\">✝</span> <span class=\"o\">:</span> <span class=\"n\">PseudoMetricSpace</span> <span class=\"n\">α</span><span class=\"o\">]</span> <span class=\"o\">{</span><span class=\"n\">x</span> <span class=\"n\">y</span> <span class=\"o\">:</span> <span class=\"n\">α</span><span class=\"o\">}</span> <span class=\"o\">:</span> <span class=\"mi\">0</span> <span class=\"bp\">≤</span> <span class=\"n\">Dist.dist</span> <span class=\"n\">x</span> <span class=\"n\">y</span>\n<span class=\"kn\">import</span> <span class=\"n\">Mathlib.Topology.MetricSpace.PseudoMetric</span>\n</code></pre></div>",
        "id": 402346866,
        "sender_full_name": "Shreyas Srinivas",
        "timestamp": 1700091848
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"466334\">Shreyas Srinivas</span> <a href=\"#narrow/stream/412902-Polynomial-Freiman-Ruzsa-conjecture/topic/Entropy/near/402346866\">said</a>:</p>\n<blockquote>\n<p><div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"bp\">'</span><span class=\"n\">dist_nonneg'</span> <span class=\"n\">has</span> <span class=\"n\">already</span> <span class=\"n\">been</span> <span class=\"n\">declaredLean</span> <span class=\"mi\">4</span>\n<span class=\"n\">dist_nonneg.</span><span class=\"o\">{</span><span class=\"n\">u</span><span class=\"o\">}</span> <span class=\"o\">{</span><span class=\"n\">α</span> <span class=\"o\">:</span> <span class=\"kt\">Type</span> <span class=\"n\">u</span><span class=\"o\">}</span> <span class=\"o\">[</span><span class=\"n\">inst</span><span class=\"bp\">✝</span> <span class=\"o\">:</span> <span class=\"n\">PseudoMetricSpace</span> <span class=\"n\">α</span><span class=\"o\">]</span> <span class=\"o\">{</span><span class=\"n\">x</span> <span class=\"n\">y</span> <span class=\"o\">:</span> <span class=\"n\">α</span><span class=\"o\">}</span> <span class=\"o\">:</span> <span class=\"mi\">0</span> <span class=\"bp\">≤</span> <span class=\"n\">Dist.dist</span> <span class=\"n\">x</span> <span class=\"n\">y</span>\n<span class=\"kn\">import</span> <span class=\"n\">Mathlib.Topology.MetricSpace.PseudoMetric</span>\n</code></pre></div><br>\n</p>\n</blockquote>\n<p>Presumably it will make sense to put all the Ruzsa distance lemmas in a single namespace to avoid this issue. In any case, renamed for now.  (Feel free to also supply these sorts of corrections through pull requests, possibly in batches if there are a lot of them.)</p>",
        "id": 402355116,
        "sender_full_name": "Terence Tao",
        "timestamp": 1700095914
    },
    {
        "content": "<p>I opened a PR with a few entropy lemmas. I'm stopping here for today: I have to go to work.</p>\n<p>About the entropy definition: one way to generalize entropy and conditional entropy to prove everything for one definition and get both as a consequence would be to do something similar as what I did for independence in mathlib, which is to use Markov kernels. We would have entropy of a random variable with respect to a kernel and a measure.</p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"kd\">def</span> <span class=\"n\">kernel.entropy</span> <span class=\"o\">(</span><span class=\"n\">X</span> <span class=\"o\">:</span> <span class=\"bp\">Ω</span> <span class=\"bp\">→</span> <span class=\"n\">S</span><span class=\"o\">)</span> <span class=\"o\">(</span><span class=\"n\">κ</span> <span class=\"o\">:</span> <span class=\"n\">kernel</span> <span class=\"n\">T</span> <span class=\"bp\">Ω</span><span class=\"o\">)</span> <span class=\"o\">(</span><span class=\"n\">μ</span> <span class=\"o\">:</span> <span class=\"n\">Measure</span> <span class=\"n\">T</span><span class=\"o\">)</span> <span class=\"o\">:=</span>\n  <span class=\"n\">μ</span><span class=\"o\">[</span><span class=\"k\">fun</span> <span class=\"n\">t</span> <span class=\"bp\">↦</span> <span class=\"n\">measureEntropy</span> <span class=\"o\">((</span><span class=\"n\">κ</span> <span class=\"n\">t</span><span class=\"o\">)</span><span class=\"bp\">.</span><span class=\"n\">map</span> <span class=\"n\">X</span><span class=\"o\">)]</span>\n</code></pre></div>\n<p>Then entropy is this with a constant kernel from a singleton space and a dirac measure, and conditional entropy of X wrt Y is this with <code>μ = volume.map Y</code> and <code>κ = fun y ↦ ℙ[|Y ⁻¹' {y}]</code> (or replace volume with any measure on Ω). That way, we don't even have the integration step when we want to deduce the conditional result: both conditional and unconditional are particular cases of this object.</p>\n<p>I won't try that change, as I think the current setup we have is good enough for now, but that's an approach I would be tempted to use if adding all of this to mathlib.</p>",
        "id": 402409452,
        "sender_full_name": "Rémy Degenne",
        "timestamp": 1700122038
    },
    {
        "content": "<p>Once all the basic entropy lemmas are proved, I'll move <code>PFR.entropy_basic</code> to <code>PFR.Mathlib.Probability.Entropy</code> in sight of PRIng it to mathlib. Then I'll try this kernel refactor.</p>",
        "id": 402412230,
        "sender_full_name": "Yaël Dillies",
        "timestamp": 1700123167
    },
    {
        "content": "<p>This isn't directly entropy, but I'd like to claim any remaining lemmas about <code>h(x) = -x log x</code>, since I proved many of them (in slightly more generality) for the exponential Ramsey project</p>",
        "id": 402568822,
        "sender_full_name": "Bhavik Mehta",
        "timestamp": 1700174050
    },
    {
        "content": "<p>Great!  I think the main remaining lemma to prove about - x log x is the converse to Jensen's inequality <a href=\"https://teorth.github.io/pfr/blueprint/sect0001.html#converse-jensen\">https://teorth.github.io/pfr/blueprint/sect0001.html#converse-jensen</a> .  If you get that, you may be able to conclude <a href=\"https://teorth.github.io/pfr/blueprint/sect0002.html#conditional-vanish\">https://teorth.github.io/pfr/blueprint/sect0002.html#conditional-vanish</a> readily (though we already have <a href=\"https://teorth.github.io/pfr/blueprint/sect0002.html#vanish-entropy\">https://teorth.github.io/pfr/blueprint/sect0002.html#vanish-entropy</a> so that is another route).  You should also get <a href=\"https://teorth.github.io/pfr/blueprint/sect0002.html#uniform-entropy\">https://teorth.github.io/pfr/blueprint/sect0002.html#uniform-entropy</a> as a quick consequence.</p>",
        "id": 402593567,
        "sender_full_name": "Terence Tao",
        "timestamp": 1700184815
    },
    {
        "content": "<p>Also if you happen to have already proven other interesting facts about x log x that can be easily ported into the neg_xlogx.lean file, I don't see much harm in adding them there even if they aren't directly used in the project.  It's conceivable that the neg_xlogx.lean and entropy.lean files eventually get converted into MathLib submissions, so if you have results are potentially of wider value, it's worth putting them in.</p>",
        "id": 402599885,
        "sender_full_name": "Terence Tao",
        "timestamp": 1700187958
    },
    {
        "content": "<p>I couldn't find the equality case of Jensen in the library, so just wrote a proof: <a href=\"https://github.com/teorth/pfr/pull/16\">https://github.com/teorth/pfr/pull/16</a></p>",
        "id": 402610518,
        "sender_full_name": "Heather Macbeth",
        "timestamp": 1700193803
    },
    {
        "content": "<p>(An important moment in a project's life: the beginning of the <code>ForMathlib</code> folder!  Some projects' <code>ForMathlib</code> folders become notorious ...)</p>",
        "id": 402611021,
        "sender_full_name": "Heather Macbeth",
        "timestamp": 1700194095
    },
    {
        "content": "<p>Off topic aside: I just want to point out that <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>x</mi><mi>log</mi><mo>⁡</mo><mi>x</mi></mrow><annotation encoding=\"application/x-tex\">x \\log x</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord mathnormal\">x</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mop\">lo<span style=\"margin-right:0.01389em;\">g</span></span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord mathnormal\">x</span></span></span></span> also features in a no-go result concerning the liquid analytic ring structure on <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi mathvariant=\"double-struck\">R</mi></mrow><annotation encoding=\"application/x-tex\">\\R</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6889em;\"></span><span class=\"mord mathbb\">R</span></span></span></span>. See <a href=\"https://math.commelin.net/files/liquid_example.pdf\">https://math.commelin.net/files/liquid_example.pdf</a> for a semi-detailed write up. All ideas are due to Clausen--Scholze. All errors are mine.</p>",
        "id": 402627872,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1700204765
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"657719\">Terence Tao</span> <a href=\"#narrow/stream/412902-Polynomial-Freiman-Ruzsa-conjecture/topic/Entropy/near/402593567\">said</a>:</p>\n<blockquote>\n<p>You should also get <a href=\"https://teorth.github.io/pfr/blueprint/sect0002.html#uniform-entropy\">https://teorth.github.io/pfr/blueprint/sect0002.html#uniform-entropy</a> as a quick consequence.</p>\n</blockquote>\n<p>I did this (<a href=\"https://github.com/teorth/pfr/pull/19\">https://github.com/teorth/pfr/pull/19</a>), modulo working out which of the degenerate cases (zero measure, infinite measure, empty type, ...) are valid ... any measure theory expert want to think about those ones?</p>",
        "id": 402769382,
        "sender_full_name": "Heather Macbeth",
        "timestamp": 1700250359
    },
    {
        "content": "<p>I'll have a look tomorrow, but the only interesting case is clearly the one you've already done!</p>",
        "id": 402770886,
        "sender_full_name": "Sebastien Gouezel",
        "timestamp": 1700251086
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"350992\">Rémy Degenne</span> <a href=\"#narrow/stream/412902-Polynomial-Freiman-Ruzsa-conjecture/topic/Entropy/near/402409452\">said</a>:</p>\n<blockquote>\n<p>I opened a PR with a few entropy lemmas. I'm stopping here for today: I have to go to work.</p>\n<p>About the entropy definition: one way to generalize entropy and conditional entropy to prove everything for one definition and get both as a consequence would be to do something similar as what I did for independence in mathlib, which is to use Markov kernels. We would have entropy of a random variable with respect to a kernel and a measure.</p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"kd\">def</span> <span class=\"n\">kernel.entropy</span> <span class=\"o\">(</span><span class=\"n\">X</span> <span class=\"o\">:</span> <span class=\"bp\">Ω</span> <span class=\"bp\">→</span> <span class=\"n\">S</span><span class=\"o\">)</span> <span class=\"o\">(</span><span class=\"n\">κ</span> <span class=\"o\">:</span> <span class=\"n\">kernel</span> <span class=\"n\">T</span> <span class=\"bp\">Ω</span><span class=\"o\">)</span> <span class=\"o\">(</span><span class=\"n\">μ</span> <span class=\"o\">:</span> <span class=\"n\">Measure</span> <span class=\"n\">T</span><span class=\"o\">)</span> <span class=\"o\">:=</span>\n  <span class=\"n\">μ</span><span class=\"o\">[</span><span class=\"k\">fun</span> <span class=\"n\">t</span> <span class=\"bp\">↦</span> <span class=\"n\">measureEntropy</span> <span class=\"o\">((</span><span class=\"n\">κ</span> <span class=\"n\">t</span><span class=\"o\">)</span><span class=\"bp\">.</span><span class=\"n\">map</span> <span class=\"n\">X</span><span class=\"o\">)]</span>\n</code></pre></div>\n<p>Then entropy is this with a constant kernel from a singleton space and a dirac measure, and conditional entropy of X wrt Y is this with <code>μ = volume.map Y</code> and <code>κ = fun y ↦ ℙ[|Y ⁻¹' {y}]</code> (or replace volume with any measure on Ω). That way, we don't even have the integration step when we want to deduce the conditional result: both conditional and unconditional are particular cases of this object.</p>\n<p>I won't try that change, as I think the current setup we have is good enough for now, but that's an approach I would be tempted to use if adding all of this to mathlib.</p>\n</blockquote>\n<p>Although I wrote that I would not do it, I finally defined a notion of entropy for kernels (see the open PR on the pfr github). It's not exactly the definition I wrote above, but the simpler <code>μ[fun t ↦ measureEntropy (κ t)]</code>.<br>\nI was motivated by the proof of the chain rule for the conditional entropy: I needed to prove something that was basically a result about disintegration of kernels, so I figured I might as well write it for kernels.<br>\nI used the kernel definition to prove the conditional chain rule and the submodularity of entropy.</p>\n<p>The chain rule for the entropy of the composition-product of kernels is rather cute:<br>\n<code>Hk[κ ⊗ₖ η, μ] = Hk[κ, μ] + Hk[η, μ ⊗ₘ κ]</code><br>\n<code>⊗ₖ</code> is the composition-product of kernels defined in mathlib, and <code>⊗ₘ</code>is the similar operation which takes <code>μ : Measure α</code> and <code>κ : kernel α β</code> and creates <code>μ ⊗ₘ κ : Measure (α × β)</code>.</p>",
        "id": 402980641,
        "sender_full_name": "Rémy Degenne",
        "timestamp": 1700381455
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"350992\">Rémy Degenne</span> <a href=\"#narrow/stream/412902-Polynomial-Freiman-Ruzsa-conjecture/topic/Entropy/near/402980641\">said</a>:</p>\n<blockquote>\n<p>Although I wrote that I would not do it, I finally defined a notion of entropy for kernels (see the open PR on the pfr github). It's not exactly the definition I wrote above, but the simpler <code>μ[fun t ↦ measureEntropy (κ t)]</code>.<br>\nI was motivated by the proof of the chain rule for the conditional entropy: I needed to prove something that was basically a result about disintegration of kernels, so I figured I might as well write it for kernels.<br>\nI used the kernel definition to prove the conditional chain rule and the submodularity of entropy.</p>\n</blockquote>\n<p>Nice! I've always been fond of probability kernels - they feel like the \"right\" way to do probability theory from a fully relativized (topos-theoretic?) point of view, but I've rarely had need to use them (except to get a concrete representation of conditional expectation for some ergodic theory applications).  I'm a little surprised that you can develop this theory though without getting bogged down into measure-theoretic minutiae such as Radon measures and the Riesz representation theorem (though of course in the finite setting of this project those details are all trivial anyway).  One can imagine that this formalism would also allow one to work with differential entropy relatively easily, though again that's not needed at all for the PFR project.</p>",
        "id": 402990966,
        "sender_full_name": "Terence Tao",
        "timestamp": 1700386825
    },
    {
        "content": "<p>Now I'm looking at the Ruzsa distance and thinking that it should get the same kernel treatment :)</p>",
        "id": 402991261,
        "sender_full_name": "Rémy Degenne",
        "timestamp": 1700386981
    },
    {
        "content": "<p>In mathlib I added results about disintegration of measures in a more general case, but not yet disintegration of kernels, precisely because there are a lot of measure-theoretic subtleties. Here in the finite case all is much easier.</p>",
        "id": 402991480,
        "sender_full_name": "Rémy Degenne",
        "timestamp": 1700387076
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"350992\">Rémy Degenne</span> <a href=\"#narrow/stream/412902-Polynomial-Freiman-Ruzsa-conjecture/topic/Entropy/near/402991261\">said</a>:</p>\n<blockquote>\n<p>Now I'm looking at the Ruzsa distance and thinking that it should get the same kernel treatment :)</p>\n</blockquote>\n<p>That could well be the case.  I've been avoiding thinking about exactly how to define conditional Ruzsa distance in a clean fashion; it's possible that the kernel approach will be nicer than just conditioning to each singleton at a time (though in this finite setting I'm sure pretty much any approach would work eventually). </p>\n<p>I noticed that you no longer need <code>MeasurableSingletonClass</code> much in the theory now.  Again, not an issue in this finite setting, but it does seem like the more natural framework if one wants to extend the theory into continuous settings.</p>",
        "id": 402993556,
        "sender_full_name": "Terence Tao",
        "timestamp": 1700388239
    },
    {
        "content": "<p>I do need <code>MeasurableSingletonClass</code> everywhere: the reason these are mostly deleted from the statements is that I put them in the variable declaration on top of the file.</p>",
        "id": 402993673,
        "sender_full_name": "Rémy Degenne",
        "timestamp": 1700388308
    },
    {
        "content": "<p>(deleted, was a wrong definition)</p>",
        "id": 402994005,
        "sender_full_name": "Rémy Degenne",
        "timestamp": 1700388531
    }
]