[
    {
        "content": "<p>Opened <a href=\"https://github.com/leanprover-community/mathlib4/pull/18034\">#18034</a>.</p>",
        "id": 478289627,
        "sender_full_name": "Pietro Monticone",
        "timestamp": 1729604821
    },
    {
        "content": "<p>I want to use entropy in Mathlib, how can I help with upstreaming the relevant parts from PFR?</p>",
        "id": 483180635,
        "sender_full_name": "Daniel Weber",
        "timestamp": 1731990977
    },
    {
        "content": "<p>The answer is to not upstream from PFR, but rather from TestingLowerBounds</p>",
        "id": 483298735,
        "sender_full_name": "Yaël Dillies",
        "timestamp": 1732032286
    },
    {
        "content": "<p>Because <span class=\"user-mention\" data-user-id=\"350992\">@Rémy Degenne</span> and <span class=\"user-mention\" data-user-id=\"638899\">@Lorenzo Luccioli</span> are also upstreaming at the same time, I am currently working on improvements to my upstreaming dashboard so that it automatically tells me all PRs to mathlib that touch a file I could upstream</p>",
        "id": 483298987,
        "sender_full_name": "Yaël Dillies",
        "timestamp": 1732032356
    },
    {
        "content": "<p>Our project contains a definition and properties of the Kullback-Leibler divergence, from which you can get entropy, but it is also in the middle of a complete overhaul that changes most definitions including KL. It changes more than 10000 lines and has many <code>sorry</code> left so don't count on us upstreaming soon.</p>\n<p>Also Mathlib might want an entropy definition with a <code>tsum</code> anyway, tailored to the discrete case. So we could PR from PFR without waiting for the TestingLowerBounds project.</p>",
        "id": 483300463,
        "sender_full_name": "Rémy Degenne",
        "timestamp": 1732032766
    },
    {
        "content": "<p>I have opened a PR for the Kullback-Leibler divergence: <a href=\"https://github.com/leanprover-community/mathlib4/pull/21053\">#21053</a> .<br>\nI still think that we also want a more direct definition for the discrete entropy (and we'll link the two definitions afterwards), so upstreaming from PFR is still a good idea.</p>",
        "id": 495976788,
        "sender_full_name": "Rémy Degenne",
        "timestamp": 1737905998
    },
    {
        "content": "<p>Interesting. What makes you think we want the direct definition? And do we want the direct definition from PFR before or after the introduction of <code>FiniteRange</code>?</p>",
        "id": 495981387,
        "sender_full_name": "Yaël Dillies",
        "timestamp": 1737909595
    },
    {
        "content": "<p>The KL definition is now merged to Mathlib.<br>\nI forgot to answer the  last question from <span class=\"user-mention silent\" data-user-id=\"387244\">Yaël Dillies</span>: after thinking about it more, I'm not really sure about it. I supposed that for probability over finite types (I wrote discrete above but I was really thinking finite) we could avoid questions of integrability, for example. But we can also define the entropy from the Kullback-Leibler divergence and write a specialized definition for the finite case that never asks about integrability if needed.</p>",
        "id": 503013770,
        "sender_full_name": "Rémy Degenne",
        "timestamp": 1741004837
    }
]