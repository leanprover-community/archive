[
    {
        "content": "<p>As of a few minutes ago, Lean managed to prove <code>PFR_conjecture</code> without any <code>sorry</code>s.  So the primary goals of this project have all been completed!  Thanks to everyone (most importantly <span class=\"user-mention\" data-user-id=\"387244\">@Yaël Dillies</span> who heroically got the project up and running in 48 hours, but also <span class=\"user-mention\" data-user-id=\"350992\">@Rémy Degenne</span>, <span class=\"user-mention\" data-user-id=\"110050\">@Sebastien Gouezel</span> , <span class=\"user-mention\" data-user-id=\"246273\">@Bhavik Mehta</span> , <span class=\"user-mention\" data-user-id=\"260507\">@Heather Macbeth</span> , <span class=\"user-mention\" data-user-id=\"373986\">@Kalle Kytölä</span>,  <span class=\"user-mention\" data-user-id=\"376152\">@Paul Lezeau</span> ,  <span class=\"user-mention\" data-user-id=\"110087\">@Scott Morrison</span>, <span class=\"user-mention\" data-user-id=\"325367\">@Mauricio Collares</span> ,  <span class=\"user-mention\" data-user-id=\"110031\">@Patrick Massot</span> ,  <span class=\"user-mention\" data-user-id=\"585783\">@Arend Mellendijk</span> , <span class=\"user-mention\" data-user-id=\"607118\">@llllvvuu</span> , <span class=\"user-mention\" data-user-id=\"605003\">@Jonas Bayer</span> , <span class=\"user-mention\" data-user-id=\"111080\">@Floris van Doorn</span> , <span class=\"user-mention\" data-user-id=\"646363\">@Ben Eltschig</span>, <span class=\"user-mention\" data-user-id=\"398581\">@Mantas Baksys</span> , <span class=\"user-mention\" data-user-id=\"306601\">@Kyle Miller</span> ,  <span class=\"user-mention\" data-user-id=\"302826\">@Aaron Anderson</span>, <span class=\"user-mention\" data-user-id=\"110596\">@Rob Lewis</span> , and everyone else who participated - sorry if I omitted anyone by mistake)  for all the contributions; this is definitely something that could not have been accomplished by just one person.</p>\n<p>While the memories of the project are still fresh, this would be a good time for participants to make any observations and reflections on how the project proceeded, and in particular what suggestions people would have for any future projects of this type.  (I don't anticipate leading another project like this in the near future, but I am sure there will be others who would like to try.)  I'll start the ball rolling with some thoughts of my own.</p>\n<ol>\n<li>\n<p>I didn't anticipate that the majority of my time on the project would be spent on the math side (in particular, organizing the blueprint) and the social side (coordinating all the other contributors); I did fill in a few sorries, but I estimate that I only contributed about 5% or so of the lines of code.  This is actually quite encouraging to me, as it suggests to me that it will be possible for mathematicians to lead Lean formalization projects without requiring extensive Lean programming skills (though one may need at least enough expertise to be able to <em>state</em> lemmas, if not prove them).  (Also, given how many times I broke the build by using my administrator privileges to push updates without passing through CIs, it is perhaps for the best that I didn't do a substantial amount of coding.)</p>\n</li>\n<li>\n<p>As with my previous formalization project, I found that the most mathematically interesting portions of the project were relatively straightforward to formalize, but it was the technical \"obvious\" steps that took the longest, most notably in the final stretch when we struggled to establish properties of independent random variables.</p>\n</li>\n<li>\n<p>Blueprint works really well to break up the project into lots of chunks of small to medium difficulty, and allow for plenty of parallelization.  In particular it seems that many contributors were able to work on one localized subtask without necessarily understanding the global proof (or even be in roughly the field of mathematics - additive combinatorics - that this result is in).</p>\n</li>\n<li>\n<p>As pointed out by <span class=\"user-mention\" data-user-id=\"110038\">@Kevin Buzzard</span> , the \"outstanding tasks\" thread was very useful in coordinating the project and encouraging people to contribute.  I wondersif there could be some way to formalize this sort of claiming and releasing of task \"tokens\", perhaps through some tighter integration with Blueprint.</p>\n</li>\n<li>\n<p>Only some very minor typos in the original paper were picked up as a consequence of the formalization project, which was reassuring (my coauthors and I did take multiple passes through the paper to check everything).  There were a larger number of minor issues with the blueprint, in that certain standard hypotheses such as measurability were sometimes omitted, or the dependency tree wasn't quite described correctly, but nothing that couldn't be easily fixed.</p>\n</li>\n</ol>",
        "id": 405996596,
        "sender_full_name": "Terence Tao",
        "timestamp": 1701762913
    },
    {
        "content": "<p>I don't want to immediately hijack this thread, but I think</p>\n<blockquote>\n<p>[...] I estimate that I only contributed about 5% or so of the lines of code.This is actually quite encouraging to me, as it suggests to me that it will be possible for mathematicians to lead Lean formalization projects without requiring extensive Lean programming skills [...]</p>\n</blockquote>\n<p>is something that will be highly dependent on some cultural factors as well. Of course you got a lot of help with this project because of its high-profile nature, derived from the fact that the formalization target was a proof by the \"A-team\" resolving an open conjecture.<br>\nAt the moment, it is still not clear how formalizers (for lack of a better job description) will be credited by the mathematical community, and how these activities will be valued on the job market.</p>\n<p>I am happy to move this message to a new thread if it spawns a longer discussion.</p>",
        "id": 405997901,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1701763404
    },
    {
        "content": "<p>Besides the author list, it's also high-profile because the conjecture itself was a central one in the field of additive combinatorics :) This year was a good one for \"Hungarian-style\" combinatorics in general (exponential Ramsey, R(4,t), density of 3-AP-free sets, and PFR), and three out of the four results I mentioned are at least partially formalized in Lean. Curiously, the one that isn't, R(4,t), is the one that's already <a href=\"https://annals.math.princeton.edu/articles/21198\">accepted for publication in the Annals</a>, although I'm sure the other ones will appear soon :)</p>",
        "id": 405998939,
        "sender_full_name": "Mauricio Collares",
        "timestamp": 1701763892
    },
    {
        "content": "<p>For those not following closely:</p>\n<ul>\n<li>exponential Ramsey is formalised <a href=\"https://github.com/b-mehta/exponential-ramsey/blob/main/src/main_results.lean\">here</a></li>\n<li>R(4, t) is not formalised (although Bhavik now has a sizable portion of the setup ready)</li>\n<li>density of 3AP-free sets is halfway through formalising in <a href=\"https://github.com/YaelDillies/LeanAPAP\">LeanAPAP</a>. The new ideas are already formalised and now I just need to power through a bunch of boring analysis</li>\n<li>PFR, well, you're on topic <span aria-label=\"wink\" class=\"emoji emoji-1f609\" role=\"img\" title=\"wink\">:wink:</span></li>\n</ul>",
        "id": 405999843,
        "sender_full_name": "Yaël Dillies",
        "timestamp": 1701764295
    },
    {
        "content": "<p>My first thought about the project (biased by my own contribution) is that in this project and in most others I am aware of, a large part of the effort is spent formalizing simple prerequisites. What is in Mathlib and what isn't is mostly driven by the specific interests of the contributors, and even though we have more and more people contributing to Mathlib it's still only a few people per mathematical area.<br>\nIn this project, I think none of the 5000+ lines I have pushed to the repository have anything to do with the main part of the paper. Everything is about the entropy notions recalled in the appendix.</p>",
        "id": 406000137,
        "sender_full_name": "Rémy Degenne",
        "timestamp": 1701764430
    },
    {
        "content": "<p>The fact that the community is housing so many probability theory experts was instrumental, for sure!</p>",
        "id": 406000474,
        "sender_full_name": "Yaël Dillies",
        "timestamp": 1701764561
    },
    {
        "content": "<p>Wow, just four months for the Ramsey number bound to get through refereeing! I guess 16 pages of combinatorics, sans references and intro, makes it slightly quicker than a 100-page paper in, say, algebraic number theory...</p>",
        "id": 406003759,
        "sender_full_name": "David Michael Roberts",
        "timestamp": 1701765641
    },
    {
        "content": "<p>As an outsider looking in:</p>\n<ol>\n<li>That seems impressively fast given the reputation that formalisation projects have for being slow and years behind the actual result.</li>\n<li>About the tool, maybe something like <a href=\"http://trello.com\">Trello</a> could come in handy for requesting and allowing claims. I am not aware of any tool other than SVN that can strictly enforce claims to files. But SVN comes with other disadvantages. Mainly, it needs an internet connection to work, and the setup is tedious.</li>\n<li>What Johann says. What are the available career paths for math formalisation? Will this work be valued? Maybe in the future we have an institute for formalisation that employs people long term for such projects (De Bruijn Institute sounds like a good name).</li>\n<li>The project quickly moved towards measure theoretic generality for probability stuff. I am curious how easy/difficult a purely discrete formalisation would, be primarily because of library support.</li>\n</ol>",
        "id": 406006744,
        "sender_full_name": "Shreyas Srinivas",
        "timestamp": 1701766728
    },
    {
        "content": "<p>As one of the formalisers, I was very impressed by the quality and detail in the blueprint. It is not easy to write a proof in such detail that an outsider can come in and just formalize a single lemma in the blueprint without knowing the context within the larger proof. But the detail in the blueprint was large enough to quite easily write the formal proofs (at least for a Lean expert).</p>",
        "id": 406007152,
        "sender_full_name": "Floris van Doorn",
        "timestamp": 1701766849
    },
    {
        "content": "<p>SVN does not enforce claims to files. Are you thinking of Visual SourceSafe?</p>",
        "id": 406008220,
        "sender_full_name": "Mauricio Collares",
        "timestamp": 1701767185
    },
    {
        "content": "<p>Yes. But there is also an SVN lock</p>",
        "id": 406008325,
        "sender_full_name": "Shreyas Srinivas",
        "timestamp": 1701767228
    },
    {
        "content": "<p>Huh, TIL</p>",
        "id": 406008430,
        "sender_full_name": "Mauricio Collares",
        "timestamp": 1701767266
    },
    {
        "content": "<p>But there's a reason people locked files back then: Merging was much harder. I think locking now would be a big regression in workflow.</p>",
        "id": 406008664,
        "sender_full_name": "Mauricio Collares",
        "timestamp": 1701767344
    },
    {
        "content": "<p>Version control-wise yes. The git approach is to work independently and make PRs to the main repo. Then the administrator can choose the PRs to merge.</p>",
        "id": 406008850,
        "sender_full_name": "Shreyas Srinivas",
        "timestamp": 1701767404
    },
    {
        "content": "<p>But if the goal is to enforce the claims mechanism to avoid duplication of work, git can't do that. SVN can.</p>",
        "id": 406008943,
        "sender_full_name": "Shreyas Srinivas",
        "timestamp": 1701767443
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"112680\">Johan Commelin</span> <a href=\"#narrow/stream/412902-Polynomial-Freiman-Ruzsa-conjecture/topic/Project.20completed!.20.20Thoughts.20and.20reflections.3F/near/405997901\">said</a>:</p>\n<blockquote>\n<p>At the moment, it is still not clear how formalizers (for lack of a better job description) will be credited by the mathematical community, and how these activities will be valued on the job market.</p>\n</blockquote>\n<p>That's a good point.  For what it's worth, I'm more than happy to mention contributions to this project in letters of reference as appropriate.  My co-authors and I will mention the Lean project (and link to the github) in the next revision of our paper, though I'm not sure whether it would be a good idea to explicitly name contributors to the project in the paper (there is the question of where to draw the threshold for the size of contribution which would merit mentioning the contributor).  One could simply point to <a href=\"https://github.com/teorth/pfr/graphs/contributors\">https://github.com/teorth/pfr/graphs/contributors</a> , perhaps, or make a link to that page from the github front page.</p>\n<p>Regarding the broader question of persuading the mathematical community (and funding agencies) to value formalization, I know there are plans to launch a journal centered around formalization, which should help.  One could potentially imagine some way to create more quantifiable metrics for formalization contributions (I'm vaguely thinking of something either along the lines of MathOverflow reputation, or some sort of \"currency\" that mathematicians seeking formalizations could put out as \"bounties\" for various lemma proofs), but metrics don't have a good track record in this community (among other things, they are often too easy to game), so I think they would have a secondary role to play at best.</p>",
        "id": 406009245,
        "sender_full_name": "Terence Tao",
        "timestamp": 1701767542
    },
    {
        "content": "<p>I hope there is a plan to migrate the appropriate material to Mathlib!</p>",
        "id": 406012528,
        "sender_full_name": "Oliver Nash",
        "timestamp": 1701768641
    },
    {
        "content": "<p>Yes! I already spent two full days tidying up the prerequisites in their appropriate files (see folder <code>Mathlib.PFR</code>). I will add a section to the website with the files that have no <code>PFR</code> imports. Then the game will be to take one of those and PR its content to mathlib. Then bump PFR. Then repeat.</p>",
        "id": 406013161,
        "sender_full_name": "Yaël Dillies",
        "timestamp": 1701768847
    },
    {
        "content": "<p>This process is what I've been doing for LeanCamCombi and it's very efficient.</p>",
        "id": 406013219,
        "sender_full_name": "Yaël Dillies",
        "timestamp": 1701768871
    },
    {
        "content": "<p>Excellent, thanks!</p>",
        "id": 406013440,
        "sender_full_name": "Oliver Nash",
        "timestamp": 1701768961
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"130272\">David Michael Roberts</span> <a href=\"#narrow/stream/412902-Polynomial-Freiman-Ruzsa-conjecture/topic/Project.20completed!.20.20Thoughts.20and.20reflections.3F/near/406003759\">said</a>:</p>\n<blockquote>\n<p>Wow, just four months for the Ramsey number bound to get through refereeing! I guess 16 pages of combinatorics, sans references and intro, makes it slightly quicker than a 100-page paper in, say, algebraic number theory...</p>\n</blockquote>\n<p>One way a modern algebraic number theory paper differs from a modern \"Hungarian style combinatorics\" (if we're to call it that) paper is that the combinatorics paper might have some good new ideas but be \"flying relatively close to the axioms\", whereas a new paper in algebraic number theory might have some good new ideas but also might crucially depend on literally thousands of pages of prior material (all the machinery developed by Grothendieck or Langlands or Deligne or Katz in the 60s/70s, perhaps all of class field theory, and then also a whole bunch of recent developments too). Somehow the very nature of the two areas is different (or has become different, perhaps for historical reasons). This doesn't mean that either area is \"better\" or \"deeper\" than the other, it just highlights the subtle and complex nature of the field. Bollobas used to tell me in Cambridge that combinatorics was a \"young\" subject and number theory was an \"old\" one.</p>",
        "id": 406014344,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1701769257
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"657719\">Terence Tao</span> <a href=\"#narrow/stream/412902-Polynomial-Freiman-Ruzsa-conjecture/topic/Project.20completed!.20.20Thoughts.20and.20reflections.3F/near/405996596\">schrieb</a>:</p>\n<blockquote>\n<ol start=\"3\">\n<li>Blueprint works really well to break up the project into lots of chunks of small to medium difficulty, and allow for plenty of parallelization.  In particular it seems that many contributors were able to work on one localized subtask without necessarily understanding the global proof (or even be in roughly the field of mathematics - additive combinatorics - that this result is in).</li>\n</ol>\n</blockquote>\n<p>Congratulations!! <span aria-label=\"clap\" class=\"emoji emoji-1f44f\" role=\"img\" title=\"clap\">:clap:</span></p>\n<p>This is huge.  The fact that we can fine tune pre-trained (using unsupervised learning) text models  to generate tactics given a proof state and embed states and premises into vectors means that we will soon have AI-assisted conjectures (wrote one colab myself today using ReProver). Formalizing all this work will be extremely important (collaborative math, math using natural language, re-using blueprint building blocks like legos, further fine tuning models with reinforcement learning). </p>\n<p>The fact that many contributors were able to work on one localized subtask without necessarily understanding the global proof immediately captured my attention. It reminds me of map reduce from back in the day. With ZKP (zero-knowledge proofs), we could have more granularity related to proofs and responsibilities. With blueprint building blocks, we could have collaborative construction. </p>\n<p>Also, perhaps LLMs will most likely learn from this human knowledge and improve their planning / reasoning skills. (and then be even better sparing partners)</p>\n<p>I am impressed by Blueprint, too. I can imagine exploring those graphs in AR while learning math in high school.</p>",
        "id": 406034876,
        "sender_full_name": "Michael Bucko",
        "timestamp": 1701775150
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110038\">Kevin Buzzard</span> <a href=\"#narrow/stream/412902-Polynomial-Freiman-Ruzsa-conjecture/topic/Project.20completed!.20.20Thoughts.20and.20reflections.3F/near/406014344\">said</a>:</p>\n<blockquote>\n<p>One way a modern algebraic number theory paper differs from a modern \"Hungarian style combinatorics\" (if we're to call it that) paper is that the combinatorics paper might have some good new ideas but be \"flying relatively close to the axioms\", whereas a new paper in algebraic number theory might have some good new ideas but also might crucially depend on literally thousands of pages of prior material .... This doesn't mean that either area is \"better\" or \"deeper\" than the other, it just highlights the subtle and complex nature of the field.</p>\n</blockquote>\n<p>Oh, I totally get that. It's what I was alluding to. But we all know that papers of much less import in much more run-of-the-mill journals can often take more than four months to referee, and not because they are more subtle or longer....</p>",
        "id": 406036835,
        "sender_full_name": "David Michael Roberts",
        "timestamp": 1701775953
    },
    {
        "content": "<p>Another thought about the project organization: the infrastructure around the lean code was essential for smooth collaboration. The blueprint was mentioned already, but I wanted to add that CI is also very important. In a project without CI to check the build, you could change a file, have it look nice, push to the repository and not realize that you broke 10 files downstream. In this project (as in Mathlib and others) PR authors could see the build issue and fix it before merging to master, so the build on master was most often fine.</p>",
        "id": 406064526,
        "sender_full_name": "Rémy Degenne",
        "timestamp": 1701785408
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"657719\">Terence Tao</span> <a href=\"#narrow/stream/412902-Polynomial-Freiman-Ruzsa-conjecture/topic/Project.20completed!.20.20Thoughts.20and.20reflections.3F/near/405996596\">said</a>:</p>\n<blockquote>\n<p>As of a few minutes ago, Lean managed to prove <code>PFR_conjecture</code> without any <code>sorry</code>s.  So the primary goals of this project have all been completed!  Thanks to everyone for all the contributions; this is definitely something that could not have been accomplished by just one person.</p>\n<p>While the memories of the project are still fresh, this would be a good time for participants to make any observations and reflections on how the project proceeded, and in particular what suggestions people would have for any future projects of this type.  (I don't anticipate leading another project like this in the near future, but I am sure there will be others who would like to try.)  I'll start the ball rolling with some thoughts of my own.</p>\n<ol>\n<li>\n<p>I didn't anticipate that the majority of my time on the project would be spent on the math side (in particular, organizing the blueprint) and the social side (coordinating all the other contributors); I did fill in a few sorries, but I estimate that I only contributed about 5% or so of the lines of code.  This is actually quite encouraging to me, as it suggests to me that it will be possible for mathematicians to lead Lean formalization projects without requiring extensive Lean programming skills (though one may need at least enough expertise to be able to <em>state</em> lemmas, if not prove them).  (Also, given how many times I broke the build by using my administrator privileges to push updates without passing through CIs, it is perhaps for the best that I didn't do a substantial amount of coding.)</p>\n</li>\n<li>\n<p>As with my previous formalization project, I found that the most mathematically interesting portions of the project were relatively straightforward to formalize, but it was the technical \"obvious\" steps that took the longest, most notably in the final stretch when we struggled to establish properties of independent random variables.</p>\n</li>\n<li>\n<p>Blueprint works really well to break up the project into lots of chunks of small to medium difficulty, and allow for plenty of parallelization.  In particular it seems that many contributors were able to work on one localized subtask without necessarily understanding the global proof (or even be in roughly the field of mathematics - additive combinatorics - that this result is in).</p>\n</li>\n<li>\n<p>As pointed out by <span class=\"user-mention silent\" data-user-id=\"110038\">Kevin Buzzard</span> , the \"outstanding tasks\" thread was very useful in coordinating the project and encouraging people to contribute.  I wondersif there could be some way to formalize this sort of claiming and releasing of task \"tokens\", perhaps through some tighter integration with Blueprint.</p>\n</li>\n<li>\n<p>Only some very minor typos in the original paper were picked up as a consequence of the formalization project, which was reassuring (my coauthors and I did take multiple passes through the paper to check everything).  There were a larger number of minor issues with the blueprint, in that certain standard hypotheses such as measurability were sometimes omitted, or the dependency tree wasn't quite described correctly, but nothing that couldn't be easily fixed.</p>\n</li>\n</ol>\n</blockquote>\n<p>Apologies for the naive question. Is there a way I can understand the wall clock time needed to execute the proving? TIA</p>",
        "id": 406070550,
        "sender_full_name": "Omar Shehab",
        "timestamp": 1701787255
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"111080\">Floris van Doorn</span> <a href=\"#narrow/stream/412902-Polynomial-Freiman-Ruzsa-conjecture/topic/Project.20completed!.20.20Thoughts.20and.20reflections.3F/near/406007152\">said</a>:</p>\n<blockquote>\n<p>As one of the formalisers, I was very impressed by the quality and detail in the blueprint. It is not easy to write a proof in such detail that an outsider can come in and just formalize a single lemma in the blueprint without knowing the context within the larger proof. But the detail in the blueprint was large enough to quite easily write the formal proofs (at least for a Lean expert).</p>\n</blockquote>\n<p>I'm beginning to realize that Blueprint is, in itself, a sort of programming language (a sort of \"Lean pseudocode\"), except that it is compiled by humans (at the current state of AI/Lean integration, at least) rather than by computers.  It does take a non-trivial effort to switch one's writing style from Standard Mathematical English/LaTeX to Blueprint/LaTeX (in particular, being more pedantic with details and dependencies), but significantly less effort than in switching from Standard Mathematical English/LaTeX to Mathlib/Lean, and this looks like a switch that many mathematicians should be able to make.  (See also this <a href=\"https://mathoverflow.net/a/11135/766\">quote by Birch</a> that  he programmed in a very high-level programming language called \"graduate student\".)</p>",
        "id": 406125467,
        "sender_full_name": "Terence Tao",
        "timestamp": 1701802614
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"657719\">Terence Tao</span> <a href=\"#narrow/stream/412902-Polynomial-Freiman-Ruzsa-conjecture/topic/Project.20completed!.20.20Thoughts.20and.20reflections.3F/near/406125467\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"111080\">Floris van Doorn</span> <a href=\"#narrow/stream/412902-Polynomial-Freiman-Ruzsa-conjecture/topic/Project.20completed!.20.20Thoughts.20and.20reflections.3F/near/406007152\">said</a>:</p>\n<blockquote>\n<p>As one of the formalisers, I was very impressed by the quality and detail in the blueprint. It is not easy to write a proof in such detail that an outsider can come in and just formalize a single lemma in the blueprint without knowing the context within the larger proof. But the detail in the blueprint was large enough to quite easily write the formal proofs (at least for a Lean expert).</p>\n</blockquote>\n<p>I'm beginning to realize that Blueprint is, in itself, a sort of programming language (a sort of \"Lean pseudocode\"), except that it is compiled by humans (at the current state of AI/Lean integration, at least) rather than by computers.  It does take a non-trivial effort to switch one's writing style from Standard Mathematical English/LaTeX to Blueprint/LaTeX (in particular, being more pedantic with details and dependencies), but significantly less effort than in switching from Standard Mathematical English/LaTeX to Mathlib/Lean, and this looks like a switch that many mathematicians should be able to make.  (See also this <a href=\"https://mathoverflow.net/a/11135/766\">quote by Birch</a> that  he programmed in a very high-level programming language called \"graduate student\".)</p>\n</blockquote>\n<p>Sounds like Blueprint/LaTeX will be a good target language for GPT-4.</p>",
        "id": 406192770,
        "sender_full_name": "Siddhartha Gadgil",
        "timestamp": 1701826271
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"266304\">Siddhartha Gadgil</span> <a href=\"#narrow/stream/412902-Polynomial-Freiman-Ruzsa-conjecture/topic/Project.20completed!.20.20Thoughts.20and.20reflections.3F/near/406192770\">said</a>:</p>\n<blockquote>\n<p>Sounds like Blueprint/LaTeX will be a good target language for GPT-4.</p>\n</blockquote>\n<p>Actually, pretty much all of the translation directions (English -&gt; Blueprint, Blueprint -&gt; Lean, Lean -&gt; Blueprint, Blueprint -&gt; English, and also Lean &lt;-&gt; other formal languages) look appealing to me as applications of LLMs (supervised somehow by some combination of humans and formal verifiers), and significantly more feasible than direct translations English &lt;-&gt; Lean.</p>",
        "id": 406198564,
        "sender_full_name": "Terence Tao",
        "timestamp": 1701829014
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"657719\">Terence Tao</span> <a href=\"#narrow/stream/412902-Polynomial-Freiman-Ruzsa-conjecture/topic/Project.20completed!.20.20Thoughts.20and.20reflections.3F/near/406198564\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"266304\">Siddhartha Gadgil</span> <a href=\"#narrow/stream/412902-Polynomial-Freiman-Ruzsa-conjecture/topic/Project.20completed!.20.20Thoughts.20and.20reflections.3F/near/406192770\">said</a>:</p>\n<blockquote>\n<p>Sounds like Blueprint/LaTeX will be a good target language for GPT-4.</p>\n</blockquote>\n<p>Actually, pretty much all of the translation directions (English -&gt; Blueprint, Blueprint -&gt; Lean, Lean -&gt; Blueprint, Blueprint -&gt; English, and also Lean &lt;-&gt; other formal languages) look appealing to me as applications of LLMs (supervised somehow by some combination of humans and formal verifiers), and significantly more feasible than direct translations English &lt;-&gt; Lean.</p>\n</blockquote>\n<p>In the informalization directions: Lean -&gt; English etc GPT-4 is already very good with just instructions. To target Lean one at least needs to give examples of Lean notation in the prompt. With examples (and automation to fill in details) there is hope for the formalization directions.</p>",
        "id": 406201642,
        "sender_full_name": "Siddhartha Gadgil",
        "timestamp": 1701829871
    },
    {
        "content": "<p>As a heads up: this project was mentioned in today's Quanta article: <a href=\"https://www.quantamagazine.org/a-team-of-math-proves-a-critical-link-between-addition-and-sets-20231206/\">https://www.quantamagazine.org/a-team-of-math-proves-a-critical-link-between-addition-and-sets-20231206/</a></p>",
        "id": 406338694,
        "sender_full_name": "Terence Tao",
        "timestamp": 1701879024
    },
    {
        "content": "<p>Congratulations to everyone involved! A massive achievement.</p>\n<p>In terms of what next, I wonder how feasible it would be to also formalise the proof of 'weak PFR over the integers' - this is implied by PFR over F_2^n as shown by Green, Manners, and Tao (Corollary 1.12 of <a href=\"https://arxiv.org/pdf/2306.13403.pdf\">https://arxiv.org/pdf/2306.13403.pdf</a>), using the same entropy-baesd toolkit.</p>\n<p>My impression is (and hopefully <span class=\"user-mention\" data-user-id=\"657719\">@Terence Tao</span> can correct me) that this should be reasonably short given the tools developed already for the PFR proof.</p>",
        "id": 406356415,
        "sender_full_name": "Thomas Bloom",
        "timestamp": 1701885018
    },
    {
        "content": "<p>The Quanta article seems to suggest the same thing many articles do:</p>\n<blockquote>\n<p>Tao announced that Lean had proved the conjecture without any “sorrys” — the standard statement that appears when the computer can’t verify a certain step.</p>\n</blockquote>\n<p>... that no humans were involved!</p>\n<p>The paragraph much later in the article is quite good, however.</p>",
        "id": 406362209,
        "sender_full_name": "Scott Morrison",
        "timestamp": 1701887223
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"458865\">Thomas Bloom</span> <a href=\"#narrow/stream/412902-Polynomial-Freiman-Ruzsa-conjecture/topic/Project.20completed!.20.20Thoughts.20and.20reflections.3F/near/406356415\">said</a>:</p>\n<blockquote>\n<p>Congratulations to everyone involved! A massive achievement.</p>\n<p>In terms of what next, I wonder how feasible it would be to also formalise the proof of 'weak PFR over the integers' - this is implied by PFR over F_2^n as shown by Green, Manners, and Tao (Corollary 1.12 of <a href=\"https://arxiv.org/pdf/2306.13403.pdf\">https://arxiv.org/pdf/2306.13403.pdf</a>), using the same entropy-baesd toolkit.</p>\n<p>My impression is (and hopefully <span class=\"user-mention silent\" data-user-id=\"657719\">Terence Tao</span> can correct me) that this should be reasonably short given the tools developed already for the PFR proof.</p>\n</blockquote>\n<p>Hmm, this could be doable - the derivation is three and a half pages in that paper, and as you say it mostly just uses the entropy tools that already are in PFR.  It would be a bit more substantial though than the other extension we already implemented of getting the homomorphism version of PFR, where the argument is more like half a page when written in regular math.  </p>\n<p>If there is sufficient interest I could try to create an addendum to the blueprint for this (or if you would like to volunteer to work on the blueprint also, that would also be appreciated :).  I don't want to presume though that just because so many people already donated their time to this project that they would be willing to do so indefinitely for further extensions of the project.  For instance, we will shortly have a paper doing the odd characteristic case of PFR as well, and on my blog someone has contributed an argument that improves the constant in PFR from 12 to 11; both of these are certainly possible to formalize as well, but it would require nontrivial effort on both the blueprint side and the formalization side.  In each of these cases the effort is much smaller than the entirety of the PFR project - each such extension can probably be done in a matter of days if we have the same level of activity and donated time as for the primary goal - but it's unclear to me whether the cost-benefit ratio is as favorable as for the primary PFR project.</p>",
        "id": 406369091,
        "sender_full_name": "Terence Tao",
        "timestamp": 1701889789
    },
    {
        "content": "<p>I certainly am willing to work on the extensions <span aria-label=\"smile\" class=\"emoji emoji-1f642\" role=\"img\" title=\"smile\">:smile:</span> The point of formalisation is both to do a publicity stunt every time we formalise a breakthrough and being able to check proposed improvements as they come.</p>",
        "id": 406369378,
        "sender_full_name": "Yaël Dillies",
        "timestamp": 1701889891
    },
    {
        "content": "<p>I'd also be up for working on extensions!</p>",
        "id": 406369584,
        "sender_full_name": "Paul Lezeau",
        "timestamp": 1701889949
    },
    {
        "content": "<p>OK.  Perhaps we could then have a somewhat open-ended second stage to the PFR project where we work on a few extensions, but perhaps at a reduced rate of activity and without any expectation of a \"speed run\".</p>",
        "id": 406372867,
        "sender_full_name": "Terence Tao",
        "timestamp": 1701891331
    },
    {
        "content": "<p>That sounds good. I am happy to provide the blueprint level proof for deducing weak PFR at some point, but I'm not able to right now. I'll start a new thread on here when I start doing so (unless anyone has already done it by that point!)</p>",
        "id": 406374645,
        "sender_full_name": "Thomas Bloom",
        "timestamp": 1701892058
    },
    {
        "content": "<p>In general, I'd say that if there's a direction, many people will follow and help out with any given lean project :)</p>",
        "id": 406385659,
        "sender_full_name": "Eric Rodriguez",
        "timestamp": 1701895826
    },
    {
        "content": "<p>I have been thinking about how to run a big long term project; here are two comments. Firstly I asked <span class=\"user-mention\" data-user-id=\"296911\">@Utensil Song</span> to put a new red possibility for nodes, meaning something like \"this is not done and there is no LaTeX blueprint either\". I think this might be useful for me; I want to use \"blue\" in the same way Terry was using it -- i.e. \"high chance that this sorry is feasible and you might be able to do it in one or a few Lean sessions even if you haven't read the paper\".</p>\n<p>Secondly I think it might be an interesting experiment to have a github issue for each node on the graph. Issues are cheap and might be a better way of storing the status of things than Terry's thrice-weekly updates; one could perhaps even hope to have some web page where you could just look at the current status of all non-green nodes, and a way of \"claiming\" nodes in real time if you want to work on them. The issue could be the one source of truth about the node if we want to reduce the chances of two people working on the same thing (which did happen once in PFR).</p>",
        "id": 406391534,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1701897908
    },
    {
        "content": "<p>It's pretty straightforward to programmatically create issues, and to add/remove/check for labels, so that could all be integrated into the dependency graph itself.</p>",
        "id": 406392418,
        "sender_full_name": "Scott Morrison",
        "timestamp": 1701898331
    },
    {
        "content": "<p>Shreyas above mentioned the trello tool. It might also be a good way to claim and release things. It's easy to use, has a long-standing company behind it, and has an API that would allow some automation if desired. But keeping things simple and within the existing ecosystem might be more valuable; I'm not sure.</p>",
        "id": 406392595,
        "sender_full_name": "Scott Morrison",
        "timestamp": 1701898426
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110038\">Kevin Buzzard</span> <a href=\"#narrow/stream/412902-Polynomial-Freiman-Ruzsa-conjecture/topic/Project.20completed!.20.20Thoughts.20and.20reflections.3F/near/406391534\">said</a>:</p>\n<blockquote>\n<p>I have been thinking about how to run a big long term project; here are two comments. Firstly I asked <span class=\"user-mention silent\" data-user-id=\"296911\">Utensil Song</span> to put a new red possibility for nodes, meaning something like \"this is not done and there is no LaTeX blueprint either\". I think this might be useful for me; I want to use \"blue\" in the same way Terry was using it -- i.e. \"high chance that this sorry is feasible and you might be able to do it in one or a few Lean sessions even if you haven't read the paper\".</p>\n<p>Secondly I think it might be an interesting experiment to have a github issue for each node on the graph. Issues are cheap and might be a better way of storing the status of things than Terry's thrice-weekly updates; one could perhaps even hope to have some web page where you could just look at the current status of all non-green nodes, and a way of \"claiming\" nodes in real time if you want to work on them. The issue could be the one source of truth about the node if we want to reduce the chances of two people working on the same thing (which did happen once in PFR).</p>\n</blockquote>\n<p>Using an existing and familiar tool such as github issues sounds worth trying.  If the code can be updated in time, one could imagine using the extensions to the PFR projects as a test case for various blueprint experiments.  I don't know if it is possible to make addons to a github issues page to allow administrators to, for instance, insert a \\leanok into a blueprint proof by clicking an extra button after approving a contributor's PR resolving that proof.</p>\n<p>Perhaps we could have a \\sorry macro in blueprint in case the statement or proof of a blueprint lemma is not yet in a form acceptable to a human reader (as opposed to a Lean compiler), and add new colors to the dependency graph accordingly.</p>",
        "id": 406392610,
        "sender_full_name": "Terence Tao",
        "timestamp": 1701898433
    },
    {
        "content": "<p>You can't make addons to the issues page, but you can achieve a lot using labels, or even just whether or not a pull request has been merged.</p>",
        "id": 406392790,
        "sender_full_name": "Scott Morrison",
        "timestamp": 1701898504
    },
    {
        "content": "<p>If there's an issue for every label, and PRs include the magic words \"Resolves <a href=\"https://github.com/leanprover-community/mathlib4/pull/347\">#347</a>\", then <a href=\"https://github.com/leanprover-community/mathlib4/pull/347\">#347</a> will automatically be closed when the PR is merged, and then the dependency graph could notice that the issue has been closed and update the blueprint accordingly.</p>",
        "id": 406392954,
        "sender_full_name": "Scott Morrison",
        "timestamp": 1701898572
    },
    {
        "content": "<p>Is PFR basically the only active example of a Blueprint in use right now?  If so it would be a natural guinea pig to use for testing experimental features, particularly since the primary goal has been achieved so there is relatively little downside risk if we temporarily break Blueprint for one reason or another.</p>",
        "id": 406393075,
        "sender_full_name": "Terence Tao",
        "timestamp": 1701898632
    },
    {
        "content": "<p>There's also <a href=\"https://github.com/YaelDillies/LeanAPAP\">LeanAPAP</a> but I'm basically the only contributor. So not great for experimentation.</p>",
        "id": 406393391,
        "sender_full_name": "Yaël Dillies",
        "timestamp": 1701898785
    },
    {
        "content": "<p>We use a <a href=\"https://leanprover-community.github.io/flt-regular/blueprint/\">blueprint</a> in the <a href=\"https://github.com/leanprover-community/flt-regular/\">flt-regular</a> project (also completed yesterday!).</p>",
        "id": 406395766,
        "sender_full_name": "Riccardo Brasca",
        "timestamp": 1701899960
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110087\">Scott Morrison</span> <a href=\"#narrow/stream/412902-Polynomial-Freiman-Ruzsa-conjecture/topic/Project.20completed!.20.20Thoughts.20and.20reflections.3F/near/406392595\">said</a>:</p>\n<blockquote>\n<p>Shreyas above mentioned the trello tool. It might also be a good way to claim and release things. It's easy to use, has a long-standing company behind it, and has an API that would allow some automation if desired. But keeping things simple and within the existing ecosystem might be more valuable; I'm not sure.</p>\n</blockquote>\n<p>It also integrates with github and has its own dependency graphs</p>",
        "id": 406397514,
        "sender_full_name": "Shreyas Srinivas",
        "timestamp": 1701900662
    },
    {
        "content": "<p>There is a new thread over at general <a href=\"#narrow/stream/113488-general/topic/CFP.3A.20improved.20Blueprint.20UX\">https://leanprover.zulipchat.com/#narrow/stream/113488-general/topic/CFP.3A.20improved.20Blueprint.20UX</a> about blueprint updates in a broader context than PFR.</p>",
        "id": 406403608,
        "sender_full_name": "Terence Tao",
        "timestamp": 1701903485
    },
    {
        "content": "<p>A nice thing about Github Issues is that they are represented directly in the Github projects kanban board, without having to use something like trello.</p>",
        "id": 406410538,
        "sender_full_name": "Yakov Pechersky",
        "timestamp": 1701906946
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"657719\">Terence Tao</span> <a href=\"#narrow/stream/412902-Polynomial-Freiman-Ruzsa-conjecture/topic/Project.20completed!.20.20Thoughts.20and.20reflections.3F/near/406393075\">said</a>:</p>\n<blockquote>\n<p>Is PFR basically the only active example of a Blueprint in use right now?  If so it would be a natural guinea pig to use for testing experimental features, particularly since the primary goal has been achieved so there is relatively little downside risk if we temporarily break Blueprint for one reason or another.</p>\n</blockquote>\n<p>I have a list of the projects using Lean 4 version of leanblueprint <a href=\"https://github.com/PatrickMassot/leanblueprint/pull/5#issuecomment-1809432850\">here</a>, and intend to keep it growing.</p>\n<p>Lean 4 version of blueprint was initially asked for by flt-regular and LeanAPAP. With <span class=\"user-mention\" data-user-id=\"110031\">@Patrick Massot</span> 's guidance and <span class=\"user-mention\" data-user-id=\"395550\">@Henrik Böving</span> 's help on the side of doc-gen4, the prototype was developed using <a href=\"https://utensil.github.io/lean-ga/blueprint/\">my experimental blueprint for lean-ga project (it has a lot to catch up with the work of <span class=\"user-mention\" data-user-id=\"310045\">@Eric Wieser</span> and the initial goal)</a> as a test bed. I set up an <a href=\"https://github.com/utensil/LeanBlueprintExample\">example project (now outdated)</a> with the idea to make it a template for both and more projects, but the solution turns out to have too many moving parts, so <span class=\"user-mention\" data-user-id=\"389019\">@Chris Birkbeck</span> asked me to set up directly for flt-regular then later by <br>\n<span class=\"user-mention\" data-user-id=\"387244\">@Yaël Dillies</span> for LeanAPAP, which was the base setup for PFR  by <span class=\"user-mention\" data-user-id=\"387244\">@Yaël Dillies</span> . </p>\n<p>During flt-regular, LeanAPAP, PFR, and with observations from <span class=\"user-mention\" data-user-id=\"387244\">@Yaël Dillies</span> and  thoughts from <span class=\"user-mention\" data-user-id=\"110038\">@Kevin Buzzard</span> , quite a few issues were discovered and fixed, the SOTA of the fixes are mostly in PFR so PFR is the latest test bed for the development of Lean 4 version of blueprint, and due to the status quo of too many moving parts in the setup, all these projects are different in certain details and might cause confusion and frustrations for mathematicians or Lean experts if something breaks due to a change to one of the building blocks, and the fixes in PFR are not back ported to previous projects yet, that's why I drafted <a href=\"https://github.com/PatrickMassot/leanblueprint/issues/6\">RFC: Absorb scattered functionalities back into leanblueprint</a> to address this discrepancy (but haven't raised it for public discussion yet as I was drowned in work lately).</p>\n<p>The most observable  improvements of these fixes are reducing the CI time from around half an hour to 17min (if the commit doesn't update Mathlib), and a simple tool <code>inv check</code> to check if all blueprint <code>\\lean</code> references do exist in the Lean code.</p>\n<p>Moving forward, I was hoping for a new active formalization project as a test bed to further improve how the blueprint works. I'll post more thoughts in the <a href=\"#narrow/stream/113488-general/topic/CFP.3A.20improved.20Blueprint.20UX\">new thread</a> by Morph Labs later.</p>",
        "id": 406422326,
        "sender_full_name": "Utensil Song",
        "timestamp": 1701912721
    },
    {
        "content": "<p>I'm a bit late to the party because I've been very busy. But I'd like to write some comments, although there is overlap with things that were already said.</p>\n<p>This projects proves once again that it is possible to efficiently formalize non-trivial mathematics using Lean and Mathlib in their current state (which is far from what we expect to be their state in a couple of years, even without any AI dreaming). </p>\n<p>This is great, but let's not forget that we are still very far from being able to formalize in real time. During the three weeks of this project, at least 2000 math papers appeared on arXiv (see for instance <a href=\"https://info.arxiv.org/help/stats/2021_by_area/index.html\">those stats</a>). Admittedly many of those papers are probably not worth reading, even less formalizing. But there is still a factor 1000 between the formalization speed of this collaboration and the production of math papers.</p>\n<p>Today if you are Peter Scholze or Terence Tao you can come here, launch a formalization project and instantly get 15 people working on it. It simply doesn't work otherwise. This isn't a thought experiment, we see this very often. Yesterday we also saw the completion of the FLT-regular project which obviously did not get such a rush, and the same applied for the sphere eversion project. Those two projects got completed eventually, but at a much lower speed.</p>\n<p>We are also currently limited in the kind of mathematics we can efficiently tackle. If Scholze comes back and proposes to formalize his paper with Laurent Fargues then there won't be a miracle in three weeks (or even one year and a half as for LTE). And it isn't clear the enthusiasm would last long enough to go through a blueprint with thousands of pages.</p>\n<p>Keeping all that in mind, the good news is that everything is improving. Mathlib gets bigger and bigger, new tactics appear every week and AI may end up helping at some point. So I still hope that formalization will become an important tool for most mathematicians in a not too distant future. We have a lot of work to do in the mean time.</p>\n<p>About speed and the blueprint, I think something hasn't been emphasized enough. Every Lean user sometimes wastes a lot of time with stupid technical issues without any mathematical content, even expert users. But my experience is that the true limiting factor is vague mathematical understanding. For me, adding details to the blueprint adds mathematical understanding, or least communicates more mathematical understanding. That the main reason why a very detailed blueprint makes formalization so much faster. It would be nice to give credit to people who take time to write mathematics at a blueprint level of detail (in case they aren't the original authors of the proofs).</p>\n<p>When I developed the blueprint infrastructure in 2020, I very much hoped that a blueprint would be an extremely valuable resource for people who want to learn mathematics without caring about Lean. I'm sure the paper on arXiv is great to communicate the PFR proof to experts in additive combinatorics. But I hope that students all over the world will be able to benefit from the blueprint without access to any expert.</p>\n<p>About improving the blueprint technology, I first want to comment that the fact that existence of Lean declarations is not checked is a regression coming from the adaptation to Lean 4. The Lean 3 version checked that from the very beginning. When people started to ask for a Lean 4 version and I had no time to do it properly, Utensil (thanks!) quickly hacked a minimal version by modifying about 10 lines of python code, but this was meant as a (very useful) emergency patch, and it threw away some features that required Lean meta-programming. I hope to be able to come back to this around Christmas. Adding more coordination features is definitely possible. However one nice thing with the current setup is that blueprints can be hosted on a fully static website (no code is executed on the server). In particular they can easily be hosted by <a href=\"http://github.io\">github.io</a>. One could use more GitHub actions, but it will never bring the flexibility of hosting a website on a server that can actually execute code and access a custom database. I'll try to think about how far we can go with a static website + GitHub actions, but the Mathlib port experience suggests this can become painful pretty quickly.</p>",
        "id": 406442912,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1701919169
    },
    {
        "content": "<blockquote>\n<p>adding details to the blueprint adds mathematical understanding, or least communicates more mathematical understanding</p>\n</blockquote>\n<blockquote>\n<p>a blueprint would be an extremely valuable resource for people who want to learn mathematics without caring about Lean</p>\n</blockquote>\n<blockquote>\n<p>But I hope that students all over the world will be able to benefit from the blueprint without access to any expert.</p>\n</blockquote>\n<p>I can confirm this as a hobbyist. Lean is the first venue I've found to engage with mathematics (however elementary it may be) since college. The potential for education is definitely there.</p>",
        "id": 406458674,
        "sender_full_name": "llllvvuu",
        "timestamp": 1701924016
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110031\">Patrick Massot</span> <a href=\"#narrow/stream/412902-Polynomial-Freiman-Ruzsa-conjecture/topic/Project.20completed!.20.20Thoughts.20and.20reflections.3F/near/406442912\">said</a>:</p>\n<blockquote>\n<p>About improving the blueprint technology, I first want to comment that the fact that existence of Lean declarations is not checked is a regression coming from the adaptation to Lean 4. The Lean 3 version checked that from the very beginning. When people started to ask for a Lean 4 version and I had no time to do it properly, Utensil (thanks!) quickly hacked a minimal version by modifying about 10 lines of python code, but this was meant as a (very useful) emergency patch, and it threw away some features that required Lean meta-programming. I hope to be able to come back to this around Christmas. Adding more coordination features is definitely possible. However one nice thing with the current setup is that blueprints can be hosted on a fully static website (no code is executed on the server). In particular they can easily be hosted by <a href=\"http://github.io\">github.io</a>. One could use more GitHub actions, but it will never bring the flexibility of hosting a website on a server that can actually execute code and access a custom database. I'll try to think about how far we can go with a static website + GitHub actions, but the Mathlib port experience suggests this can become painful pretty quickly.</p>\n</blockquote>\n<p>As <span class=\"user-mention\" data-user-id=\"110031\">@Patrick Massot</span> explained, the emergency patch version of blueprint for Lean 4 came at a cost, it no longer checks the existence of Lean declarations internally. <code>inv check</code> is a rather low-tech solution that makes use of the product of doc-gen4 (which did all the heavy lifting).</p>\n<p>Another notable regression from the Lean 3 blueprint is the CI time. Lean 3 blueprint extracts Lean declarations with a short Lean script via meta-programming in a much lightweight way. The logic can't be directly ported to Lean 4 as meta-programming changed significantly since then, but it can be distilled from doc-gen4 which did also much more with these declarations which shoudn't block the build and check of blueprint. So, with Patrick's work, CI time will also be significantly reduced to just a few minutes, the result is that the blueprint will jump to the Github source code like in Lean 3, instead of doc-gen4 which takes longer to build (it seems to hit <a href=\"#narrow/stream/113488-general/topic/Blueprint.20for.20Lean.204/near/401922510\">an optimization bottleneck for now</a>) or it can link to both document and source code, but the document can be async generated.</p>",
        "id": 406465185,
        "sender_full_name": "Utensil Song",
        "timestamp": 1701927743
    },
    {
        "content": "<p>Also, a short comment on the speed of formalization. As Patrick pointed out, the current model doesn't scale. A significant portion of Lean experts on Mathlib are involved in the project, solved obstacles much more efficiently than the people that other formalization projects might be able to gather, it's more likely a few mathematicians with expertise on the field but only basic Lean expertise, so there will be more technical obstacles to resolve in a much slower speed even with help from experts on Zulip.</p>\n<p>Besides that, larger formalization projects will have fundamental issues with formalizing the mathematical constructs in an (almost-)optimal way that wouldn't affect the proving work seriously. Organizing these mathematical constructs in a proper way and in the hierarchies of type class, is a recurring theme for even undergraduate level math, and previous formalization projects (as explained in their formalization papers). It also involves modifying the existing Mathlib in related math branches, which would have to involve more mathematicians and Lean experts for design discussions. Depending on the area of math, this could be the greatest blocking stone.</p>\n<p>Lastly, the steps of PFR can be broken down to manageable pieces by almost one mathematician, but this is certainly not the case for a project like <a href=\"#narrow/stream/113486-announce/topic/Formalising.20Fermat\">FLT</a> and also requires it to scale on the mathematician side. That's where <span class=\"user-mention\" data-user-id=\"110038\">@Kevin Buzzard</span> 's red node idea came from, although the implementation is again only a few lines of Python code, the underlying need is to address the work around \"the statement/proof of this result needs to be broken down into smaller formalizable pieces\". It will also requires further tooling support for project managements like claiming, status check etc. discussed repeatedly in this topic, which can also be implemented easily with Github Actions, bots, Github Issues, and kanbans in Github Projects.</p>",
        "id": 406468197,
        "sender_full_name": "Utensil Song",
        "timestamp": 1701929347
    },
    {
        "content": "<p>Just as LaTeX is now a standard part of the \"A-team\" mathematician's toolkit, it may come to pass that presenting verified proofs in Lean and using blueprints and various kinds of AI proof assistants will become part of the day to day methodology.  As a methodology change, it would help if A-teamers routinely presented a GitHub of Lean code verifying their proofs in their references as evidence of their work, when they publish a proof, i.e., not as an add-on, but as part of the standard of proof of work.</p>\n<p>A-listers presenting proof of work in this way, if they verify their own proofs, would need to know Lean to do so.  In 1978, nobody know <a href=\"https://en.wikipedia.org/wiki/TeX\">TeX</a> and in 1984 nobody knew <a href=\"https://en.wikipedia.org/wiki/LaTeX\">LaTeX</a>, but now every A-lister does.  Similarly there will be an adoption curve for Lean.  This experiment has established that an A-list mathematician can go from Lean newbie to knowing enough to complete state-of-the-art work in the 58 days from <a href=\"https://mathstodon.xyz/@tao/111206761117553482\">October 9th</a> to <a href=\"#narrow/stream/412902-Polynomial-Freiman-Ruzsa-conjecture/topic/Project.20completed!.20.20Thoughts.20and.20reflections.3F/near/405996596\">December 5th.</a></p>\n<p>A methodology change to always verifying proofs would address what some see as a minor reproducibility crisis in mathematics, for example see</p>\n<ul>\n<li><a href=\"https://mathoverflow.net/questions/370898/replication-crisis-in-mathematics\">Replication crisis in mathematics</a></li>\n<li><a href=\"https://link.springer.com/article/10.1007/s00283-020-10037-7\">A Replication Crisis in Mathematics?</a></li>\n<li><a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6240027/\">“Reproducible” research in mathematical sciences requires changes in our peer review culture and modernization of our current publication approach</a></li>\n</ul>\n<p>There will probably not be a job category for people who code other people's proofs into Lean. The people doing that now have a passion for symbolic or computational logic or computer science or the topic of verification itself, along with skills and training in the subject matter of mathematics.  That is a  small community.  Whether this community gets funding, and who controls the intellectual property that results, is the topic of articles such as</p>\n<ul>\n<li><a href=\"https://siliconreckoner.substack.com/p/automation-compels-mathematicians\">Automation compels mathematicians to reflect on our values, Part II</a></li>\n<li>(In another field, but same problem.) <a href=\"https://www.statnews.com/2023/12/15/nih-life-science-postdocs-salary-increase/\">NIH panel calls for fewer, better-paid postdocs in bid to halt loss of scientists to industry</a></li>\n</ul>\n<p>As to the matter of how many authors of lines of code in the PFR proof should be credited explictly by the author of the proof:</p>\n<ul>\n<li>The proof itself, in it's blackboard form, was published prior to it's formal verification.</li>\n<li>So the formal verification is a separate accomplishment.</li>\n<li>It would be reasonable to write up the verification of PFR as a separate article, whose authors, <a href=\"https://www.nature.com/articles/nature.2015.17567,\">in the tradition of the physics field</a> would be every person that had a hand in it.</li>\n</ul>\n<p>As the substance of more and more verified proofs make their way as definitions and theorems into Lean's Mathlib, and into the training of AI proof assistants, it should become easier and easier to verify proofs as a matter of course.  In that sense the work of all those Mathlib contributors will become unsung in subsequent verifications that rely on Lean.  This is no different from using 20 or 30 different Python packages to get something done, each of which has its own authors and history.  That lack of attribution is unavoidable for anybody relying on a large multi-author software product with a long history.</p>",
        "id": 408687465,
        "sender_full_name": "Lars Ericson",
        "timestamp": 1702933446
    }
]