[
    {
        "content": "<p>I know that there have been efforts to apply machine learning to automatic theorem proving.</p>\n<p>Conversely, have any attempts been made to implement machine learning algorithms in Lean4? To what extent has the field of mathematical optimization been formalized in Lean?</p>",
        "id": 398831396,
        "sender_full_name": "Asei Inoue",
        "timestamp": 1698388215
    },
    {
        "content": "<p>Have you looked at <a class=\"stream\" data-stream-id=\"219941\" href=\"/#narrow/stream/219941-Machine-Learning-for-Theorem-Proving\">#Machine Learning for Theorem Proving</a> ?</p>",
        "id": 398837438,
        "sender_full_name": "Yaël Dillies",
        "timestamp": 1698390403
    },
    {
        "content": "<p>I think Asei is asking about the \"converse\", which isn't much discussed in that stream.</p>",
        "id": 398838776,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1698390872
    },
    {
        "content": "<p>There is <a href=\"https://github.com/dselsam/certigrad\">https://github.com/dselsam/certigrad</a> but that's Lean 2.</p>",
        "id": 398838923,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1698390930
    },
    {
        "content": "<p>It's not Lean, but this library might interest you: <a href=\"https://github.com/IBM/FormalML\">https://github.com/IBM/FormalML</a></p>\n<p>About optimization more specifically than ML in general, in Lean we have the Hahn-Banach separation theorem, which is one of the main tools needed for convex optimization theory, the formulation of dual optimization problems, strong duality, etc. We also have results about convex functions, but I think we don't have much about convex optimization and we don't have anything about particular optimization algorithms. You won't find a proof of convergence of stochastic gradient descent in mathlib, for example.</p>\n<p>I am interested in this, but my formalization efforts have been focused on the \"stochastic\" part of \"stochastic gradient descent\": a lot of ML is about optimizing models with stochastic algorithms and/or in a stochastic environment, and to formalize that you need some probability.</p>",
        "id": 398841996,
        "sender_full_name": "Rémy Degenne",
        "timestamp": 1698392104
    },
    {
        "content": "<p>Back in lean 3 there was also <a href=\"https://github.com/jtristan/stump-learnable\">https://github.com/jtristan/stump-learnable</a></p>",
        "id": 398845802,
        "sender_full_name": "Alex J. Best",
        "timestamp": 1698393606
    },
    {
        "content": "<p>Why don't those libraries exist in lean4? Have they decided that it is not worth to be ported?</p>",
        "id": 398865979,
        "sender_full_name": "Asei Inoue",
        "timestamp": 1698400879
    },
    {
        "content": "<p>Lean 4 is still pretty new!</p>",
        "id": 398874223,
        "sender_full_name": "Scott Morrison",
        "timestamp": 1698404041
    },
    {
        "content": "<p>Also these lean projects seemed to be for the most part one off research projects, and perhaps not completely polished or seeing wide use, the original authors moved on to other things years ago in some cases. You'd have to ask them if they planned to continue, but nobody in the community decided to maintain or port them</p>",
        "id": 398893473,
        "sender_full_name": "Alex J. Best",
        "timestamp": 1698411321
    },
    {
        "content": "<p>I found <a href=\"https://github.com/lecopivo/SciLean\">https://github.com/lecopivo/SciLean</a>.</p>",
        "id": 399023951,
        "sender_full_name": "Asei Inoue",
        "timestamp": 1698479571
    }
]