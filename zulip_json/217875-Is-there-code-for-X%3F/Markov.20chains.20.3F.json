[
    {
        "content": "<p>Are Markov chains in mathlib ? I couldn't find them, but I do not claim to be an expert searcher. If not, do you know if somebody working on formalizing them ? I am interested in discrete-time, and mostly in discrete space too.</p>",
        "id": 364552356,
        "sender_full_name": "Sophie Morel",
        "timestamp": 1686228885
    },
    {
        "content": "<p>They're not there yet, but <span class=\"user-mention\" data-user-id=\"350992\">@Rémy Degenne</span> is working on the prerequisites on kernels, towards a general theory. See for instance the directory (in mathlib3) <code>probability/kernel/</code>.</p>",
        "id": 364554441,
        "sender_full_name": "Sebastien Gouezel",
        "timestamp": 1686229307
    },
    {
        "content": "<p>Thank! Do you know if he intends to do Markov chains after that ?</p>",
        "id": 364600643,
        "sender_full_name": "Sophie Morel",
        "timestamp": 1686237879
    },
    {
        "content": "<p>I guess that's the plan, but I have no idea about the time scale.</p>",
        "id": 364604272,
        "sender_full_name": "Sebastien Gouezel",
        "timestamp": 1686238455
    },
    {
        "content": "<p>I am indeed adding prerequisites for Markov decision processes (MDP), which become Markov chains if you choose a policy. That means that I'll have to add everything needed for markov chains along the way. I am not taking the quick route though, and it will take time: I try to develop each notion needed in a general enough setting, in order to not get only MDPs at the end, but also a good foundation for other probability results.</p>",
        "id": 364604848,
        "sender_full_name": "Rémy Degenne",
        "timestamp": 1686238584
    },
    {
        "content": "<p>My next step is to define conditional independence, but the way I want to do it requires a refactor of the current definition of independence, and that has already been ported. So the project is on hold until the end of the port (which is imminent :) )and will resume in mathlib 4.</p>",
        "id": 364605771,
        "sender_full_name": "Rémy Degenne",
        "timestamp": 1686238793
    },
    {
        "content": "<p>You are already allowed to edit and add stuff to mathlib4</p>",
        "id": 364690118,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1686263147
    },
    {
        "content": "<p>AFAIK, refactors are not allowed yet.</p>",
        "id": 364730214,
        "sender_full_name": "Yury G. Kudryashov",
        "timestamp": 1686286758
    },
    {
        "content": "<p>Yeah that would be probably going a bit too far right now, maybe wait about 10 days until the port is done :-)</p>",
        "id": 364742324,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1686291742
    },
    {
        "content": "<p>The refactor would break at least one proof in an unported file and would change the imports of several ported and unported files. Attempting to do it now would create a mess. Allowed or not, it's much better to do it once everything is ported.</p>",
        "id": 364747813,
        "sender_full_name": "Rémy Degenne",
        "timestamp": 1686293379
    },
    {
        "content": "<p>Which is hopefully about 2 weeks from now.</p>",
        "id": 364750741,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1686294277
    },
    {
        "content": "<p>At this point it seems we are okay with golfing proofs, adding new lemmas, add new files, but not reorganising or refactoring.</p>",
        "id": 364754550,
        "sender_full_name": "Scott Morrison",
        "timestamp": 1686295347
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"350992\">Rémy Degenne</span> <a href=\"#narrow/stream/217875-Is-there-code-for-X.3F/topic/Markov.20chains.20.3F/near/364604848\">said</a>:</p>\n<blockquote>\n<p>I am indeed adding prerequisites for Markov decision processes (MDP), which become Markov chains if you choose a policy. That means that I'll have to add everything needed for markov chains along the way. I am not taking the quick route though, and it will take time: I try to develop each notion needed in a general enough setting, in order to not get only MDPs at the end, but also a good foundation for other probability results.</p>\n</blockquote>\n<p>Gotcha, thank you for explaining your plans !</p>",
        "id": 364927422,
        "sender_full_name": "Sophie Morel",
        "timestamp": 1686332452
    }
]