[
    {
        "content": "<p>This PR looks great on so many axes: small diff (+16/-23), code simplification and a really nice performance benefit (-180 * 10‚Åπ instructions, including a 20% speed-up on some files). I'd approve it on these grounds alone, but this seems important: can an expert about fast_instance take a look? CC <span class=\"user-mention\" data-user-id=\"310045\">@Eric Wieser</span> <span class=\"user-mention\" data-user-id=\"306577\">@Matthew Ballard</span></p>",
        "id": 558135272,
        "sender_full_name": "Michael Rothgang",
        "timestamp": 1763539209
    },
    {
        "content": "<p>The other question: should we have a linter for missing <code>fast_instance%</code> annotations?</p>",
        "id": 558135306,
        "sender_full_name": "Michael Rothgang",
        "timestamp": 1763539223
    },
    {
        "content": "<p>(Do we want to enforce a rule of making that the default?)</p>",
        "id": 558135333,
        "sender_full_name": "Michael Rothgang",
        "timestamp": 1763539234
    },
    {
        "content": "<p>Aha, I didn't see the extent of the speedup before going to bed, this is nice indeed! For context, this came up because I was noticing slowdowns while working on distributions, where I have to work with types such as <code>ùìì^{n}_{K}(E, F) ‚ÜíL[ùïú] E ‚Üí·µá (E [√ói]‚ÜíL[‚Ñù] F)</code>, and I noticed that Lean spent a lot of tim unifying stuff related to continuous multilinear maps. And indeed this file was sped up a ton.</p>",
        "id": 558147812,
        "sender_full_name": "Anatole Dedecker",
        "timestamp": 1763543425
    },
    {
        "content": "<p>Was <a href=\"https://github.com/leanprover-community/mathlib4/pull/31790\">#31790</a> also motivated by the same observation? (That PR is a mostly neutral, one file slows down and others speed up a bit. I don't understand well if that means we should merge it as well.)</p>",
        "id": 558148290,
        "sender_full_name": "Michael Rothgang",
        "timestamp": 1763543563
    },
    {
        "content": "<p>This is now merged, but here is a followup question. The <code>leanprover-radar</code> bot only reported (very) positive changes, but <code>leanprover-bot</code> was slightly less enthusiastic, do these run completely separatey? </p>\n<p>Among the negative changes, two are very understandable: the modified files became slightly slower (presumably because <code>fast_instance%</code> does some more work?) but most of the dependent files became faster.</p>\n<p>The two other ones seem weirder. First, there is <code>Mathlib.Tactic.CC.Lemmas</code>, which is way earlier in the import tree so I <em>have</em> to assume that it should not be affected by my changes. The other one is <code>Mathlib.LinearAlgebra.Alternating.Uncurry.Fin</code>, which is more worrying, and I don't understand why it would get slower.</p>\n<p>So, are any of these annoying? And how do we explain the discrepancy between the two summaries?</p>",
        "id": 558149565,
        "sender_full_name": "Anatole Dedecker",
        "timestamp": 1763543916
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"634338\">Michael Rothgang</span> <a href=\"#narrow/channel/144837-PR-reviews/topic/.2331789.20More.20fast_instance.25/near/558148290\">said</a>:</p>\n<blockquote>\n<p>Was <a href=\"https://github.com/leanprover-community/mathlib4/pull/31790\">#31790</a> also motivated by the same observation? (That PR is a mostly neutral, one file slows down and others speed up a bit. I don't understand well if that means we should merge it as well.)</p>\n</blockquote>\n<p>It is. Intuitively I would argue that slowing up one file to make all the files downstream faster is a good thing, but this is just intuition.</p>",
        "id": 558150731,
        "sender_full_name": "Anatole Dedecker",
        "timestamp": 1763544220
    },
    {
        "content": "<p>Since a lot of stuff has changed with the module system and all, let me merge master and bench again</p>",
        "id": 558151223,
        "sender_full_name": "Anatole Dedecker",
        "timestamp": 1763544327
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"268315\">Anatole Dedecker</span> <a href=\"#narrow/channel/144837-PR-reviews/topic/.2331789.20More.20fast_instance.25/near/558149565\">said</a>:</p>\n<blockquote>\n<p>This is now merged, but here is a followup question. The <code>leanprover-radar</code> bot only reported (very) positive changes, but <code>leanprover-bot</code> was slightly less enthusiastic, do these run completely separatey? </p>\n</blockquote>\n<p>Yes, that's my understanding</p>",
        "id": 558157425,
        "sender_full_name": "Ruben Van de Velde",
        "timestamp": 1763546188
    },
    {
        "content": "<p>Then I guess the bots might just have different metrics about what is a notable change</p>",
        "id": 558158313,
        "sender_full_name": "Anatole Dedecker",
        "timestamp": 1763546415
    },
    {
        "content": "<p><code>fast_instance</code> attempts a semi-normalization of a term with respect to the rule: can typeclass synthesis fill this in? It works up to the instances transparency. You will see slow downs on direct use because you are calling synthesis while unpacking the term and checking each step. You could see slow downs downstream because unification is being attempted against another instance whose shape was a ‚Äúbetter fit‚Äù before to un-normalized term. I would default to the assumption that the other term is poorly formed also.</p>",
        "id": 558163593,
        "sender_full_name": "Matthew Ballard",
        "timestamp": 1763547970
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"306577\">Matthew Ballard</span> <a href=\"#narrow/channel/144837-PR-reviews/topic/.2331789.20More.20fast_instance.25/near/558163593\">said</a>:</p>\n<blockquote>\n<p>I would default to the assumption that the other term is poorly formed also.</p>\n</blockquote>\n<p>Do I read this correctly as \"if <code>fast_instance%</code> causes slowdowns then the solution is probably more <code>fast_instance%</code>\"?</p>",
        "id": 558165430,
        "sender_full_name": "Anatole Dedecker",
        "timestamp": 1763548441
    },
    {
        "content": "<p>I communicate poorly. It‚Äôs the other instance.</p>",
        "id": 558165540,
        "sender_full_name": "Matthew Ballard",
        "timestamp": 1763548468
    },
    {
        "content": "<p>Yes, if I make instance <code>A</code> a <code>fast_instance</code> and unifying it with instance <code>B</code> becomes slower, then I should make <code>B</code> a <code>fast_instance</code> as well, right?</p>",
        "id": 558165746,
        "sender_full_name": "Anatole Dedecker",
        "timestamp": 1763548519
    },
    {
        "content": "<p><code>fastInst =?= badInst</code></p>",
        "id": 558165797,
        "sender_full_name": "Matthew Ballard",
        "timestamp": 1763548532
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"268315\">Anatole Dedecker</span> <a href=\"#narrow/channel/144837-PR-reviews/topic/.2331789.20More.20fast_instance.25/near/558165746\">said</a>:</p>\n<blockquote>\n<p>Yes, if I make instance <code>A</code> a <code>fast_instance</code> and unifying it with instance <code>B</code> becomes slower, then I should make <code>B</code> a <code>fast_instance</code> as well, right?</p>\n</blockquote>\n<p>I would start there. Fast instance doesn‚Äôt completely normalize (but should) so it could make problems itself too</p>",
        "id": 558166092,
        "sender_full_name": "Matthew Ballard",
        "timestamp": 1763548608
    },
    {
        "content": "<p>The InjSurj instances are not the only pattern yielding <code>badInst</code> but the most prominent</p>",
        "id": 558166609,
        "sender_full_name": "Matthew Ballard",
        "timestamp": 1763548768
    },
    {
        "content": "<p>After a new benchmark in <a href=\"https://github.com/leanprover-community/mathlib4/pull/31790\">#31790</a> I believe that the changes are minor but good overall. I think the only regression which is not noise is the modified file, and most files downstream are faster so it seems like a good change to me.</p>",
        "id": 558167866,
        "sender_full_name": "Anatole Dedecker",
        "timestamp": 1763549099
    },
    {
        "content": "<p>Is it possible to have a linter for missing <code>fast_instance%</code>s?</p>",
        "id": 558207115,
        "sender_full_name": "Jireh Loreaux",
        "timestamp": 1763560049
    },
    {
        "content": "<p><a href=\"#narrow/channel/144837-PR-reviews/topic/.2331789.20More.20fast_instance.25/near/558135306\">I was wondering the same</a> :-)</p>",
        "id": 558208308,
        "sender_full_name": "Michael Rothgang",
        "timestamp": 1763560339
    }
]