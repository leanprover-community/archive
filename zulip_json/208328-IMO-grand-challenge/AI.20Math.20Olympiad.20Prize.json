[
    {
        "content": "<p><a href=\"https://aimoprize.com/\">https://aimoprize.com/</a></p>\n<p>$10 million prize fund! And I appreciate that models must be \"publicly-shared\"</p>",
        "id": 404416504,
        "sender_full_name": "David Renshaw",
        "timestamp": 1701093182
    },
    {
        "content": "<p>My university's network is blocking that site as potentially malicious... How serious is this?</p>",
        "id": 404439321,
        "sender_full_name": "Adam Topaz",
        "timestamp": 1701099961
    },
    {
        "content": "<p>Looks pretty legit to me. <a href=\"https://aimoprize.com/supporters\">https://aimoprize.com/supporters</a> has blurbs from Terence Tao, Leonardo de Moura, and Kevin Buzzard.</p>",
        "id": 404440234,
        "sender_full_name": "David Renshaw",
        "timestamp": 1701100235
    },
    {
        "content": "<p>A big difference from the IMO Grand Challenge is that this one is framed as informal-to-informal.</p>",
        "id": 404440303,
        "sender_full_name": "David Renshaw",
        "timestamp": 1701100258
    },
    {
        "content": "<p>Gotcha. Ok, I'll spin up my VPN :)</p>",
        "id": 404440337,
        "sender_full_name": "Adam Topaz",
        "timestamp": 1701100271
    },
    {
        "content": "<p>(But I still think the best way to get there is through formal-to-formal.)</p>",
        "id": 404440390,
        "sender_full_name": "David Renshaw",
        "timestamp": 1701100289
    },
    {
        "content": "<p>They are taking this really seriously.  $10M, paid roles, and prizes for partial progress.  That is great to hear!  I think they are missing a lot of details, like what is the \"AI-MO\"public sharing protocol\"?  What are the partial progress goals?  What is the entry criteria?  How many resources can one use?</p>",
        "id": 404448906,
        "sender_full_name": "Jason Rute",
        "timestamp": 1701102951
    },
    {
        "content": "<p>presumably the folks in the paid roles will eventually fill in those details</p>",
        "id": 404449080,
        "sender_full_name": "David Renshaw",
        "timestamp": 1701103008
    },
    {
        "content": "<p>Overall I hope the criteria is not too onerous.  Otherwise we could have a situation where some tech company produces a working solution which gets a gold medal in the IMO and publishes in Nature, but it doesn't count since it relies on proprietary components, so a bunch of teams rush over that next year to publicly reproduce the results to get the $10M.  (Or maybe this is fine too.  It is the progress that matters.)</p>",
        "id": 404449310,
        "sender_full_name": "Jason Rute",
        "timestamp": 1701103091
    },
    {
        "content": "<p>As for legitimacy, let's ask <span class=\"user-mention\" data-user-id=\"110038\">@Kevin Buzzard</span>.</p>",
        "id": 404449350,
        "sender_full_name": "Jason Rute",
        "timestamp": 1701103105
    },
    {
        "content": "<blockquote>\n<p>but it doesn't count since it relies on proprietary components, so a bunch of teams rush over that next year to publicly reproduce the results to get the $10M.</p>\n</blockquote>\n<p>that sounds like a good outcome to me</p>",
        "id": 404449480,
        "sender_full_name": "David Renshaw",
        "timestamp": 1701103146
    },
    {
        "content": "<p>Also, this is more  money than the Millenium prizes combined.  Are there any other comparably-sized prizes in AI?  I do worry that this might be too much money.  Hopefully it doesn't end up like the <a href=\"https://en.wikipedia.org/wiki/Netflix_Prize\">Netflix prize</a> where the solutions are just a hodgepodge of models and techniques with no overall pattern and generalizability (or so I thought I remember hearing, as it was before I was in AI).</p>",
        "id": 404449792,
        "sender_full_name": "Jason Rute",
        "timestamp": 1701103246
    },
    {
        "content": "<p>To me, it is not clear what they are going to do against lengthy calculations / proofs. Human beings are not capable of writing as long proofs as computer programs in 4.5 hours, and according to standard IMO rules, solution of any length should be accepted as long as it is correct.</p>",
        "id": 404450080,
        "sender_full_name": "Miroslav Olšák",
        "timestamp": 1701103327
    },
    {
        "content": "<p>I think the Netflix prize was of the form \"whoever decreases the loss the most wins\". Here we have a concrete endpoint we're aiming for.</p>",
        "id": 404450118,
        "sender_full_name": "David Renshaw",
        "timestamp": 1701103342
    },
    {
        "content": "<blockquote>\n<p>AI models must consume problems in the same format as human contestants and must produce human readable solutions that can be graded by an expert panel, using standard Olympiad criteria.</p>\n</blockquote>\n<p>A human grader would not accept an enormous proof.</p>",
        "id": 404451463,
        "sender_full_name": "David Renshaw",
        "timestamp": 1701103790
    },
    {
        "content": "<blockquote>\n<p>I think the Netflix prize was of the form \"whoever decreases the loss the most wins\".  Here we have a concrete endpoint we're aiming for.</p>\n</blockquote>\n<p>I'm not sure what you mean here.  Maybe I don't know enough about the Netflix prize.  How is this different?  (Is it because the test set is hidden?) Couldn't we easily end up in the situation where there are 100 sub-models?  Each model does better on a different type of IMO problem.  Teams realizing they are not quite there, start to combine into super teams where they aggregate all their models.  There are a lot of hard coded solutions for particular common types of problems.  There is very complicated and ad hoc logic to decide what model to use in each situation and what solution to send to the reviewers.  Of course complexity can be fine.  Alpha-fold 2 is quite complex.  But I think high prize money could lead to a kitchen-sink approach where everything is thrown in.</p>",
        "id": 404453078,
        "sender_full_name": "Jason Rute",
        "timestamp": 1701104289
    },
    {
        "content": "<p>Alternately, another possible issue with extreme prize money is that teams not wanting to get scooped on $10M stop sharing their partial results.  (Are we going to stop getting models like LLEMMA now?)</p>",
        "id": 404453107,
        "sender_full_name": "Jason Rute",
        "timestamp": 1701104301
    },
    {
        "content": "<p>Of course I might just be too jaded.  The attention will be good, and most AI labs will still be looking to the big picture even if they aren't first (and $10M isn't that much money).</p>",
        "id": 404453116,
        "sender_full_name": "Jason Rute",
        "timestamp": 1701104305
    },
    {
        "content": "<blockquote>\n<p>A human grader would not accept an enormous proof.</p>\n</blockquote>\n<p>On IMO, I am pretty confident they would (although truly enormous proof couldn't appear).  If there is an exception in this challenge (which I find pretty reasonable), I would consider it fair to define \"enormous\".</p>",
        "id": 404453927,
        "sender_full_name": "Miroslav Olšák",
        "timestamp": 1701104530
    },
    {
        "content": "<p>Netflix Prize = \"win computer chess tournament\"<br>\nAI-MO Prize = \"beat Garry Kasparov\"</p>",
        "id": 404453943,
        "sender_full_name": "David Renshaw",
        "timestamp": 1701104535
    },
    {
        "content": "<p>Like, there are lot of people saying that it's just never going to happen. Part of the point is to prove those people wrong.</p>",
        "id": 404454132,
        "sender_full_name": "David Renshaw",
        "timestamp": 1701104595
    },
    {
        "content": "<p>Still can't connect from my university network :-/ Is there an expected timeline for this, or is it completely open-ended?</p>",
        "id": 404454157,
        "sender_full_name": "Adam Topaz",
        "timestamp": 1701104602
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"243791\">David Renshaw</span> <a href=\"#narrow/stream/208328-IMO-grand-challenge/topic/AI.20Math.20Olympiad.20Prize/near/404440390\">said</a>:</p>\n<blockquote>\n<p>(But I still think the best way to get there is through formal-to-formal.)</p>\n</blockquote>\n<p>I think formal-to-formal could still be an important part of the winning solution, especially if it is the best way to get there.  Imagine something like draft-sketch-prove-sketch-draft.</p>",
        "id": 404454411,
        "sender_full_name": "Jason Rute",
        "timestamp": 1701104685
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"243562\">Adam Topaz</span> <a href=\"#narrow/stream/208328-IMO-grand-challenge/topic/AI.20Math.20Olympiad.20Prize/near/404454157\">said</a>:</p>\n<blockquote>\n<p>Still can't connect from my university network :-/ Is there an expected timeline for this, or is it completely open-ended?</p>\n</blockquote>\n<p>From the website:</p>\n<blockquote>\n<p>The first AI-MO approved competitions will open to participants in early 2024. There will be a presentation of progress at the 65th IMO, which will be held in Bath, England in July 2024</p>\n</blockquote>",
        "id": 404454508,
        "sender_full_name": "Jason Rute",
        "timestamp": 1701104723
    },
    {
        "content": "<p>Overall, they don't give many concrete details.</p>",
        "id": 404454569,
        "sender_full_name": "Jason Rute",
        "timestamp": 1701104740
    },
    {
        "content": "<p>yeah this is definitely a thing, XTX Markets are behind it. My understanding from talking to them is that they (i.e. XTX) get to decide what \"partial progress\" means.</p>\n<p>As for this v the netflix prize, here there is a very clear goal. XTX are working in collaboration with the IMO organisers so will probably manage to persuade them to mark a couple of computer entries, if there are any this year.</p>\n<p>Re sharing: I was talking to a bunch of DeepMind and ex DeepMind people over the weekand and they say that this (suppression of results) is already happening a lot anyway.</p>",
        "id": 404455662,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1701105145
    },
    {
        "content": "<p>I do especially like the partial progress part.  My big complaint on the original IMO Grand Challenge is that there is no mechanism for measuring, rewarding, or acknowledging partial progress.</p>",
        "id": 404459475,
        "sender_full_name": "Jason Rute",
        "timestamp": 1701106541
    },
    {
        "content": "<p>Ok, I now understand <span class=\"user-mention\" data-user-id=\"243791\">@David Renshaw</span>'s point.  Since one doesn't have to beat other models, just humans, there isn't as much need for extreme optimization as seen in some Kaggle competitions and the Netflix challenge.  So it might (hopefully) be that a model of reasonable complexity does fine on all types of problems, or that maybe there is a model for only a few select types of problems, but not the kitchen sink aggregate approach I am worried is needed to squeeze out that remaining 1% of improvement.</p>",
        "id": 404460696,
        "sender_full_name": "Jason Rute",
        "timestamp": 1701106975
    },
    {
        "content": "<p>My big complaint on the original IMO grand challenge is that if you look at the 2023 IMO day 1, two of the questions aren't \"prove this\", they are \"determine this set\", and I have never figured out how to formalise this. This is why I think the natural language approach is a better idea -- it makes it much easier to define the question.</p>",
        "id": 404460782,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1701107010
    },
    {
        "content": "<blockquote>\n<p>My big complaint on the original IMO grand challenge is that if you look at the 2023 IMO day 1, two of the questions aren't \"prove this\", they are \"determine this set\", and I have never figured out how to formalise this. This is why I think the natural language approach is a better idea -- it makes it much easier to define the question.</p>\n</blockquote>\n<p>One option already mentioned here (I think) was to have human-checked solution to the \"determine\" part but computer-verified proof, which is going a bit towards AI-MO Prize just without people having to check the proofs (which is more annoying part).</p>\n<p>Another (more formal) option is to restrict per problem which constructing operations are allowed. For example in case of IMO 2023-1, it would be a set defined by a free variable <code>x</code>, and besides this variable, allowed functions would be boolean connectives, equality, integer less than, arithmetic operations,, prime decomposition, and basic functions providing manipulation with the prime decomposition (length of a list, index into a list, ...).</p>",
        "id": 404471927,
        "sender_full_name": "Miroslav Olšák",
        "timestamp": 1701111312
    },
    {
        "content": "<p>yeah, like I said, we could either contort ourselves into a convoluted position or just ask for a natural language solution.</p>",
        "id": 404473724,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1701112015
    },
    {
        "content": "<p>my problem with human-checking is that I wouldn't be much motivated to check 20 pages of geometry calculations that are likely correct (in case they came from a computer algebra system, and not ChatGPT <span aria-label=\"laughing\" class=\"emoji emoji-1f606\" role=\"img\" title=\"laughing\">:laughing:</span> )</p>",
        "id": 404475039,
        "sender_full_name": "Miroslav Olšák",
        "timestamp": 1701112719
    },
    {
        "content": "<p>After (briefly) discussing this prize with XTX a few weeks ago I noted a few considerations that didn't come up in that discussion but would be relevant for establishing detailed rules, one of which was the matter of establishing a length limit on solutions to avoid coordinators needing to read 1000-page claimed proofs (which have a legitimate place in mathematics, but not in solving IMO problems, since that's far longer than an IMO contestant could reasonably write in 4.5 hours).</p>",
        "id": 404538072,
        "sender_full_name": "Joseph Myers",
        "timestamp": 1701142549
    },
    {
        "content": "<p>If a human IMO contestant produces a solution with 20 pages of algebra (which is within what might be written in reality by such a contestant, occasionally, albeit 20 handwritten pages for the human contestant), the coordinators need to read it, even if boring. I think motivation in the AI-MO Prize case might be provided by paying the coordinators to check the AI solutions. In both cases, coordinators are free to use computer algebra systems themselves to help them in checking.</p>",
        "id": 404538496,
        "sender_full_name": "Joseph Myers",
        "timestamp": 1701142753
    },
    {
        "content": "<p>How exactly is this a problem? If they came from a computer algebra system can't we just verify it with a computer algebra system?</p>\n<p>By the way, can someone correct my understanding on this. I actually thought most plane geometry problems can be efficiently solved by computer algebra. But i gather this isn't true?</p>",
        "id": 404550090,
        "sender_full_name": "Andy Jiang",
        "timestamp": 1701149659
    },
    {
        "content": "<p>As I understand if you trust the algebra systems then you can do so but with proved algorithms it is not so easy. My experiments on this are at <a href=\"https://siddhartha-gadgil.github.io/automating-mathematics/posts/solving-pappus/\">https://siddhartha-gadgil.github.io/automating-mathematics/posts/solving-pappus/</a> (following on <a href=\"https://siddhartha-gadgil.github.io/automating-mathematics/posts/proving-by-solving/\">https://siddhartha-gadgil.github.io/automating-mathematics/posts/proving-by-solving/</a>).</p>\n<p>If someone knows about checked algorithms that work I would be grateful for the information.</p>",
        "id": 404552934,
        "sender_full_name": "Siddhartha Gadgil",
        "timestamp": 1701151414
    },
    {
        "content": "<p>If the problem reduces to showing some polynomial equations in the coordinates imply another polynomial equation in the coordinates, then it can be solved efficiently (in practice) by Gröbner bases. Otherwise (if there are inequalities involved), you need quantifier elimination, which is much less efficient.</p>\n<p>A large proportion of IMO geometry problems do in fact involve configuration or nondegeneracy information that prevents them reducing to Gröbner bases. For example, IMO 2023 problem 2 asks to prove that two points meet on an internal angle bisector (the polynomials in question won't distinguish internal from external bisectors, and indeed a similar issue applies to the definition of the point S). IMO 2023 problem 6 asks to prove that circles have two common points, which polynomials won't distinguish from having a single common point.</p>\n<p>Sometimes the relevant information in the conclusion, beyond what can be deduced with Gröbner bases, may be geometrically obvious and not need remarking on in a human solution, but that's not always the case. In IMO 2023 problem 6 you could lose points for not justifying various nondegeneracy conditions needed in a solution. In IMO 2002 problem 2 you could lose a point for failing to explain why an angle condition meant you had the incentre rather than an excentre.</p>\n<p>Even if you don't have such configuration information in the conclusion, you might need to use such information from the hypotheses. Maybe the polynomials generate an ideal that contains polynomial <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>P</mi><mi>Q</mi></mrow><annotation encoding=\"application/x-tex\">PQ</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8778em;vertical-align:-0.1944em;\"></span><span class=\"mord mathnormal\">PQ</span></span></span></span>, but actually you have to prove something equivalent to <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>P</mi><mo>=</mo><mn>0</mn></mrow><annotation encoding=\"application/x-tex\">P=0</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">P</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6444em;\"></span><span class=\"mord\">0</span></span></span></span>, and excluding the possibility of <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>Q</mi><mo>=</mo><mn>0</mn></mrow><annotation encoding=\"application/x-tex\">Q=0</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8778em;vertical-align:-0.1944em;\"></span><span class=\"mord mathnormal\">Q</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6444em;\"></span><span class=\"mord\">0</span></span></span></span> with <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>P</mi><mo mathvariant=\"normal\">≠</mo><mn>0</mn></mrow><annotation encoding=\"application/x-tex\">P\\ne 0</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">P</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\"><span class=\"mrel\"><span class=\"mord vbox\"><span class=\"thinbox\"><span class=\"rlap\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"inner\"><span class=\"mord\"><span class=\"mrel\"></span></span></span><span class=\"fix\"></span></span></span></span></span><span class=\"mrel\">=</span></span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6444em;\"></span><span class=\"mord\">0</span></span></span></span> requires using nondegeneracy conditions from the problem statement, for example. Again, it depends on the problem whether this is something that needs explicit justification in a solution, but if you're doing an algebraic solution you probably need to least to interpret <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>Q</mi><mo>=</mo><mn>0</mn></mrow><annotation encoding=\"application/x-tex\">Q=0</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8778em;vertical-align:-0.1944em;\"></span><span class=\"mord mathnormal\">Q</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6444em;\"></span><span class=\"mord\">0</span></span></span></span> geometrically before saying it can't occur.</p>",
        "id": 404766718,
        "sender_full_name": "Joseph Myers",
        "timestamp": 1701226951
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"266253\">Joseph Myers</span> <a href=\"#narrow/stream/208328-IMO-grand-challenge/topic/AI.20Math.20Olympiad.20Prize/near/404766718\">said</a>:</p>\n<blockquote>\n<p>If the problem reduces to showing some polynomial equations in the coordinates imply another polynomial equation in the coordinates, then it can be solved efficiently (in practice) by Gröbner bases. Otherwise (if there are inequalities involved), you need quantifier elimination, which is much less efficient.</p>\n<p>A large proportion of IMO geometry problems do in fact involve configuration or nondegeneracy information that prevents them reducing to Gröbner bases. For example, IMO 2023 problem 2 asks to prove that two points meet on an internal angle bisector (the polynomials in question won't distinguish internal from external bisectors, and indeed a similar issue applies to the definition of the point S). IMO 2023 problem 6 asks to prove that circles have two common points, which polynomials won't distinguish from having a single common point.</p>\n<p>Sometimes the relevant information in the conclusion, beyond what can be deduced with Gröbner bases, may be geometrically obvious and not need remarking on in a human solution, but that's not always the case. In IMO 2023 problem 6 you could lose points for not justifying various nondegeneracy conditions needed in a solution. In IMO 2002 problem 2 you could lose a point for failing to explain why an angle condition meant you had the incentre rather than an excentre.</p>\n<p>Even if you don't have such configuration information in the conclusion, you might need to use such information from the hypotheses. Maybe the polynomials generate an ideal that contains polynomial <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>P</mi><mi>Q</mi></mrow><annotation encoding=\"application/x-tex\">PQ</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8778em;vertical-align:-0.1944em;\"></span><span class=\"mord mathnormal\">PQ</span></span></span></span>, but actually you have to prove something equivalent to <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>P</mi><mo>=</mo><mn>0</mn></mrow><annotation encoding=\"application/x-tex\">P=0</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">P</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6444em;\"></span><span class=\"mord\">0</span></span></span></span>, and excluding the possibility of <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>Q</mi><mo>=</mo><mn>0</mn></mrow><annotation encoding=\"application/x-tex\">Q=0</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8778em;vertical-align:-0.1944em;\"></span><span class=\"mord mathnormal\">Q</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6444em;\"></span><span class=\"mord\">0</span></span></span></span> with <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>P</mi><mo mathvariant=\"normal\">≠</mo><mn>0</mn></mrow><annotation encoding=\"application/x-tex\">P\\ne 0</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">P</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\"><span class=\"mrel\"><span class=\"mord vbox\"><span class=\"thinbox\"><span class=\"rlap\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"inner\"><span class=\"mord\"><span class=\"mrel\"></span></span></span><span class=\"fix\"></span></span></span></span></span><span class=\"mrel\">=</span></span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6444em;\"></span><span class=\"mord\">0</span></span></span></span> requires using nondegeneracy conditions from the problem statement, for example. Again, it depends on the problem whether this is something that needs explicit justification in a solution, but if you're doing an algebraic solution you probably need to least to interpret <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>Q</mi><mo>=</mo><mn>0</mn></mrow><annotation encoding=\"application/x-tex\">Q=0</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8778em;vertical-align:-0.1944em;\"></span><span class=\"mord mathnormal\">Q</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6444em;\"></span><span class=\"mord\">0</span></span></span></span> geometrically before saying it can't occur.</p>\n</blockquote>\n<p>Are Grobner basis efficient in practice for Euclidean geometry problems? My experience was they are not (and I believe they are doubly exponential).</p>",
        "id": 404788682,
        "sender_full_name": "Siddhartha Gadgil",
        "timestamp": 1701236902
    },
    {
        "content": "<p>Both Gröbner bases and quantifier elimination are doubly exponential in worst cases, but I think Gröbner bases are much more likely to work with reasonable resources in practice. A previous discussion <a href=\"#narrow/stream/208328-IMO-grand-challenge/topic/geometry.20problems\">https://leanprover.zulipchat.com/#narrow/stream/208328-IMO-grand-challenge/topic/geometry.20problems</a> says something about what problems could be proved with Gröbner bases <em>plus handling nondegeneracy conditions manually</em>.</p>",
        "id": 404980237,
        "sender_full_name": "Joseph Myers",
        "timestamp": 1701306054
    },
    {
        "content": "<p>Recently, I have noticed that the <a href=\"https://aimoprize.com/\">AIMO Prize website</a> spins my CPU's. What is it doing? Are they using my hardware to solve IMO problems :-D? Am I the only one, or is it happening to someone else too? I am on Firefox 118.0.2 (Linux).</p>",
        "id": 405414579,
        "sender_full_name": "Miroslav Olšák",
        "timestamp": 1701454199
    },
    {
        "content": "<p>Yeah me too, with Firefox and Chrome on Linux.</p>",
        "id": 405414986,
        "sender_full_name": "David Renshaw",
        "timestamp": 1701454352
    },
    {
        "content": "<p>For me on Firefox it looks like it spins up like 6 or 7 threads.</p>",
        "id": 405415139,
        "sender_full_name": "David Renshaw",
        "timestamp": 1701454425
    },
    {
        "content": "<p>It's this SVG file: <a href=\"https://aimoprize.com/pattern-tile.svg\">https://aimoprize.com/pattern-tile.svg</a></p>",
        "id": 405416545,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1701455074
    },
    {
        "content": "<p>I've reported the issue to XTX. Thanks.</p>",
        "id": 405432448,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1701461984
    },
    {
        "content": "<p>Cross-posting this: <a class=\"stream-topic\" data-stream-id=\"219941\" href=\"/#narrow/stream/219941-Machine-Learning-for-Theorem-Proving/topic/AlphaGeometry\">#Machine Learning for Theorem Proving &gt; AlphaGeometry</a> Solves 25 of 30 recent olympiad geometry problems.</p>",
        "id": 416083113,
        "sender_full_name": "Jason Rute",
        "timestamp": 1705512335
    },
    {
        "content": "<p>I'm looking to connect with people from India who want to put together a team to participate in the AIMO prize 2024 as well as the IMO-Grand-Challenge. I met <span class=\"user-mention\" data-user-id=\"266304\">@Siddhartha Gadgil</span> this Saturday at IISc, Bangalore. <span aria-label=\"pray\" class=\"emoji emoji-1f64f\" role=\"img\" title=\"pray\">:pray:</span> </p>\n<p>We have a whatsapp group. Please DM me if anyone discovers this thread and wants to join. :-)</p>",
        "id": 422363190,
        "sender_full_name": "Nilesh",
        "timestamp": 1708415552
    },
    {
        "content": "<p>Im interested in collaborating with any open groups/teams aimed at tackling the AIMO prize 2024, if anyone is open please DM me, thank you :)</p>",
        "id": 422793810,
        "sender_full_name": "David Afonso Valente",
        "timestamp": 1708600096
    },
    {
        "content": "<p>preliminary AIMO \"progress prize\" rules were announced just now:<br>\n<a href=\"https://www.reddit.com/r/AIMOprize/comments/1ay4aiu/progress_prize_pre_announcement/\">https://www.reddit.com/r/AIMOprize/comments/1ay4aiu/progress_prize_pre_announcement/</a></p>",
        "id": 423070109,
        "sender_full_name": "David Renshaw",
        "timestamp": 1708712145
    },
    {
        "content": "<blockquote>\n<p>We will have 100 completely new problems created. Problems will be in style of AIME: <a href=\"https://artofproblemsolving.com/wiki/index.php/AIME_Problems_and_Solutions\">https://artofproblemsolving.com/wiki/index.php/AIME_Problems_and_Solutions</a>.</p>\n<p>In particular, the answer to each problem is a number from 0 to 999.</p>\n<p>Complexity of problems will be a bit easier than AIME and targeted between AIME and AMC'12 level: <a href=\"https://artofproblemsolving.com/wiki/index.php/AMC_12_Problems_and_Solutions\">https://artofproblemsolving.com/wiki/index.php/AMC_12_Problems_and_Solutions</a></p>\n<p>Processing multi modal inputs (specifically diagrams) is not required, all problems are text only (although geometry problems are allowed).</p>\n<p>Total prize fund is $1,048,576.</p>\n</blockquote>",
        "id": 423070208,
        "sender_full_name": "David Renshaw",
        "timestamp": 1708712178
    },
    {
        "content": "<p>The first progress prize competition is now live and accepting submissions: <a href=\"https://www.kaggle.com/competitions/ai-mathematical-olympiad-prize/overview\">https://www.kaggle.com/competitions/ai-mathematical-olympiad-prize/overview</a></p>",
        "id": 430818537,
        "sender_full_name": "Terence Tao",
        "timestamp": 1712072181
    },
    {
        "content": "<ul>\n<li>submission deadline: 27June 2024 </li>\n<li>scored on 50 new problems, difficulty between AMC and AIME, stated in English/LaTeX, answers between 0 and 999</li>\n<li>submissions get a total of 9 hours of compute time on a machine with 4 cpus, 29GB of memory, and either a P100 gpu or 2xT4 gpus (Kaggle also has a TPU option, but I think it's not allowed for submissions in this contest?)</li>\n<li>max team size of 5</li>\n<li>\"Freely &amp; publicly available external data is allowed, including pre-trained models\"</li>\n<li>no live internet access allowed during evaluation</li>\n</ul>",
        "id": 430838215,
        "sender_full_name": "David Renshaw",
        "timestamp": 1712078308
    },
    {
        "content": "<p>Also the way they deal with the problems is interesting. 110 problems were created for this contest.</p>\n<ul>\n<li>10 problems are \"training problems\", which you can read if you enter the competition</li>\n<li>50 problems are \"public problems\", which are <em>not</em> publicly available, but which are used over the next three months to assess the quality of submissions on the leaderboard: <a href=\"https://www.kaggle.com/competitions/ai-mathematical-olympiad-prize/leaderboard\">https://www.kaggle.com/competitions/ai-mathematical-olympiad-prize/leaderboard</a></li>\n<li>50 problems are \"private problems\" and are actually used to determine the competition ranking.</li>\n</ul>",
        "id": 430843727,
        "sender_full_name": "Floris van Doorn",
        "timestamp": 1712080340
    },
    {
        "content": "<p>too bad zero of them are actually public for non-contestants</p>",
        "id": 430848060,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1712081870
    },
    {
        "content": "<p>To sign up, I needed to agree to the terms:<br>\n\"You agree to use reasonable and suitable measures to prevent persons who have not formally agreed to these Rules from gaining access to the Competition Data.\"</p>",
        "id": 430848769,
        "sender_full_name": "David Renshaw",
        "timestamp": 1712082142
    },
    {
        "content": "<p>I haven't managed to get in -- \"unable to phone verify\", on the other hand, so far I am looking at it more out of curiosity, not sure if I would compete in this</p>",
        "id": 430849771,
        "sender_full_name": "Mirek Olšák",
        "timestamp": 1712082526
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110049\">Mario Carneiro</span> <a href=\"#narrow/stream/208328-IMO-grand-challenge/topic/AI.20Math.20Olympiad.20Prize/near/430848060\">said</a>:</p>\n<blockquote>\n<p>too bad zero of them are actually public for non-contestants</p>\n</blockquote>\n<p>It is <em>highly nontrivial</em> to make 110 original questions of this nature.</p>",
        "id": 430860330,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1712086723
    },
    {
        "content": "<p>Actually, when  I searched enough, I was able to find some examples of the <code>train</code> problems in publicly available on the Kaggle website...</p>",
        "id": 431287970,
        "sender_full_name": "Mirek Olšák",
        "timestamp": 1712229726
    },
    {
        "content": "<p>Yeah, the 10 training problems + (unofficial) solutions are now visible here: <a href=\"https://www.kaggle.com/competitions/ai-mathematical-olympiad-prize/discussion/490640\">https://www.kaggle.com/competitions/ai-mathematical-olympiad-prize/discussion/490640</a><br>\nThere was apparently a mistake/typo in one of the training problems.</p>",
        "id": 431292421,
        "sender_full_name": "Floris van Doorn",
        "timestamp": 1712231093
    },
    {
        "content": "<p>Maybe I'm confused about the rules... looking at the <a href=\"https://www.kaggle.com/competitions/ai-mathematical-olympiad-prize/models\">models</a> tab lists things like mixtral, which I can't imagine would run on the VMs provided for this competition, as well as Gemini pro which is certainly not open-source and only behind an API. What do the models listed here actually refer to?</p>",
        "id": 431295397,
        "sender_full_name": "Adam Topaz",
        "timestamp": 1712231949
    },
    {
        "content": "<p>Mixtral with 4-bit quantization just barely fits into RAM.</p>",
        "id": 431295583,
        "sender_full_name": "David Renshaw",
        "timestamp": 1712232001
    },
    {
        "content": "<p>not sure why Gemini is listed there</p>",
        "id": 431295675,
        "sender_full_name": "David Renshaw",
        "timestamp": 1712232017
    },
    {
        "content": "<p>oh wow. is that with the 2xT4 or the P100? P100 has something like ~18G ram right?</p>",
        "id": 431295846,
        "sender_full_name": "Adam Topaz",
        "timestamp": 1712232058
    },
    {
        "content": "<p>I mean CPU RAM</p>",
        "id": 431295992,
        "sender_full_name": "David Renshaw",
        "timestamp": 1712232098
    },
    {
        "content": "<p>aha I see. But in this case I think the 9 hour limit would be an issue if you're not using the GPU</p>",
        "id": 431296262,
        "sender_full_name": "Adam Topaz",
        "timestamp": 1712232163
    },
    {
        "content": "<p>but also looks like each GPU in the T4x2 configuration has 15GB of memory, so I think it fits there too?</p>",
        "id": 431296268,
        "sender_full_name": "David Renshaw",
        "timestamp": 1712232165
    },
    {
        "content": "<p>Trying to run models on more than one GPU is intimidating for me... does the transformers library do the hard work for you? Edit: it seems that a simple <code>device_map = 'auto'</code> might just do the trick</p>",
        "id": 431297161,
        "sender_full_name": "Adam Topaz",
        "timestamp": 1712232431
    },
    {
        "content": "<p>The starter notebook I'm looking at uses llama_cpp (through a python wrapper), which seems to be pretty good at spreading things out:</p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"n\">llama_new_context_with_model</span><span class=\"o\">:</span> <span class=\"n\">total</span> <span class=\"n\">VRAM</span> <span class=\"n\">used</span><span class=\"o\">:</span> <span class=\"mi\">25329</span><span class=\"bp\">.</span><span class=\"mi\">59</span> <span class=\"n\">MiB</span> <span class=\"o\">(</span><span class=\"n\">model</span><span class=\"o\">:</span> <span class=\"mi\">25145</span><span class=\"bp\">.</span><span class=\"mi\">55</span> <span class=\"n\">MiB</span><span class=\"o\">,</span> <span class=\"n\">context</span><span class=\"o\">:</span> <span class=\"mi\">184</span><span class=\"bp\">.</span><span class=\"mi\">04</span> <span class=\"n\">MiB</span><span class=\"o\">)</span>\n</code></pre></div>",
        "id": 431298360,
        "sender_full_name": "David Renshaw",
        "timestamp": 1712232776
    },
    {
        "content": "<p>Is this starter notebook available publicly? Do you mind sharing?</p>",
        "id": 431298646,
        "sender_full_name": "Adam Topaz",
        "timestamp": 1712232867
    },
    {
        "content": "<p><a href=\"https://www.kaggle.com/competitions/ai-mathematical-olympiad-prize/discussion/490734\">https://www.kaggle.com/competitions/ai-mathematical-olympiad-prize/discussion/490734</a></p>",
        "id": 431298892,
        "sender_full_name": "David Renshaw",
        "timestamp": 1712232933
    },
    {
        "content": "<p>The submissions so far are able to solve 17/50 problems of the public problems, which is quite an impressive score!</p>",
        "id": 432029539,
        "sender_full_name": "Floris van Doorn",
        "timestamp": 1712596571
    },
    {
        "content": "<p>FWIW, there's a public notebook that gets 13/50 (and supposedly just by setting a higher temp it's possible to get a few more)</p>",
        "id": 432031051,
        "sender_full_name": "Adam Topaz",
        "timestamp": 1712597205
    },
    {
        "content": "<p>All this public notebook does is essentially self-consistency chain of thought together with straightforward python code execution, along with a particular choice of open-source model.</p>",
        "id": 432031284,
        "sender_full_name": "Adam Topaz",
        "timestamp": 1712597275
    },
    {
        "content": "<p>Is there an easy link to this notebook for those of us too lazy to go hunting?</p>",
        "id": 432034785,
        "sender_full_name": "Oliver Nash",
        "timestamp": 1712598484
    },
    {
        "content": "<p>I think this is it: <a href=\"https://www.kaggle.com/code/olyatsimboy/aimo-zero-shot-sc-mmos-deepseekmath\">https://www.kaggle.com/code/olyatsimboy/aimo-zero-shot-sc-mmos-deepseekmath</a></p>",
        "id": 432035246,
        "sender_full_name": "Adam Topaz",
        "timestamp": 1712598616
    },
    {
        "content": "<p>Am I right in thinking that one can cheat in the following way: look at the training data, solve the problems manually, and then write some kind of obfuscated code which just prints out the correct solutions? And then you'd get 0 on the test data (so wouldn't win any $$) but you could still be top of the kaggle leader board? Or have I misunderstood how things work?</p>",
        "id": 432035506,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1712598700
    },
    {
        "content": "<p>I think submitted notebooks don't have internet access, and we don't know the problems that they run on.</p>",
        "id": 432035713,
        "sender_full_name": "Adam Topaz",
        "timestamp": 1712598759
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"243562\">Adam Topaz</span> <a href=\"#narrow/stream/208328-IMO-grand-challenge/topic/AI.20Math.20Olympiad.20Prize/near/432035246\">said</a>:</p>\n<blockquote>\n<p>I think this is it: <a href=\"https://www.kaggle.com/code/olyatsimboy/aimo-zero-shot-sc-mmos-deepseekmath\">https://www.kaggle.com/code/olyatsimboy/aimo-zero-shot-sc-mmos-deepseekmath</a></p>\n</blockquote>\n<p>Note that this gets 0/10 on the test set, but if you change the <code>n_repetitions</code> to <code>5</code> on the test set it does get more than 0.</p>",
        "id": 432036101,
        "sender_full_name": "Adam Topaz",
        "timestamp": 1712598874
    },
    {
        "content": "<p>The problems are not publicly available. Even the so-called public problems are unknown, the only thing known is the leaderboard of scores that programs get on the public problems.</p>",
        "id": 432036189,
        "sender_full_name": "Floris van Doorn",
        "timestamp": 1712598903
    },
    {
        "content": "<p>right, and since there's no internet access you can't make a submission that just uploads the problems somewhere</p>",
        "id": 432036317,
        "sender_full_name": "Adam Topaz",
        "timestamp": 1712598949
    },
    {
        "content": "<p>the 10 test problems that we can read are disjoint from the public or private set.</p>",
        "id": 432036322,
        "sender_full_name": "Floris van Doorn",
        "timestamp": 1712598950
    },
    {
        "content": "<p>So the 50 \"public\" problems are not known to the people writing the AIs? I had misunderstood. (I knew they weren't available to the general public)</p>",
        "id": 432037810,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1712599402
    },
    {
        "content": "<p>The problem texts aren't public, but the success rate on them is</p>",
        "id": 432037929,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1712599434
    },
    {
        "content": "<p>Then what is the point of splitting the 100 secret questions into two sets of 50? Sorry to ask such basic questions,</p>",
        "id": 432044212,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1712601673
    },
    {
        "content": "<p>so that you can't optimize your submissions to the actual problems that will determine the prize</p>",
        "id": 432044650,
        "sender_full_name": "Adam Topaz",
        "timestamp": 1712601868
    },
    {
        "content": "<p>submissions close in june, and then the submissions run on the <em>SUPER SECRET</em> 50 questions that no submission has seen before.</p>",
        "id": 432044728,
        "sender_full_name": "Adam Topaz",
        "timestamp": 1712601897
    },
    {
        "content": "<p>But I thought we'd just established that we can't see the problems?</p>",
        "id": 432044729,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1712601897
    },
    {
        "content": "<p>yeah but you can still tune your model by making submissions each day and seeing what score you get</p>",
        "id": 432044819,
        "sender_full_name": "Adam Topaz",
        "timestamp": 1712601919
    },
    {
        "content": "<p>This was posted two days ago: <a href=\"https://www.kaggle.com/competitions/ai-mathematical-olympiad-prize/discussion/492178\">https://www.kaggle.com/competitions/ai-mathematical-olympiad-prize/discussion/492178</a></p>\n<p>Also, there is currently a public notebook that supposedly gets 16/20 here: <a href=\"https://www.kaggle.com/code/quan0095/more-diversity-in-output-improve-score\">https://www.kaggle.com/code/quan0095/more-diversity-in-output-improve-score</a></p>\n<p>But the highest score is still 17/20 :-/</p>",
        "id": 432566156,
        "sender_full_name": "Adam Topaz",
        "timestamp": 1712775139
    },
    {
        "content": "<p>\"16/50\", if I understand correctly</p>",
        "id": 432646883,
        "sender_full_name": "Mauricio Collares",
        "timestamp": 1712822112
    },
    {
        "content": "<p>Curious whether anyone has attempted <a href=\"https://arxiv.org/abs/2404.06405\">https://arxiv.org/abs/2404.06405</a> as an accompany tool to LLMs?</p>\n<blockquote>\n<p>solves 21 out of 30 methods by just using a CPU-only laptop with a time limit of 5 minutes per problem. Essentially, this classic method solves just 4 problems less than AlphaGeometry</p>\n</blockquote>",
        "id": 432653484,
        "sender_full_name": "fzyzcjy",
        "timestamp": 1712824404
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"325367\">Mauricio Collares</span> <a href=\"#narrow/stream/208328-IMO-grand-challenge/topic/AI.20Math.20Olympiad.20Prize/near/432646883\">said</a>:</p>\n<blockquote>\n<p>\"16/50\", if I understand correctly</p>\n</blockquote>\n<p>Yeah, sorry both 20's were a typo</p>",
        "id": 432688021,
        "sender_full_name": "Adam Topaz",
        "timestamp": 1712836432
    },
    {
        "content": "<p>This notebook has now got 20/50: <a href=\"https://www.kaggle.com/code/piotrzamisnii/aimo-zero-shot-sc-mmos-deepseekmath-e3248b\">https://www.kaggle.com/code/piotrzamisnii/aimo-zero-shot-sc-mmos-deepseekmath-e3248b</a> </p>\n<p>Note that it is essentially identical to the ones mentioned above which got 13 and eventually 17 by adjusting the temperature, and number of repetitions. I find it a bit disappointing that getting to 20/50 was more-or-less a lottery.</p>",
        "id": 434345620,
        "sender_full_name": "Adam Topaz",
        "timestamp": 1713527409
    },
    {
        "content": "<p>version 2 of this notebook had the following suspicious code:</p>\n<div class=\"codehilite\" data-code-language=\"Python\"><pre><span></span><code><span class=\"k\">for</span> <span class=\"n\">a</span><span class=\"p\">,</span> <span class=\"n\">b</span> <span class=\"ow\">in</span> <span class=\"nb\">zip</span><span class=\"p\">(</span><span class=\"n\">total_answers</span><span class=\"p\">,</span> <span class=\"n\">total_results</span><span class=\"p\">):</span>\n    <span class=\"n\">a</span> <span class=\"o\">=</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">array</span><span class=\"p\">(</span><span class=\"n\">a</span><span class=\"p\">)</span>\n    <span class=\"n\">b</span> <span class=\"o\">=</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">array</span><span class=\"p\">(</span><span class=\"n\">b</span><span class=\"p\">)</span>\n    <span class=\"n\">a</span><span class=\"p\">[</span><span class=\"n\">a</span> <span class=\"o\">&lt;</span> <span class=\"mi\">0</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">b</span><span class=\"p\">[</span><span class=\"n\">a</span> <span class=\"o\">&lt;</span> <span class=\"mi\">0</span><span class=\"p\">]</span>\n    <span class=\"n\">pred</span> <span class=\"o\">=</span> <span class=\"n\">Counter</span><span class=\"p\">(</span><span class=\"n\">a</span><span class=\"o\">.</span><span class=\"n\">tolist</span><span class=\"p\">())</span><span class=\"o\">.</span><span class=\"n\">most_common</span><span class=\"p\">(</span><span class=\"mi\">2</span><span class=\"p\">)</span>\n    <span class=\"n\">enumerates</span> <span class=\"o\">=</span> <span class=\"n\">df</span><span class=\"o\">.</span><span class=\"n\">enumerates</span><span class=\"o\">.</span><span class=\"n\">values</span><span class=\"p\">[</span><span class=\"n\">enumerate_i</span><span class=\"p\">]</span>\n    <span class=\"k\">if</span> <span class=\"n\">enumerates</span> <span class=\"ow\">in</span> <span class=\"p\">[</span><span class=\"mi\">3</span><span class=\"p\">,</span> <span class=\"mi\">4</span><span class=\"p\">,</span> <span class=\"mi\">5</span><span class=\"p\">]:</span>\n        <span class=\"n\">ans</span> <span class=\"o\">=</span> <span class=\"n\">pred</span><span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">][</span><span class=\"mi\">0</span><span class=\"p\">]</span>\n    <span class=\"k\">elif</span> <span class=\"n\">enumerates</span> <span class=\"ow\">in</span> <span class=\"p\">[</span><span class=\"mi\">30</span><span class=\"p\">,</span> <span class=\"mi\">36</span><span class=\"p\">]:</span>\n        <span class=\"n\">ans</span> <span class=\"o\">=</span> <span class=\"n\">pred</span><span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">][</span><span class=\"mi\">0</span><span class=\"p\">]</span> <span class=\"k\">if</span> <span class=\"ow\">not</span> <span class=\"n\">pred</span><span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">][</span><span class=\"mi\">0</span><span class=\"p\">]</span> <span class=\"o\">&lt;</span> <span class=\"mi\">0</span> <span class=\"k\">else</span> <span class=\"n\">pred</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">][</span><span class=\"mi\">0</span><span class=\"p\">]</span>\n    <span class=\"k\">else</span><span class=\"p\">:</span>\n        <span class=\"n\">ans</span> <span class=\"o\">=</span> <span class=\"n\">pred</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">][</span><span class=\"mi\">0</span><span class=\"p\">]</span> <span class=\"k\">if</span> <span class=\"ow\">not</span> <span class=\"n\">pred</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">][</span><span class=\"mi\">0</span><span class=\"p\">]</span> <span class=\"o\">&lt;</span> <span class=\"mi\">0</span> <span class=\"k\">else</span> <span class=\"n\">pred</span><span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">][</span><span class=\"mi\">0</span><span class=\"p\">]</span>\n    <span class=\"n\">enumerate_i</span><span class=\"o\">+=</span> <span class=\"mi\">1</span>\n    <span class=\"n\">final_answers</span><span class=\"o\">.</span><span class=\"n\">append</span><span class=\"p\">(</span><span class=\"n\">ans</span><span class=\"p\">)</span>\n    <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">ans</span><span class=\"p\">)</span>\n</code></pre></div>",
        "id": 434346889,
        "sender_full_name": "Adam Topaz",
        "timestamp": 1713527935
    },
    {
        "content": "<p>What does that code do?</p>",
        "id": 434356829,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1713531331
    },
    {
        "content": "<p>Disclosure: as of recently I am one of the people involved with the organisation of this prize</p>",
        "id": 434356984,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1713531378
    },
    {
        "content": "<p><code>total_answers</code> and <code>total_results</code> hold solution values that were computed in different ways. (I think the former is from running generated python code and the latter is from parsing what's in a generated \\box{}.) The above code implements voting, so that the most common solution gets chosen, with some priority given between the two styles of solution. The weird thing is the hard coding of the priority in problems 3,4,5,30, and 36.</p>",
        "id": 434358475,
        "sender_full_name": "David Renshaw",
        "timestamp": 1713531847
    },
    {
        "content": "<p>Thanks for the explanation!</p>",
        "id": 434370138,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1713535556
    },
    {
        "content": "<p>Huh, I would have figured submissions are run on a random ordering of the 50 problems to prevent any probing.</p>",
        "id": 434390236,
        "sender_full_name": "George Tsoukalas",
        "timestamp": 1713541898
    },
    {
        "content": "<p>The final competition is on 50 private problems that will not be used at all while the submissions are open, so it is impossible to probe the private problems.</p>",
        "id": 434404344,
        "sender_full_name": "Floris van Doorn",
        "timestamp": 1713546906
    },
    {
        "content": "<p><a href=\"https://www.kaggle.com/competitions/ai-mathematical-olympiad-prize/discussion/495133\">https://www.kaggle.com/competitions/ai-mathematical-olympiad-prize/discussion/495133</a></p>",
        "id": 434431453,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1713558793
    },
    {
        "content": "<p>Another submission is claiming 20/50 without probing: <a href=\"https://www.kaggle.com/competitions/ai-mathematical-olympiad-prize/discussion/492178#2763188\">https://www.kaggle.com/competitions/ai-mathematical-olympiad-prize/discussion/492178#2763188</a></p>",
        "id": 434571467,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1713688570
    },
    {
        "content": "<p>The competition for Progress Prize 1 ended 5 days ago, and apparently the highest score is 29/50 on the <a href=\"https://www.kaggle.com/competitions/ai-mathematical-olympiad-prize/leaderboard\">private leaderboard</a>, pending verification. (<strong>Update</strong>: the scores appear to be still on the public test set, see <a href=\"#narrow/stream/208328-IMO-grand-challenge/topic/AI.20Math.20Olympiad.20Prize/near/448829380\">below</a>.)</p>",
        "id": 448711713,
        "sender_full_name": "Junyan Xu",
        "timestamp": 1719958153
    },
    {
        "content": "<p>Is that the final score?  I’m trying to understand this post including the comment that the person currently in first place is still refreshing to see if the final results have come in.  <a href=\"https://www.kaggle.com/competitions/ai-mathematical-olympiad-prize/discussion/515516\">https://www.kaggle.com/competitions/ai-mathematical-olympiad-prize/discussion/515516</a></p>",
        "id": 448713204,
        "sender_full_name": "Jason Rute",
        "timestamp": 1719958744
    },
    {
        "content": "<p>My understanding is that the scores on the super-secret 50 questions are yet to be publically released.</p>",
        "id": 448714909,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1719959703
    },
    {
        "content": "<p>This is what I see, from which I understand that the submissions have been run on the private set but the results have not been verified. The verification looks like it might not be automated? Otherwise it would be strange to have a long delay. I think it makes sense that each submission is run on the private set when it's submitted, just the result is not published. If these are not results from the private test set, why call it \"preliminary\" \"private leaderboard\" rather than \"public leaderboard\"? But maybe I'm wrong and not all submissions have been run on the private set yet.<br>\n<a href=\"/user_uploads/3121/dy-co5ri1J3y6PSyf2kj6rSw/image.png\">image.png</a></p>\n<div class=\"message_inline_image\"><a href=\"/user_uploads/3121/dy-co5ri1J3y6PSyf2kj6rSw/image.png\" title=\"image.png\"><img src=\"/user_uploads/3121/dy-co5ri1J3y6PSyf2kj6rSw/image.png\"></a></div><p>(And thanks to <span class=\"user-mention\" data-user-id=\"115715\">@Jason Rute</span> for posting a link to the thread, I was not previously aware of it.)</p>",
        "id": 448715273,
        "sender_full_name": "Junyan Xu",
        "timestamp": 1719959945
    },
    {
        "content": "<p>My understanding is that they were hoping that everything would be done by now but it's not done yet.</p>",
        "id": 448715442,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1719960029
    },
    {
        "content": "<p>I've heard that you shouldn't be hitting refresh every 5 minutes and that the results from the private leaderboard might not appear for another day or two.</p>",
        "id": 448717272,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1719961060
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"224323\">Junyan Xu</span> <a href=\"#narrow/stream/208328-IMO-grand-challenge/topic/AI.20Math.20Olympiad.20Prize/near/448711713\">said</a>:</p>\n<blockquote>\n<p>The competition for Progress Prize 1 ended 5 days ago, and apparently the highest score is 29/50 on the <a href=\"https://www.kaggle.com/competitions/ai-mathematical-olympiad-prize/leaderboard\">private leaderboard</a>, pending verification.</p>\n</blockquote>\n<p>You call this \"the private leaderboard\", but isn't this just the scores on the \"public\" set of problems?</p>",
        "id": 448811534,
        "sender_full_name": "Floris van Doorn",
        "timestamp": 1720001976
    },
    {
        "content": "<p>It  does seem  that the scores are just the previous ones from the public test set.  The confusion seems to be that Kaggle itself calls this the “private leaderboard”.  And the note at the top of the leaderboard is confusing.  It implies that the private leaderboard has been run, but just needs verification.   I think that is just some generic kaggle text that doesn’t match the status of this competition.  (Also, there have been a few superficial changes from the public scores seen at the end of the competition.  Namely, the second-place Meta-math team was disqualified, and among the many teams  with a score of 26/50, their order has changed.  This makes it look superficially like the leaderboard is different from the old public one, which isn’t available anymore.)</p>",
        "id": 448828493,
        "sender_full_name": "Jason Rute",
        "timestamp": 1720007740
    },
    {
        "content": "<p>For what it's worth, here's a csv snapshot of the public leaderboard that I downloaded at the end of the submission period last week:<br>\n<a href=\"/user_uploads/3121/ATwPztHmlWv1_MGVbNaKrIIR/ai-mathematical-olympiad-prize-publicleaderboard-2024-06-27T104202.csv\">ai-mathematical-olympiad-prize-publicleaderboard-2024-06-27T104202.csv</a><br>\nAt a quick glance, it looks to me like this lines up with what's currently being displayed.</p>",
        "id": 448829380,
        "sender_full_name": "David Renshaw",
        "timestamp": 1720008041
    },
    {
        "content": "<p>The reordering might be due to the fact that I think these “new” scores are only calculated on the versions of the notebook that were submitted for final scoring.  In particular, I believe ties are broken by the notebook that was submitted first.</p>",
        "id": 448829463,
        "sender_full_name": "Jason Rute",
        "timestamp": 1720008064
    },
    {
        "content": "<p>OK the scores now represent the scores on the super-secret 50. Note that the top team, Numina, scored 29/50 on both the \"public\" and the \"private\" questions.</p>",
        "id": 448940186,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1720037526
    },
    {
        "content": "<p>It seems that the <a href=\"https://www.kaggle.com/competitions/ai-mathematical-olympiad-prize/leaderboard\">private leaderboard</a> is finally updated.  Most of the private scores are much lower than the corresponding public scores, except the winning team which was the winning team of the public leaderboard and still got 29/50 correct.  I look forward to learning about their method.  I am suspicious of the 2nd, 4th and 5th results.  Was that pure luck?  They didn’t even score in the top 100 on the public board as far as I can see, right?  (There were only 50 problems so randomness was very possibly a factor.)  Also it seems that <del>a number</del> (edit: one) of the top public leaderboard submissions crashed when run on the private leaderboard.  I feel sorry for them.  It is also sad that the second place public leaderboard team was disqualified.  I would have liked to see their method.</p>",
        "id": 448940207,
        "sender_full_name": "Jason Rute",
        "timestamp": 1720037529
    },
    {
        "content": "<p>Here is public to private for the top 5 public and top five private teams:</p>\n<div class=\"codehilite\" data-code-language=\"Text only\"><pre><span></span><code>Numina        1st public (29/50) -&gt; 1st private (29/50)\nMetaMath-AIMO 2nd public (28/50) -&gt; Disqualified?\nafter exams   3rd public (27/50) -&gt; 3rd private (22/50)\n[Deleted]     4th public (27/50) -&gt; Disqualified?\nZoltan        5th public (28/50) -&gt; 7th private (20/50)\n...\nZhiqing SUN 176th public (22/50) -&gt; 2nd private (22/50)\ncodeinter    90th public (23/50) -&gt; 4th private (21/50)\nConor #2    771st public (19/50) -&gt; 5th private (20/50)\n</code></pre></div>",
        "id": 448943749,
        "sender_full_name": "Jason Rute",
        "timestamp": 1720038561
    },
    {
        "content": "<p>The notebooks of the winner(s) will be made public, right?</p>",
        "id": 448944096,
        "sender_full_name": "Adam Topaz",
        "timestamp": 1720038686
    },
    {
        "content": "<p>According to <a href=\"https://x.com/JiaLi52524397/status/1808888071397507552\">this tweet</a> the champion team consists of the following members:</p>\n<blockquote>\n<p><a href=\"https://x.com/edwardbeeching\">Edward Beeching</a> <br>\n<a href=\"https://x.com/AlbertQJiang\">Albert Jiang</a> (on Zulip)<br>\n<a href=\"https://x.com/JiaLi52524397\">Jia Li</a><br>\n<a href=\"https://x.com/roman_soletskyi\">Roman Soletskyi</a> (on Zulip, never posted)<br>\n<a href=\"https://x.com/_lewtun\">Lewis Tunstall</a></p>\n</blockquote>\n<p>and founding members:</p>\n<blockquote>\n<p>Hélène Evain<br>\n<a href=\"https://x.com/yannfleureau\">Yann Fleureau</a><br>\n<a href=\"https://x.com/GuillaumeLample\">Guillaume Lample</a> (on Zulip)<br>\n<a href=\"https://x.com/spolu\">Stanislas Polu</a> (on Zulip)</p>\n</blockquote>\n<p>and sponsors:</p>\n<blockquote>\n<p>Hugging Face<br>\nMistral AI<br>\nAnswer AI<br>\nGeneral Catalyst</p>\n</blockquote>\n<p>Congratulations to all!</p>\n<p>See also:<br>\n<a href=\"https://x.com/_lewtun/status/1808917534646718793\">https://x.com/_lewtun/status/1808917534646718793</a><br>\n<a href=\"https://x.com/AlbertQJiang/status/1808903324625744162\">https://x.com/AlbertQJiang/status/1808903324625744162</a></p>",
        "id": 449207898,
        "sender_full_name": "Junyan Xu",
        "timestamp": 1720151123
    },
    {
        "content": "<p>A preview of the methodology:</p>\n<p><a href=\"https://x.com/_lewtun/status/1808898804822720769\">Lewis Tunstall</a>:</p>\n<blockquote>\n<p>fine-tuning open LLMs ... Our Numina Math 7B model ... Stay tuned - we will release the model, dataset, and methodology very soon!</p>\n</blockquote>\n<p><a href=\"https://x.com/edwardbeeching/status/1808945095565324296\">Edward Beeching</a>:</p>\n<blockquote>\n<p>We will be sharing the details of our method over the coming weeks. This will include open source models, training code and evaluation pipelines.<br>\nTree of Thoughts algorithm that interleaved generation with code execution and correction. ... an optimized and elegant solution to scale up to majority voting with 48 candidate solutions per problem.</p>\n</blockquote>\n<p><a href=\"/user_uploads/3121/ZxR8nNr2_72xI6hBrVT8chsy/GRqpX4mbMAYSdC5.jpeg\">GRqpX4mbMAYSdC5.jpeg</a></p>\n<div class=\"message_inline_image\"><a href=\"/user_uploads/3121/ZxR8nNr2_72xI6hBrVT8chsy/GRqpX4mbMAYSdC5.jpeg\" title=\"GRqpX4mbMAYSdC5.jpeg\"><img src=\"/user_uploads/3121/ZxR8nNr2_72xI6hBrVT8chsy/GRqpX4mbMAYSdC5.jpeg\"></a></div>",
        "id": 449208606,
        "sender_full_name": "Junyan Xu",
        "timestamp": 1720151665
    },
    {
        "content": "<p>Interesting!  I was telling someone recently that I doubted this Kaggle competition would attract serious research efforts because of all the onerous requirements (strict team limit of 5, can’t share code/data with anyone outside your team, limits on the models you can use, and strict open source requirements).  I thought it would only be a good measure of current methods.  So it is great to see that I am wrong and a serious research effort (with hopefully exciting new ideas) made it to the top place!  Congratulations!  I look forward to reading the solution!</p>",
        "id": 449406862,
        "sender_full_name": "Jason Rute",
        "timestamp": 1720218382
    },
    {
        "content": "<p><a href=\"https://huggingface.co/blog/winning-aimo-progress-prize\">https://huggingface.co/blog/winning-aimo-progress-prize</a></p>",
        "id": 451017973,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1720800246
    },
    {
        "content": "<blockquote>\n<p>If the computer is a bicycle for the mind, artificial intelligence is its engine</p>\n</blockquote>\n<p>I'm really old-fashioned... my bicycle doesn't have an engine <span aria-label=\"bicycle\" class=\"emoji emoji-1f6b2\" role=\"img\" title=\"bicycle\">:bicycle:</span> <span aria-label=\"rofl\" class=\"emoji emoji-1f923\" role=\"img\" title=\"rofl\">:rofl:</span></p>",
        "id": 451052992,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1720811280
    },
    {
        "content": "<p>One disadvantage of the scoring chosen by this competition is that it encourages a model to output a solution, even if it's wrong. In other words, the scoring system does not promote checking the correctness of the solution. To a human problem-solver it's usually easy to say: \"this I can do, but this is too difficult for me\". If negative scoring was introduced for wrong answers (but no negative score given to the \"I don't know\" answer), we could see competing teams adjust to this way of scoring, by e.g. including an additional machine learning model to check the correctness of reasoning (or maybe even translating the solution to lean!). If the model is not convinced it produced a correct solution, it could just output the \"I don't know\" answer (e.g. negative one, or something like this), to avoid losing points.</p>",
        "id": 451372154,
        "sender_full_name": "Adam Kurkiewicz",
        "timestamp": 1720980679
    },
    {
        "content": "<p>But of course, huge success by the winning team! 29/50 problems is really big!!! A few months ago my best guess would have been that top model will barely get a few answers right, if any at all!</p>",
        "id": 451372255,
        "sender_full_name": "Adam Kurkiewicz",
        "timestamp": 1720980779
    },
    {
        "content": "<p>I think it is a bit difficult to know how hard the test problems were.  They said (somewhere on Kaggle) that they were more diverse than the 10 public ones (which were on the harder end).  But still 29/50 does seem good given the baselines and other scores.  Also it is fun to directly play with their model here: <a href=\"https://huggingface.co/spaces/AI-MO/math-olympiad-solver\">https://huggingface.co/spaces/AI-MO/math-olympiad-solver</a> It’s a nice way to prove how good/bad it is without having to interpret the scores.</p>",
        "id": 451373543,
        "sender_full_name": "Jason Rute",
        "timestamp": 1720982260
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"111040\">Adam Kurkiewicz</span> <a href=\"#narrow/stream/208328-IMO-grand-challenge/topic/AI.20Math.20Olympiad.20Prize/near/451372154\">said</a>:</p>\n<blockquote>\n<p>One disadvantage of the scoring chosen by this competition is that it encourages a model to output a solution, even if it's wrong. In other words, the scoring system does not promote checking the correctness of the solution. To a human problem-solver it's usually easy to say: \"this I can do, but this is too difficult for me\". If negative scoring was introduced for wrong answers (but no negative score given to the \"I don't know\" answer), we could see competing teams adjust to this way of scoring, by e.g. including an additional machine learning model to check the correctness of reasoning (or maybe even translating the solution to lean!). If the model is not convinced it produced a correct solution, it could just output the \"I don't know\" answer (e.g. negative one, or something like this), to avoid losing points.</p>\n</blockquote>\n<p>Great point!</p>\n<p>This reminds me of the book \"How to Measure Anything.\" In chapter 5, \"Calibrated Estimates: How Much Do You Know Now?\", it introduces a subjective confidence level self-test. The author points out that most people are systematically overconfident, some are systematically underconfident, and very few people are naturally calibrated estimators. However, most people can be calibrated after mere hours of training. (I did the test myself and got a surprisingly poor result, then improved my estimation following the author's advice on calibration training.)</p>\n<p>When we encourage a model to output a solution even if it's wrong, we are indeed encouraging overconfident behavior in the model.</p>\n<p>If we can explicitly or implicitly extract the confidence level of the AI model, then we will be able to draw a 2D scatter chart with one dimension for the subjective confidence level of the model and the other dimension for the actual average score, grouped by subjective confidence level. If the model is perfectly calibrated, then we should see the 2D scatter chart resemble a perfect diagonal line. This means when the model believes it has 100% confidence, it should answer 100% of questions correctly, and when it believes it has 50% confidence, it should answer about 50% of questions correctly.</p>\n<p>Whether the confidence level of a model can be calibrated/fine-tuned, similar to how humans can be calibrated as shown in prior psychology research, would be an interesting research topic in itself. If a model's confidence level could be accurately calibrated, then in theory, we could use that information as a hint for expert routing, using the confidence level to identify the right expert for the right problem domain.</p>\n<p><a href=\"/user_uploads/3121/mGr_aXVqT_9p3YV1Y3X9gXoY/confidence-level.png\">confidence-level.png</a></p>\n<div class=\"message_inline_image\"><a href=\"/user_uploads/3121/mGr_aXVqT_9p3YV1Y3X9gXoY/confidence-level.png\" title=\"confidence-level.png\"><img src=\"/user_uploads/3121/mGr_aXVqT_9p3YV1Y3X9gXoY/confidence-level.png\"></a></div>",
        "id": 452007350,
        "sender_full_name": "Qian Hong",
        "timestamp": 1721208591
    },
    {
        "content": "<p>Now that this year's IMO is taking place/finished--is there a list anywhere of how many AI models entered into the challenge this year? I presume that grading will be later but would be good to see if/how many people threw their hat in the ring</p>",
        "id": 452233904,
        "sender_full_name": "Andy Jiang",
        "timestamp": 1721271567
    },
    {
        "content": "<p>I’m not sure aware of anything public.  It is possible Google/DeepMind or OpenAI has a secret thing going.  It also is interesting that Mathstral (by Minstral) was released right before the IMO.</p>",
        "id": 452236196,
        "sender_full_name": "Jason Rute",
        "timestamp": 1721272816
    },
    {
        "content": "<p>But to be clear, I’m not at IMO and not privy to any inside information.  Maybe those there know something I don’t.</p>",
        "id": 452241202,
        "sender_full_name": "Jason Rute",
        "timestamp": 1721275982
    },
    {
        "content": "<p>(not at the IMO) From what I hear, Deepmind is presenting AlphaGeometry at the moment. There'll be a presentation by Project Numina on the 1st progress-prize winning solution. It's not livestreamed afaik but hopefully recorded.</p>",
        "id": 452839403,
        "sender_full_name": "Albert Jiang",
        "timestamp": 1721482014
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"662620\">Andy Jiang</span> <a href=\"#narrow/stream/208328-IMO-grand-challenge/topic/AI.20Math.20Olympiad.20Prize/near/452233904\">said</a>:</p>\n<blockquote>\n<p>Now that this year's IMO is taking place/finished--is there a list anywhere of how many AI models entered into the challenge this year? I presume that grading will be later but would be good to see if/how many people threw their hat in the ring</p>\n</blockquote>\n<p>The questions are already out so the various teams can run their models on the questions on their own (and I bet many are and not just Google/OAI...).</p>",
        "id": 452918020,
        "sender_full_name": "Sid",
        "timestamp": 1721523529
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"246665\">Sid</span> <a href=\"#narrow/stream/208328-IMO-grand-challenge/topic/AI.20Math.20Olympiad.20Prize/near/452918020\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"662620\">Andy Jiang</span> <a href=\"#narrow/stream/208328-IMO-grand-challenge/topic/AI.20Math.20Olympiad.20Prize/near/452233904\">said</a>:</p>\n<blockquote>\n<p>Now that this year's IMO is taking place/finished--is there a list anywhere of how many AI models entered into the challenge this year? I presume that grading will be later but would be good to see if/how many people threw their hat in the ring</p>\n</blockquote>\n<p>The questions are already out so the various teams can run their models on the questions on their own (and I bet many are and not just Google/OAI...).</p>\n</blockquote>\n<p>I agree with this--just wondering if there was anything official this year or was it only the progress prize that was available this year. Is it correct to say that the main prize is not open yet this year? (otherwise I would guess some people would submit models for the judges to determine the score)</p>",
        "id": 453000314,
        "sender_full_name": "Andy Jiang",
        "timestamp": 1721576830
    },
    {
        "content": "<p>There was talk of some of the tech companies having a go this year but I'm pretty sure there was nothing submitted to AI-MO yet (indeed, there is nothing to submit to right now).</p>",
        "id": 453017031,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1721583951
    },
    {
        "content": "<p>Out of curiosity--what's the process for someone to submit to the actual AIMO? there doesn't seem to be an official method on the website, is it just like if you're a big company you can reach out otherwise you can't attempt it?</p>",
        "id": 453019534,
        "sender_full_name": "Andy Jiang",
        "timestamp": 1721585199
    },
    {
        "content": "<p>The AIMO announces competitions. For example they announced the progress prize which has just been won. The fund wants to encourage development of open source models which can win gold at IMO. This seems a bit optimistic right now, especially because big companies won't open source their models. There will no doubt be future progress prizes announced by the AIMO. [Disclaimer: I'm on the advisory committee]</p>",
        "id": 453025085,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1721587411
    },
    {
        "content": "<p>Given that there are some good open source models being released recently/in the near future (deepseek/ llama3) and the recent success of the AIMO progress team winner (whose Numina-72B model is claiming 12/30 on 2024 AIME) I don't think it's impossible that by next year even the open source models (especially those based in China with large funding like deepseek) can make a serious push for IMO gold.</p>",
        "id": 453032714,
        "sender_full_name": "Andy Jiang",
        "timestamp": 1721591705
    },
    {
        "content": "<p>I can certainly relay this to the people in charge. They are certainly going to be running other progress prizes but there are no details yet decided about what future prizes will look like.</p>",
        "id": 453040492,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1721596526
    },
    {
        "content": "<ol>\n<li>One big complaint I have for the setup of the progress prize is the severe limitation of the computational resource (GPU limit and time limit). This prevents people from using the larger, more capable models and essentially encourages hacking and overfitting the validation set. A clear evidence of this is that there were lots of solutions with &gt; 25 solutions on the public validation set and drop off to &lt;20 on the private test set. It would be great if the people in charge of setting up the future progress prizes can take this into account.</li>\n</ol>",
        "id": 453095535,
        "sender_full_name": "Albert Jiang",
        "timestamp": 1721630884
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"258175\">Albert Jiang</span> <a href=\"#narrow/stream/208328-IMO-grand-challenge/topic/AI.20Math.20Olympiad.20Prize/near/453095535\">said</a>:</p>\n<blockquote>\n<ol>\n<li>One big complaint I have for the setup of the progress prize is the severe limitation of the computational resource (GPU limit and time limit). This prevents people from using the larger, more capable models and essentially encourages hacking and overfitting the validation set. A clear evidence of this is that there were lots of solutions with &gt; 25 solutions on the public validation set and drop off to &lt;20 on the private test set. It would be great if the people in charge of setting up the future progress prizes can take this into account.</li>\n</ol>\n</blockquote>\n<p>This is a very important point. The difference between being able to solve in an hour versus a minute is far less fundamental than between being able to solve in an hour (or day) versus not at all. If I understand correctly, competitive programming is all about fast solutions where a solution in principle is not hard, which is not the case at all here.</p>",
        "id": 453121859,
        "sender_full_name": "Siddhartha Gadgil",
        "timestamp": 1721639035
    },
    {
        "content": "<p><a href=\"https://deepmind.google/discover/blog/ai-solves-imo-problems-at-silver-medal-level/\">https://deepmind.google/discover/blog/ai-solves-imo-problems-at-silver-medal-level/</a></p>",
        "id": 453982207,
        "sender_full_name": "Andy Jiang",
        "timestamp": 1721921958
    },
    {
        "content": "<p>I've made a thread about that <a href=\"#narrow/stream/219941-Machine-Learning-for-Theorem-Proving/topic/IMO.20results.20from.20Google.20DeepMind/near/453980266\">here</a></p>",
        "id": 453982853,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1721922170
    }
]