[
    {
        "content": "<p>Hey, I saw today's Quanta article about the IMO grand challenge. It sounds cool. I was wondering what the current status is - are there any teams working on an IMO problem solver with some work in progress? I'd be interested in helping out if there was some group open to outside contributors</p>",
        "id": 210802841,
        "sender_full_name": "Kevin Lacker",
        "timestamp": 1600723900
    },
    {
        "content": "<p>We are currently very interested in getting a nice collection of IMO problems formalised, both statements and proofs</p>",
        "id": 210805259,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1600725279
    },
    {
        "content": "<p>is there a repo of this stuff somewhere</p>",
        "id": 210805291,
        "sender_full_name": "Kevin Lacker",
        "timestamp": 1600725304
    },
    {
        "content": "<p>There are a couple of Olympiad problems formalised in mathlib</p>",
        "id": 210805376,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1600725359
    },
    {
        "content": "<p>is there a big list or is it like, the combinatorics ones are in the combinatorics directory, etc</p>",
        "id": 210805481,
        "sender_full_name": "Kevin Lacker",
        "timestamp": 1600725426
    },
    {
        "content": "<p><a href=\"https://github.com/leanprover-community/mathlib/blob/master/archive/imo1988_q6.lean\">https://github.com/leanprover-community/mathlib/blob/master/archive/imo1988_q6.lean</a></p>",
        "id": 210805508,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1600725450
    },
    {
        "content": "<p>There are very few</p>",
        "id": 210805514,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1600725454
    },
    {
        "content": "<p>It would be nice to start organising them like that</p>",
        "id": 210805538,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1600725468
    },
    {
        "content": "<p>They will all live in the archive directory</p>",
        "id": 210805551,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1600725479
    },
    {
        "content": "<p>src is for the standard maths library, this is entertainment</p>",
        "id": 210805614,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1600725504
    },
    {
        "content": "<p>i wonder what the very easiest IMO problem to formalize is...</p>",
        "id": 210805894,
        "sender_full_name": "Kevin Lacker",
        "timestamp": 1600725707
    },
    {
        "content": "<p>IMO 1972 b2 is quite easy and we chatted about its formalization in general a few weeks ago. I'll make a PR to add to to archive/</p>",
        "id": 210832546,
        "sender_full_name": "Stanislas Polu",
        "timestamp": 1600756858
    },
    {
        "content": "<p>Done here: <a href=\"https://github.com/leanprover-community/mathlib/pull/4209\">https://github.com/leanprover-community/mathlib/pull/4209</a></p>",
        "id": 210834330,
        "sender_full_name": "Stanislas Polu",
        "timestamp": 1600758522
    },
    {
        "content": "<p>For some problems that ask you to find a certain object (say IMO 2019 P1 &amp; P4), how would you write the statement in Lean?</p>",
        "id": 210854349,
        "sender_full_name": "Quang Dao",
        "timestamp": 1600772198
    },
    {
        "content": "<p>There has been quite some discussion about that (on this stream) without a satisfactory answer so far</p>",
        "id": 210854386,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1600772228
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"246591\">@Quang Dao</span> see <a href=\"#narrow/stream/208328-IMO-grand-challenge/topic/How.20to.20help.3F/near/175254384\">https://leanprover.zulipchat.com/#narrow/stream/208328-IMO-grand-challenge/topic/How.20to.20help.3F/near/175254384</a></p>",
        "id": 210854579,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1600772379
    },
    {
        "content": "<p>(took some time to find that discussion)</p>",
        "id": 210854590,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1600772389
    },
    {
        "content": "<p>thanks! this link from the discussion is now unusable: <a href=\"https://github.com/IMO-grand-challenge/formal-encoding/blob/master/design/determine.lean\">https://github.com/IMO-grand-challenge/formal-encoding/blob/master/design/determine.lean</a></p>",
        "id": 210855205,
        "sender_full_name": "Quang Dao",
        "timestamp": 1600772803
    },
    {
        "content": "<p>do you know where it has moved to?</p>",
        "id": 210855223,
        "sender_full_name": "Quang Dao",
        "timestamp": 1600772817
    },
    {
        "content": "<p>anyway, I'm trying to find simpler instances in Lean where the problem is \"find something\". Could you solve a polynomial equation (say a quadratic) in Lean?</p>",
        "id": 210855687,
        "sender_full_name": "Quang Dao",
        "timestamp": 1600773216
    },
    {
        "content": "<p>Reposting my list of \"find something\" answers of shortlisted problems 2006 -- 2018: <a href=\"http://www.olsak.net/mirek/determine-answers.txt\">http://www.olsak.net/mirek/determine-answers.txt</a></p>",
        "id": 210856199,
        "sender_full_name": "Miroslav Olšák",
        "timestamp": 1600773616
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"246591\">Quang Dao</span> <a href=\"#narrow/stream/208328-IMO-grand-challenge/topic/Current.20status.3F/near/210855205\">said</a>:</p>\n<blockquote>\n<p>thanks! this link from the discussion is now unusable: <a href=\"https://github.com/IMO-grand-challenge/formal-encoding/blob/master/design/determine.lean\">https://github.com/IMO-grand-challenge/formal-encoding/blob/master/design/determine.lean</a></p>\n</blockquote>\n<p><a href=\"https://gist.github.com/dselsam/da69f929de2d623b4a8b5d8ef8a278f9\">https://gist.github.com/dselsam/da69f929de2d623b4a8b5d8ef8a278f9</a></p>",
        "id": 210867561,
        "sender_full_name": "Daniel Selsam",
        "timestamp": 1600780433
    },
    {
        "content": "<p>What's the status of the IMO challenge??? What are some of the noteworthy attempts at solving it and what benchmarks have they set??</p>",
        "id": 320459370,
        "sender_full_name": "Lucas Teixeira",
        "timestamp": 1673359886
    },
    {
        "content": "<p>Nvm, I think this topic is more appropriate for <a class=\"stream\" data-stream-id=\"219941\" href=\"/#narrow/stream/219941-Machine-Learning-for-Theorem-Proving\">#Machine Learning for Theorem Proving</a></p>",
        "id": 320459925,
        "sender_full_name": "Lucas Teixeira",
        "timestamp": 1673360021
    },
    {
        "content": "<p>The IMO grand challenge has always seemed to me to be more of an idea than a concrete plan.  I suspect it won't start happening until a group has an AI which they think can do well on it.  Although there is a <a href=\"https://imo-grand-challenge.github.io/\">committee</a> so maybe it is active and I'm just not in the loop.  Nonetheless, there has been a lot of progress on the <a href=\"https://paperswithcode.com/sota/automated-theorem-proving-on-minif2f-test\">MiniF2F benchmark</a> which can be thought of as an easier version of the IMO grand challenge.</p>",
        "id": 320524853,
        "sender_full_name": "Jason Rute",
        "timestamp": 1673377751
    },
    {
        "content": "<p>In <a href=\"#narrow/stream/219941-Machine-Learning-for-Theorem-Proving/topic/Meta.20IMO.20result/near/312748505\">another thread</a> <span class=\"user-mention\" data-user-id=\"266253\">@Joseph Myers</span> (who is not on the IMO Grand Challenge committee but seems very interested in it) was trying to get it going.</p>",
        "id": 320528195,
        "sender_full_name": "Jason Rute",
        "timestamp": 1673378820
    },
    {
        "content": "<p>Just a thought: is it possible to set up something like the <a href=\"https://super.gluebenchmark.com/faq\">SuperGLUE</a> benchmark/leaderboard ...</p>",
        "id": 320528326,
        "sender_full_name": "Junyan Xu",
        "timestamp": 1673378862
    },
    {
        "content": "<p>I should also point out that a major premise of the IMO grand challenge is that for a computer to do well on the IMO (and for a human to trust the computer's solution) it has to give a formal proof.  Models like Minerva (and even ChatGPT) are starting to cast doubt on that assumption.  (Although models like Draft Sketch Prove  (<a class=\"stream-topic\" data-stream-id=\"219941\" href=\"/#narrow/stream/219941-Machine-Learning-for-Theorem-Proving/topic/More.20papers.20on.20autoformalization\">#Machine Learning for Theorem Proving &gt; More papers on autoformalization</a>)  also show the two approaches are quite compatible and systems which generate informal proofs and convert them to formal theorem proofs are a nice symbiosis.)</p>",
        "id": 320531844,
        "sender_full_name": "Jason Rute",
        "timestamp": 1673380031
    },
    {
        "content": "<p>Why do you say that even ChatGPT starts to cast doubt on that assumption?<br>\nIf anything, it has strengthened my belief that I'll only believe a computer-generated proof if it is formally verified. ChatGPT is way too good at bullshitting.</p>",
        "id": 320532510,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1673380243
    },
    {
        "content": "<p>Before Minerva, I was 99% sure the first computer solutions to the IMO grand challenge would be formal.  After, I'm 80% sure.  As for BS, the question is if that is a fundamental property of large language model applications, or if it can be fixed (without having to formalize everything in a formal system).</p>",
        "id": 320534064,
        "sender_full_name": "Jason Rute",
        "timestamp": 1673380757
    },
    {
        "content": "<p>(To be clear, I don't think ChatGPT itself, especially the current version, would do well.)</p>",
        "id": 320534494,
        "sender_full_name": "Jason Rute",
        "timestamp": 1673380882
    },
    {
        "content": "<p>(I thought I was posting in <a class=\"stream-topic\" data-stream-id=\"208328\" href=\"/#narrow/stream/208328-IMO-grand-challenge/topic/Current.20status.3F\">#IMO-grand-challenge &gt; Current status?</a> in response to a question asked there.  Sorry to resurrect this old thread.)</p>",
        "id": 320536711,
        "sender_full_name": "Jason Rute",
        "timestamp": 1673381737
    },
    {
        "content": "<p>5 messages were moved here from <a class=\"stream-topic\" data-stream-id=\"219941\" href=\"/#narrow/stream/219941-Machine-Learning-for-Theorem-Proving/topic/Meta.20IMO.20result\">#Machine Learning for Theorem Proving &gt; Meta IMO result</a> by <span class=\"user-mention silent\" data-user-id=\"112680\">Johan Commelin</span>.</p>",
        "id": 320539538,
        "sender_full_name": "Notification Bot",
        "timestamp": 1673382774
    },
    {
        "content": "<p>Pretty soon we should be able to translate most of minif2f to Lean 4.</p>",
        "id": 320546659,
        "sender_full_name": "David Renshaw",
        "timestamp": 1673385545
    },
    {
        "content": "<p>A key feature of the IMO Grand Challenge should be that it keeps entrants honest: (a) the problems are new, and entrants required to have finished their coding and training before the IMO, so they can't have learned from reading an informal solution to the same problem; (b) the marking criteria are as far as possible objective, public and such that marks for a solution can be independently verified without inside knowledge (they don't depend on the (non-public, not collected anywhere) mark schemes used for human solutions at the IMO, nor on having a common understanding of what somewhat vague natural language attempts do or do not count as sufficient for a complete solution worth full marks); (c) entrants make a public declaration in advance that they are entering, to avoid publication bias from only announcing results that sound good; (d) the formal statements are independently agreed before the competition to be an accurate translation of the informal statements.</p>\n<p>I don't think existing public claims of AI to have solved olympiad-like problems satisfy any of (a), (c) or (d), while it's not clear how informal-to-informal AI would manage (b) (at least it would need independent assessment of any claimed solutions by someone who was a coordinator on the relevant problem at the IMO).</p>",
        "id": 320566208,
        "sender_full_name": "Joseph Myers",
        "timestamp": 1673394270
    },
    {
        "content": "<p>I think something in the spirit of (b) is possible for informal-to-informal.  By the way, one reason that Daniel Selsam, the creator of the IMO grand challenge, didn't address the informal-to-informal part is that he thought this would so hard that he said he would resign if it happens (see section ML-topia in <a href=\"https://dselsam.github.io/IMO-GC-battle-of-ideas/\">his blog post</a>).  I don't know if he still thinks that, but I'd hate to think that a natural language solution is rejected just because it is in natural language.  (If like 2019 Daniel Selsam, one thinks that it is so impossible it is not worth planning for, I can respect that opinion.)</p>",
        "id": 320578641,
        "sender_full_name": "Jason Rute",
        "timestamp": 1673402010
    },
    {
        "content": "<p>I'm on the committee and as far as I know it's not active. I've been taking a great interest in Joseph's posts on how the technical details should work</p>",
        "id": 320648019,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1673427301
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"115715\">@Jason Rute</span> time will tell but fwiw I think formal is now the underdog -- and I <em>did</em> resign! I just got a new job :)</p>",
        "id": 320834276,
        "sender_full_name": "Daniel Selsam",
        "timestamp": 1673492180
    },
    {
        "content": "<blockquote>\n<p>I think formal is now the underdog </p>\n</blockquote>\n<p><span aria-label=\"open mouth\" class=\"emoji emoji-1f62e\" role=\"img\" title=\"open mouth\">:open_mouth:</span></p>",
        "id": 320840502,
        "sender_full_name": "David Renshaw",
        "timestamp": 1673494422
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"230999\">@Daniel Selsam</span> Congrats on the new job! (Mind telling us where/what?)</p>\n<p>What made you switch positions so that you now think formal is the underdog? Is there a big breakthrough that I missed?</p>",
        "id": 320869162,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1673508537
    },
    {
        "content": "<p>+1 pretty curious why formal is not a good approach?</p>",
        "id": 320917390,
        "sender_full_name": "fzyzcjy",
        "timestamp": 1673524018
    },
    {
        "content": "<p>You could do an autoformalization challenge on IMO problems: give the AI formal statements (easy-mode, i.e. answers for any \"determine\" problem included) for the problems of an IMO from after that AI was coded and trained <em>and</em> informal statements and solutions, and ask it to produce formal proofs of the provided formal statements based on the given informal proofs. My impression of the current state of AI is that this is a lot closer to working than producing full proofs of recent IMO problems from scratch (and that as discussed above, if an AI could produce a valid informal solution then it could be connected to an AI that produces a formal version from that).</p>",
        "id": 320925484,
        "sender_full_name": "Joseph Myers",
        "timestamp": 1673526520
    },
    {
        "content": "<p>The IMO Grand Challenge as originally stated, i.e. formal to formal, still strongly resonates with me. If that approach is now the underdog (or perhaps more charitably: is receiving less hype these days) well, then, all the more glory there will be when it arrives at the destination first. :P</p>",
        "id": 320928860,
        "sender_full_name": "David Renshaw",
        "timestamp": 1673527600
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"112680\">Johan Commelin</span> <a href=\"#narrow/stream/208328-IMO-grand-challenge/topic/Current.20status.3F/near/320869162\">said</a>:</p>\n<blockquote>\n<p>Is there a big breakthrough that I missed?</p>\n</blockquote>\n<p>No recent breakthroughs, but that is the whole point: the current models are the same models as a few years ago (which couldn't even produce coherent sentences) just bigger. </p>\n<ul>\n<li>scaling reliably lowers perplexity</li>\n<li>lowering perplexity reliably improves capabilities</li>\n<li>tons of runway left in compute &amp; data, + low-hanging algorithmic fruit everywhere</li>\n</ul>\n<p>I think formal is the underdog now for IMO because there is a lot of hard work humans would need to do and they are not strongly incentivized to do it, whereas informal gets to ride the scaling wave and will (I think) eventually fall as a side-effect. I agree with you that current models are nowhere near and think that if one did not know their history one would be right to dismiss them entirely -- however, I think this annoying extrapolation argument is actually very strong. We'll see.</p>",
        "id": 320970134,
        "sender_full_name": "Daniel Selsam",
        "timestamp": 1673538335
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"230999\">@Daniel Selsam</span> What do you think is the median year in which the challenge will be completed, if you don't mind my asking?</p>",
        "id": 320972864,
        "sender_full_name": "Bolton Bailey",
        "timestamp": 1673539016
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"230999\">@Daniel Selsam</span> <a href=\"#narrow/stream/208328-IMO-grand-challenge/topic/Current.20status.3F/near/320970134\">said</a>:</p>\n<blockquote>\n<p>I agree with you that current models are nowhere near and think that if one did not know their history one would be right to dismiss them entirely -- however, I think this annoying extrapolation argument is actually very strong. We'll see.</p>\n</blockquote>\n<p>There is a limit to the extrapolation argument. Right now the models are so big that only large companies can run the models and everyone else has to buy time on them. If they keep growing they will become national level artifacts. At some point it won't be worth their time to run some silly problem some researchers thought up about a math problem. This doesn't seem to be <em>scaling</em> to me in the sense that we aren't empowering everyone to do formal methods, we are centralizing and gatekeeping the tools because of the spectacular costs involved. It's not really a question of whether it is <em>possible</em> (well it is to some extent, but once we prove it is possible that won't be enough to keep the funding coming) - it is whether it is <em>economical</em>, and while you can handwave to some extent and say tech gets better and cheaper over time, the growth of ML models is <em>far</em> outpacing that growth.</p>",
        "id": 320982506,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1673541587
    },
    {
        "content": "<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"230999\">Daniel Selsam</span> I think formal is the underdog now for IMO because there is a lot of hard work humans would need to do and they are not strongly incentivized to do it</p>\n</blockquote>\n<p>I would appreciate it if I could know what are those hard work -  Do you mean deep learning algorithms and ideas, or the time-consuming work to formalize the whole math world?</p>",
        "id": 321056690,
        "sender_full_name": "fzyzcjy",
        "timestamp": 1673567459
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110049\">Mario Carneiro</span> <a href=\"#narrow/stream/208328-IMO-grand-challenge/topic/Current.20status.3F/near/320982506\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"230999\">Daniel Selsam</span> <a href=\"#narrow/stream/208328-IMO-grand-challenge/topic/Current.20status.3F/near/320970134\">said</a>:</p>\n<blockquote>\n<p>I agree with you that current models are nowhere near and think that if one did not know their history one would be right to dismiss them entirely -- however, I think this annoying extrapolation argument is actually very strong. We'll see.</p>\n</blockquote>\n<p>There is a limit to the extrapolation argument. Right now the models are so big that only large companies can run the models and everyone else has to buy time on them. If they keep growing they will become national level artifacts. At some point it won't be worth their time to run some silly problem some researchers thought up about a math problem. This doesn't seem to be <em>scaling</em> to me in the sense that we aren't empowering everyone to do formal methods, we are centralizing and gatekeeping the tools because of the spectacular costs involved. It's not really a question of whether it is <em>possible</em> (well it is to some extent, but once we prove it is possible that won't be enough to keep the funding coming) - it is whether it is <em>economical</em>, and while you can handwave to some extent and say tech gets better and cheaper over time, the growth of ML models is <em>far</em> outpacing that growth.</p>\n</blockquote>\n<p>The way I think of this issue is that large models are becoming utilities, like power plants. Very few companies/people will generate electricity, but many will make electrical appliances and most people will use them.</p>\n<p>The above holds provided \"prompt engineering\" and \"post processing\" will be enough to get good results from the huge models.</p>",
        "id": 321070435,
        "sender_full_name": "Siddhartha Gadgil",
        "timestamp": 1673575613
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"110049\">@Mario Carneiro</span> I think models like the <a href=\"https://twitter.com/timo_schick/status/1624058382142345216\">Toolformer</a> that <strong>offloads/outsources</strong> some capabilities to external (symbolic) tools will drive down at least the inference cost, if not the training cost as well. <a href=\"https://arxiv.org/pdf/2302.04761.pdf\">The paper</a> reports competitive zero-shot performance with much lower parameter count. (Langchain's <a href=\"https://arxiv.org/pdf/2205.00445.pdf\">MRKL systems</a> are also mentioned by many people in connection with it.) <a href=\"https://www.deepmind.com/blog/improving-language-models-by-retrieving-from-trillions-of-tokens\">RETRO</a> performs well on <strong>knowledge-intensive</strong> tasks with much lower parameter count, by retrieving from a database rather than a toolbox. And there are architecture innovations like <a href=\"https://github.com/BlinkDL/RWKV-LM\">RWKV-LM</a> that are less resource-intensive than transformers but may prove to be as powerful (they just released an RNN with 14B parameters).</p>\n<div class=\"inline-preview-twitter\"><div class=\"twitter-tweet\"><a href=\"https://twitter.com/timo_schick/status/1624058382142345216\"><img class=\"twitter-avatar\" src=\"https://uploads.zulipusercontent.net/2eac49831a92a217eed265f1e5adabb640a0434f/68747470733a2f2f7062732e7477696d672e636f6d2f70726f66696c655f696d616765732f313536343135333732353135363939303937372f586b6e6e635369795f6e6f726d616c2e706e67\"></a><p><span aria-label=\"tada\" class=\"emoji emoji-1f389\" role=\"img\" title=\"tada\">:tada:</span> New paper <span aria-label=\"tada\" class=\"emoji emoji-1f389\" role=\"img\" title=\"tada\">:tada:</span> Introducing the Toolformer, a language model that teaches itself to use various tools in a self-supervised way. This significantly improves zero-shot performance and enables it to outperform much larger models. <span aria-label=\"toolbox\" class=\"emoji emoji-1f9f0\" role=\"img\" title=\"toolbox\">:toolbox:</span>\n\n<span aria-label=\"link\" class=\"emoji emoji-1f517\" role=\"img\" title=\"link\">:link:</span> Link: <a href=\"https://t.co/FvjzhysMze\">http://arxiv.org/abs/2302.04761</a> <a href=\"https://t.co/sBSGaQIABI\">https://twitter.com/timo_schick/status/1624058382142345216/photo/1</a></p><span>- Timo Schick (@timo_schick)</span></div></div><p>Next-generation models may be trained to not just use tools, but also <strong>create tools</strong> and organize them into a codebase (think of long-term memory, or <strong>crystallized intelligence</strong>), and they're gonna read books and papers and grow mathlib for us automatically (auto-formalization). Being able to execute programs and observe outputs serves as a strong form of <strong>grounding</strong> (<a href=\"https://gist.github.com/cedrickchee/054956f6277430ae5a973c61e4a93073#natural-vs-curated-language-modeling\">Yoav Goldberg</a>, 5th paragraph), similar to formalization of mathematics. <a href=\"https://www.pnas.org/doi/abs/10.1073/pnas.2123433119\">Drori et al.'s PNAS paper</a> and <a href=\"https://arxiv.org/pdf/2211.10435.pdf\">Program-aided Language Models</a> from CMU already do <strong>program synthesis</strong> in Python, but do not store the programs and build upon them; as we know, to prove a big theorem, it's often necessary to have lots of intermediate lemmas in place.</p>\n<p>As the model <strong>continually learns</strong>, it might gradually <strong>optimize</strong> programs in its codebase (think of AlphaTensor), including other models it creates and stores there, so more efficient models could eventually emerge in the codebase and the original model could offload most of its capability to them, and we could just use the most efficient one. The original model probably need to be of <strong>adaptive computation time</strong> though, since otherwise offloading can't possibly save time even though it may improve accuracy. <a href=\"https://www.deepmind.com/blog/deepmind-ai-reduces-google-data-centre-cooling-bill-by-40\">Data center cooling</a> and <a href=\"https://ai.googleblog.com/2020/04/chip-design-with-deep-reinforcement.html\">chip design</a> are other places where a positive feedback loop for AI efficiency could be formed.</p>\n<p>ChatGPT has shown that <strong>reinforcement learning</strong> can be a very effective way of aligning language models to our purposes, and a codebase has a naturally associated dependency graph, which could potentially help with <strong>credit assignment</strong>, so actions that wrote the most popular functions/theorems in the codebase/library could be rewarded. As a bonus, <a href=\"https://cstheory.stackexchange.com/questions/50507/pagerank-in-directed-acyclic-graphs-dag\">PageRank is easy on a DAG</a>.</p>\n<p>I've written down some thoughts in <a href=\"https://twitter.com/Junyan_Xu/status/1617789258898759680\">this tweet thread</a> a few weeks ago but apparently I was talking into air <span aria-label=\"laughter tears\" class=\"emoji emoji-1f602\" role=\"img\" title=\"laughter tears\">:laughter_tears:</span> Are my ideas too crazy, or too well-known and already actively pursued in major labs <span class=\"user-mention\" data-user-id=\"514145\">@Geoffrey Irving</span> <span class=\"user-mention\" data-user-id=\"359917\">@Timothee Lacroix</span>? Or maybe I was just shadow-banned by Twitter. (Unfortunately it seems OpenAI's Lean paper authors have all left ...)</p>\n<div class=\"inline-preview-twitter\"><div class=\"twitter-tweet\"><a href=\"https://twitter.com/Junyan_Xu/status/1617789258898759680\"><img class=\"twitter-avatar\" src=\"https://uploads.zulipusercontent.net/7d0f41a7951a82cff4eb3a8b8fa7be4060781616/68747470733a2f2f7062732e7477696d672e636f6d2f70726f66696c655f696d616765732f313438343733333635343733313437323839382f6b364734426f48385f6e6f726d616c2e6a7067\"></a><p><a href=\"https://twitter.com/fchollet\">@fchollet</a> How about making LLM build a knowledge graph from scratch during training, keeping prediction accuracy as the main self-supervised training target but also including rewards for graph-building actions that lead to successful retrievals that improve accuracy? ...</p><span>- Junyan Xu (@Junyan_Xu)</span></div></div><p>I think these ideas overlap with those of <a href=\"https://arxiv.org/abs/2203.08913\">memorizing transformers</a> from <span class=\"user-mention\" data-user-id=\"240875\">@Yuhuai Tony Wu</span>, <span class=\"user-mention\" data-user-id=\"239426\">@Christian Szegedy</span>, et al. which use non-differentiable memory as well, but memory access is via kNN lookup of vector embeddings. Since LMs are supposed to good at languages, I think it's natural to let them establish and follow <strong>naming conventions</strong> to name the new concepts they invented, and interact with their memory via tokens, but I don't have the experience to judge which approach is more practical.</p>\n<p>As for <strong>democratization of access</strong>, I'm generally optimistic: I'm pretty impressed that I can now run Stable Diffusion (SD) to create 512x512 images <a href=\"https://github.com/cmdr2/stable-diffusion-ui\">with just 4GB VRAM</a> on my laptop. And it may not be difficult to adapt LMs to our particular purpose: for example, it now suffice to fine-tune only 3MB of the SD model's parameters on custom data, thanks to <a href=\"https://huggingface.co/blog/lora\">LoRA</a>. <strong><a href=\"https://open-assistant.io/\">Open Assistant</a></strong> is now crowd-sourcing training data to create a ChatGPT clone, and this paradigm of distributed data generation combined with centralized training could be traced back to Leela Zero / Leela Chess Zero. It's worth noting that people are building <a href=\"https://twitter.com/m_ryabinin/status/1625175933492641814\">distributed training infrastructure</a> as well, but it may take time to mature.</p>\n<div class=\"inline-preview-twitter\"><div class=\"twitter-tweet\"><a href=\"https://twitter.com/m_ryabinin/status/1625175933492641814\"><img class=\"twitter-avatar\" src=\"https://uploads.zulipusercontent.net/11b837d0d5668d2b12a462dd2170c35a155a7b04/68747470733a2f2f7062732e7477696d672e636f6d2f70726f66696c655f696d616765732f313331343838353939373832363538303438302f67476468314c59565f6e6f726d616c2e6a7067\"></a><p>We present SWARM, an efficient algorithm for model-parallel training across the Internet (e.g. with volunteers). \nKey advantages:\n<span aria-label=\"gem\" class=\"emoji emoji-1f48e\" role=\"img\" title=\"gem\">:gem:</span> Fault-tolerant\n<span aria-label=\"justice\" class=\"emoji emoji-2696\" role=\"img\" title=\"justice\">:justice:</span>️ Self-balancing on slow GPUs/networks\n<span aria-label=\"snail\" class=\"emoji emoji-1f40c\" role=\"img\" title=\"snail\">:snail:</span> Works in low-bandwidth setups\n\n<span aria-label=\"scroll\" class=\"emoji emoji-1f4dc\" role=\"img\" title=\"scroll\">:scroll:</span> <a href=\"https://t.co/wCnf6vDCv4\">https://arxiv.org/abs/2301.11913</a>\n<span aria-label=\"desktop computer\" class=\"emoji emoji-1f5a5\" role=\"img\" title=\"desktop computer\">:desktop_computer:</span>️ <a href=\"https://t.co/pVe0GDmfrK\">https://github.com/yandex-research/swarm</a> <a href=\"https://t.co/zUh7mzUwi8\">https://twitter.com/m_ryabinin/status/1625175933492641814/photo/1</a></p><span>- Max Ryabinin (@m_ryabinin)</span><div class=\"twitter-image\"><a href=\"https://t.co/zUh7mzUwi8\"><img src=\"https://uploads.zulipusercontent.net/02177588c9509663e18646d3ec39d21c1242f2a8/68747470733a2f2f7062732e7477696d672e636f6d2f6d656469612f466f3230527968616741416e4b57672e6a70673a736d616c6c\"></a></div></div></div><p><strong><a href=\"https://en.wikipedia.org/wiki/Volunteer_computing\">Volunteer computing</a></strong> has a long history and people have donated massive amounts of compute to projects like GIMPS (Mersenne prime search), or <a href=\"https://github.com/glinscott/fishtest#readme\">Fishtest</a>, and through BOINC. So it's just a matter of <strong>popularizing mathematics</strong> to get more computing resources directed to mathlib. When AI is capable of creating new mathematics, it will draw even more volunteer resources: it's much more exciting to see long-standing conjectures being solved than seeing Elo rating keeps improving monotonically (pun intended). Considering how fast LMs can turn natural language into code and vice versa (already useful in reverse engineering), I think the <strong>formal-informal gap</strong> could be fairly small for machines.</p>\n<p>Time is on our side. Conversational LMs will <strong>revolutionize education</strong>, and people around the world will get equal access to the most sophisticated mathematical ideas. Advanced mathematics will come out of brains of geniuses and ivory towers and reach more people than ever. (mathlib is already democratizing access to every detail for every proof and definition in it, which you don't normally get in textbooks, and LMs will be able to parse and summarize the Lean code and explain the big picture.) As automation progresses and people work less hours, they will have more spare time to devote to mathematics, among other means of entertainment. Gladly, Microsoft's CEO seems to <a href=\"https://youtu.be/UNbyT7wPwk4?t=989\">share the same vision</a>:</p>\n<div class=\"youtube-video message_inline_image\"><a data-id=\"UNbyT7wPwk4\" href=\"https://youtu.be/UNbyT7wPwk4?t=989\"><img src=\"https://uploads.zulipusercontent.net/d4175226c2f0808c1f0bb6dca85efcf6a46a2ec6/68747470733a2f2f692e7974696d672e636f6d2f76692f554e627954377750776b342f64656661756c742e6a7067\"></a></div><blockquote>\n<p>Do we need to learn math anymore? Why learn math?<br>\nLemme tell you, I'm an electrical engineer who never understood the Maxwell's equations. So now I finally get, thanks to ChatGPT, a better understanding of it. So I think one of the things is we will all enjoy a lot more math because we will have that personalized tutor who will, in fact, be able to intervene at the crucial time when you're making a conceptual mistake and help you learn. So just imagine that, just Matt, what if there was a fantastic tutor teacher for every student learning math going forward, that is now possible.</p>\n</blockquote>\n<p>Exciting times are ahead!</p>\n<p>(Mandatory disclaimer: ChatGPT did not engage in the writing of this essay.)</p>",
        "id": 327700013,
        "sender_full_name": "Junyan Xu",
        "timestamp": 1676356101
    },
    {
        "content": "<p>The above post is being updated <a href=\"https://github.com/alreadydone/contents/issues/3#issuecomment-1484009563\">here</a> with latest developments. Many tools look helpful to mathlib development, but I haven't formed an actionable plan to combine them in the best way. Meanwhile, <span class=\"user-mention\" data-user-id=\"110087\">@Scott Morrison</span> has already built something like ReAct over at the <a href=\"#narrow/stream/219941-Machine-Learning-for-Theorem-Proving/topic/GPT\">GPT thread</a>.</p>",
        "id": 344609049,
        "sender_full_name": "Junyan Xu",
        "timestamp": 1679816738
    },
    {
        "content": "<p><a href=\"https://www.lesswrong.com/posts/sHcHriEoJAGcRt3oC/i-bet-usd500-on-ai-winning-the-imo-gold-medal-by-2026\">https://www.lesswrong.com/posts/sHcHriEoJAGcRt3oC/i-bet-usd500-on-ai-winning-the-imo-gold-medal-by-2026</a></p>",
        "id": 365432401,
        "sender_full_name": "Junyan Xu",
        "timestamp": 1686542691
    },
    {
        "content": "<p><a href=\"https://twitter.com/azsantosk/status/1655998142544846865\">https://twitter.com/azsantosk/status/1655998142544846865</a></p>\n<blockquote>\n<p>(excluding open-source, I don't want to encourage that)</p>\n</blockquote>\n<p>Wow. It feels disorienting to hear this kind of attitude.</p>",
        "id": 365571192,
        "sender_full_name": "David Renshaw",
        "timestamp": 1686578066
    },
    {
        "content": "<p>Is that person who doesn't want open-source AI coming from the existential risk school of AI alignment?</p>",
        "id": 365707412,
        "sender_full_name": "Joseph Myers",
        "timestamp": 1686615840
    },
    {
        "content": "<p>That was my understanding of the statement.</p>",
        "id": 365708445,
        "sender_full_name": "Scott Morrison",
        "timestamp": 1686616391
    },
    {
        "content": "<p>One of the coordinators at IMO 2023 asked ChatGPT to solve problem 1 (i.e., informal-to-informal) and posted the results on the internal coordinator Discord. ChatGPT produced a load of nonsense, not even guessing the right answer (prime powers). I suspect that's more representative of what current AI can actually do on current IMO problems at present than the misleading hype we sometimes see.</p>",
        "id": 375640162,
        "sender_full_name": "Joseph Myers",
        "timestamp": 1689464188
    },
    {
        "content": "<p>On one hand, I’m not sure ChatGPT used naively (especially without a systematic feedback and filtering strategy), is really the state of the art on IMO problems.  On the other hand, I’m not sure that any state of the art system would do much better at the moment (especially since no one has taken up the challenge so far).</p>",
        "id": 375656473,
        "sender_full_name": "Jason Rute",
        "timestamp": 1689473505
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"115715\">Jason Rute</span> <a href=\"#narrow/stream/208328-IMO-grand-challenge/topic/Current.20status.3F/near/375656473\">said</a>:</p>\n<blockquote>\n<p>On one hand, I’m not sure ChatGPT used naively (especially without a systematic feedback and filtering strategy), is really the state of the art on IMO problems.  On the other hand, I’m not sure that any state of the art system would do much better at the moment (especially since no one has taken up the challenge so far).</p>\n</blockquote>\n<p>I suspect the method in <a href=\"https://arxiv.org/abs/2305.20050\">\"Let's Verify Step by Step\"</a> would generate something that isn't nonsense  some of the time and would be able to catch nonsense solutions.</p>\n<p>I also suspect oai might've nerfed the results in the paper for publication, as the industry labs are rumored to be doing.</p>",
        "id": 376392470,
        "sender_full_name": "Zhangir Azerbayev",
        "timestamp": 1689694417
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"284997\">Zhangir Azerbayev</span> <a href=\"#narrow/stream/208328-IMO-grand-challenge/topic/Current.20status.3F/near/376392470\">said</a>:</p>\n<blockquote>\n<p>I also suspect oai might've nerfed the results in the paper for publication, as the industry labs are rumored to be doing.</p>\n</blockquote>\n<p>Could you explain what you mean by this? What does it mean to nerf the results, and what is the incentive to do so?</p>",
        "id": 376397330,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1689695343
    },
    {
        "content": "<p>By \"the paper for publication\" you mean LVSbS?</p>",
        "id": 376398813,
        "sender_full_name": "Jason Rute",
        "timestamp": 1689695622
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110049\">Mario Carneiro</span> <a href=\"#narrow/stream/208328-IMO-grand-challenge/topic/Current.20status.3F/near/376397330\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"284997\">Zhangir Azerbayev</span> <a href=\"#narrow/stream/208328-IMO-grand-challenge/topic/Current.20status.3F/near/376392470\">said</a>:</p>\n<blockquote>\n<p>I also suspect oai might've nerfed the results in the paper for publication, as the industry labs are rumored to be doing.</p>\n</blockquote>\n<p>Could you explain what you mean by this? What does it mean to nerf the results, and what is the incentive to do so?</p>\n</blockquote>\n<p>The industry labs don't publish their best innovations anymore for competitive and safety reasons. Given this fact, it's not implausible that some of the publications that do come out don't include all the researcher's finding. </p>\n<p>There are two things that jump out at me as natural ways to improve LVSbS: namely finetuning the model for more than just 1.5B tokens of mathematical text and doing reinforcement learning using the verifier. But there's also a good chance I'm just being paranoid and these two things simply didn't work or the team didn't have time to implement them.</p>",
        "id": 376715910,
        "sender_full_name": "Zhangir Azerbayev",
        "timestamp": 1689782096
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"115715\">Jason Rute</span> <a href=\"#narrow/stream/208328-IMO-grand-challenge/topic/Current.20status.3F/near/376398813\">said</a>:</p>\n<blockquote>\n<p>By \"the paper for publication\" you mean LVSbS?</p>\n</blockquote>\n<p>Yes.</p>",
        "id": 376715975,
        "sender_full_name": "Zhangir Azerbayev",
        "timestamp": 1689782106
    },
    {
        "content": "<p>Is anybody here working on this at the moment?</p>",
        "id": 382438886,
        "sender_full_name": "Aren Güralp",
        "timestamp": 1691354743
    },
    {
        "content": "<p>I’d be surprised if anyone admits as much.  A number of people are working on AI in both formal and informal theorem proving, including the MiniF2F benchmark which contains old Olympiad problems, but I don’t know of anyone publicly working on preparing for the 2024 IMO (and I don’t think the IMO Grand Challenge committee has done anything in years).  I know some people want to force there to be a competition sooner rather than later even if all the entrants do terribly, but at the same time I can’t imagine anyone stepping forward to compete unless they think they can get a non-zero score.</p>",
        "id": 382449630,
        "sender_full_name": "Jason Rute",
        "timestamp": 1691361844
    },
    {
        "content": "<p>I think a different competition filled with a range of problem difficulties would be better but no one is talking about organizing that, and I don’t claim it would be easy to organize since one still has to come up with problems, rules, and entrants.</p>",
        "id": 382449651,
        "sender_full_name": "Jason Rute",
        "timestamp": 1691361866
    },
    {
        "content": "<p>I can confirm that the IMO Grand Challenge committee has not done anything in years. Is there anything in particular that you want us to do? The only thing I thought of was summarising some of Joseph Myers' excellent posts about the practicalities of the grand challenge, but I half-wondered whether less is more.</p>",
        "id": 382449790,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1691361988
    },
    {
        "content": "<p>I still have a long-term interest in the challenge, though somewhat backburnered at the moment.</p>",
        "id": 382450987,
        "sender_full_name": "David Renshaw",
        "timestamp": 1691363004
    },
    {
        "content": "<p>Could the committee encourage or be involved in producing \"mathematician endorsed\" benchmarks that would allow reporting on intermediate progress towards IMO automation?</p>",
        "id": 382471917,
        "sender_full_name": "Scott Morrison",
        "timestamp": 1691373126
    },
    {
        "content": "<p>Another question to ask is how an attempt would even take place- it's not as if every IMO comes with formalized versions of its problems. Could the committee contribute to progress on the challenge by producing \"official\" formalizations of IMO problems/solutions for past years and each passing year?</p>",
        "id": 382473842,
        "sender_full_name": "Aren Güralp",
        "timestamp": 1691373937
    },
    {
        "content": "<p>I would presume that the committee is not inclined to produce official solutions. There are many formalised solutions in the <code>Archive/IMO/</code> directory of the Mathlib repository.</p>",
        "id": 382485106,
        "sender_full_name": "Scott Morrison",
        "timestamp": 1691379227
    },
    {
        "content": "<p>\"Official\" formalised statements for at least the last few years is an excellent question, however!</p>",
        "id": 382485253,
        "sender_full_name": "Scott Morrison",
        "timestamp": 1691379277
    },
    {
        "content": "<p>And formulating a plan to generate formalisations of the new problems each year as quickly as possible after the IMO might be useful too!</p>",
        "id": 382485355,
        "sender_full_name": "Scott Morrison",
        "timestamp": 1691379323
    },
    {
        "content": "<p>I started a new thread about automated theorem proving competitions in general since I think the discussion here shows some interest in this topic: <a class=\"stream-topic\" data-stream-id=\"219941\" href=\"/#narrow/stream/219941-Machine-Learning-for-Theorem-Proving/topic/Automatic.20Theorem.20Proving.20Competitions\">#Machine Learning for Theorem Proving &gt; Automatic Theorem Proving Competitions</a> I don't have any concrete answers but it would be nice to think more about this topic in general, not just in the context of the IMO Grand Challenge.</p>",
        "id": 383113286,
        "sender_full_name": "Jason Rute",
        "timestamp": 1691542886
    },
    {
        "content": "<p>Dear the IMO Grand Challenge committee, </p>\n<p>I'm contemplating entering the IMO 2024 challenge but with Isabelle/HOL. Would the committee be open to the following approach?</p>\n<ol>\n<li>I'll submit my enhanced Isabelle extension tailored for IMO problems to the committee before the start of IMO2024.</li>\n<li>The IMO2024 challenge takes place.</li>\n<li>After the challenge, I'll formalize the year's IMO problems using Isabelle/HOL.</li>\n<li>Next, I'll evaluate how effectively my tool addresses these problems.</li>\n<li>If successful, I'll share the results with the committee for validation.</li>\n<li>It's important to emphasize that I'd like to formalize the problems myself. The complexity in the proof search can shift dramatically depending on their framing in Isabelle/HOL.</li>\n</ol>\n<p>For the record, I don't expect to lean heavily on extensive computational power or unique hardware for the proof search. I assume this won't pose any concerns.</p>\n<p>Regards,<br>\nYutaka</p>",
        "id": 388204398,
        "sender_full_name": "Yutaka Nagashima",
        "timestamp": 1693433667
    },
    {
        "content": "<p>It would be nice to know your full name but as far as I'm concerned anything goes right now when it comes to how this will actually work.</p>",
        "id": 388208199,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1693435782
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"644409\">@Yutaka</span> that sounds great. I imagine that the way things will get jump started on the Lean side is when someone does basically those same steps, but for Lean.</p>",
        "id": 388208873,
        "sender_full_name": "David Renshaw",
        "timestamp": 1693436202
    },
    {
        "content": "<blockquote>\n<p>If successful, I'll share the results with the committee for validation.</p>\n</blockquote>\n<p>sharing unsuccessful results is also good and interesting!</p>",
        "id": 388208963,
        "sender_full_name": "David Renshaw",
        "timestamp": 1693436273
    },
    {
        "content": "<p>(I am not on any official committee, but my impression is that there has not been much central coordination for the IMO Grand Challenge since its inception, except for what can be found in this Zulip channel. )</p>",
        "id": 388209648,
        "sender_full_name": "David Renshaw",
        "timestamp": 1693436596
    },
    {
        "content": "<p>Hi, <span class=\"user-mention\" data-user-id=\"644409\">@Yutaka</span> , have you tried your system on any previous IMO problems? I am curious what your system can do. The induction tactics I have seen (if you are the Yutaka I know) were quite impressive but I would be afraid that it is still rather far from IMO level...</p>",
        "id": 388209663,
        "sender_full_name": "Miroslav Olšák",
        "timestamp": 1693436611
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110038\">Kevin Buzzard</span> <a href=\"#narrow/stream/208328-IMO-grand-challenge/topic/Current.20status.3F/near/388208199\">said</a>:</p>\n<blockquote>\n<p>It would be nice to know your full name but as far as I'm concerned anything goes right now when it comes to how this will actually work.</p>\n</blockquote>\n<p>Hi, sorry, that was my first or second post to Zulipchat. And I am still learning how to use this.<br>\nI think now my profile shows my full name.</p>",
        "id": 388210132,
        "sender_full_name": "Yutaka Nagashima",
        "timestamp": 1693436895
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"243791\">David Renshaw</span> <a href=\"#narrow/stream/208328-IMO-grand-challenge/topic/Current.20status.3F/near/388209648\">said</a>:</p>\n<blockquote>\n<p>(I am not on any official committee, but my impression is that there has not been much central coordination for the IMO Grand Challenge since its inception, except for what can be found in this Zulip channel. )</p>\n</blockquote>\n<p>Perhaps things will change when someone solves a problem, making the prospect of winning a gold medal seem more attainable.</p>",
        "id": 388210323,
        "sender_full_name": "Yutaka Nagashima",
        "timestamp": 1693437043
    },
    {
        "content": "<p>You should publish your proposed formalization conventions for how IMO problem statements are translated from English to Isabelle/HOL before the IMO. I expect that would include things such as choices of types (IMO problem statements are happy to e.g. use subtraction or division on natural numbers when a formal statement might need to be more explicit about the type of the result of such an operation) and exactly how particular phrases in an IMO problem are interpreted as implying or not implying nondegeneracy conditions (that's mainly for geometry, but also e.g. if a problem involves division it should probably be taken as including a requirement that there is no division by zero), and how the statement presented to your solver should indicate the result to be proved and any data to be provided for \"determine\" problems.</p>\n<p>To avoid publication bias, you should also commit to announce your results whether or not your solver manages to solve any problems.</p>",
        "id": 388211697,
        "sender_full_name": "Joseph Myers",
        "timestamp": 1693438083
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"133339\">Miroslav Olšák</span> <a href=\"#narrow/stream/208328-IMO-grand-challenge/topic/Current.20status.3F/near/388209663\">said</a>:</p>\n<blockquote>\n<p>Hi, @_<strong>Yutaka</strong> , have you tried your system on any previous IMO problems? I am curious what your system can do. The induction tactics I have seen (if you are the Yutaka I know) were quite impressive but I would be afraid that it is still rather far from IMO level...</p>\n</blockquote>\n<p>Yes, I'm Yutaka from Prague, among other places.</p>\n<p>I've yet to test my system against IMO problems, and I anticipate that there's room for improvement in the initial results.</p>\n<p>I've recently upgraded the induction prover using an abduction graph (<a href=\"https://youtu.be/d7IXk0vB2p0?t=120\">https://youtu.be/d7IXk0vB2p0?t=120</a>) enabling it to autonomously identify beneficial conjectures.</p>\n<div class=\"youtube-video message_inline_image\"><a data-id=\"d7IXk0vB2p0\" href=\"https://youtu.be/d7IXk0vB2p0?t=120\"><img src=\"https://uploads.zulipusercontent.net/a78e12825473e44f3a1e9d5b35b210e8ce8e8e9c/68747470733a2f2f692e7974696d672e636f6d2f76692f643749586b3076423270302f64656661756c742e6a7067\"></a></div><p>In the coming months, I'm set on infusing it with more intelligence and introducing domain-specific heuristics crafted for IMO challenges. <br>\nMy hope is that by the summer of 2024, solving one of the IMO problems of that year will become a feasible goal.</p>",
        "id": 388211755,
        "sender_full_name": "Yutaka Nagashima",
        "timestamp": 1693438103
    },
    {
        "content": "<p>Oh hi you are the Yutaka I was expecting/hoping :-) Yeah I think that right now IMO is too hard for any system which is why I'm not too fussed about protocol but I think Joseph makes some good points. Do you have any thoughts about how to translate questions of the form \"work out the number x\"?</p>",
        "id": 388212204,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1693438390
    },
    {
        "content": "<p>Hi <span class=\"user-mention\" data-user-id=\"644409\">@Yutaka Nagashima</span> !  I'm familiar with some of your previous work.  You started doing neural theorem proving for Isabelle, before it was fashionable. <span aria-label=\"smile\" class=\"emoji emoji-1f642\" role=\"img\" title=\"smile\">:smile:</span>  However, I'm curious if you know about the PISA and MiniF2F benchmarks.  <a href=\"https://github.com/albertqjiang/Portal-to-ISAbelle\">PISA</a> is a benchmark of Isabelle/HOL theorems.  <a href=\"https://github.com/facebookresearch/miniF2F\">MiniF2F</a> is a benchmark of competition problems ranging from easy to IMO problems (in many languages including Isabelle/HOL).  I think you should really consider testing your system on MiniF2F (and PISA if possible) to see how well it does.  That might give you a sense how close your system is to being able to compete in IMO (and solve a problem or two).  Also, benchmarks in general are a good way to compare progress.  For example, do you think your system has a lot of progress over other Isabelle systems like SledgeHammer, Thor, Draft-Sketch-Prove, Baldur, MagnusHammer, \"Decomposing the Enigma\", and others?  <span class=\"user-mention\" data-user-id=\"258175\">@Albert Jiang</span> and <span class=\"user-mention\" data-user-id=\"384425\">@Wenda Li</span> (also at Cambridge) would be good people to talk to about setting up a benchmark.</p>",
        "id": 388324558,
        "sender_full_name": "Jason Rute",
        "timestamp": 1693488489
    },
    {
        "content": "<p>Along those lines does the system in your video have a paper associated with it?</p>",
        "id": 388324580,
        "sender_full_name": "Jason Rute",
        "timestamp": 1693488496
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"266253\">Joseph Myers</span> <a href=\"#narrow/stream/208328-IMO-grand-challenge/topic/Current.20status.3F/near/388211697\">said</a>:</p>\n<blockquote>\n<p>You should publish your proposed formalization conventions for how IMO problem statements are translated from English to Isabelle/HOL before the IMO. I expect that would include things such as choices of types (IMO problem statements are happy to e.g. use subtraction or division on natural numbers when a formal statement might need to be more explicit about the type of the result of such an operation) and exactly how particular phrases in an IMO problem are interpreted as implying or not implying nondegeneracy conditions (that's mainly for geometry, but also e.g. if a problem involves division it should probably be taken as including a requirement that there is no division by zero), and how the statement presented to your solver should indicate the result to be proved and any data to be provided for \"determine\" problems.</p>\n</blockquote>\n<p>Yes, I can declare which types I use in advance. I will likely use the standard types provided by Isabelle for numerical problems. I don't think using the types in the standard library would cause serious concerns regarding the integrity of the formalization. If there were, mathematicians wouldn't use Isabelle.</p>\n<p>For my 2024 projects, I am planning to skip geometry. At least by myself, it seems harder to formalize the geometry problems in Isabelle.</p>\n<p>It would be nice to know a list of typical controversial English expressions used in IMO problems, which cause confusion when formalizing those problems.</p>\n<blockquote>\n<p>To avoid publication bias, you should also commit to announce your results whether or not your solver manages to solve any problems.</p>\n</blockquote>\n<p>Yes. That’s right.</p>",
        "id": 388406091,
        "sender_full_name": "Yutaka Nagashima",
        "timestamp": 1693516051
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110038\">Kevin Buzzard</span> <a href=\"#narrow/stream/208328-IMO-grand-challenge/topic/Current.20status.3F/near/388212204\">said</a>:</p>\n<blockquote>\n<p>Oh hi you are the Yutaka I was expecting/hoping :-) Yeah I think that right now IMO is too hard for any system which is why I'm not too fussed about protocol but I think Joseph makes some good points. Do you have any thoughts about how to translate questions of the form \"work out the number x\"?</p>\n</blockquote>\n<p>I believe “work out the number x” means “find the number x (that satisfies certain conditions specified in the problem)” in English.</p>\n<p>I think that is equivalent to proving “there exists x, such that …”?</p>\n<p>Then, to prove the theorem, a prover must at least internally know what “x” is.</p>\n<p>My proof would likely refer explicitly to the value of “x” unless finding that value is trivial for existing tools.</p>\n<p>For example, Isabelle can prove \"∃x. x\" using the “auto” tactic. So, my proof wouldn't explicitly state “x=True”, but Isabelle's proof checker should recognize that it proves this theorem by instantiating “x” as True.</p>\n<p>For more challenging problems, we have to provide instances explicitly, and we can probably see them in the proof scripts.</p>",
        "id": 388408433,
        "sender_full_name": "Yutaka Nagashima",
        "timestamp": 1693517218
    },
    {
        "content": "<p>No, \"find <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>x</mi></mrow><annotation encoding=\"application/x-tex\">x</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.4306em;\"></span><span class=\"mord mathnormal\">x</span></span></span></span>\" and \"prove that <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>x</mi></mrow><annotation encoding=\"application/x-tex\">x</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.4306em;\"></span><span class=\"mord mathnormal\">x</span></span></span></span> exists\" are two different problems.</p>",
        "id": 388408918,
        "sender_full_name": "Yury G. Kudryashov",
        "timestamp": 1693517462
    },
    {
        "content": "<p>E.g., \"how many roots has the following equation?\"</p>",
        "id": 388408966,
        "sender_full_name": "Yury G. Kudryashov",
        "timestamp": 1693517481
    },
    {
        "content": "<p>Or \"how many weighings does one need to find the bad coin?\"</p>",
        "id": 388409090,
        "sender_full_name": "Yury G. Kudryashov",
        "timestamp": 1693517524
    },
    {
        "content": "<p>To be more specific, what do you expect as input and output for <a href=\"https://artofproblemsolving.com/wiki/index.php/2023_IMO_Problems/Problem_1\">https://artofproblemsolving.com/wiki/index.php/2023_IMO_Problems/Problem_1</a> ?</p>",
        "id": 388409237,
        "sender_full_name": "Yury G. Kudryashov",
        "timestamp": 1693517615
    },
    {
        "content": "<p>Surely the type of the output for that problem needs to be a sigma type, with the first element being a function <code>(n : ℕ) → composite n → Bool</code>, and the second an iff proof relating that condition to the condition in the statement.</p>\n<p>Scoring well is not just an inhabitation of this type (which one could do trivially because the condition in the statement is decidable, and hence has a coercion to Bool), but an inhabitation for which the first component is \"obviously\" \"n = p^x for some prime p and x ≥ 2\". </p>\n<p>As far as I understand, the GC committee have never specified whether \"obviously\" here consists of a human inspecting the term after \"submission\" or some allowed step of automation (aesop?) to compare with the standard answer.</p>\n<p>(I feel like everyone has already acknowledged that IMO problems do not reduce to inhabitations of specified types, but keeps avoiding this issue?)</p>",
        "id": 388413420,
        "sender_full_name": "Scott Morrison",
        "timestamp": 1693519881
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"214703\">Yury G. Kudryashov</span> <a href=\"#narrow/stream/208328-IMO-grand-challenge/topic/Current.20status.3F/near/388408918\">said</a>:</p>\n<blockquote>\n<p>No, \"find <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>x</mi></mrow><annotation encoding=\"application/x-tex\">x</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.4306em;\"></span><span class=\"mord mathnormal\">x</span></span></span></span>\" and \"prove that <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>x</mi></mrow><annotation encoding=\"application/x-tex\">x</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.4306em;\"></span><span class=\"mord mathnormal\">x</span></span></span></span> exists\" are two different problems.</p>\n</blockquote>\n<p>Thanks. I struggle with variables that are not bound explicitly.<br>\nI should not have written \"is equivalent to\".<br>\nBut how about \"implies\"?</p>\n<p>Does proving \"there exists x, such that...\" imply \"finding x such that...\"?</p>",
        "id": 388413980,
        "sender_full_name": "Yutaka Nagashima",
        "timestamp": 1693520211
    },
    {
        "content": "<p>No, this is not enough.</p>",
        "id": 388414034,
        "sender_full_name": "Scott Morrison",
        "timestamp": 1693520251
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"644409\">Yutaka Nagashima</span> <a href=\"#narrow/stream/208328-IMO-grand-challenge/topic/Current.20status.3F/near/388406091\">said</a>:</p>\n<blockquote>\n<p>Yes, I can declare which types I use in advance. I will likely use the standard types provided by Isabelle for numerical problems. I don't think using the types in the standard library would cause serious concerns regarding the integrity of the formalization. If there were, mathematicians wouldn't use Isabelle.</p>\n</blockquote>\n<p>Using standard types is entirely appropriate, but in Lean, for example, if a problem says something is a positive integer, there is a choice to be made between <code>ℕ</code>, <code>ℤ</code> and <code>ℕ+</code>, which is not a distinction that needs considering in informal mathematics, and if the choice made is <code>ℕ</code>, then you need to convert to <code>ℤ</code> for subtraction (or at least for subtraction that might have a negative result) since IMO problems definitely aren't discussing truncating subtraction, and much the same applies for division. I don't know how Isabelle handles these sorts of issues, but looking at past problems may help you establish rules for choices of types in expressions like that.</p>",
        "id": 388414197,
        "sender_full_name": "Joseph Myers",
        "timestamp": 1693520333
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"214703\">Yury G. Kudryashov</span> <a href=\"#narrow/stream/208328-IMO-grand-challenge/topic/Current.20status.3F/near/388408966\">said</a>:</p>\n<blockquote>\n<p>E.g., \"how many roots has the following equation?\"</p>\n</blockquote>\n<p>I assume this implies that the answer is a single number.<br>\nSo, how about proving \"∃! n. n is the number of roots of the equation\"?</p>",
        "id": 388414203,
        "sender_full_name": "Yutaka Nagashima",
        "timestamp": 1693520340
    },
    {
        "content": "<p>IMO problems often expect the participant to actually write down an explicit numeral to get full points. Lean's type system (merely by allowing substitution --- so this applies to many theorem proving languages) doesn't really allow us to insist on this.</p>",
        "id": 388414329,
        "sender_full_name": "Scott Morrison",
        "timestamp": 1693520409
    },
    {
        "content": "<p>You can add small requirements outside the type system: the solver might be expected to return a <code>s : { x : ℕ // P x }</code>, but with the extra requirement that <code>#eval s.1</code> prints a numeral in finite time.</p>",
        "id": 388414457,
        "sender_full_name": "Scott Morrison",
        "timestamp": 1693520490
    },
    {
        "content": "<p>Imo2023Q1 linked to above is a more extreme version of this, where the solver is expected to return \"an explicit predicate\", so we need either human inspection or an agreed upon automation step to check that the explicit predicate is sufficiently explicit (and equivalent to the required answer).</p>",
        "id": 388414645,
        "sender_full_name": "Scott Morrison",
        "timestamp": 1693520591
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"644409\">Yutaka Nagashima</span> <a href=\"#narrow/stream/208328-IMO-grand-challenge/topic\">said</a></p>\n<blockquote>\n<p>E.g., \"how many roots has the following equation?\"<br>\nI assume this implies that the answer is a single number.<br>\nSo, how about proving \"∃! n. n is the number of roots of the equation\"?</p>\n</blockquote>\n<p>That is not a good idea, you just instantiate n = \"the number of roots\" :-)<br>\nBut really -- this discussion again? Why don't we just allow for start specifying the constant we are looking for in the problem statement? The main part of any IMO problem is the proof anyway.</p>",
        "id": 388414909,
        "sender_full_name": "Miroslav Olšák",
        "timestamp": 1693520748
    },
    {
        "content": "<p>My expectation is that a human checks the term in such cases. Certainly there are problems with multiple reasonable forms for expressing the term; consider IMO 2023 problem 5 where <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mo stretchy=\"false\">⌊</mo><msub><mrow><mi>log</mi><mo>⁡</mo></mrow><mn>2</mn></msub><mi>n</mi><mo stretchy=\"false\">⌋</mo><mo>+</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">\\lfloor \\log_2 n \\rfloor + 1</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">⌊</span><span class=\"mop\"><span class=\"mop\">lo<span style=\"margin-right:0.01389em;\">g</span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.207em;\"><span style=\"top:-2.4559em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2441em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord mathnormal\">n</span><span class=\"mclose\">⌋</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6444em;\"></span><span class=\"mord\">1</span></span></span></span> or <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mo stretchy=\"false\">⌈</mo><msub><mrow><mi>log</mi><mo>⁡</mo></mrow><mn>2</mn></msub><mo stretchy=\"false\">(</mo><mi>n</mi><mo>+</mo><mn>1</mn><mo stretchy=\"false\">)</mo><mo stretchy=\"false\">⌉</mo></mrow><annotation encoding=\"application/x-tex\">\\lceil \\log_2 (n+1)\\rceil</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">⌈</span><span class=\"mop\"><span class=\"mop\">lo<span style=\"margin-right:0.01389em;\">g</span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.207em;\"><span style=\"top:-2.4559em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2441em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">n</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\">1</span><span class=\"mclose\">)⌉</span></span></span></span> are both reasonable informal representations.</p>",
        "id": 388414919,
        "sender_full_name": "Joseph Myers",
        "timestamp": 1693520752
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"644409\">@Yutaka Nagashima</span> I don't think you have understood the issue here. If the question says \"which number works\" then the answer cannot be \"there exists a number which works\". Indeed the existence might be obvious and all the work might be finding the right number</p>",
        "id": 388414925,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1693520760
    },
    {
        "content": "<p>I did previously suggest an \"easy mode\" of the IMO Grand Challenge, where the solver is given a formal statement to prove that includes the answer for such \"determine\" problems. But any claims of solutions in easy mode for such a problem do need to make clear that it's an easy-mode problem that was solved rather than claiming to have solved an actual IMO problem.</p>",
        "id": 388415422,
        "sender_full_name": "Joseph Myers",
        "timestamp": 1693521015
    },
    {
        "content": "<p>The issue is that there are IMO problems which do not translate directly into a proposition where the goal is to prove the proposition. The translation into a proposition is sometimes the hard part.</p>",
        "id": 388415462,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1693521040
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"133339\">Miroslav Olšák</span> <a href=\"#narrow/stream/208328-IMO-grand-challenge/topic/Current.20status.3F/near/388414909\">said</a>:</p>\n<blockquote>\n<p>But really -- this discussion again?</p>\n</blockquote>\n<p>because the GC committee still hasn't made a decision, rather spoiling the point of having the GC? :-) (Or maybe spoiling the point of having the committee? <span aria-label=\"stuck out tongue wink\" class=\"emoji emoji-1f61c\" role=\"img\" title=\"stuck out tongue wink\">:stuck_out_tongue_wink:</span>)</p>\n<p>It's clear from this thread that lacking such a decision/announcement is still a problem.</p>",
        "id": 388416939,
        "sender_full_name": "Scott Morrison",
        "timestamp": 1693522059
    },
    {
        "content": "<p>It's sort of hard for mathematicians to complain about ML teams claiming results on the IMO without actually specifying the standards! But there's certainly been this sort of (well-justified) complaining.</p>",
        "id": 388417042,
        "sender_full_name": "Scott Morrison",
        "timestamp": 1693522131
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"115715\">Jason Rute</span> <a href=\"#narrow/stream/208328-IMO-grand-challenge/topic/Current.20status.3F/near/388324558\">said</a>:</p>\n<blockquote>\n<p>Hi <span class=\"user-mention silent\" data-user-id=\"644409\">Yutaka Nagashima</span> !  I'm familiar with some of your previous work. </p>\n</blockquote>\n<p>Hi Jason, I think I saw you on YouTube. <span aria-label=\"smile\" class=\"emoji emoji-1f642\" role=\"img\" title=\"smile\">:smile:</span></p>\n<blockquote>\n<p>You started doing neural theorem proving for Isabelle, before it was fashionable. <span aria-label=\"smile\" class=\"emoji emoji-1f642\" role=\"img\" title=\"smile\">:smile:</span>  However, I'm curious if you know about the PISA and MiniF2F benchmarks.  <a href=\"https://github.com/albertqjiang/Portal-to-ISAbelle\">PISA</a> is a benchmark of Isabelle/HOL theorems. </p>\n</blockquote>\n<p>I had a look at MiniF2F and that was why I prefer to specify problems by myself. The way MiniF2F formalizes the problems makes it hard for the Abduction Prover to solve them (for technical reasons mostly specific to Isabelle and my tool).</p>\n<blockquote>\n<p><a href=\"https://github.com/facebookresearch/miniF2F\">MiniF2F</a> is a benchmark of competition problems ranging from easy to IMO problems (in many languages including Isabelle/HOL).  I think you should really consider testing your system on MiniF2F (and PISA if possible) to see how well it does.</p>\n</blockquote>\n<p>Yes. I will do so (at least for MiniF2F) at some point. </p>\n<p>But for the current implementation, I am fairly certain that the result of the Abduction Prover against MiniF2F is not going to be great: the Abduction Prover assumes that it is facing inductive problems without library support (specialized tactics or auxiliary lemmas). The Abduction Prover also assumes that it cannot know the types used in the problems in advance. </p>\n<p>These assumptions are an unnecessary burden when we have concrete problem domains in mind like we do so for Math competitions. The way the Abduction Prover produces conjectures is not suitable for IMO problems either, I suppose.</p>\n<blockquote>\n<p>That might give you a sense how close your system is to being able to compete in IMO (and solve a problem or two).  Also, benchmarks in general are a good way to compare progress.  </p>\n</blockquote>\n<p>Yes. I agree.<br>\nAt the same time, I'm curious about the measures taken to ensure test sets aren't used during LLM training. I also wonder how to interpret evaluations that use varying levels of computational resources but are based on the same benchmark.<br>\nPerhaps these concerns have been discussed elsewhere?</p>\n<blockquote>\n<p>For example, do you think your system has a lot of progress over other Isabelle systems like SledgeHammer, Thor, Draft-Sketch-Prove, Baldur, MagnusHammer, \"Decomposing the Enigma\", and others?  </p>\n</blockquote>\n<p>For Sledgehammer, I am confident, since I use it as my subtool and conducted experiments for a predecessor of the Abduction Prover.</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"258175\">Albert Jiang</span> and <span class=\"user-mention silent\" data-user-id=\"384425\">Wenda Li</span> (also at Cambridge) would be good people to talk to about setting up a benchmark.</p>\n</blockquote>\n<p>Thanks. I met them.</p>",
        "id": 388430028,
        "sender_full_name": "Yutaka Nagashima",
        "timestamp": 1693529449
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"115715\">Jason Rute</span> <a href=\"#narrow/stream/208328-IMO-grand-challenge/topic/Current.20status.3F/near/388324580\">said</a>:</p>\n<blockquote>\n<p>Along those lines does the system in your video have a paper associated with it?</p>\n</blockquote>\n<p>The original idea of the Abduction Prover is presented in this short paper: <a href=\"https://doi.org/10.1007/978-3-319-96812-4_19\">Goal-Oriented Conjecturing for Isabelle/HOL</a> (or at <a href=\"https://arxiv.org/abs/1806.04774\">arXiv</a>). The current implementation is quite different, though</p>",
        "id": 388433312,
        "sender_full_name": "Yutaka Nagashima",
        "timestamp": 1693530838
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"644409\">Yutaka Nagashima</span> <a href=\"#narrow/stream/208328-IMO-grand-challenge/topic/Current.20status.3F/near/388430028\">said</a>:</p>\n<blockquote>\n<p>At the same time, I'm curious about the measures taken to ensure test sets aren't used during LLM training. I also wonder how to interpret evaluations that use varying levels of computational resources but are based on the same benchmark.<br>\nPerhaps these concerns have been discussed elsewhere?</p>\n</blockquote>\n<p>Those are two really good questions which deserve more answers.</p>\n<p>For the first question, my impression is that researchers fall into two camps.  (1) Those who think it is not a problem, and (2) those who think it invalidates all the results so far.  I fall in the middle.  I think data contamination is a problem, but it is subtle because it also depends a lot on the use cases.  This is discussed in a fair amount of details in our appendix to the <a href=\"https://arxiv.org/abs/2102.06203\">PACT paper</a>.  It is also a frequent topic on <a class=\"stream\" data-stream-id=\"219941\" href=\"/#narrow/stream/219941-Machine-Learning-for-Theorem-Proving\">#Machine Learning for Theorem Proving</a>.  The best solution is just to test on new theorems which come after the training data.  The IMO Grand Challenge is an extreme version of this approach, but I think it is too extreme, since it is hard to get a good signal from so few and so hard of problems.</p>\n<p>As for computational resources, that is also an important and often discussed thing.  One nice approach is to plot performance as a function of resources.  The <a href=\"https://arxiv.org/abs/2303.04488\">MagnusHammer paper</a> does this really well.  And it is easy to do for both time (theorems proven verse search time) and search steps (if it is a search based algorithm).  This isn't perfect and it is again subtle since neural approaches want GPUs, classical ATPs want lots of cores, reinforcement learning algorithms want days instead of minutes, and so on.  It also depends a lot on the use case.  A system which can solve IMO problems with a couple GPUs and lots of cores in a few hours seems fine for the IMO grand challenge, but for a typical ITP user, they may want something which just runs on a laptop (or over an inexpensive API) in seconds.  Again, I think having benchmarks and competitions which take into account computational resources would be good, but I also don't want to say powerful techniques which currently take days on many GPUs are worthless, since it is very possible to bring both the cost and resources of those approaches down in the near future (and conversely, some approaches specifically work because they scale well with resources, whereas some other approaches can't scale well even if given a lot more resources).</p>",
        "id": 388532415,
        "sender_full_name": "Jason Rute",
        "timestamp": 1693577798
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"644409\">Yutaka Nagashima</span> <a href=\"#narrow/stream/208328-IMO-grand-challenge/topic/Current.20status.3F/near/388430028\">said</a>:</p>\n<blockquote>\n<p>I had a look at MiniF2F and that was why I prefer to specify problems by myself. The way MiniF2F formalizes the problems makes it hard for the Abduction Prover to solve them (for technical reasons mostly specific to Isabelle and my tool).</p>\n</blockquote>\n<p>The conventions for formalizing problem statements should be reasonably idiomatic for each ITP, but not biased to what a particular tool wants to see as input. In particular, if there is more than one entrant using Isabelle/HOL, all those entrants should agree on the conventions used so that only a single version of the statements in Isabelle/HOL is needed.</p>",
        "id": 388606733,
        "sender_full_name": "Joseph Myers",
        "timestamp": 1693606396
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"115715\">Jason Rute</span> <a href=\"#narrow/stream/208328-IMO-grand-challenge/topic/Current.20status.3F/near/388532415\">said</a>:</p>\n<blockquote>\n<p>The best solution is just to test on new theorems which come after the training data.  The IMO Grand Challenge is an extreme version of this approach, but I think it is too extreme, since it is hard to get a good signal from so few and so hard of problems.</p>\n</blockquote>\n<p>You could easily enough pick ten national and regional olympiads held every year with original problems and hold competitions with all of those, as long as there's some agreement between entrants about which olympiads to use. Or use the IMO shortlist (minus the competition problems) when it's released a year later, though that does run the risk of people having posted national selection tests (that may use the shortlist problems during the year that the shortlist remains confidential) online during that time (and also there would be the question of whether to exclude any shortlist problems that the Jury eliminated as being already known, or too close to something already known).</p>",
        "id": 388607135,
        "sender_full_name": "Joseph Myers",
        "timestamp": 1693606623
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"214703\">Yury G. Kudryashov</span> <a href=\"#narrow/stream/208328-IMO-grand-challenge/topic/Current.20status.3F/near/388409237\">said</a>:</p>\n<blockquote>\n<p>To be more specific, what do you expect as input and output for <a href=\"https://artofproblemsolving.com/wiki/index.php/2023_IMO_Problems/Problem_1\">https://artofproblemsolving.com/wiki/index.php/2023_IMO_Problems/Problem_1</a> ?</p>\n</blockquote>\n<p>Thank you for focusing on a concrete problem.<br>\nI will give it a try to formalize this problem (probably when the prover is ready for math problems).<br>\nIt might take a while, but I assume there's no urgency at the moment.</p>",
        "id": 388615197,
        "sender_full_name": "Yutaka Nagashima",
        "timestamp": 1693611588
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"133339\">Miroslav Olšák</span> <a href=\"#narrow/stream/208328-IMO-grand-challenge/topic/Current.20status.3F/near/388414909\">said</a>:</p>\n<blockquote>\n<p>That is not a good idea, you just instantiate n = \"the number of roots\" :-)<br>\nBut really -- this discussion again? Why don't we just allow for start specifying the constant we are looking for in the problem statement? The main part of any IMO problem is the proof anyway.</p>\n</blockquote>\n<p>It sounds like a similar conversation happened in the past. Anyway, let’s continue this in France next week.</p>",
        "id": 388616491,
        "sender_full_name": "Yutaka Nagashima",
        "timestamp": 1693612276
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110038\">Kevin Buzzard</span> <a href=\"#narrow/stream/208328-IMO-grand-challenge/topic/Current.20status.3F/near/388414925\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"644409\">Yutaka Nagashima</span> I don't think you have understood the issue here. If the question says \"which number works\" then the answer cannot be \"there exists a number which works\". Indeed the existence might be obvious and all the work might be finding the right number</p>\n</blockquote>\n<p>It seems that if we require a proof to be in the form of “n works; therefore, there exists a number which works”, that should suffice, since the first part (“n works”) answers the question of “which number works”.</p>\n<p>By the way, I am also considering using what's known as “schematic variables” in Isabelle for \"work out\" problems. However, I haven't had the chance to use schematic variables directly, so I'm unsure about its effectiveness.</p>\n<p>In any case, I'll revisit this topic once I've had some hands-on experience with formalizing IMO problems on my own. Up to now, I've mainly explored problems that were already formalized in MiniF2F. I might gain more insight into the concern you mentioned as I delve deeper into specific IMO problems.</p>",
        "id": 388624846,
        "sender_full_name": "Yutaka Nagashima",
        "timestamp": 1693616301
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"115715\">Jason Rute</span> <a href=\"#narrow/stream/208328-IMO-grand-challenge/topic/Current.20status.3F/near/388532415\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"644409\">Yutaka Nagashima</span> <a href=\"#narrow/stream/208328-IMO-grand-challenge/topic/Current.20status.3F/near/388430028\">said</a>:</p>\n<blockquote>\n<p>At the same time, I'm curious about the measures taken to ensure test sets aren't used during LLM training. I also wonder how to interpret evaluations that use varying levels of computational resources but are based on the same benchmark.<br>\nPerhaps these concerns have been discussed elsewhere?</p>\n</blockquote>\n<p>Those are two really good questions which deserve more answers.</p>\n<p>For the first question, my impression is that researchers fall into two camps.  (1) Those who think it is not a problem, and (2) those who think it invalidates all the results so far.  I fall in the middle.  I think data contamination is a problem, but it is subtle because it also depends a lot on the use cases.  This is discussed in a fair amount of details in our appendix to the <a href=\"https://arxiv.org/abs/2102.06203\">PACT paper</a>.  It is also a frequent topic on <a class=\"stream\" data-stream-id=\"219941\" href=\"/#narrow/stream/219941-Machine-Learning-for-Theorem-Proving\">#Machine Learning for Theorem Proving</a>.  The best solution is just to test on new theorems which come after the training data.  The IMO Grand Challenge is an extreme version of this approach, but I think it is too extreme, since it is hard to get a good signal from so few and so hard of problems.</p>\n<p>As for computational resources, that is also an important and often discussed thing.  One nice approach is to plot performance as a function of resources.  The <a href=\"https://arxiv.org/abs/2303.04488\">MagnusHammer paper</a> does this really well.  And it is easy to do for both time (theorems proven verse search time) and search steps (if it is a search based algorithm).  This isn't perfect and it is again subtle since neural approaches want GPUs, classical ATPs want lots of cores, reinforcement learning algorithms want days instead of minutes, and so on.  It also depends a lot on the use case.  A system which can solve IMO problems with a couple GPUs and lots of cores in a few hours seems fine for the IMO grand challenge, but for a typical ITP user, they may want something which just runs on a laptop (or over an inexpensive API) in seconds.  Again, I think having benchmarks and competitions which take into account computational resources would be good, but I also don't want to say powerful techniques which currently take days on many GPUs are worthless, since it is very possible to bring both the cost and resources of those approaches down in the near future (and conversely, some approaches specifically work because they scale well with resources, whereas some other approaches can't scale well even if given a lot more resources).</p>\n</blockquote>\n<p>I lean more towards (2) myself, but I can also see value in good results obtained from data contamination. It's possible that such results might reflect a system's efficacy as a search engine.</p>\n<p>Presentation is crucial to me. While I have reservations about associating good results from data contamination with robust reasoning capabilities, I do think they might often translate to a better user experience.</p>\n<p>Regarding computational resources, I'm largely in agreement with you. My only slight concern is that the term “search steps” might be interpreted in various ways by different individuals. </p>\n<p>A practical solution might be to request authors to clearly declare the computational resources they've utilized. This would allow for a basic comparison, even if, as you rightly pointed out, the exact nature or quantity of these resources can't be distilled into a singular value.</p>",
        "id": 388630497,
        "sender_full_name": "Yutaka Nagashima",
        "timestamp": 1693618950
    }
]