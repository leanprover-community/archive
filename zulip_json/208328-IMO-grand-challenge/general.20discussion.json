[
    {
        "content": "<ol>\n<li>Problems of the \"find / determine\" type<br>\nI have collected the answers of the problems of this type from all the shortlists available on the official IMO website for a general idea how the answers can look like.<br>\n<a href=\"http://www.olsak.net/mirek/determine-answers.txt\" target=\"_blank\" title=\"http://www.olsak.net/mirek/determine-answers.txt\">http://www.olsak.net/mirek/determine-answers.txt</a></li>\n</ol>",
        "id": 177153047,
        "sender_full_name": "Miroslav Olšák",
        "timestamp": 1570025236
    },
    {
        "content": "<ol start=\"3\">\n<li>Other domains.<br>\nIt is well known that IMO problems are of four categories: \"Geometry / Algebra / Number Theory / Combinatorics\" (a friend of mine once came with a nice comparison to \"Imagination / Computation / Knowledge / Thinking\" :-) ). The problem statements are relatively monotonous inside a single domain unless there is a combinatorial flavour. The most difficult problems from both formalisation perspective and the problem solving perspective are imho problems from Combinatorial Geometry. I am for example curious about the formalisation of the windmill problem (2011-2, <a href=\"https://www.youtube.com/watch?v=M64HUIJFTZM\" target=\"_blank\" title=\"https://www.youtube.com/watch?v=M64HUIJFTZM\">https://www.youtube.com/watch?v=M64HUIJFTZM</a>).</li>\n</ol>\n<div class=\"youtube-video message_inline_image\"><a data-id=\"M64HUIJFTZM\" href=\"https://www.youtube.com/watch?v=M64HUIJFTZM\" target=\"_blank\" title=\"https://www.youtube.com/watch?v=M64HUIJFTZM\"><img src=\"https://i.ytimg.com/vi/M64HUIJFTZM/default.jpg\"></a></div>",
        "id": 177153084,
        "sender_full_name": "Miroslav Olšák",
        "timestamp": 1570025266
    },
    {
        "content": "<ol start=\"5\">\n<li>Partial points<br>\nSome of the IMO problems are actually multiple (two) independent tasks, for example 2016-6 (= C7). Whether to allow partial points in such cases is worth consideration.</li>\n</ol>",
        "id": 177153162,
        "sender_full_name": "Miroslav Olšák",
        "timestamp": 1570025304
    },
    {
        "content": "<blockquote>\n<p>I am for example curious about the formalisation of the windmill problem (2011-2, <a href=\"https://www.youtube.com/watch?v=M64HUIJFTZM\" target=\"_blank\" title=\"https://www.youtube.com/watch?v=M64HUIJFTZM\">https://www.youtube.com/watch?v=M64HUIJFTZM</a>).</p>\n</blockquote>\n<p><span class=\"user-mention\" data-user-id=\"133339\">@Miroslav Olšák</span> For the windmill problem, are you concerned about formalizing the statement, finding a solution, or formalizing a solution?</p>",
        "id": 177243163,
        "sender_full_name": "Daniel Selsam",
        "timestamp": 1570108967
    },
    {
        "content": "<blockquote>\n<p>Are we interested in formalizing olympiad-like mathematical puzzles not necessarily coming from IMO?</p>\n</blockquote>\n<p><span class=\"user-mention\" data-user-id=\"133339\">@Miroslav Olšák</span> There are many sources of problems that I think would provide valuable data for IMO, e.g. problems from national Olympiads. It is hard to say without knowing more whether your folklore list is worth the trouble of you translating it to English.</p>",
        "id": 177243625,
        "sender_full_name": "Daniel Selsam",
        "timestamp": 1570109276
    },
    {
        "content": "<blockquote>\n<ol start=\"5\">\n<li>Partial points<br>\nSome of the IMO problems are actually multiple (two) independent tasks, for example 2016-6 (= C7). Whether to allow partial points in such cases is worth consideration.</li>\n</ol>\n</blockquote>\n<p><span class=\"user-mention\" data-user-id=\"133339\">@Miroslav Olšák</span> I agree. Unfortunately, I don't see any official statement concerning the number of points for solving sub-problems of problems. One option is to say \"partial credit will be given for fully formalized sub-problems according to the number of points human judges would have awarded for the same sub-problems\". What do you think?</p>",
        "id": 177244300,
        "sender_full_name": "Daniel Selsam",
        "timestamp": 1570109691
    },
    {
        "content": "<blockquote>\n<p>Because of that, I am now focused mainly on geometry, and I have translated the officialy available shortlists to a semi-formal language (parseable but without detailed semantics and not in any particular therem prover so far). So I could help a bit with this part.</p>\n</blockquote>\n<p><span class=\"user-mention\" data-user-id=\"133339\">@Miroslav Olšák</span> Nice! Can you share one example to give us a sense of the semi-formal language?</p>",
        "id": 177244510,
        "sender_full_name": "Daniel Selsam",
        "timestamp": 1570109827
    },
    {
        "content": "<blockquote>\n<ol>\n<li>Problems of the \"find / determine\" type<br>\nI have collected the answers of the problems of this type from all the shortlists available on the official IMO website for a general idea how the answers can look like.<br>\n<a href=\"http://atrey.karlin.mff.cuni.cz/~mirecek/determine-answers.txt\" target=\"_blank\" title=\"http://atrey.karlin.mff.cuni.cz/~mirecek/determine-answers.txt\">http://atrey.karlin.mff.cuni.cz/~mirecek/determine-answers.txt</a></li>\n</ol>\n</blockquote>\n<p><span class=\"user-mention\" data-user-id=\"133339\">@Miroslav Olšák</span> Nice! What do you think about the current plan, of requiring human-assessment of the witnesses and only accepting witnesses that human judges would have accepted? See <a href=\"https://github.com/IMO-grand-challenge/formal-encoding/blob/master/design/determine.lean\" target=\"_blank\" title=\"https://github.com/IMO-grand-challenge/formal-encoding/blob/master/design/determine.lean\">https://github.com/IMO-grand-challenge/formal-encoding/blob/master/design/determine.lean</a> for more context.</p>",
        "id": 177244913,
        "sender_full_name": "Daniel Selsam",
        "timestamp": 1570110093
    },
    {
        "content": "<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"133339\">Miroslav Olšák</span> For the windmill problem, are you concerned about formalizing the statement, finding a solution, or formalizing a solution?</p>\n</blockquote>\n<p>I am not concerned that formalizing the problem statement, or formalizing the solution would be impossible, I just find it somewhat challenging, so I would like to see it. Of course, if an automated system (not designed for solving this particular problem) could find a solution of it, I would be super-impressed. However, I feel the following issue of the formalization of the problem statement. There are some facts about the problem that are so obvious (but really nontrivial to formally proof) that it is unclear whether they are actually a part of the problem statement, or a part of the solution. I mean for example \"given any initial line, there is exactly one windmill process\".</p>",
        "id": 177244984,
        "sender_full_name": "Miroslav Olšák",
        "timestamp": 1570110126
    },
    {
        "content": "<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"133339\">Miroslav Olšák</span> I agree. Unfortunately, I don't see any official statement concerning the number of points for solving sub-problems of problems. One option is to say \"partial credit will be given for fully formalized sub-problems according to the number of points human judges would have awarded for the same sub-problems\". What do you think?</p>\n</blockquote>\n<p>It makes sense. Note that although there is no public document for the IMO marking scheme, the judges prepare it and agree on the marking scheme before checking the solutions.</p>",
        "id": 177245552,
        "sender_full_name": "Miroslav Olšák",
        "timestamp": 1570110515
    },
    {
        "content": "<blockquote>\n<p>However, I feel the following issue of the formalization of the problem statement. There are some facts about the problem that are so obvious (but really nontrivial to formally proof) that it is unclear whether they are actually a part of the problem statement, or a part of the solution. I mean for example \"given any initial line, there is exactly one windmill process\".</p>\n</blockquote>\n<p><span class=\"user-mention\" data-user-id=\"133339\">@Miroslav Olšák</span> I agree that these are big challenges. One approach might be to have a DSL for geometric processes, and then to encode the windmill process as a program in the DSL. </p>\n<div class=\"codehilite\"><pre><span></span>windmill(S, s, l) =\n  while true:\n    l \\gets rotateUntil(l, s, CLOCK_WISE, fun l =&gt; exists s&#39; \\in S, s \\neq s&#39; /\\ on(s&#39;, l))\n    s \\gets choose({s&#39; \\in S : s&#39; \\neq s /\\ on(s&#39;, l)})\n</pre></div>\n\n\n<p>Here it would be provable that the <code>{s' \\in S : ...}</code> set always has exactly one element (since by assumption |S| &gt; 1 and no three points are collinear) and thus the process is deterministic. The key insight required to solve the problem could then be cast as discovering an invariant of the program.</p>\n<p>I am not sure what kind of semantics such a hypothetical DSL would warrant, probably operational, and bottoming out into some geometric object parameterized by time. I am also not sure whether we would have already had such abstractions before the windmill year, or whether the abstractions we can build now will be good enough for future problems.</p>",
        "id": 177248253,
        "sender_full_name": "Daniel Selsam",
        "timestamp": 1570112048
    },
    {
        "content": "<blockquote>\n<p>As far as I know, the computational methods (Wu's method / Gröbner basis / ...) are stronger than any synthetic approach, and I have heard that they are capable of solving at least some of the IMO problems<br>\n...<br>\nNote that I also have a parser for that, so I can tell the types of the objects, possibly convert it to other format, etc.</p>\n</blockquote>\n<p><span class=\"user-mention\" data-user-id=\"133339\">@Miroslav Olšák</span> I am very curious which existing problems can be solved by which existing tools. What do you think are the most relevant off-the-shelf tools to try?</p>",
        "id": 177249198,
        "sender_full_name": "Daniel Selsam",
        "timestamp": 1570112598
    },
    {
        "content": "<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"133339\">Miroslav Olšák</span> Nice! What do you think about the current plan, of requiring human-assessment of the witnesses and only accepting witnesses that human judges would have accepted? See <a href=\"https://github.com/IMO-grand-challenge/formal-encoding/blob/master/design/determine.lean\" target=\"_blank\" title=\"https://github.com/IMO-grand-challenge/formal-encoding/blob/master/design/determine.lean\">https://github.com/IMO-grand-challenge/formal-encoding/blob/master/design/determine.lean</a> for more context.</p>\n</blockquote>\n<p>Well, putting a human into the loop is fine, it just rather postpones the problem than solves it (but it may be a good thing to postpone it). I also like the idea of whitelist of allowed operations for every individual problem where the problems available so far would help us prepare templates for such whitelists. But if a problem requiring something more complex emerged, we could simply modify the whitelist to allow what is necessary without providing much hints (it is actually also putting a human to the loop but to another place).</p>",
        "id": 177249634,
        "sender_full_name": "Miroslav Olšák",
        "timestamp": 1570112846
    },
    {
        "content": "<p>This looks interesting : <a href=\"https://mathoverflow.net/a/337705\" target=\"_blank\" title=\"https://mathoverflow.net/a/337705\">https://mathoverflow.net/a/337705</a> . I don't know if it's good enough to solve IMO problems though</p>",
        "id": 177259600,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1570119002
    },
    {
        "content": "<p>Maybe this conversation should move to another Zulip thread. That one is meant to be used by the Zulip AI only. More seriously, it would make it easier to find back this conversation. Miroslav, I think you can to the move by editing your first message in this thread.</p>",
        "id": 177284270,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1570134096
    },
    {
        "content": "<p>(Miroslav, Patrick is referring to the topic \"stream events\" in case it's not clear)</p>",
        "id": 177284413,
        "sender_full_name": "Reid Barton",
        "timestamp": 1570134151
    },
    {
        "content": "<p>Oh, yes, sorry, I am not so familiar with Zulip.</p>",
        "id": 177284424,
        "sender_full_name": "Miroslav Olšák",
        "timestamp": 1570134158
    },
    {
        "content": "<p>Now it is \"hmble\", any suggestion for a better name? (why does it actually require a name, I just wanted to contribute to the general discussion)</p>",
        "id": 177284617,
        "sender_full_name": "Miroslav Olšák",
        "timestamp": 1570134278
    },
    {
        "content": "<p>Well, then call it \"general discussion\"</p>",
        "id": 177284682,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1570134312
    },
    {
        "content": "<blockquote>\n<p>I don't know, perhaps we should ask people from the community aroung automated deduction in geometry.</p>\n</blockquote>\n<p><span class=\"user-mention\" data-user-id=\"133339\">@Miroslav Olšák</span> I am most curious about which (non-synthetic) decision procedures work for which existing problems, e.g. by considering them as nonlinear real arithmetic (NRA) problems.</p>",
        "id": 177285218,
        "sender_full_name": "Daniel Selsam",
        "timestamp": 1570134612
    },
    {
        "content": "<p>(deleted)</p>",
        "id": 177377100,
        "sender_full_name": "Joe Hendrix",
        "timestamp": 1570221636
    },
    {
        "content": "<blockquote>\n<p>Well, then call it \"general discussion\"</p>\n</blockquote>\n<p>Maybe I'm not reading carefully enough, but I was under the impression there was a clear geometry thread. If this is not specific enough then it means we give up using Zulip threads.</p>",
        "id": 177377845,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1570222269
    },
    {
        "content": "<blockquote>\n<blockquote>\n<p>Well, then call it \"general discussion\"</p>\n</blockquote>\n<p>Maybe I'm not reading carefully enough, but I was under the impression there was a clear geometry thread. If this is not specific enough then it means we give up using Zulip threads.</p>\n</blockquote>\n<p>I had several remarks, only one of them is related to geometry (and I don't consider the Windmill problem related to geometry, it is rather combinatorics).</p>",
        "id": 177380191,
        "sender_full_name": "Miroslav Olšák",
        "timestamp": 1570224069
    },
    {
        "content": "<blockquote>\n<p>I had several remarks, only one of them is related to geometry</p>\n</blockquote>\n<p><span class=\"user-mention\" data-user-id=\"133339\">@Miroslav Olšák</span> FYI the recommended style is to use different topics for each question/comment in a batch.</p>",
        "id": 177380365,
        "sender_full_name": "Daniel Selsam",
        "timestamp": 1570224185
    },
    {
        "content": "<p>By the way, the comments teaching me how to use Zulip look irrelevant from the general perspective. I suggest using rather private messages next time. By the way, can I delete at least my comments of regarding Zulip?</p>",
        "id": 177381547,
        "sender_full_name": "Miroslav Olšák",
        "timestamp": 1570225242
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"133339\">@Miroslav Olšák</span> I'm very sorry my message may have sounded a bit aggressive. I'm sure Daniel and the whole grand-challenge team is very happy to read your contributions. Experience on this forum suggests things are a bit easier if we somehow try to separate topics, but there are plenty of counterexamples. So please don't let that issue prevent you from contributing.</p>",
        "id": 177406559,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1570267914
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"230999\">@Daniel Selsam</span> I am trying to understand the specifications we are trying to pin down in this community. Inspired by a question on the Intermediate Langauge stream referencing HOList and worrying about portability of the competition if things get tied down to lean, is the goal of the project also to re-implement something like HOList? How is it going to be different? </p>\n<p>From the comment on that thread/stream it seems that re-implementing HOList would be a pain (I wish I understood why), but I think it would be important to understand the difference and planning things out before going out and re-implementing a complicated system like HOList. What are your thoughts?</p>",
        "id": 178889560,
        "sender_full_name": "Brando Miranda",
        "timestamp": 1571860362
    },
    {
        "content": "<blockquote>\n<p>From the comment on that thread/stream it seems that re-implementing HOList would be a pain (I wish I understood why), but I think it would be important to understand the difference and planning things out before going out and re-implementing a complicated system like HOList. What are your thoughts?</p>\n</blockquote>\n<p>It is not hard to interface with ML systems. Lean has a tactic framework, with excellent meta-programming support, and also a foreign function interface.</p>",
        "id": 178904475,
        "sender_full_name": "Daniel Selsam",
        "timestamp": 1571871199
    },
    {
        "content": "<blockquote>\n<p>it seems that re-implementing HOList would be a pain (I wish I understood why)</p>\n</blockquote>\n<p><span class=\"user-mention\" data-user-id=\"246156\">@Brando Miranda</span> I can try to address (narrowly) what I think would need to happen to reimplement HOList in Lean.  I know at least one person here is working on it.  I don’t know what progress they have made.  I’m probably the one who said this  a “pain”.  I should probably backtrack and say it is doable with a good amount of engineering work, and I hope someone builds it!  As I think you have an ML background, I won’t try to cover up the ML terminology.</p>",
        "id": 178908913,
        "sender_full_name": "Jason Rute",
        "timestamp": 1571875572
    },
    {
        "content": "<p>As I see it, the HOList projects have the following parts that would need to be reimplemented:</p>\n<ol>\n<li><em>A list of theorems</em> For both training and testing, one needs a list of theorems (and the full context in some nicely parsable form) to train on.</li>\n<li><em>Proof recording (optional)</em> If one wants to do supervised learning, then one needs a list of proofs as well to train on.  These proofs will contain the theorem to prove (with the context) as well as the various tactics which have been applied along with their arguments.  This needs to be at some intermediate level which records the name of the tactic and the arguments (so at a higher level than type theory), but probably not at the level of the raw lean code.  I’ve heard from some in the Lean community that the tactic environment could be hacked to provide this information, but I don’t know that it has ever been done.  HOL Light has some advantages here.  It has a simpler tactic framework (I think), it is a larger library (more training data), it is written by one person mostly (so is more uniform), and HOL Light only uses tactics (whereas Lean uses a mixture of tactics and the type theoretic framework).  However, the ASTactic (CogGym) and ProverBot9001 projects also used proof recording for Coq.</li>\n<li><em>An interactive environment</em> If one wants to do reinforcement learning and/or tree search, one needs to be able to quickly interact with the system.  For tree search, given a particular state, one needs to be able to try possible tactics, see what the results are and back track if needed (using for example beam search).  Also, for reinforcement learning, one needs to be able to try out a very large number of scenarios (in this case theorems, either real or synthetic, to prove).  This necessitates an even faster back-and-forth between the agent and the system.  Google rewrote HOL Light in C++ for this purpose.  (The various Coq ML projects don’t use reinforcement learning.)</li>\n<li><em>A system for scoring tactics and tactic arguments</em>  Scoring the tactics can be done as a probability distribution over the tactics (computed by a neural network), but scoring the arguments to these tactics can be a bit more tricky because of the large number of possibilities.  HOList has one system for doing this.  The two Coq projects have another system.  I don’t know if either is readily adaptable to Lean.</li>\n<li><em>Access to neural networks and computer power for training and evaluation</em> The agent will have to compute tactic and argument scores via (graph?) neural networks.  Therefore, it needs access to TensorFlow or PyTorch and a distributed computing system.</li>\n</ol>",
        "id": 178908916,
        "sender_full_name": "Jason Rute",
        "timestamp": 1571875587
    },
    {
        "content": "<p>Some further comments.  One doesn’t need proof recording.  Instead one can train solely with theorem statements and reinforcement learning.  Conversely, if one doesn’t use reinforcement learning, then one doesn’t need as much speed in the interactive environment.  Also, the tree search agent could live inside Lean (as a tactic) making FFI calls to TensorFlow, say.  Alternately it could have the agent in Python or C++.  Then it would have to guide Lean from the outside.  I don’t know which is better.</p>",
        "id": 178908921,
        "sender_full_name": "Jason Rute",
        "timestamp": 1571875600
    },
    {
        "content": "<blockquote>\n<p>I know at least one person here is working on it.</p>\n</blockquote>\n<p>Awesome! Do you think its possible to get me in touch with them or their team? thanks!</p>",
        "id": 178912124,
        "sender_full_name": "Brando Miranda",
        "timestamp": 1571879510
    },
    {
        "content": "<blockquote>\n<p>Google rewrote HOL Light in C++ for this purpose. (The various Coq ML projects don’t use reinforcement learning.)</p>\n</blockquote>\n<p>Are you saying google wrote HOL Light (the entire Theorm prover, idk if that is a lot of work or not but it sounds like it) only so that they could do RL on HOL Light? (trying to repeat it back to you to make sure I got it).</p>\n<p>On a very related note, does that mean for someone to re-implement HOList to make LeanList we would need to re-implement Lean in a language that allows for high performance/speed to do RL?</p>\n<p>I think the fundamental thing I don't understand is how to do  the IMO-grand-challenge without a system like HOList built already. Why wouldn't that need to be a pre-requisite?</p>",
        "id": 178912366,
        "sender_full_name": "Brando Miranda",
        "timestamp": 1571879764
    },
    {
        "content": "<p>Lean is implemented in C++ already</p>",
        "id": 178912398,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1571879817
    },
    {
        "content": "<p>and high performance has always been an objective</p>",
        "id": 178912414,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1571879842
    },
    {
        "content": "<blockquote>\n<p>Lean is implemented in C++ already</p>\n</blockquote>\n<p>So its fast enough to do Reinforcement Learning (RL) on it already? Is that what your saying?</p>",
        "id": 178912418,
        "sender_full_name": "Brando Miranda",
        "timestamp": 1571879849
    },
    {
        "content": "<p>I have no idea what specifically is required for that, but FFI should be sufficient</p>",
        "id": 178912474,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1571879886
    },
    {
        "content": "<blockquote>\n<p>I have no idea what specifically is required for that, but FFI should be sufficient</p>\n</blockquote>\n<p>what does FFI mean?</p>",
        "id": 178912485,
        "sender_full_name": "Brando Miranda",
        "timestamp": 1571879910
    },
    {
        "content": "<p>foreign function interface, i.e. calling functions in other languages</p>",
        "id": 178912491,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1571879925
    },
    {
        "content": "<p>I am also curious about \"Google rewrote HOL Light\"</p>",
        "id": 178912501,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1571879945
    },
    {
        "content": "<p>Im curious, for Foreign Function Interface (FFI), is Lean's faster than Coq?</p>",
        "id": 178912586,
        "sender_full_name": "Brando Miranda",
        "timestamp": 1571880053
    },
    {
        "content": "<p>Lean 3 got an FFI only in the community version, and I haven't used Lean 4's</p>",
        "id": 178912611,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1571880098
    },
    {
        "content": "<p>I don't see any reason why FFI should be very slow</p>",
        "id": 178912667,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1571880135
    },
    {
        "content": "<p>I'm sure Lean 4's will be fast.</p>",
        "id": 178912669,
        "sender_full_name": "Reid Barton",
        "timestamp": 1571880144
    },
    {
        "content": "<p>I guess marshaling of large objects might be a performance penalty</p>",
        "id": 178912681,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1571880179
    },
    {
        "content": "<p>Is an Foreign Function Interface (FFI), bi-directional? or is it only powerful from within Lean to say Python? What about the reverse?</p>",
        "id": 178912697,
        "sender_full_name": "Brando Miranda",
        "timestamp": 1571880210
    },
    {
        "content": "<p>The only way I am aware of for other languages to talk to lean is through the server mode, which uses JSON for message passing</p>",
        "id": 178912750,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1571880247
    },
    {
        "content": "<p>I guess you could also try literally linking with lean as a library, but I've never seen that done and I have no idea if it's doable</p>",
        "id": 178912755,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1571880283
    },
    {
        "content": "<p>How does SerAPI (<a href=\"https://github.com/ejgallego/coq-serapi\" target=\"_blank\" title=\"https://github.com/ejgallego/coq-serapi\">https://github.com/ejgallego/coq-serapi</a>) compare to Lean's foreign function interface (ffi)? Or are they totally different?</p>",
        "id": 178912866,
        "sender_full_name": "Brando Miranda",
        "timestamp": 1571880434
    },
    {
        "content": "<p>It looks like something different</p>",
        "id": 178913034,
        "sender_full_name": "Reid Barton",
        "timestamp": 1571880627
    },
    {
        "content": "<p>SerAPI looks more like Lean's server mode, at least from my quick skim of the Github readme. At least all of Lean's editor integration is done via <code>lean --server</code>.</p>",
        "id": 178913056,
        "sender_full_name": "Bryan Gin-ge Chen",
        "timestamp": 1571880690
    },
    {
        "content": "<p>Though as Mario said, the Lean server mode uses JSON and it looks like SerAPI is doing something much more sophisticated.</p>",
        "id": 178913109,
        "sender_full_name": "Bryan Gin-ge Chen",
        "timestamp": 1571880736
    },
    {
        "content": "<p>The Lean FFI lets you call C functions from a compiled Lean program. For example <a href=\"https://github.com/leanprover/lean4/blob/master/library/Init/System/IO.lean#L115\" target=\"_blank\" title=\"https://github.com/leanprover/lean4/blob/master/library/Init/System/IO.lean#L115\">handle.close</a> is implemented by <a href=\"https://github.com/leanprover/lean4/blob/faf7d7daf60413b74120cdcecda455f25f8210aa/src/runtime/io.cpp#L124\" target=\"_blank\" title=\"https://github.com/leanprover/lean4/blob/faf7d7daf60413b74120cdcecda455f25f8210aa/src/runtime/io.cpp#L124\">lean_io_prim_handle_close</a> (okay, bad example!)</p>",
        "id": 178913123,
        "sender_full_name": "Reid Barton",
        "timestamp": 1571880782
    },
    {
        "content": "<p>or <a href=\"https://github.com/leanprover/lean4/blob/master/library/Init/Data/Int/Basic.lean#L49\" target=\"_blank\" title=\"https://github.com/leanprover/lean4/blob/master/library/Init/Data/Int/Basic.lean#L49\">Int.add</a> is implemented by <a href=\"https://github.com/leanprover/lean4/blob/870db93c8e6f75ce3a1facbb0c494b1afad7c1f5/src/runtime/lean.h#L1359\" target=\"_blank\" title=\"https://github.com/leanprover/lean4/blob/870db93c8e6f75ce3a1facbb0c494b1afad7c1f5/src/runtime/lean.h#L1359\">lean_int_add</a></p>",
        "id": 178913144,
        "sender_full_name": "Reid Barton",
        "timestamp": 1571880817
    },
    {
        "content": "<p>can you pass or return objects?</p>",
        "id": 178913214,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1571880869
    },
    {
        "content": "<p>Like <code>Int</code>s? <span aria-label=\"slight smile\" class=\"emoji emoji-1f642\" role=\"img\" title=\"slight smile\">:slight_smile:</span></p>",
        "id": 178913237,
        "sender_full_name": "Reid Barton",
        "timestamp": 1571880902
    },
    {
        "content": "<p>though probably <code>Int</code> is itself some kind of magic when compiled</p>",
        "id": 178913252,
        "sender_full_name": "Reid Barton",
        "timestamp": 1571880918
    },
    {
        "content": "<p>As long as there is no message passing, I guess there is no reason for much performance overhead with the FFI; total runtime should be dominated by the C function itself</p>",
        "id": 178913269,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1571880949
    },
    {
        "content": "<p>but if you have some huge array you have to pass in, that could hurt if the FFI layer isn't done properly</p>",
        "id": 178913332,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1571880980
    },
    {
        "content": "<p>Based on the other performance engineering that has already gone into Lean 4, I'm confident that it will be at least possible to do efficient FFI</p>",
        "id": 178913536,
        "sender_full_name": "Reid Barton",
        "timestamp": 1571881224
    },
    {
        "content": "<p>The <code>@&amp;</code> in the type of <code>Int.add</code> means that the argument is borrowed, I think</p>",
        "id": 178913548,
        "sender_full_name": "Reid Barton",
        "timestamp": 1571881238
    },
    {
        "content": "<p><a href=\"https://github.com/leanprover/lean4/blob/master/library/Init/Data/Array/Basic.lean#L75\" target=\"_blank\" title=\"https://github.com/leanprover/lean4/blob/master/library/Init/Data/Array/Basic.lean#L75\">https://github.com/leanprover/lean4/blob/master/library/Init/Data/Array/Basic.lean#L75</a> makes me think you can do zero-copy FFI with <code>Array</code> (assuming the C side is well-behaved of course)</p>",
        "id": 178913638,
        "sender_full_name": "Reid Barton",
        "timestamp": 1571881344
    },
    {
        "content": "<p>It would be cool if there was an FFI to Rust that could cooperate with the Rust types</p>",
        "id": 178913665,
        "sender_full_name": "Reid Barton",
        "timestamp": 1571881415
    },
    {
        "content": "<p>although I have no idea whether that is even possible</p>",
        "id": 178913672,
        "sender_full_name": "Reid Barton",
        "timestamp": 1571881426
    },
    {
        "content": "<p>Is this High Performance conversation with the foreign function interface (FFI) the reason Coq projects (CoqGym, gamepad, etc) do not do Reinforcement Learning (RL)? Anyone know?</p>",
        "id": 178913728,
        "sender_full_name": "Brando Miranda",
        "timestamp": 1571881457
    },
    {
        "content": "<p>I don't know the answer to that, but this FFI business is relevant because it means it is actually viable to build your ML system in Lean, which gives you direct access to the Lean tactic state and so on as well. For other theorem provers, you'd want to use a different programming language and then you have the problem of importing/exporting data like the tactic state. (Although I'm not sure why you couldn't just use OCaml as the host language for the theorem provers written in it.)</p>",
        "id": 178913994,
        "sender_full_name": "Reid Barton",
        "timestamp": 1571881878
    },
    {
        "content": "<p>Well, most serious ML researchers use python, so thats why, I believe most of us don't know OCaml (I'm learning it myself now thought cuz I predicted it might be useful as you have pointed out, but even if I write my ML in OCaml then it means little people can build on it if its all in OCaml)</p>",
        "id": 178915602,
        "sender_full_name": "Brando Miranda",
        "timestamp": 1571884092
    },
    {
        "content": "<blockquote>\n<p>but this FFI business is relevant because it means it is actually viable to build your ML system in Lean, which gives you direct access to the Lean tactic state and so on as well.</p>\n</blockquote>\n<p>Oh interesting! But would that mean I can build an ML system inside of Lean or inside of Python?</p>",
        "id": 178915705,
        "sender_full_name": "Brando Miranda",
        "timestamp": 1571884213
    },
    {
        "content": "<blockquote>\n<p>For other theorem provers, you'd want to use a different programming language and then you have the problem of importing/exporting data like the tactic state.</p>\n</blockquote>\n<p>Do you mind expanding what this means? In particular, why does one need an external programming language for most ITPs? (perhaps a few examples would be nice) Also, why isn't this a problem in Lean? Is it because Lean is a programming language itself or because of the foreign function interface (FFI)?</p>\n<p>(Perhaps I will go and play with Lean's foreign function interface (FFI) so that its less wishy-washy in my head and get my hands dirty).</p>",
        "id": 178915783,
        "sender_full_name": "Brando Miranda",
        "timestamp": 1571884357
    },
    {
        "content": "<p>As for rewriting HOL light in C++.  I tried to look it up.  It seems that in <a href=\"https://arxiv.org/pdf/1904.03241.pdf\" target=\"_blank\" title=\"https://arxiv.org/pdf/1904.03241.pdf\">the first HOList paper</a> and <a href=\"https://sites.google.com/view/holist/home\" target=\"_blank\" title=\"https://sites.google.com/view/holist/home\">the website</a> mention that their modified form of HOL Light is called DeepHOL.  I think looking at the code they seemed to have just rewritten the kernel in C++, but I am not certain.  The whole thing is usable as a docker container where one can treat it as a black box theorem prover interface.  (See the website for how to use it.)</p>",
        "id": 178915898,
        "sender_full_name": "Jason Rute",
        "timestamp": 1571884542
    },
    {
        "content": "<p>Other theorem provers (including Lean 3, really) either aren't programming languages at all, or aren't adequate as programming languages for the task (though I must say I don't understand the situation with Coq, in particular)</p>",
        "id": 178916069,
        "sender_full_name": "Reid Barton",
        "timestamp": 1571884775
    },
    {
        "content": "<p>I think one would need the following in a project like this.  </p>\n<ul>\n<li>A reinforcement learning master algorithm which decides which problems to try to attempt, tells the agent to try to solve them, records the results, and uses these results to train the neural network.  This would also probably be a heavily parallelized application.</li>\n<li>A search algorithm which tries to solve a particular problem (repeatedly querying a neural network as an oracle).</li>\n<li>The part which actually runs the neural network.  (And for speed it probably needs to batch up calls to the neural network and send them together to make efficient use of the GPU.</li>\n<li>The part which trains the neural network.</li>\n</ul>\n<p>I think the last two need to be in Python or C++.  The tree search agent could be in Lean with FFI to the part which calls the network, but I don't know how well a purely functional language  does with (non-depth-first) tree search.  The overall master agent could be written in lean, but I assume it would make more sense in something else.</p>",
        "id": 178916196,
        "sender_full_name": "Jason Rute",
        "timestamp": 1571884983
    },
    {
        "content": "<p>Also, I guess speed doesn't matter as much when you have massive parallelism.  (At my job, when we need something done fast, we just reserve more AWS instances.  [Well in theory.  In practice there always seems to be a bottle neck or it is too expensive.])</p>",
        "id": 178916279,
        "sender_full_name": "Jason Rute",
        "timestamp": 1571885103
    },
    {
        "content": "<p>I thought a bit more about tree search algorithms in Lean.  In general, reasonably efficient search algorithms can be implemented with maps (hash tables or other lookup data structures) and priority queues (heaps).  I know Lean 3 doesn't have a priority queue/heap but I found a good one in the book <a href=\"https://www.amazon.com/Purely-Functional-Data-Structures-Okasaki/dp/0521663504\" target=\"_blank\" title=\"https://www.amazon.com/Purely-Functional-Data-Structures-Okasaki/dp/0521663504\">Purely Functional Data Structures</a>.  A few weeks ago I tried implementing both their BinomialHeap and SplayHeap in Lean.  The SplayHeap is about an order of magnitude faster than the Binomial Heap and can do heap sort in Lean as fast as Lean's merge sort.  (I noticed Lean 4 implements BinomialHeaps in the base library, and I wonder if SplayHeaps would be better.)  So maybe if Lean is decked out with the fastest purely functional fastest data structures (or uses FFI to call non-functional C++ data structures), then it wouldn't be a large bottleneck to have the search agent live in Lean.  Then one would have a powerful fast search tactic in Lean (which could be guided by FFI calls to a pre-trained neural network).</p>",
        "id": 178945994,
        "sender_full_name": "Jason Rute",
        "timestamp": 1571919897
    },
    {
        "content": "<blockquote>\n<p>Then one would have a powerful fast search tactic in Lean (which could be guided by FFI calls to a pre-trained neural network).</p>\n</blockquote>\n<p>What worries me is the \"pre-trained\" neural net (NN) part. I think if Lean is going to be used besides just a theorem prover, it should allow for training of the NN. Also, another thing to consider is that its going to be hard for people to adopt the challenge or ITP Lean environment/dataset if it all lives in a new programming language that is not \"standard\" like python. I dont think its going to be able to kick off like the famous large-scale computer vision competition/dataset (ImageNet). It has to be taken into account that if every competitor is forced to learn a new programming paradigm (like functional programming (fp)), note this isn't only a new programming language, it might take some time to people really use it (or perhaps people won't). It takes some time to get good at a new programming language, specially if its a new paradigm. Having things in Python imho will make any ITP challenge more likely to thrive.</p>",
        "id": 178955075,
        "sender_full_name": "Brando Miranda",
        "timestamp": 1571926022
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"246156\">@Brando Miranda</span> I think in some sense one needs both (to (1) be able to run a search algorithm inside Lean with a NN and (2) guide Lean from the outside in something like Python).  Setting aside the IMO challenge and just thinking about improving Lean, from the perspective of a Lean user, they want whatever system one is building to be usable in Lean.  And this is really a problem with the other tools out there.  I don't know if any of the AI/ITP systems currently out there are usable and useful to the practitioners of that ITP system.  However, if Lean had a HOList-like tactic called <code>lean_ist</code> (which admittedly would involve some additional setup), then they could write <code>by lean_ist</code>.  The system would behave similar to the <code>library_search</code> tactic, outputting a proof which can be pasted into Lean.</p>",
        "id": 179011212,
        "sender_full_name": "Jason Rute",
        "timestamp": 1571962887
    },
    {
        "content": "<p>On the flip side, something that inhibits the growth of these AI for ITP systems is that it is a major engineering feat to link your AI library to your theorem prover (and just as large of a feat to learn the intricacies of the logic).  One thing that has really increased neural network research progress has been environments which are easy to spin up and play with.  These \"gym\" environments allow you apply the same training algorithm to many different problems which have the same interface.  I think a very useful research project would be the following:  Go through the other AI for theorem proving projects out there, and find a common gym-like interface for interactive theorem provers and related systems, including tableau calculus, constraint solvers, QBF solvers, SMT solvers with tactics, non-classical proof systems.  (I can point one to over a dozen papers, each in a separate system.)   As far as I see they have the following uniform framework:</p>\n<ul>\n<li>A term and formula language</li>\n<li>A local goal state: What one is trying to prove at the moment (as an ordered list of formulas in some formal language)</li>\n<li>Premise List: all the possible previously proven theorem statements one could use (which needs to be significantly narrowed down in a process called “premise selection”)</li>\n<li>Tactics or inference rules: a fixed finite set of rules one can apply to ones current goal state</li>\n<li>Tactic parameters: the possible parameters that can be added to the above tactics.  (This is by far the most inconsistent and flexible part of the framework.  These parameters can include numbers, terms, and premises from the premise list.)</li>\n<li>a training and test set: formulas to prove (and possibly proofs for supervised learning)</li>\n<li>application: one needs to be able to quickly apply a rule/tactic</li>\n<li>persistence/backtracking: So that any tree search algorithm can be applied, one needs a notion of backtracking.  (Practically, this means that states need to be persistent.  If one applies a tactic it creates a new state, without changing the old state.  Think immutable data structures.)</li>\n</ul>",
        "id": 179011250,
        "sender_full_name": "Jason Rute",
        "timestamp": 1571962906
    },
    {
        "content": "<p>Now not all systems use all of the above.  A simple logical system, e.g. QBFs, may not use premise selection or tactic parameters.   A fully automatic system (e.g. an ATP like E-prover) may only have one tactic (solve) and the challenge is just premise selection.  Some systems also don’t have the backtracking, but that severely limits how effectively one can search.</p>",
        "id": 179011267,
        "sender_full_name": "Jason Rute",
        "timestamp": 1571962915
    },
    {
        "content": "<p>Now HOList has basically created a system like this in DeepHOL (although not very well documented) which they make easier to use by burying it in a docker container, so it just becomes a black box (a gym).  I also think they had to do a lot of work to make the persistence/backtracking thing work, but that is also not documented well.  I think the CoqGym and GamePad systems also try to do something similar for Coq.  In some systems like MetaMath, it shouldn’t be terribly hard to just rewrite the logic to make such an environment.  <strong>The question is, can Lean be abstracted into a system like this which is fast (and more importantly, it satisfies the persistence/backtracking requirement).</strong></p>",
        "id": 179011311,
        "sender_full_name": "Jason Rute",
        "timestamp": 1571962927
    },
    {
        "content": "<p>Getting back to the IMO challenge, I feel the goal is different than developing a training algorithm for an arbitrary neural theorem prover.  However, I agree that it isn’t clear if this project will attract those outside of the established Lean community or Microsoft Research because of the barrier to entry.  However, you are here @Brando, so maybe it is working. :)</p>",
        "id": 179011320,
        "sender_full_name": "Jason Rute",
        "timestamp": 1571962942
    },
    {
        "content": "<p>lean has always had a backtracking tactic state</p>",
        "id": 179011638,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1571963236
    },
    {
        "content": "<p>speed might be an issue, but possibly lean 4 has solved that problem</p>",
        "id": 179011649,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1571963252
    },
    {
        "content": "<p>But is it useable from the outside.  Could it be wrapped in a black box with a set number of tactics?  (So from the outside it is just like a chess board with a set number of possible moves?)</p>",
        "id": 179011742,
        "sender_full_name": "Jason Rute",
        "timestamp": 1571963330
    },
    {
        "content": "<p>I would really like a C++ API for doing this</p>",
        "id": 179011962,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1571963570
    },
    {
        "content": "<p>You can do it with lean --server but there is far too much overhead involved</p>",
        "id": 179011991,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1571963592
    },
    {
        "content": "<p>The IMO Grand challenge <a href=\"https://imo-grand-challenge.github.io\">https://imo-grand-challenge.github.io</a><br>\nrules state that the AI must be open-source, does this mean:<br>\n(a) Open code and open pre-training source and open inference source and open weights<br>\nor<br>\n(b) Open code and open inference source and open weights<br>\nor<br>\n(c) Open code and API calls</p>",
        "id": 492119997,
        "sender_full_name": "Iddo Drori",
        "timestamp": 1736175277
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"817095\">@Iddo Drori</span> The IMO grand challenge doesn’t really exist.  It was just an ambitious idea that went officially nowhere, but inspired a lot of work.  There is AIMO (which I think you have participated it). There are lots of benchmarks related to AI for IMO problems.  There are AI agents (like AlphaGeometry, AlphaProof, o1, o3, etc), that can do IMO problems at different levels of success, and I’m sure more to come.</p>",
        "id": 492123356,
        "sender_full_name": "Jason Rute",
        "timestamp": 1736176348
    },
    {
        "content": "<p>(speaking as someone who's listed on that web page, I can confirm Jason is correct)</p>",
        "id": 492126349,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1736177353
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"115715\">@Jason Rute</span> we're well aware of the field and different competitions.<br>\n<span class=\"user-mention\" data-user-id=\"110038\">@Kevin Buzzard</span> we'd appreciate an answer to the question:<br>\nDoes open source AI for the IMO grand challenge mean:<br>\n(a) Open source (such as OLMo 2)<br>\nor<br>\n(b) Open weights (such as DeepSeek V3)<br>\nor<br>\n(c) Code with API calls (such as o1)<br>\nBtw: Looks like Deepmind participated in the IMO grand challenge last year.</p>",
        "id": 492128969,
        "sender_full_name": "Gaston Longhitano",
        "timestamp": 1736178217
    },
    {
        "content": "<p>It is unlikely that the IMO-grand-challenge committee will ever make some formal response to your question so I would enjoy the freedom which this situation brings and make your own rules up.</p>",
        "id": 492130715,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1736178739
    },
    {
        "content": "<p>I do not agree with your claim that DeepMind partipated in the challenge last year. Firstly none of their work is open source in any of the senses you suggest above, and secondly they did not contact any of the committee members indicating that they were participating in any way.</p>",
        "id": 492130952,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1736178821
    },
    {
        "content": "<p>I have heard through the grapevine that there is at least one tech company that wants to participate in IMO 2025 in some kind of official way, but I am not involved in the organization of IMO 2025 in any way and I would suggest that you contact the IMO organizers directly if you have an interest in this.</p>",
        "id": 492131521,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1736178977
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"817114\">@Gaston Longhitano</span> My point is that these questions are meaningless.  There is no official committee or money behind the IMO Grand Challenge to adjudicate claims of solving the IMO Grand Challenge.  Daniel Selsam's views have almost certainly changed since he dreamed up the competition (as he works on o1-style reasoning at OpenAI), and the committee listed on that website doesn't meet.  Remember these rules came even before <del>Codex</del> GPT-3 was a thing, much less ChatGPT.  If one wants something official, like <span class=\"user-mention\" data-user-id=\"110038\">@Kevin Buzzard</span> says, I suggest they contact the official IMO 2025 organizers.  Or if one wants the XTX AIMO $1 million prize money, they contact that organization.  If you just want <em>the opinions</em> of the people in this chat forum, then lots of folks might have different answers.  I know for example <span class=\"user-mention\" data-user-id=\"266253\">@Joseph Myers</span> has strong views on this matter.</p>",
        "id": 492133927,
        "sender_full_name": "Jason Rute",
        "timestamp": 1736179684
    },
    {
        "content": "<p>If you would like to know Daniel's thought process he said this in 2021:<br>\n<span class=\"user-mention silent\" data-user-id=\"230999\">Daniel Selsam</span> <a href=\"#narrow/channel/208328-IMO-grand-challenge/topic/The.20Aim.20and.20Timeline.20IMO.20Grand.20Challenge/near/240066800\">said</a>:</p>\n<blockquote>\n<ul>\n<li>\n<p>related: how to ensure winning technology advances science as much as possible (i.e. is reproducible)?</p>\n<ul>\n<li>the original rules (requiring entire system be open-source and easily reproducible) is ideal but might not be feasible, e.g. if the NN is an org's singular $1B model, so we'll have to adjust the rules depending on the technical approaches taken</li>\n</ul>\n</li>\n</ul>\n</blockquote>",
        "id": 492137213,
        "sender_full_name": "Jason Rute",
        "timestamp": 1736180688
    },
    {
        "content": "<p>Although I guess there are betting markets, such as <a href=\"https://manifold.markets/FlorisvanDoorn/what-will-be-the-year-that-the-imo?play=true\">https://manifold.markets/FlorisvanDoorn/what-will-be-the-year-that-the-imo?play=true</a> by <span class=\"user-mention\" data-user-id=\"111080\">@Floris van Doorn</span> which reference these rules.  I guess they will have to figure out how to adjudicate this. <span aria-label=\"smile\" class=\"emoji emoji-1f642\" role=\"img\" title=\"smile\">:smile:</span></p>",
        "id": 492141812,
        "sender_full_name": "Jason Rute",
        "timestamp": 1736182083
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"110038\">@Kevin Buzzard</span>  Thank you for your response and confirming that:</p>\n<ol>\n<li>The IMO grand challenge committee exists.</li>\n<li>Deepmind did not participate in the IMO grand challenge.</li>\n</ol>\n<p>Btw: Perhaps we were confused by Deepmind's blog post (<a href=\"https://deepmind.google/discover/blog/ai-solves-imo-problems-at-silver-medal-level\">https://deepmind.google/discover/blog/ai-solves-imo-problems-at-silver-medal-level</a>) \"More recently, the annual IMO competition has also become widely recognised as a grand challenge in machine learning and an aspirational benchmark for measuring an AI system’s advanced mathematical reasoning capabilities.\"</p>",
        "id": 492141919,
        "sender_full_name": "Mao Mao",
        "timestamp": 1736182122
    },
    {
        "content": "<p>Thank you everyone, looking forward to IMO 2025 in Australia: <a href=\"https://imo2025.au\">https://imo2025.au</a></p>",
        "id": 492142288,
        "sender_full_name": "Iddo Drori",
        "timestamp": 1736182246
    },
    {
        "content": "<p>I very much hope that the IMO will embrace these new possibilities!</p>",
        "id": 492146216,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1736183594
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"817122\">Mao Mao</span> <a href=\"#narrow/stream/208328-IMO-grand-challenge/topic/general.20discussion/near/492141919\">said</a>:</p>\n<blockquote>\n<ol>\n<li>The IMO grand challenge committee exists.</li>\n</ol>\n</blockquote>\n<p>Maybe I’m belaboring this point but, there is a committee only in the sense that there are 7 names on a website.  I don’t think they have met in the last 3 years if not more.  I don’t think they have drafted rules (as I think those rules on the website predate the committee’s formation), and they certainly have never done anything official in regards to hosting or judging competitions.  If someone comes out and says “I’ve solved the IMO Grand Challenge” I’m not even sure if you could get the committee to meet to confirm this fits the criteria or add that achievement to their website.  <span class=\"user-mention\" data-user-id=\"110038\">@Kevin Buzzard</span> can correct me if I’m wrong.</p>",
        "id": 492147683,
        "sender_full_name": "Jason Rute",
        "timestamp": 1736184051
    },
    {
        "content": "<p>The IMO grand challenge is a website made about 6 years ago and literally nothing else, I do not know how I can stress this any more than I have already. It is vaporware. Jason's understanding is correct.</p>",
        "id": 492148667,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1736184360
    },
    {
        "content": "<p>Should the website be updated to reflect that?</p>",
        "id": 492153266,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1736185863
    },
    {
        "content": "<p>That's a question for Selsam. I have never had any access to the website or indeed done anything other than replying \"yes\" to an email Dan sent me 7 years ago; that is the totality of my contribution here.</p>",
        "id": 492154819,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1736186359
    },
    {
        "content": "<p>Yes!  If <span class=\"user-mention\" data-user-id=\"230999\">@Daniel Selsam</span> would be willing to add a note at the top it would go a long way to clarifying things.  He could even emphasize that while this website never materialized to an official competition, it has had tremendous influence including competitions like AIMO, Math AI like AlphaGeometry, AlphaProof, DeepSeek-Prover, o1, Gemini-Pro, o3, and benchmarks like MiniF2F, AIME 2024, IMO-Bench, Putnam-Bench, FrontierMath, etc.</p>",
        "id": 492155199,
        "sender_full_name": "Jason Rute",
        "timestamp": 1736186471
    },
    {
        "content": "<p>Hi folks, not really a lean user (although I am a math nerd and software engineer so maybe one day haha), but I joined this forum to mention that there are some <a href=\"https://kalshi.com/markets/kximoai/imo-ai\">additional betting markets</a> tied to this. I'm relatively familiar with how these markets work, and they will resolve the market to No if whomever comprises the \"IMO Grand Challenge Committee\" do not announce a winner and the $5 million <a href=\"https://aimoprize.com/\">AIMO grand prize</a> hasn't been won by year end. (Regardless of if the committee actually exists, etc.) In case you are curious in that market the <a href=\"https://kalshi-public-docs.s3.amazonaws.com/contract_terms/IMOAI.pdf\">contractual rules</a> state that the payout is achieved if \"either the IMO Grand Challenge/the AIMO Grand Prize has been won before &lt;date&gt;\"</p>\n<p>I've thought this market was inefficiently priced for a while now and have been lurking this channel, but I recently hit my max position size so no point keeping quiet. I think there's a lot of AI hype and not enough experts involved which has led to a rare poorly priced market. As \"the experts\" I'd be curious what you'd all peg the odds of an AI winning the AIMO grand prize or the (apparently non-existent) IMO grand challenge by year end? </p>\n<p>As I understand it, the AIMO is still in (relatively) early stages, as we're only at the second progress prize and it sounds like the IMO Grand Challenge isn't being won anytime soon as it isn't even really a thing anymore and is unlikely to ever be won. Is there something I'm missing that would explain why the markets think there's a 56% chance AI wins by year end other than hype?  Is there some official competition from XTX markets for the grand prize later this year? It doesn't sound like there are plans to reconvene the committee and award a prize. Anyways... it looks to me like you can buy $1 for $0.53 at the moment unless I've misunderstood the conversations in this thread. Sorry if this is off-topic, I assume when you folks originally came up with the IMO Grand Challenge you didn't think people would be betting on it years later. <span aria-label=\"joy\" class=\"emoji emoji-1f602\" role=\"img\" title=\"joy\">:joy:</span></p>",
        "id": 492428666,
        "sender_full_name": "Tristen Harr",
        "timestamp": 1736307397
    },
    {
        "content": "<p>I do think there is an excellent chance that multiple models will gold medal at the 2025 IMO (perhaps with somewhat relaxed standards about how the problems are presented to the models).</p>\n<p>If any of those are open-source-ish, I think there is going to be a pretty plausible argument to resolve yes, even if \"the IMO Grand Challenge\" doesn't actually exist in any meaningful way.</p>",
        "id": 492432239,
        "sender_full_name": "Kim Morrison",
        "timestamp": 1736310204
    },
    {
        "content": "<p>Are betting markets the reason all these questions popped up recently in this thread?</p>",
        "id": 492434865,
        "sender_full_name": "Jason Rute",
        "timestamp": 1736312333
    },
    {
        "content": "<p>Yes. People (myself included) have thousands of dollars on the line based on those old websites. </p>\n<p>While I’d agree about there being a plausible argument if we’re talking about multiple models potentially IMO gold medalling, unless it’s officially stated that the IMO Grand Challenge is won, or the XTX Markets $5 million grand prize is won it won’t count. They’re very specific about the contract rules, as these are regulated event contracts. You might say “a reasonable person would say an open-source AI won” but these often resolve on technicalities. If the committee is going to reconvene and announce an official winner then I’d hope they’d follow the rules laid out on the page, even if it’s outdated/irrelevant. Checkable by the Lean kernel in 10 minutes, no opportunity for partial credit, as much time as a human competitor, open sourced and publicly released before the first day of the IMO and easily reproducible alongside not having the capability to query the internet. I’d argue that it also ought to be F2F if there’s an official winner. I guess it would be whatever the committee decided though, although for the sake of people who did bet, I’d hope if the committee reconvenes and announces a winner, they would clarify that nobody won the original IMO Grand Challenge, unless someone actually does. It’s what is linked as the page that will be used to decide who wins the money. <span aria-label=\"sweat smile\" class=\"emoji emoji-1f605\" role=\"img\" title=\"sweat smile\">:sweat_smile:</span></p>\n<p>This zulip channel is linked from the page they say will be used to ultimately decide the winners of the bet. I'd almost guarantee if you've had a ton of questions popping up that is why.</p>",
        "id": 492435559,
        "sender_full_name": "Tristen Harr",
        "timestamp": 1736312653
    },
    {
        "content": "<p>It might sound silly, but my bet boils down to you folks not reconvening the committee and changing the website to say there is an official winner, and nobody winning the XTX markets grand prize by the end of the year. That’ll be what decides it. I guess your zulip channel has officially become high-stakes. <span aria-label=\"joy\" class=\"emoji emoji-1f602\" role=\"img\" title=\"joy\">:joy:</span> Anyways, I’ll leave you folks to it, hope I didn’t bother anyone, thanks for the info! If you have any other thoughts would love other expert opinions.</p>",
        "id": 492436397,
        "sender_full_name": "Tristen Harr",
        "timestamp": 1736313390
    },
    {
        "content": "<p>Sounds like there are some excellent market manipulation opportunities here!</p>",
        "id": 492438743,
        "sender_full_name": "Kim Morrison",
        "timestamp": 1736315314
    },
    {
        "content": "<p>I propose that Kevin \"announces\" a result that will cause the highest loss to people who have wasted time talking about betting markets on this zulip. :-)</p>",
        "id": 492439258,
        "sender_full_name": "Kim Morrison",
        "timestamp": 1736315761
    },
    {
        "content": "<p>The people who set up betting pools based on something that was an idea for a competition rather than ever being an actual fully-specified competition (and where some details in the idea may have been left behind by how AI has developed in the past five years) have created their own problem and it's probably for them to figure out what if anything to do to solve the problem they created!</p>",
        "id": 492497016,
        "sender_full_name": "Joseph Myers",
        "timestamp": 1736340411
    },
    {
        "content": "<p>Here are some key differences between DeepMind getting one point short of gold in 2024, and the principles for the IMO Grand Challenge as originally stated:</p>\n<ul>\n<li>The DeepMind AIs aren't open source (parts of AlphaGeometry 1 are open source, though I think not the synthetic data generation code; as far as I can tell, AlphaGeometry 2, as used for IMO 2024, hasn't been released).</li>\n<li>The DeepMind work used two separate languages (Lean for non-geometry, and an AlphaGeometry domain-specific language for geometry); the IMO Grand Challenge envisaged everything being in Lean.</li>\n<li>DeepMind prepared their own Lean versions of the problems, not following any externally defined conventions; the IMO Grand Challenge envisaged externally-agreed conventions and probably independently written Lean statements (\"We are working on a proposal for encoding IMO problems in Lean and will seek broad consensus on the protocol.\"). In particular, if you have multiple F2F entrants attempting the problems of a given IMO, they all ought to use the same Lean version of the problems (one Lean version per problem), for a proper comparison between those entrants.</li>\n</ul>",
        "id": 492499364,
        "sender_full_name": "Joseph Myers",
        "timestamp": 1736341185
    },
    {
        "content": "<p>And also:</p>\n<ul>\n<li>AlphaProof used a lot more wall-clock time than the same-time-limit-as-for-humans (4.5 hours per paper) rule in the IMO Grand Challenge.</li>\n</ul>",
        "id": 492499776,
        "sender_full_name": "Joseph Myers",
        "timestamp": 1736341305
    },
    {
        "content": "<p>Whilst I find Kim's suggestion <em>funny</em>, I am pretty sure that the committee will act sensibly here. Right now I have no evidence that the challenge was accomplished in 2024, with the only serious attempt AFAIK being DeepMind's AlphaProof, which did not satisfy the requirements as Joseph has clearly pointed out above. If there is something which gets closer in 2025 then clearly the committee will actually have to <em>do</em> something.</p>",
        "id": 492507315,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1736343739
    },
    {
        "content": "<p>I have contacted the other members of the IMO Grand Challenge committee and alerted them to the fact that we might be called on to make a ruling if it looks like a system has satisfied the criteria laid out on the website. </p>\n<p>I should also stress strongly here that the IMO Grand Challenge and the XTX-backed AIMO are unrelated projects (although they have connections, e.g. I am involved with both of them) and I am quite surprised that the two projects seem to be casually linked in the betting market links mentioned above. In stark contrast to the IMO Grand Challenge (which is just a website), the AIMO is a serious endeavour backed up by a committee who do do a lot of work and they can certainly be relied upon to make pronouncements on e.g. their progress prizes.</p>\n<p>I hope everything now is completely clear.</p>",
        "id": 492523122,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1736348556
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110038\">Kevin Buzzard</span> <a href=\"#narrow/channel/208328-IMO-grand-challenge/topic/general.20discussion/near/492131521\">said</a>:</p>\n<blockquote>\n<p>I have heard through the grapevine that there is at least one tech company that wants to participate in IMO 2025 in some kind of official way, but I am not involved in the organization of IMO 2025 in any way and I would suggest that you contact the IMO organizers directly if you have an interest in this.</p>\n</blockquote>\n<p>It would probably be best for anyone who wants to have their AI participate \"officially\" (whatever that means) to contact the IMO Board, since this is more a Board-level issue than one for the organizers of a particular IMO.</p>\n<p>And if you want something involving significant preparation on either the IMO side or the mathlib side (e.g. an official Lean version of the problems, or common externally agreed rules for all AI F2F entrants), it would be best to start the arrangements with the Board and others well in advance (e.g. now) so there is time for appropriate preparations to be made.</p>",
        "id": 492616589,
        "sender_full_name": "Joseph Myers",
        "timestamp": 1736388823
    }
]