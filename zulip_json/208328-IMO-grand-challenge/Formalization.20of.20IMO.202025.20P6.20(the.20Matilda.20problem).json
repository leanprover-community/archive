[
    {
        "content": "<p>Hi everyone,</p>\n<p>I’m excited to share a complete formalization of <strong>IMO 2025 Problem 6</strong>. To my knowledge, this is the first <code>sorry</code>-free solution for this problem in Lean 4. </p>\n<p>The proof spans about 4,700 lines. My approach focused on:</p>\n<ul>\n<li><strong>Lower bound</strong>: A set-theoretic topological partitioning of the grid, avoiding complex analytic boundary casework by using unions/intersections of discrete intervals, combined with the Erdős–Szekeres Theorem. I engineered a <strong>\"topological pivot\"</strong> region to identify required properties within discrete set intervals, avoiding the grueling analytic coordinate casework often associated with boundary conditions.</li>\n<li><strong>Upper bound</strong>: An explicit fiber-based construction using integer forms and linear congruences to ensure the tiles cover the grid correctly for the $n=k^2$ case.</li>\n</ul>\n<p>This was a high-intensity collaboration between human intuition and AI assistance. I acted as the lead architect, rigorously decomposing the problem into a granular series of lemmas, which were then implemented and cross-checked with the assistance of <strong>Gemini 3 Pro</strong>. This workflow allowed for a rapid yet verified formalization of this challenging combinatorics problem.</p>\n<p>The code is fully compatible with Lean <code>v4.28.0-rc1</code> and passes all CI checks. I have submitted a PR to <code>compfiles</code>:<br>\n<a href=\"https://github.com/dwrensha/compfiles/pull/166\">https://github.com/dwrensha/compfiles/pull/166</a></p>\n<p>Given the current length (~4,700 lines), I plan to golf and refactor the code to improve readability and eventually create a Lean Blueprint to visualize the proof's structure in the near future.</p>\n<p>I would be very grateful for any feedback from this amazing community. Thank you!</p>",
        "id": 573900905,
        "sender_full_name": "lean-tom",
        "timestamp": 1771078719
    },
    {
        "content": "<p>How many lines do you estimate an idiomatic solution to the problem will have?</p>",
        "id": 573906707,
        "sender_full_name": "Snir Broshi",
        "timestamp": 1771083592
    },
    {
        "content": "<p>Well done for achieving this. But in general you'll find that the community here is not particularly interested in giving feedback on AI-generated code. The generic feedback is \"yes we know AI can write lean code and it's typically very unidiomatic and about 5 to 10 times as long as a proof written by a human expert\".</p>",
        "id": 573907077,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1771083906
    },
    {
        "content": "<p>The <em>statement</em> is definitely a lot longer than necessary; it's longer than the statement I wrote in IMOLean, which itself is longer than necessary because I wasn't away of <a href=\"https://leanprover-community.github.io/mathlib4_docs/find/?pattern=NonemptyInterval#doc\">docs#NonemptyInterval</a> when I wrote it, and expressing the tiles with NonemptyInterval allows a very concise statement.</p>",
        "id": 573908858,
        "sender_full_name": "Joseph Myers",
        "timestamp": 1771085511
    },
    {
        "content": "<p>There are lots of different ways to solve this problem (you can find several posted on AoPS by someone on the PSC; unfortunately most years don't produce an official IMO solutions document such as I did for 2019 and 2024). I don't know the relative merits of the different solutions as regards complexity of formalization.</p>",
        "id": 573909373,
        "sender_full_name": "Joseph Myers",
        "timestamp": 1771085967
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110038\">Kevin Buzzard</span> <a href=\"#narrow/channel/208328-IMO-grand-challenge/topic/Formalization.20of.20IMO.202025.20P6.20.28the.20Matilda.20problem.29/near/573907077\">said</a>:</p>\n<blockquote>\n<p>it's typically very unidiomatic and about 5 to 10 times as long as a proof written by a human expert</p>\n</blockquote>\n<p>On the other hand, the same can be said about a Lean proof by a human non-expert. To me, it is a bit hard to distinguish this.</p>\n<p>I also don't feel very motivated reading code that even its author didn't understand properly , and understand that manually spending time trying to figure out how to make Lean satisfied without AI tools can make the author understand the code better. However</p>\n<ul>\n<li>is struggling with Lean without AI tools an efficiently spend time?</li>\n<li>does a beginner actually understand a proof when finishing some of the branches with chaotically trying out \"simp\", \"grind\", \"simp!\" until something gets through</li>\n</ul>",
        "id": 573913049,
        "sender_full_name": "Mirek Olšák",
        "timestamp": 1771089304
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"1029040\">@lean-tom</span> thanks for the contribution. I autogolfed it somewhat here: <a href=\"https://github.com/dwrensha/compfiles/commit/0cc1cecc554d86d10a2f081887e583a23ccd245a\">https://github.com/dwrensha/compfiles/commit/0cc1cecc554d86d10a2f081887e583a23ccd245a</a></p>",
        "id": 573913332,
        "sender_full_name": "David Renshaw",
        "timestamp": 1771089522
    },
    {
        "content": "<p>further simplifications welcome!</p>",
        "id": 573913377,
        "sender_full_name": "David Renshaw",
        "timestamp": 1771089562
    },
    {
        "content": "<p>Hi everyone, thank you so much for the warm welcome and the invaluable feedback!</p>\n<p><span class=\"user-mention\" data-user-id=\"243791\">@David Renshaw</span>  Thank you for the autogolf and for merging the PR! I’m honored to have this contribution in compfiles. I will continue to work on refactoring the code to make it more readable and idiomatic, as suggested.</p>\n<p><span class=\"user-mention\" data-user-id=\"110038\">@Kevin Buzzard</span>  I am taking your point about the noise in AI-assisted code to heart. I’m using this merged version as a \"scaffold\" to learn the Mathlib way, and I will do my best to understand and address this noise as I refactor the proof. My goal is to manually \"golf\" it into something concise and readable, and I’m eager to understand how a human expert would have structured the logic. This is very much a learning project for me.</p>\n<p><span class=\"user-mention\" data-user-id=\"266253\">@Joseph Myers</span>  Thank you for the pointer to <a href=\"https://leanprover-community.github.io/mathlib4_docs/find/?pattern=NonemptyInterval#doc\">docs#NonemptyInterval</a>. I’ve just refactored the ProblemSetup using it, and it already looks much cleaner and more concise! I can see how this abstraction will help eliminate a significant amount of manual coordinate casework and boundary-related lemmas as I refactor the rest of the proof.</p>\n<p><span class=\"user-mention\" data-user-id=\"933054\">@Snir Broshi</span>  It’s hard to estimate exactly as a Lean beginner, but given Kevin’s observation about the 5-10x factor, I suspect an idiomatic expert solution might land somewhere between 500 and 800 lines. My goal is to see how close I can get to that.</p>\n<p><span class=\"user-mention\" data-user-id=\"133339\">@Mirek Olšák</span>  Thank you for the support! You’ve hit on a key part of my workflow: using AI to bridge the initial \"syntax gap\" while I focused on the global logical architecture. Interestingly, the rigor required by Lean—facilitated by AI’s speed—led me to arrive at a set-theoretic topological approach to region partitioning. This was a deliberate strategic choice to bypass the messy analytic casework and instead capture the combinatorial essence of the Erdős–Szekeres application within discrete intervals. While experts might find such an approach redundant, it was a perspective I arrived at because Lean forced me to find a more robust logical structure than my initial pen-and-paper intuition. I’m still learning whether this is the most efficient path, but this formalization process itself has already deeply reshaped my understanding of the problem.</p>",
        "id": 573959737,
        "sender_full_name": "lean-tom",
        "timestamp": 1771143389
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"243791\">@David Renshaw</span>  Thank you so much for the additional refactoring! I’m embarrassed to admit that while you were golfing my code from 4,700 to 3,700 lines (and significantly collapsing the exhaustive casework I had initially expanded to around 50 cases), I was so buried in studying Mathlib's design patterns and Leonardo's blog that I haven't even caught up with your latest changes yet.<br>\nOver the past two weeks, inspired by Joseph Myers’ code and the feedback regarding redundancy or noise, I’ve been obsessed with finding a \"sparsifying\" backbone for this proof.<br>\nI’m currently designing a roadmap to refactor the Sufficiency (Upper Bound) part using a bivariate polynomial approach in <code>Z[X, Y]</code>. My goal is to prove the tiling’s validity through algebraic identities.</p>\n<p>The Roadmap:</p>\n<p>Map each cell (i,j) to the monomial <code>X^i * Y^j</code>.<br>\nRepresent the entire grid and each rectangular tile as polynomials in <code>Z[X, Y]</code>.<br>\nUtilize the property that a tiling corresponds to a direct sum decomposition, which translates to a polynomial sum identity.<br>\nUse geometric series to represent the tiles and verify the partition algebraically using the ring tactic.<br>\nWhile this strategy might seem elementary or inefficient to the experts here, I want to ensure I’m building on the right Mathlib's direction.<br>\nQuestions:</p>\n<p>Are there specific files or lemmas in Mathlib regarding MvPolynomial that would be particularly effective for this kind of tiling problem?<br>\nIs there a preferred \"idiomatic\" way to bridge the gap between a Finset of coordinates and its polynomial representation?<br>\nI’d appreciate any guidance on whether this \"sparsifying\" direction is aligned with Mathlib's standards, or if there’s a more direct way I should be looking at. Thank you!</p>",
        "id": 575830506,
        "sender_full_name": "lean-tom",
        "timestamp": 1772040256
    },
    {
        "content": "<p>What do you expect to <em>gain</em> from an MvPolynomial formulation? Why do you want to make this change? In general, it's bringing in a lot of extra \"machinery\" that feels irrelevant. So, probably, all the facts that you need about MvPolynomial are better expressed in some simpler structure.</p>",
        "id": 575833290,
        "sender_full_name": "Alex Meiburg",
        "timestamp": 1772041090
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"448405\">@Alex Meiburg</span>  Thank you for the sharp observation. I see now that bringing in the full \"machinery\" of Mvpolynomial would indeed be overengineering for this problem.  After reflecting on your comment, I realized that I don't even need polynomials and geometric series formulas. The core algebraic idea I was aiming for can be expressed much more simply: by representing the grid cells via indicator functions and expressing each rectangle  via differences, leading to telescoping sum for the whole tiling.</p>\n<p>My goal isn't to use ring theory, but simply to translate the geometric casework into a verifiable algebraic calculation.<br>\nMotivation for the change: My initial thought was to find a more \"generalizable\" approach that could handle complex tilings on Z-grids (beyond just n×n squares) by converting geometric shapes into algebraic calculation. I wanted to avoid the extensive coordinate-based casework. </p>\n<p>I’m still learning where the line is between \"elegant generalization\" and \"unnecessary machinery.\"<br>\nThank you again for helping me find a simpler path!</p>",
        "id": 576005376,
        "sender_full_name": "lean-tom",
        "timestamp": 1772107475
    }
]