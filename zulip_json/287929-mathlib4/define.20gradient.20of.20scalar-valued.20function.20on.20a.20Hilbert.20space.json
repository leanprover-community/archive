[
    {
        "content": "<p>Hello, <span class=\"user-mention\" data-user-id=\"614366\">@Chenyi Li</span>  and I are the authors of the pull requese <a href=\"https://github.com/leanprover-community/mathlib4/pull/7074\">#7074( feat: define gradient of scalar-valued function on a Hilbert space)</a>. We have noticed the reviewer's comments on GitHub and greatly appreciated the reviewer's efforts.<br>\nWe are working on formalizing Computational mathematics and starting with Convex Optimization. <br>\nIn Computational mathematics, we mainly focused on functions from R^n  to R, for which the gradient might offer a more concise way of representation. <br>\nAlso, in practical and physical applications, the computation of the gradient is often simpler and more efficient, especially for common numerical methods. <br>\nGiven the direct significance of the gradient in many applications (such as multivariate function ODEs, g numerical algebra, numerical analysis, the theory of machine learning and deep learning, optimization algorithms, etc.), introducing it in the library could make the library more appealing and practical.<br>\nSo, we think the introduction of <code>Gradient</code> is significant and will address the issue raised by the reviewer. After successfully uploading, we will subsequently upload the formalizations of the theorems related to the <code>first-order conditions of convex functions (strongly convex functions)</code> and the convergence rate of <code>Gradient Descent Method</code></p>",
        "id": 390212910,
        "sender_full_name": "Ziyu Wang",
        "timestamp": 1694394658
    },
    {
        "content": "<p>Hello, <span class=\"user-mention\" data-user-id=\"615957\">@Ziyu Wang</span>  and I are working on the pull requese <a href=\"https://github.com/leanprover-community/mathlib4/pull/7074\">#7074</a>( feat: define gradient of scalar-valued function on a Hilbert space). When examining optimization methods such as gradient descent or stochastic gradient descent, one must directly compute <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>x</mi><mo>−</mo><mi>α</mi><mi mathvariant=\"normal\">∇</mi><mi>f</mi><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">x−\\alpha \\nabla f(x)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6667em;vertical-align:-0.0833em;\"></span><span class=\"mord mathnormal\">x</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.0037em;\">α</span><span class=\"mord\">∇</span><span class=\"mord mathnormal\" style=\"margin-right:0.10764em;\">f</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">x</span><span class=\"mclose\">)</span></span></span></span>. In numerous contexts, additional calculations utilizing the derivative information become indispensable. Utilizing only 'fderiv' poses challenges in handling the subtraction of a vector x from a continuous linear map in <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msup><mi mathvariant=\"double-struck\">R</mi><mi>n</mi></msup></mrow><annotation encoding=\"application/x-tex\">\\mathbb{R}^n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6889em;\"></span><span class=\"mord\"><span class=\"mord mathbb\">R</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6644em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">n</span></span></span></span></span></span></span></span></span></span></span>. This underscores the imperative need to integrate a gradient definition into mathlib.</p>",
        "id": 390213577,
        "sender_full_name": "Chenyi Li",
        "timestamp": 1694394925
    },
    {
        "content": "<p>Thank you for starting this conversation, <span class=\"user-mention\" data-user-id=\"615957\">@Ziyu Wang</span> and <span class=\"user-mention\" data-user-id=\"614366\">@Chenyi Li</span>.  I am the reviewer who suggested discussing whether a separate theory of gradients should be added.  Let me ping some authors and users of the multivariable calculus library: <span class=\"user-mention\" data-user-id=\"268315\">@Anatole Dedecker</span> <span class=\"user-mention\" data-user-id=\"412682\">@Moritz Doll</span> <span class=\"user-mention\" data-user-id=\"110050\">@Sebastien Gouezel</span> <span class=\"user-mention\" data-user-id=\"110031\">@Patrick Massot</span> <span class=\"user-mention\" data-user-id=\"240862\">@Oliver Nash</span> <span class=\"user-mention\" data-user-id=\"214703\">@Yury G. Kudryashov</span></p>",
        "id": 390214016,
        "sender_full_name": "Heather Macbeth",
        "timestamp": 1694395130
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"614366\">Chenyi Li</span> <a href=\"#narrow/stream/287929-mathlib4/topic/define.20gradient.20of.20scalar-valued.20function.20on.20a.20Hilbert.20space/near/390213577\">said</a>:</p>\n<blockquote>\n<p>Hello, <span class=\"user-mention silent\" data-user-id=\"615957\">Ziyu Wang</span>  and I are working on the pull requese <a href=\"https://github.com/leanprover-community/mathlib4/pull/7074\">#7074</a>( feat: define gradient of scalar-valued function on a Hilbert space). When examining optimization methods such as gradient descent or stochastic gradient descent, one must directly compute <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>x</mi><mo>−</mo><mi>α</mi><mi mathvariant=\"normal\">∇</mi><mi>f</mi><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">x−\\alpha \\nabla f(x)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6667em;vertical-align:-0.0833em;\"></span><span class=\"mord mathnormal\">x</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.0037em;\">α</span><span class=\"mord\">∇</span><span class=\"mord mathnormal\" style=\"margin-right:0.10764em;\">f</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">x</span><span class=\"mclose\">)</span></span></span></span>. In numerous contexts, additional calculations utilizing the derivative information become indispensable. Utilizing only 'fderiv' poses challenges in handling the subtraction of a vector x from a continuous linear map in <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msup><mi mathvariant=\"double-struck\">R</mi><mi>n</mi></msup></mrow><annotation encoding=\"application/x-tex\">\\mathbb{R}^n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6889em;\"></span><span class=\"mord\"><span class=\"mord mathbb\">R</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6644em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">n</span></span></span></span></span></span></span></span></span></span></span>. This underscores the imperative need to integrate a gradient definition into mathlib.</p>\n</blockquote>\n<p>I think what you want there is <code>innerSL k x - α \\smul fderiv k f x</code>.</p>",
        "id": 390218587,
        "sender_full_name": "Moritz Doll",
        "timestamp": 1694397697
    },
    {
        "content": "<p>Moritz, the issue is they want the result to have the same type as <code>x</code> if this meant as a step in a gradient descent algorithm. Of course you could apply the isomorphism from the dual to the original space. This would be a bit cumbersome, but maybe less than duplicating so many lemmas about differentials.</p>",
        "id": 390219479,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1694398223
    },
    {
        "content": "<p>Or simply we could inline the definition and see how many lemmas we need to actually prove some numerical analysis theorem.</p>",
        "id": 390219616,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1694398323
    },
    {
        "content": "<p>I'm torn here.</p>\n<p>An argument in favour: we have <code>deriv</code>, a special-casing-for-convenience of <code>fderiv</code> when the <em>domain</em> is a scalar, so why not also add a special-casing-for-convenience of <code>fderiv</code> when the <em>codomain</em> is a scalar?</p>\n<p>An argument against: it's tedious work to build out a full theory in which all actual mathematical content is obtained by special-casing more general results, and may be particularly frustrating for authors who are new mathlib contributors and have to learn all our conventions by trial and error over the course of the review.</p>",
        "id": 390220059,
        "sender_full_name": "Heather Macbeth",
        "timestamp": 1694398576
    },
    {
        "content": "<p>I think that it makes sense to have <code>grad</code> as a separate definition.</p>",
        "id": 390233573,
        "sender_full_name": "Yury G. Kudryashov",
        "timestamp": 1694407116
    },
    {
        "content": "<p>Given how useful the gradient is in many situations, I have no doubt we should have it as a first class citizen, roughly on par with <code>deriv</code>. In particular, we should have all the API like <code>HasGradientWithinAt</code> and so on. On the other hand, it should definitely not be defined just by itself, but in terms of <code>fderiv</code> and the canonical isomorphism between the space and its dual. In this way, most results in the API should derive directly from the corresponding <code>fderiv</code> lemmas.</p>",
        "id": 390237442,
        "sender_full_name": "Sebastien Gouezel",
        "timestamp": 1694409557
    },
    {
        "content": "<p>And it's true that it's a difficult PR for newcomers!</p>",
        "id": 390238026,
        "sender_full_name": "Sebastien Gouezel",
        "timestamp": 1694409944
    },
    {
        "content": "<p>A good way to do it would probably be to start over from the file <code>Deriv.lean</code> and adapt it, replacing <code>Deriv</code> with <code>Gradient</code> and <code>deriv</code> with <code>grad</code> in most statements.</p>",
        "id": 390244450,
        "sender_full_name": "Sebastien Gouezel",
        "timestamp": 1694413653
    },
    {
        "content": "<p>I also agree it's worth having this special case of <code>fderiv</code> and I especially agree with the suggestion to model the new API on the relevant parts of the <code>Deriv.lean</code>.</p>",
        "id": 390274830,
        "sender_full_name": "Oliver Nash",
        "timestamp": 1694426251
    },
    {
        "content": "<p>The only unanswered question I see is whether we should specialise to the case that the domain is an inner-product space so that the gradient can be defined to take values in <code>F</code> rather than <code>NormedSpace.Dual 𝕜 F</code>? I would say \"yes\" (this is what the PR does).</p>",
        "id": 390274963,
        "sender_full_name": "Oliver Nash",
        "timestamp": 1694426290
    },
    {
        "content": "<p>So then I suppose a possible start might be:</p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"kn\">import</span> <span class=\"n\">Mathlib.Analysis.InnerProductSpace.Dual</span>\n<span class=\"kn\">import</span> <span class=\"n\">Mathlib.Analysis.Calculus.FDeriv.Basic</span>\n\n<span class=\"kd\">noncomputable</span> <span class=\"kn\">section</span>\n\n<span class=\"kn\">open</span> <span class=\"n\">Topology</span>\n\n<span class=\"kd\">variable</span> <span class=\"o\">{</span><span class=\"bp\">𝕜</span> <span class=\"n\">F</span> <span class=\"o\">:</span> <span class=\"kt\">Type</span><span class=\"bp\">*</span><span class=\"o\">}</span> <span class=\"o\">[</span><span class=\"n\">IsROrC</span> <span class=\"bp\">𝕜</span><span class=\"o\">]</span> <span class=\"o\">[</span><span class=\"n\">NormedAddCommGroup</span> <span class=\"n\">F</span><span class=\"o\">]</span> <span class=\"o\">[</span><span class=\"n\">InnerProductSpace</span> <span class=\"bp\">𝕜</span> <span class=\"n\">F</span><span class=\"o\">]</span> <span class=\"o\">[</span><span class=\"n\">CompleteSpace</span> <span class=\"n\">F</span><span class=\"o\">]</span>\n  <span class=\"o\">(</span><span class=\"n\">f</span> <span class=\"o\">:</span> <span class=\"n\">F</span> <span class=\"bp\">→</span> <span class=\"bp\">𝕜</span><span class=\"o\">)</span> <span class=\"o\">(</span><span class=\"n\">f'</span> <span class=\"o\">:</span> <span class=\"n\">F</span><span class=\"o\">)</span>\n\n<span class=\"c1\">-- Optionally one could use `InnerProductSpace.toDualMap` and not require `CompleteSpace F` till</span>\n<span class=\"c1\">-- later but I doubt there's any point.</span>\n<span class=\"kd\">def</span> <span class=\"n\">HasGradientAtFilter</span> <span class=\"o\">(</span><span class=\"n\">x</span> <span class=\"o\">:</span> <span class=\"n\">F</span><span class=\"o\">)</span> <span class=\"o\">(</span><span class=\"n\">L</span> <span class=\"o\">:</span> <span class=\"n\">Filter</span> <span class=\"n\">F</span><span class=\"o\">)</span> <span class=\"o\">:=</span>\n  <span class=\"n\">HasFDerivAtFilter</span> <span class=\"n\">f</span> <span class=\"o\">(</span><span class=\"n\">InnerProductSpace.toDual</span> <span class=\"bp\">𝕜</span> <span class=\"n\">F</span> <span class=\"n\">f'</span><span class=\"o\">)</span> <span class=\"n\">x</span> <span class=\"n\">L</span>\n\n<span class=\"kd\">def</span> <span class=\"n\">HasGradientWithinAt</span> <span class=\"o\">(</span><span class=\"n\">s</span> <span class=\"o\">:</span> <span class=\"n\">Set</span> <span class=\"n\">F</span><span class=\"o\">)</span> <span class=\"o\">(</span><span class=\"n\">x</span> <span class=\"o\">:</span> <span class=\"n\">F</span><span class=\"o\">)</span> <span class=\"o\">:=</span>\n  <span class=\"n\">HasGradientAtFilter</span> <span class=\"n\">f</span> <span class=\"n\">f'</span> <span class=\"n\">x</span> <span class=\"o\">(</span><span class=\"bp\">𝓝</span><span class=\"o\">[</span><span class=\"n\">s</span><span class=\"o\">]</span> <span class=\"n\">x</span><span class=\"o\">)</span>\n\n<span class=\"kd\">def</span> <span class=\"n\">HasGradientAt</span> <span class=\"o\">(</span><span class=\"n\">x</span> <span class=\"o\">:</span> <span class=\"n\">F</span><span class=\"o\">)</span> <span class=\"o\">:=</span>\n  <span class=\"n\">HasGradientAtFilter</span> <span class=\"n\">f</span> <span class=\"n\">f'</span> <span class=\"n\">x</span> <span class=\"o\">(</span><span class=\"bp\">𝓝</span> <span class=\"n\">x</span><span class=\"o\">)</span>\n\n<span class=\"c1\">-- Probably don't want this because we're over `ℝ` or `ℂ`.</span>\n<span class=\"c1\">-- def HasStrictGradientAt (x : F) :=</span>\n<span class=\"c1\">--   HasStrictFDerivAt f (InnerProductSpace.toDual 𝕜 F f') x</span>\n\n<span class=\"kd\">def</span> <span class=\"n\">gradient</span> <span class=\"o\">(</span><span class=\"n\">f</span> <span class=\"o\">:</span> <span class=\"n\">F</span> <span class=\"bp\">→</span> <span class=\"bp\">𝕜</span><span class=\"o\">)</span> <span class=\"o\">(</span><span class=\"n\">x</span> <span class=\"o\">:</span> <span class=\"n\">F</span><span class=\"o\">)</span> <span class=\"o\">:</span> <span class=\"n\">F</span> <span class=\"o\">:=</span> <span class=\"o\">(</span><span class=\"n\">InnerProductSpace.toDual</span> <span class=\"bp\">𝕜</span> <span class=\"n\">F</span><span class=\"o\">)</span><span class=\"bp\">.</span><span class=\"n\">symm</span> <span class=\"o\">(</span><span class=\"n\">fderiv</span> <span class=\"bp\">𝕜</span> <span class=\"n\">f</span> <span class=\"n\">x</span><span class=\"o\">)</span>\n\n<span class=\"c1\">-- TODO Lots of API</span>\n</code></pre></div>",
        "id": 390276545,
        "sender_full_name": "Oliver Nash",
        "timestamp": 1694426846
    },
    {
        "content": "<p>Even though I'm the first one to annoy people by using Fréchet derivatives instead of gradients, I think it makes sense to have it in mathlib. The example of gradient descent is quite convincing, and I'm pretty sure I had thoughts of a few cases where it does indeed make our life easier. The only one I can think of right now is defining the Laplacian in a way that is obviously invariant under change of orthonormal basis, by <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi mathvariant=\"normal\">Δ</mi><mi>f</mi><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo><mo>=</mo><mrow><mi mathvariant=\"normal\">T</mi><mi mathvariant=\"normal\">r</mi></mrow><msub><mi>D</mi><mi>x</mi></msub><mo stretchy=\"false\">(</mo><mrow><mi mathvariant=\"normal\">g</mi><mi mathvariant=\"normal\">r</mi><mi mathvariant=\"normal\">a</mi><mi mathvariant=\"normal\">d</mi></mrow><mi>f</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">\\Delta f(x) = \\mathrm{Tr} D_x(\\mathrm{grad} f)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\">Δ</span><span class=\"mord mathnormal\" style=\"margin-right:0.10764em;\">f</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">x</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathrm\">Tr</span></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">D</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.1514em;\"><span style=\"top:-2.55em;margin-left:-0.0278em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">x</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathrm\">grad</span></span><span class=\"mord mathnormal\" style=\"margin-right:0.10764em;\">f</span><span class=\"mclose\">)</span></span></span></span> (aka divergence of gradient).</p>",
        "id": 390297364,
        "sender_full_name": "Anatole Dedecker",
        "timestamp": 1694434467
    },
    {
        "content": "<p>Regarding the actual implementation, the thing I'm not sure about is how much duplication do we need. In particular, I don't know if we really want <code>HasGradientAt</code> instead of just <code>gradient</code> (or <code>grad</code>, I don't care about the name). If we do want the predicate, I think we might as well use <a href=\"https://leanprover-community.github.io/mathlib4_docs/find/?pattern=InnerProductSpace.toDualMap#doc\">docs#InnerProductSpace.toDualMap</a> instead of <a href=\"https://leanprover-community.github.io/mathlib4_docs/find/?pattern=InnerProductSpace.toDual#doc\">docs#InnerProductSpace.toDual</a> because it's technically more general (although arguably we may not care) and it doesn't cost anything.</p>",
        "id": 390298755,
        "sender_full_name": "Anatole Dedecker",
        "timestamp": 1694435005
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"240862\">@Oliver Nash</span> ,we  agree with your perspective. Currently, it seems essential to formalize the gradient. However, we might need to modify our format, mirroring the <code>deriv.lean</code> file by defining <code>HasGradientWithinAt</code>, <code>HasGradientAtFilter</code>, <code>HasGradientAt</code>, and <code>gradient</code>. We plan to revise our code this week, but there may be some improvements in naming, such as changing <code>gradient</code> to <code>∇</code>. Furthermore, students participating in our computational mathematics formalization group hope that our work of translating the language into an \\(\\epsilon-\\delta\\) language will be preserved. Many scenarios in computational mathematics and most of the existing proofs are based on the \\(\\epsilon-\\delta\\) language. Using <code>Filter</code> for formalizing computational mathematics, especially for beginners, is out of sync with mainstream non-formalized textbooks, which can pose some obstacles in use.</p>",
        "id": 390354440,
        "sender_full_name": "Ziyu Wang",
        "timestamp": 1694451979
    },
    {
        "content": "<p>I think keeping the epsilon-delta changes (assuming you're using them as hypothesis and in definitions) will be a rather harder sell I'm afraid, though im not the best person to explain why</p>",
        "id": 390355549,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1694452407
    },
    {
        "content": "<p>The main reason is that most students who have undergone mathematical analysis and computational mathematics training have not been exposed to <code>Filter</code>. We merely hope to retain the interfaces of a few theorems for subsequent formalization. We will adhere to <code>Filter</code> for refining the definition of the gradient itself. However, most of the subsequent theorems in computational mathematics are essentially defined as vector-valued functions from <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msup><mi mathvariant=\"double-struck\">R</mi><mi>n</mi></msup></mrow><annotation encoding=\"application/x-tex\">\\mathbb{R}^n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6889em;\"></span><span class=\"mord\"><span class=\"mord mathbb\">R</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6644em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">n</span></span></span></span></span></span></span></span></span></span></span>   to <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi mathvariant=\"double-struck\">R</mi></mrow><annotation encoding=\"application/x-tex\"> \\mathbb{R}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6889em;\"></span><span class=\"mord mathbb\">R</span></span></span></span> and the epsilon-delta language is sufficient for these purposes.</p>",
        "id": 390356418,
        "sender_full_name": "Ziyu Wang",
        "timestamp": 1694452767
    },
    {
        "content": "<p>sufficient ≠ easiest to use. In general, I would advocate for sticking with <code>Filter</code> language everywhere, and only going to <code>ε</code> and <code>δ</code> within proofs when necessary.</p>",
        "id": 390360408,
        "sender_full_name": "Jireh Loreaux",
        "timestamp": 1694454375
    },
    {
        "content": "<p>I should say that I develop real analysis with epsilons and deltas very early on my course, but my course is independent of mathlib (it uses mathlib, but in this part of the course I am just teaching them basic tactics). If the goal is to extend mathlib then you should do things the mathlib way, there's no point fighting it.</p>",
        "id": 390361165,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1694454706
    },
    {
        "content": "<p>But Kevin, you never do one-sided limits I guess? Otherwise combining all the different notions of convergence is absolutely hellish.</p>",
        "id": 390362019,
        "sender_full_name": "Jireh Loreaux",
        "timestamp": 1694455063
    },
    {
        "content": "<p>yeah this is just a warm-up: I get them to prove limit of sum is sum of limits and limit of product is product of limits, and at the end of it they've seen <code>specialize</code> and <code>ring</code> and <code>linarith</code> etc etc; we then go on to group theory.</p>",
        "id": 390362288,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1694455162
    },
    {
        "content": "<p>Crucially, we then <em>throw this code away</em> and never use it again.</p>",
        "id": 390362353,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1694455183
    },
    {
        "content": "<p>I definitely agree with everyone here that you should state everything using the filter API. But <em>in principle</em> you shouldn't have to know much about filters for this to work. You can just think of filters as \"a way something can converge\" and <a href=\"https://leanprover-community.github.io/mathlib4_docs/find/?pattern=Tendsto#doc\">docs#Tendsto</a> as \"when <code>x</code> converges in some way, <code>f(x)</code> converges in some other way\". More importantly, if you need to translate from filters to epsilon/deltas, we <em>should</em> have the necessary API (by which I mean we probably don't have it but it has its place in mathlib). <br>\nMost importantly, do not hesitate to ask for help on this, there are plenty of people who will be willing to help!</p>",
        "id": 390382210,
        "sender_full_name": "Anatole Dedecker",
        "timestamp": 1694463668
    },
    {
        "content": "<p>Mostly agreed, but I'm betting we have most of the necessary API already. I did this as an exercise with my students at one point (taking statements in filter language and showing they were equivalent using the library to the concrete (i.e., <code>ε</code> and <code>δ</code>) definition, and we didn't really run into any problems.</p>",
        "id": 390384646,
        "sender_full_name": "Jireh Loreaux",
        "timestamp": 1694464729
    },
    {
        "content": "<p>BTW, I think that we don't really need <a href=\"https://leanprover-community.github.io/mathlib4_docs/find/?pattern=HasFDerivAtFilter#doc\">docs#HasFDerivAtFilter</a>, just <a href=\"https://leanprover-community.github.io/mathlib4_docs/find/?pattern=HasFDerivWithinAt#doc\">docs#HasFDerivWithinAt</a> and <code>HasFDerivAt f f' x := HasFDerivWithinAt f f' univ x</code>.</p>",
        "id": 390405029,
        "sender_full_name": "Yury G. Kudryashov",
        "timestamp": 1694474150
    },
    {
        "content": "<p>At least, we never use <code>HasFDerivAtFilter</code> with a filter other than <code>nhds</code> or <code>nhdsWithin</code>.</p>",
        "id": 390405121,
        "sender_full_name": "Yury G. Kudryashov",
        "timestamp": 1694474178
    },
    {
        "content": "<p>Or do we (plan to) use it with something like <code>𝓝 x ⊓ μ.ae</code>?</p>",
        "id": 390405238,
        "sender_full_name": "Yury G. Kudryashov",
        "timestamp": 1694474243
    },
    {
        "content": "<p>Hello everyone, we have revised our <a href=\"https://github.com/leanprover-community/mathlib4/pull/7074\">code</a> and created the files Gradient.Basic and Gradient.Calculus. Basic includes definitions of gradient (HasGradientAtFilter, HasGradientWithinAt, HasGradientAt, Gradient), its relationship with Fderiv and Deriv, its relationship with continuity, conversion to the little o notation, and so on. Calculus mainly covers the chain rule for scalar functions composed of vector functions, gradient addition, multiplication, finite addition, finite multiplication, and more. We recently hope to cultivate more students at PKU to engage in the formalization of computational mathematics. Therefore, we hope to upload the gradient-related content to Mathlib soon and look forward to the reviews from experts.</p>",
        "id": 392944070,
        "sender_full_name": "Ziyu Wang",
        "timestamp": 1695630689
    },
    {
        "content": "<p>So what should we do next to upload our code? We have revised the question in <a href=\"https://github.com/leanprover-community/mathlib4/pull/7074\">#7074</a></p>",
        "id": 393255744,
        "sender_full_name": "Ziyu Wang",
        "timestamp": 1695740756
    },
    {
        "content": "<p>As I asked on the PR, could you resolve all conversations which you think are resolved? Otherwise, we can't know if there are still pending issues.</p>",
        "id": 393261869,
        "sender_full_name": "Sebastien Gouezel",
        "timestamp": 1695741987
    },
    {
        "content": "<p>To be clear: Sebastien means literally \"click the 'resolve' button\", after you have addressed the issue.</p>",
        "id": 393263013,
        "sender_full_name": "Jireh Loreaux",
        "timestamp": 1695742198
    },
    {
        "content": "<p>If the resolution isn't trivial, sometimes it's better to reply to the threads with something like \"I think I resolved this by doing X, please check it looks ok\"</p>",
        "id": 393264987,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1695742611
    },
    {
        "content": "<p>Sorry that this is our first time to upload something to Mathlib. We clicked the 'resolve button' just now.</p>",
        "id": 393266144,
        "sender_full_name": "Ziyu Wang",
        "timestamp": 1695742933
    },
    {
        "content": "<p>I have pushed a review.</p>",
        "id": 393282844,
        "sender_full_name": "Sebastien Gouezel",
        "timestamp": 1695747161
    },
    {
        "content": "<p>Thanks, we will correct our file tomorrow</p>",
        "id": 393283180,
        "sender_full_name": "Ziyu Wang",
        "timestamp": 1695747248
    },
    {
        "content": "<p>We have revised our code last week, is there any expert who can take a look at it on GitHub?</p>",
        "id": 396501523,
        "sender_full_name": "Ziyu Wang",
        "timestamp": 1697202088
    }
]