[
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110049\">Mario Carneiro</span> <a href=\"#narrow/stream/287929-mathlib4/topic/port.20benchmark/near/340975442\">said</a>:</p>\n<blockquote>\n<p>ooh, this is really useful data. Can the port benchmark bot collect it?</p>\n</blockquote>\n<p>Some of you may already know <a href=\"http://speedcenter.informatik.kit.edu/velcom\">http://speedcenter.informatik.kit.edu/velcom</a>, which we use to track performance regressions in the lean4 repo. I've now set up a mathlib4 version at <a href=\"http://speedcenter.informatik.kit.edu/mathlib4\">http://speedcenter.informatik.kit.edu/mathlib4</a>. It compiles every new commit on <code>master</code> once; we'll see how long that will scale. For now I've retroactively benchmarked a few old commits to get a sense of the evolution of build times. Unsurprisingly, lines go up, though you can also see the positive impact of <a href=\"https://github.com/leanprover/lean4/pull/2003\">lean4#2003</a> for which I specifically selected the adjacent commits. If there are any other interesting commits for which you want to see the specific deltas, I can add those to the queue as well. <a href=\"/user_uploads/3121/qQts4DBBVNLLe3ENxQ_pQs0-/image.png\">image.png</a></p>\n<div class=\"message_inline_image\"><a href=\"/user_uploads/3121/qQts4DBBVNLLe3ENxQ_pQs0-/image.png\" title=\"image.png\"><img src=\"/user_uploads/3121/qQts4DBBVNLLe3ENxQ_pQs0-/image.png\"></a></div><p><a href=\"http://speedcenter.informatik.kit.edu/mathlib4/repo-detail/e7b27246-a3e6-496a-b552-ff4b45c7236e?zoomXStart=1667257200000&amp;zoomXEnd=1678921200000&amp;dimensions=build%3Aelaboration%3Awall-clock%3Ainterpretation%3A.olean%20serialization%3Acompilation%3Atypeclass%20inference%3Adsimp%3Ainitialization%3Aimport%3AC%20code%20generation%3Acompilation%20new%3Anorm_num%3Aring%3Aparsing%3Alinting%3Atask-clock%3Asimp&amp;dayEquidistant=true\">http://speedcenter.informatik.kit.edu/mathlib4/repo-detail/e7b27246-a3e6-496a-b552-ff4b45c7236e?zoomXStart=1667257200000&amp;zoomXEnd=1678921200000&amp;dimensions=build%3Aelaboration%3Awall-clock%3Ainterpretation%3A.olean%20serialization%3Acompilation%3Atypeclass%20inference%3Adsimp%3Ainitialization%3Aimport%3AC%20code%20generation%3Acompilation%20new%3Anorm_num%3Aring%3Aparsing%3Alinting%3Atask-clock%3Asimp&amp;dayEquidistant=true</a></p>",
        "id": 342052914,
        "sender_full_name": "Sebastian Ullrich",
        "timestamp": 1678885941
    },
    {
        "content": "<p>Finally, as each commit is benchmarked exactly once, a bit of noise is to be expected</p>",
        "id": 342053176,
        "sender_full_name": "Sebastian Ullrich",
        "timestamp": 1678886019
    },
    {
        "content": "<p>It might be interesting to have another version which scales the y axis to account for number of files / lines</p>",
        "id": 342054011,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1678886230
    },
    {
        "content": "<p>Adding every commit that does a lean bump and the parent before it (as determined by the lake file)  might be a natural set of old commits to add, of that's not already what you did.</p>",
        "id": 342054640,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1678886373
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"310045\">Eric Wieser</span> <a href=\"#narrow/stream/287929-mathlib4/topic/mathlib4.20speedcenter/near/342054011\">said</a>:</p>\n<blockquote>\n<p>It might be interesting to have another version which scales the y axis to account for number of files / lines</p>\n</blockquote>\n<p>Yes, but there is no such functionality right now; the whole software is held together more or less by duct tape ever since the student project it originated from finished. We could also add either of these as a separate metric, but since there is only one y axis, only metrics of the same order of magnitude are sensibly displayable in the same graph</p>",
        "id": 342054953,
        "sender_full_name": "Sebastian Ullrich",
        "timestamp": 1678886432
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"310045\">Eric Wieser</span> <a href=\"#narrow/stream/287929-mathlib4/topic/mathlib4.20speedcenter/near/342054640\">said</a>:</p>\n<blockquote>\n<p>Adding every commit that does a lean bump and the parent before it (as determined by the lake file)  might be a natural set of old commits to add, of that's not already what you did.</p>\n</blockquote>\n<p>Ah right, I searched and added a few old \"bump [...]\" commits to the queue, but I should add the preceding commits as well</p>",
        "id": 342055790,
        "sender_full_name": "Sebastian Ullrich",
        "timestamp": 1678886625
    },
    {
        "content": "<p>Is there any chance to get per-file measurements?  Could we just add every file as a metric?</p>",
        "id": 342126356,
        "sender_full_name": "Gabriel Ebner",
        "timestamp": 1678902171
    },
    {
        "content": "<p>I could see the software struggling with that many metrics even when not displaying all of them in the graph, it definitely isn't built for that. What kind of reports are you thinking of for this? commit-pair diffs sorted by relative delta is the one that comes to mind that should already be supported.</p>",
        "id": 342131523,
        "sender_full_name": "Sebastian Ullrich",
        "timestamp": 1678903495
    },
    {
        "content": "<p>I should probably mention that the server software is written in Java. I'm really trying not to touch it.</p>",
        "id": 342131980,
        "sender_full_name": "Sebastian Ullrich",
        "timestamp": 1678903613
    },
    {
        "content": "<blockquote>\n<p>What kind of reports are you thinking of for this?</p>\n</blockquote>\n<p>What I'm always afraid of with big changes is failing to notice local regressions.  Like you make a change to mathlib that improves performance by 10%, but the same change makes one file take twice as long.  (And it doesn't show up in the aggregate because it's just one file.)</p>\n<p>So ideally the report I'd like would be: this commit made (unrelated) file XYZ 30% slower, you probably did something stupid.</p>",
        "id": 342134427,
        "sender_full_name": "Gabriel Ebner",
        "timestamp": 1678904303
    },
    {
        "content": "<p>I suppose the low tech solution would be to name the metrics <code>z $module</code>, then they would be listed below the current metrics in the standard view, but you could sort by \"Change %\" to get the desired result</p>",
        "id": 342160004,
        "sender_full_name": "Sebastian Ullrich",
        "timestamp": 1678912127
    },
    {
        "content": "<p>Then the remaining questions I see are:</p>\n<ul>\n<li>How exactly do we measure file times while reusing the current <code>lake build -v</code> invocation, as building twice would be too expensive? Perhaps we can inject a <code>lean</code> wrapper script into Lake's <code>PATH</code> that creates the appropriate output by wrapping the real <code>lean</code> in <code>time</code>. That would also obviate the need for injecting <code>--profile</code> into the lakefile like I do right now. The current setup for this is all in <a href=\"https://github.com/kha/mathlib4-bench\">https://github.com/kha/mathlib4-bench</a> btw; it might make sense to move some of this into the mathlib4 repo.</li>\n<li>Will the UI really cope? I guess we'll just have to see what happens, though maybe after a database backup.</li>\n</ul>",
        "id": 342161401,
        "sender_full_name": "Sebastian Ullrich",
        "timestamp": 1678912620
    },
    {
        "content": "<p>By the way, we can also add other kinds of benchmarks such as the <code>library_search</code> test file (/cc <span class=\"user-mention\" data-user-id=\"110087\">@Scott Morrison</span>). Preferably ones measured in seconds, not tens of minutes.</p>",
        "id": 342161528,
        "sender_full_name": "Sebastian Ullrich",
        "timestamp": 1678912672
    },
    {
        "content": "<p>Against all better judgment, I spent the day with frontend engineering and database wrangling. At least all these changes will be equally valuable to the lean4 instance.</p>\n<ul>\n<li>New metrics \"size .lean [lines]\" and \"size .olean [bytes]\". The lines metric has been backfilled for all previously benchmarked commits.</li>\n<li>The graph display will now use a second y-axis on the right-hand side for any metric not measured in seconds, which makes it possible to compare build times with lines, instructions, and maxrss. The latter is particularly interesting, apparently memory usage jumped from 2GB to 4GB at the beginning of Feburary, which must be due to a single dominating file <a href=\"/user_uploads/3121/tCuz3UyEzGIT-W29xUeZ-LUU/image.png\">image.png</a> . Lines on the other hand scale pretty much 1:1 with CPU time so far. <a href=\"/user_uploads/3121/uDZEBntv7B9W_Wf70zTVCj63/image.png\">image.png</a><div class=\"message_inline_image\"><a href=\"/user_uploads/3121/tCuz3UyEzGIT-W29xUeZ-LUU/image.png\" title=\"image.png\"><img src=\"/user_uploads/3121/tCuz3UyEzGIT-W29xUeZ-LUU/image.png\"></a></div><div class=\"message_inline_image\"><a href=\"/user_uploads/3121/uDZEBntv7B9W_Wf70zTVCj63/image.png\" title=\"image.png\"><img src=\"/user_uploads/3121/uDZEBntv7B9W_Wf70zTVCj63/image.png\"></a></div></li>\n<li>New button for normalized charts. Adding a selector for the metric to use for normalization is too complicated for me, so instead the metric with the highest value is used for each individual commit, which works well with e.g. normalizing by lines as long as we, hopefully, never exceed 1 second per line <a href=\"/user_uploads/3121/VVueNVi4F7XGbb3sMvjFGbc2/image.png\">image.png</a>.<div class=\"message_inline_image\"><a href=\"/user_uploads/3121/VVueNVi4F7XGbb3sMvjFGbc2/image.png\" title=\"image.png\"><img src=\"/user_uploads/3121/VVueNVi4F7XGbb3sMvjFGbc2/image.png\"></a></div></li>\n</ul>",
        "id": 342384098,
        "sender_full_name": "Sebastian Ullrich",
        "timestamp": 1678988682
    },
    {
        "content": "<blockquote>\n<p>metric with the highest value is used for each individual commit</p>\n</blockquote>\n<p>I think maxrss is the biggest metric.</p>",
        "id": 342386838,
        "sender_full_name": "Gabriel Ebner",
        "timestamp": 1678989474
    },
    {
        "content": "<p>Oh yes, it's the highest <em>selected</em> metric!</p>",
        "id": 342387457,
        "sender_full_name": "Sebastian Ullrich",
        "timestamp": 1678989657
    },
    {
        "content": "<p>Yes I just found that out when plotting the normalized memory usage. <span aria-label=\"smile\" class=\"emoji emoji-1f642\" role=\"img\" title=\"smile\">:smile:</span></p>",
        "id": 342387533,
        "sender_full_name": "Gabriel Ebner",
        "timestamp": 1678989676
    },
    {
        "content": "<p>I might give the per-file timings a try tomorrow. <span class=\"user-mention\" data-user-id=\"110043\">@Gabriel Ebner</span> What metrics do you think should we include per file? I'm considering measuring only instructions in order to keep the list short and to make sure we're not drowned in regression reports purely from noise</p>",
        "id": 342424131,
        "sender_full_name": "Sebastian Ullrich",
        "timestamp": 1679001373
    },
    {
        "content": "<p>That sounds good!</p>",
        "id": 342424510,
        "sender_full_name": "Gabriel Ebner",
        "timestamp": 1679001562
    },
    {
        "content": "<p>Another thing that would be cool to have is <code>!bench</code> on mathlib PRs.</p>",
        "id": 342424825,
        "sender_full_name": "Gabriel Ebner",
        "timestamp": 1679001715
    },
    {
        "content": "<p>Like this? :) <a href=\"https://github.com/leanprover-community/mathlib4/pull/2906#issuecomment-1470105871\">https://github.com/leanprover-community/mathlib4/pull/2906#issuecomment-1470105871</a></p>",
        "id": 342424980,
        "sender_full_name": "Sebastian Ullrich",
        "timestamp": 1679001785
    },
    {
        "content": "<p>One caveat is that the delta is computed relative to the PR base commit, but the PR benchmark run is placed at the head of the queue. So one should either base the PR on an already-benchmarked commit or wait with <code>!bench</code> until the base commit is at least being benchmarked. Otherwise no delta is posted in the comment.</p>",
        "id": 342430499,
        "sender_full_name": "Sebastian Ullrich",
        "timestamp": 1679004136
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110024\">Sebastian Ullrich</span> <a href=\"#narrow/stream/287929-mathlib4/topic/mathlib4.20speedcenter/near/342384098\">said</a>:</p>\n<blockquote>\n<p>apparently memory usage jumped from 2GB to 4GB at the beginning of Feburary, which must be due to a single dominating file</p>\n</blockquote>\n<p>I bisected this down to <a href=\"https://github.com/leanprover-community/mathlib4/pull/1744\">!4#1744</a> in the speedcenter, local Lean agrees</p>\n<div class=\"codehilite\" data-code-language=\"Bash Session\"><pre><span></span><code><span class=\"gp\">$ </span>lake<span class=\"w\"> </span>env<span class=\"w\"> </span><span class=\"se\">\\t</span>ime<span class=\"w\"> </span>-v<span class=\"w\"> </span>lean<span class=\"w\"> </span>Mathlib/Data/Sign.lean\n<span class=\"go\">    Command being timed: \"lean Mathlib/Data/Sign.lean\"</span>\n<span class=\"go\">    User time (seconds): 32.12</span>\n<span class=\"go\">    System time (seconds): 0.77</span>\n<span class=\"go\">    Percent of CPU this job got: 99%</span>\n<span class=\"go\">    Elapsed (wall clock) time (h:mm:ss or m:ss): 0:32.90</span>\n<span class=\"go\">    Average shared text size (kbytes): 0</span>\n<span class=\"go\">    Average unshared data size (kbytes): 0</span>\n<span class=\"go\">    Average stack size (kbytes): 0</span>\n<span class=\"go\">    Average total size (kbytes): 0</span>\n<span class=\"go\">    Maximum resident set size (kbytes): 4131452  &lt;- !!</span>\n<span class=\"go\">    Average resident set size (kbytes): 0</span>\n<span class=\"go\">    Major (requiring I/O) page faults: 0</span>\n<span class=\"go\">    Minor (reclaiming a frame) page faults: 864188</span>\n<span class=\"go\">    Voluntary context switches: 5</span>\n<span class=\"go\">    Involuntary context switches: 169</span>\n<span class=\"go\">    Swaps: 0</span>\n<span class=\"go\">    File system inputs: 0</span>\n<span class=\"go\">    File system outputs: 0</span>\n<span class=\"go\">    Socket messages sent: 0</span>\n<span class=\"go\">    Socket messages received: 0</span>\n<span class=\"go\">    Signals delivered: 0</span>\n<span class=\"go\">    Page size (bytes): 4096</span>\n<span class=\"go\">    Exit status: 0</span>\n</code></pre></div>",
        "id": 342595677,
        "sender_full_name": "Sebastian Ullrich",
        "timestamp": 1679067253
    },
    {
        "content": "<p>more precisely, it seems to be the instance declaration:</p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"kd\">set_option</span> <span class=\"n\">maxHeartbeats</span> <span class=\"mi\">0</span>\n<span class=\"c1\">-- Porting note: This takes too long, likely fixed by lean4#2003</span>\n<span class=\"c\">/-</span><span class=\"cm\"> We can define a `Field` instance on `SignType`, but it's not mathematically sensible,</span>\n<span class=\"cm\">so we only define the `CommGroupWithZero`. -/</span>\n<span class=\"kd\">instance</span> <span class=\"o\">:</span> <span class=\"n\">CommGroupWithZero</span> <span class=\"n\">SignType</span> <span class=\"n\">where</span>\n  <span class=\"n\">zero</span> <span class=\"o\">:=</span> <span class=\"mi\">0</span>\n  <span class=\"n\">one</span> <span class=\"o\">:=</span> <span class=\"mi\">1</span>\n  <span class=\"n\">mul</span> <span class=\"o\">:=</span> <span class=\"o\">(</span><span class=\"bp\">·</span> <span class=\"bp\">*</span> <span class=\"bp\">·</span><span class=\"o\">)</span>\n  <span class=\"n\">inv</span> <span class=\"o\">:=</span> <span class=\"n\">id</span>\n  <span class=\"n\">mul_zero</span> <span class=\"n\">a</span> <span class=\"o\">:=</span> <span class=\"kd\">by</span> <span class=\"n\">cases</span> <span class=\"n\">a</span> <span class=\"bp\">&lt;;&gt;</span> <span class=\"n\">rfl</span>\n  <span class=\"n\">zero_mul</span> <span class=\"n\">a</span> <span class=\"o\">:=</span> <span class=\"kd\">by</span> <span class=\"n\">cases</span> <span class=\"n\">a</span> <span class=\"bp\">&lt;;&gt;</span> <span class=\"n\">rfl</span>\n  <span class=\"n\">mul_one</span> <span class=\"n\">a</span> <span class=\"o\">:=</span> <span class=\"kd\">by</span> <span class=\"n\">cases</span> <span class=\"n\">a</span> <span class=\"bp\">&lt;;&gt;</span> <span class=\"n\">rfl</span>\n  <span class=\"n\">one_mul</span> <span class=\"n\">a</span> <span class=\"o\">:=</span> <span class=\"kd\">by</span> <span class=\"n\">cases</span> <span class=\"n\">a</span> <span class=\"bp\">&lt;;&gt;</span> <span class=\"n\">rfl</span>\n  <span class=\"n\">mul_inv_cancel</span> <span class=\"n\">a</span> <span class=\"n\">ha</span> <span class=\"o\">:=</span> <span class=\"kd\">by</span> <span class=\"n\">cases</span> <span class=\"n\">a</span> <span class=\"bp\">&lt;;&gt;</span> <span class=\"n\">trivial</span>\n  <span class=\"n\">mul_comm</span> <span class=\"n\">a</span> <span class=\"n\">b</span> <span class=\"o\">:=</span> <span class=\"kd\">by</span> <span class=\"n\">cases</span> <span class=\"n\">a</span> <span class=\"bp\">&lt;;&gt;</span> <span class=\"n\">cases</span> <span class=\"n\">b</span> <span class=\"bp\">&lt;;&gt;</span> <span class=\"n\">rfl</span>\n  <span class=\"n\">mul_assoc</span> <span class=\"n\">a</span> <span class=\"n\">b</span> <span class=\"n\">c</span> <span class=\"o\">:=</span> <span class=\"kd\">by</span> <span class=\"n\">cases</span> <span class=\"n\">a</span> <span class=\"bp\">&lt;;&gt;</span> <span class=\"n\">cases</span> <span class=\"n\">b</span> <span class=\"bp\">&lt;;&gt;</span> <span class=\"n\">cases</span> <span class=\"n\">c</span> <span class=\"bp\">&lt;;&gt;</span> <span class=\"n\">rfl</span>\n  <span class=\"n\">exists_pair_ne</span> <span class=\"o\">:=</span> <span class=\"o\">⟨</span><span class=\"mi\">0</span><span class=\"o\">,</span> <span class=\"mi\">1</span><span class=\"o\">,</span> <span class=\"kd\">by</span> <span class=\"n\">rintro</span> <span class=\"o\">⟨</span><span class=\"n\">_</span><span class=\"o\">⟩⟩</span>\n  <span class=\"n\">inv_zero</span> <span class=\"o\">:=</span> <span class=\"n\">rfl</span>\n</code></pre></div>\n<p>(there are two other instances which are also slow but not as bad as this one)</p>",
        "id": 342600324,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1679068130
    },
    {
        "content": "<p>the <code>set_option maxHeartbeats 0</code> is very smelly</p>",
        "id": 342600453,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1679068154
    },
    {
        "content": "<p>and the porting note is over-optimistic</p>",
        "id": 342600549,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1679068175
    },
    {
        "content": "<p>Yes, please use <code>--profile</code> before blaming things on random Lean issues :) (though it's of course possible that the bottleneck shifted after that issue was resolved)</p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"n\">compilation</span> <span class=\"n\">of</span> <span class=\"n\">SignType.instCommGroupWithZeroSignType</span> <span class=\"n\">took</span> <span class=\"mi\">27</span><span class=\"bp\">.</span><span class=\"mi\">3</span><span class=\"n\">s</span>\n</code></pre></div>\n<p>This should be fixed with the new compiler, do people mark such declarations as <code>noncomputable</code>in the meantime?</p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code>    <span class=\"n\">compilation</span> <span class=\"mi\">27</span><span class=\"bp\">.</span><span class=\"mi\">4</span><span class=\"n\">s</span>\n    <span class=\"n\">compilation</span> <span class=\"n\">new</span> <span class=\"mi\">42</span><span class=\"bp\">.</span><span class=\"mi\">9</span><span class=\"n\">ms</span>\n</code></pre></div>",
        "id": 342601354,
        "sender_full_name": "Sebastian Ullrich",
        "timestamp": 1679068338
    },
    {
        "content": "<p>There is no need for that, further bisection reveals the issue is caused by the big case splits in <code>mul_comm</code> and <code>mul_assoc</code>, which should not be relevant for the compiler in the first place since they are proofs. <a href=\"https://github.com/leanprover-community/mathlib4/pull/2957\">!4#2957</a></p>",
        "id": 342608041,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1679069725
    },
    {
        "content": "<p>Great, basically what the new compiler does automatically!</p>",
        "id": 342608504,
        "sender_full_name": "Sebastian Ullrich",
        "timestamp": 1679069852
    },
    {
        "content": "<p>This is decidably faster:</p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"kd\">instance</span> <span class=\"o\">:</span> <span class=\"n\">CommGroupWithZero</span> <span class=\"n\">SignType</span> <span class=\"n\">where</span>\n  <span class=\"n\">zero</span> <span class=\"o\">:=</span> <span class=\"mi\">0</span>\n  <span class=\"n\">one</span> <span class=\"o\">:=</span> <span class=\"mi\">1</span>\n  <span class=\"n\">mul</span> <span class=\"o\">:=</span> <span class=\"o\">(</span><span class=\"bp\">·</span> <span class=\"bp\">*</span> <span class=\"bp\">·</span><span class=\"o\">)</span>\n  <span class=\"n\">inv</span> <span class=\"o\">:=</span> <span class=\"n\">id</span>\n  <span class=\"n\">mul_zero</span> <span class=\"o\">:=</span> <span class=\"kd\">by</span> <span class=\"n\">decide</span>\n  <span class=\"n\">zero_mul</span> <span class=\"o\">:=</span> <span class=\"kd\">by</span> <span class=\"n\">decide</span>\n  <span class=\"n\">mul_one</span> <span class=\"o\">:=</span> <span class=\"kd\">by</span> <span class=\"n\">decide</span>\n  <span class=\"n\">one_mul</span> <span class=\"o\">:=</span> <span class=\"kd\">by</span> <span class=\"n\">decide</span>\n  <span class=\"n\">mul_inv_cancel</span> <span class=\"o\">:=</span> <span class=\"kd\">by</span> <span class=\"n\">decide</span>\n  <span class=\"n\">mul_comm</span> <span class=\"o\">:=</span> <span class=\"kd\">by</span> <span class=\"n\">decide</span>\n  <span class=\"n\">mul_assoc</span> <span class=\"o\">:=</span> <span class=\"kd\">by</span> <span class=\"n\">decide</span>\n  <span class=\"n\">exists_pair_ne</span> <span class=\"o\">:=</span> <span class=\"o\">⟨</span><span class=\"mi\">0</span><span class=\"o\">,</span> <span class=\"mi\">1</span><span class=\"o\">,</span> <span class=\"kd\">by</span> <span class=\"n\">rintro</span> <span class=\"o\">⟨</span><span class=\"n\">_</span><span class=\"o\">⟩⟩</span>\n  <span class=\"n\">inv_zero</span> <span class=\"o\">:=</span> <span class=\"n\">rfl</span>\n</code></pre></div>",
        "id": 342609434,
        "sender_full_name": "Kyle Miller",
        "timestamp": 1679070081
    },
    {
        "content": "<p>This version: tactic execution took 199ms, typeclass inference took 167ms</p>\n<p>Previous version: compilation of SignType.instCommGroupWithZeroSignType took 34.7s</p>\n<p>(I used <code>set_option profiler true</code>. I don't really comprehend what it's reporting, but I see &lt;1s and &gt;30s)</p>",
        "id": 342610710,
        "sender_full_name": "Kyle Miller",
        "timestamp": 1679070388
    },
    {
        "content": "<p>I tried <code>decide</code> but it didn't work, I think the instance wasn't in scope?</p>",
        "id": 342612431,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1679070784
    },
    {
        "content": "<p>I guess it's just for the <code>&lt;=</code> theorems that <code>decide</code> fails</p>",
        "id": 342612717,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1679070846
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110024\">Sebastian Ullrich</span> <a href=\"#narrow/stream/287929-mathlib4/topic/mathlib4.20speedcenter/near/342424131\">said</a>:</p>\n<blockquote>\n<p>I might give the per-file timings a try tomorrow</p>\n</blockquote>\n<p>First results are in: <a href=\"http://speedcenter.informatik.kit.edu/mathlib4/run-detail/e7b27246-a3e6-496a-b552-ff4b45c7236e/50ba914cce63cd43429baf8cf1459ae5c2a03efa\">http://speedcenter.informatik.kit.edu/mathlib4/run-detail/e7b27246-a3e6-496a-b552-ff4b45c7236e/50ba914cce63cd43429baf8cf1459ae5c2a03efa</a>. Looks good, the only detected significant change is in a file the PR extended. And so far the software seems to cope with the onslaught of data.</p>",
        "id": 342629787,
        "sender_full_name": "Sebastian Ullrich",
        "timestamp": 1679075233
    },
    {
        "content": "<p>Interestingly it does not agree everywhere on whether \"~\" should come before or after the other metrics <a href=\"/user_uploads/3121/QSN65MDgW-9lexCte8Ufre0g/image.png\">image.png</a></p>\n<div class=\"message_inline_image\"><a href=\"/user_uploads/3121/QSN65MDgW-9lexCte8Ufre0g/image.png\" title=\"image.png\"><img src=\"/user_uploads/3121/QSN65MDgW-9lexCte8Ufre0g/image.png\"></a></div>",
        "id": 342630050,
        "sender_full_name": "Sebastian Ullrich",
        "timestamp": 1679075306
    },
    {
        "content": "<p>Sebastian thanks so much for putting in the effort to make this. This really seems to be a game changer in places.</p>",
        "id": 342648024,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1679080585
    },
    {
        "content": "<p>I re-benchmarked the last two lean4 bumps to get per-file deltas:<br>\n<a href=\"http://speedcenter.informatik.kit.edu/mathlib4/run-detail/e7b27246-a3e6-496a-b552-ff4b45c7236e/5bbbc25c541921a19dea0844c9370c4026d03141\">http://speedcenter.informatik.kit.edu/mathlib4/run-detail/e7b27246-a3e6-496a-b552-ff4b45c7236e/5bbbc25c541921a19dea0844c9370c4026d03141</a><br>\n<a href=\"http://speedcenter.informatik.kit.edu/mathlib4/run-detail/e7b27246-a3e6-496a-b552-ff4b45c7236e/9cbf797aa91c0a342c8ea232557937ac02adc2b5\">http://speedcenter.informatik.kit.edu/mathlib4/run-detail/e7b27246-a3e6-496a-b552-ff4b45c7236e/9cbf797aa91c0a342c8ea232557937ac02adc2b5</a><br>\nApparently both were almost regression-free!</p>",
        "id": 342906853,
        "sender_full_name": "Sebastian Ullrich",
        "timestamp": 1679220502
    },
    {
        "content": "<p>The \"significant difference chips\" at the top do kind of lose their meaning when a majority of measures has significant changes...</p>",
        "id": 342906976,
        "sender_full_name": "Sebastian Ullrich",
        "timestamp": 1679220588
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"110024\">@Sebastian Ullrich</span> Do you have any idea why this commit has such a huge impact? <a href=\"http://speedcenter.informatik.kit.edu/mathlib4/run-detail/2d483167-10ef-423a-9a05-76d18847a65e\">http://speedcenter.informatik.kit.edu/mathlib4/run-detail/2d483167-10ef-423a-9a05-76d18847a65e</a></p>",
        "id": 343794851,
        "sender_full_name": "Gabriel Ebner",
        "timestamp": 1679522957
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"110043\">@Gabriel Ebner</span> I ran it again (see very end), the changes vanished. I have no idea why this could happen, maybe the CPU was feeling cold?</p>",
        "id": 343795299,
        "sender_full_name": "Sebastian Ullrich",
        "timestamp": 1679523163
    },
    {
        "content": "<p>What's the base commit for the first comparison? The PR is \"old\", maybe it got benchmarked against a pre <a href=\"https://github.com/leanprover/lean4/pull/2151\">lean4#2151</a> base build for some reason.</p>",
        "id": 343837529,
        "sender_full_name": "Mauricio Collares",
        "timestamp": 1679546408
    },
    {
        "content": "<p>It's not a PR run, the base is the previous commit on master</p>",
        "id": 343902517,
        "sender_full_name": "Sebastian Ullrich",
        "timestamp": 1679559957
    },
    {
        "content": "<p>Another likely compiler edge case in <a href=\"https://github.com/leanprover-community/mathlib4/pull/2977\">!4#2977</a> <a href=\"http://speedcenter.informatik.kit.edu/mathlib4/run-detail/e7b27246-a3e6-496a-b552-ff4b45c7236e/fa99b8007c4294b295a0dbcf22859ca5a145e95b\">http://speedcenter.informatik.kit.edu/mathlib4/run-detail/e7b27246-a3e6-496a-b552-ff4b45c7236e/fa99b8007c4294b295a0dbcf22859ca5a145e95b</a></p>",
        "id": 346132816,
        "sender_full_name": "Sebastian Ullrich",
        "timestamp": 1680338055
    },
    {
        "content": "<p>This speedcenter seems really really useful (assuming it is at least roughly reliable).</p>",
        "id": 346134583,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1680338708
    },
    {
        "content": "<p>I think I looked at that pr and hit timeouts I couldn't make progress on, so seems plausible</p>",
        "id": 346135552,
        "sender_full_name": "Ruben Van de Velde",
        "timestamp": 1680339076
    },
    {
        "content": "<p>Getting that PR over the finish line was a nightmare, so that doesn't surprise me at all</p>",
        "id": 346135789,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1680339158
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110031\">Patrick Massot</span> <a href=\"#narrow/stream/287929-mathlib4/topic/mathlib4.20speedcenter/near/346134583\">said</a>:</p>\n<blockquote>\n<p>This speedcenter seems really really useful (assuming it is at least roughly reliable).</p>\n</blockquote>\n<p>Here is the delta for a trivial commit, giving an example of the involved noise: <a href=\"http://speedcenter.informatik.kit.edu/mathlib4/run-detail/95b40a5f-b1c0-4458-b97f-4acf81384714\">http://speedcenter.informatik.kit.edu/mathlib4/run-detail/95b40a5f-b1c0-4458-b97f-4acf81384714</a>. Time measurements may fluctuate by one or two percent, or more if they are only a small part of the total time (which fortunately means that we are not particularly interested in them). Instructions is the most robust time-like measurement, which is why it's the only metric we use for individual files.</p>",
        "id": 346172180,
        "sender_full_name": "Sebastian Ullrich",
        "timestamp": 1680350364
    },
    {
        "content": "<p>In the porting meeting, <span class=\"user-mention\" data-user-id=\"110049\">@Mario Carneiro</span> asked about where the sources for the speedcenter software and setup are</p>\n<ul>\n<li><a href=\"https://github.com/IPDSnelting/velcom\">https://github.com/IPDSnelting/velcom</a> is the server software as well as the runner that takes care of accepting benchmark requests, checking out the commit, and running the benchmark script</li>\n<li><a href=\"https://github.com/Kha/mathlib4-bench\">https://github.com/Kha/mathlib4-bench</a> is the current benchmark script, which is where the actual metrics are encoded. I mentioned that I intend to move parts of this to mathlib4 like is already the case for the lean4 setup</li>\n<li><a href=\"https://github.com/parttimenerd/temci\">https://github.com/parttimenerd/temci</a> is used by the script to do the actual benchmarking, mostly because I'm not aware of other benchmarking tools that take a sufficiently expressive benchmarking suite config</li>\n</ul>\n<p>If I mentioned duct tape above, here's more</p>",
        "id": 346669256,
        "sender_full_name": "Sebastian Ullrich",
        "timestamp": 1680553150
    },
    {
        "content": "<p>Also, both the server and the runner are KIT machines, which will be a bit suboptimal when I leave there in a little over a month</p>",
        "id": 346673972,
        "sender_full_name": "Sebastian Ullrich",
        "timestamp": 1680554996
    },
    {
        "content": "<p>Wall-clock build time vs lines of code <br>\n<a href=\"/user_uploads/3121/IaLhVVsmKuQByI-kqtf17HEP/image.png\">image.png</a><br>\n<a href=\"http://speedcenter.informatik.kit.edu/mathlib4/repo-detail/e7b27246-a3e6-496a-b552-ff4b45c7236e?zoomXStart=1667257200000&amp;zoomXEnd=1684274400000&amp;dimensions=size%3A.lean%3A%3Abuild%3Awall-clock&amp;dayEquidistant=true\">http://speedcenter.informatik.kit.edu/mathlib4/repo-detail/e7b27246-a3e6-496a-b552-ff4b45c7236e?zoomXStart=1667257200000&amp;zoomXEnd=1684274400000&amp;dimensions=size%3A.lean%3A%3Abuild%3Awall-clock&amp;dayEquidistant=true</a></p>\n<div class=\"message_inline_image\"><a href=\"/user_uploads/3121/IaLhVVsmKuQByI-kqtf17HEP/image.png\" title=\"image.png\"><img src=\"/user_uploads/3121/IaLhVVsmKuQByI-kqtf17HEP/image.png\"></a></div>",
        "id": 358751979,
        "sender_full_name": "Sebastian Ullrich",
        "timestamp": 1684247592
    },
    {
        "content": "<p>Wait we already have over 800000 lines of mathlib4 code? I think Lean 4 must somehow be more verbose than Lean 3. We only have 2/3 of mathlib which is something like 1.1M LOC right now.</p>",
        "id": 358802819,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1684258262
    },
    {
        "content": "<p>I think a lot of it is the <code>#align</code>s</p>",
        "id": 358805076,
        "sender_full_name": "Heather Macbeth",
        "timestamp": 1684258762
    },
    {
        "content": "<p>A bunch of</p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"kd\">lemma</span> <span class=\"n\">trivial_lemma1</span> <span class=\"o\">:</span> <span class=\"n\">short_statement1</span> <span class=\"o\">:=</span> <span class=\"n\">easy_proof1</span>\n<span class=\"kd\">lemma</span> <span class=\"n\">trivial_lemma2</span> <span class=\"o\">:</span> <span class=\"n\">short_statement2</span> <span class=\"o\">:=</span> <span class=\"n\">easy_proof2</span>\n</code></pre></div>\n<p>sadly got turned into</p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"kd\">theorem</span> <span class=\"n\">trivial_lemma1</span> <span class=\"o\">:</span>\n    <span class=\"n\">short_statement1</span> <span class=\"o\">:=</span>\n  <span class=\"n\">easy_proof1</span>\n<span class=\"bp\">#</span><span class=\"n\">align</span> <span class=\"n\">trivial_lemma1</span> <span class=\"n\">trivial_lemma1</span>\n\n<span class=\"kd\">theorem</span> <span class=\"n\">trivial_lemma2</span> <span class=\"o\">:</span>\n    <span class=\"n\">short_statement2</span> <span class=\"o\">:=</span>\n  <span class=\"n\">easy_proof2</span>\n<span class=\"bp\">#</span><span class=\"n\">align</span> <span class=\"n\">trivial_lemma2</span> <span class=\"n\">trivial_lemma2</span>\n</code></pre></div>\n<p>which is five times more verbose!</p>",
        "id": 358806825,
        "sender_full_name": "Yaël Dillies",
        "timestamp": 1684259197
    },
    {
        "content": "<p>Is it just me or did mathlib4 become slower than before re-enabling global eta <em>after</em> we removed all the <code>-instance</code> lines and such?</p>",
        "id": 358869344,
        "sender_full_name": "Jeremy Tan",
        "timestamp": 1684282479
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"598052\">Jeremy Tan</span> <a href=\"#narrow/stream/287929-mathlib4/topic/mathlib4.20speedcenter/near/358869344\">said</a>:</p>\n<blockquote>\n<p>Is it just me or did mathlib4 become slower than before re-enabling global eta <em>after</em> we removed all the <code>-instance</code> lines and such?</p>\n</blockquote>\n<p>You can look in the speedcenter! We can also watch the next post in <a href=\"#narrow/stream/287929-mathlib4/topic/port.20benchmark\">port benchmark</a> in a few hours.</p>",
        "id": 358969137,
        "sender_full_name": "Scott Morrison",
        "timestamp": 1684326216
    },
    {
        "content": "<p>It's certainly not impossible.</p>",
        "id": 358969156,
        "sender_full_name": "Scott Morrison",
        "timestamp": 1684326224
    },
    {
        "content": "<p>It looks like the clean up PRs have landed in the speed center and it doesn't show a serious bump. My repeated rebuilds have been noticeably snappier :)</p>",
        "id": 358990418,
        "sender_full_name": "Matthew Ballard",
        "timestamp": 1684331711
    },
    {
        "content": "<p>The benchmark bot disagrees, unfortunately: <a href=\"#narrow/stream/287929-mathlib4/topic/port.20benchmark/near/359033805\">https://leanprover.zulipchat.com/#narrow/stream/287929-mathlib4/topic/port.20benchmark/near/359033805</a></p>",
        "id": 359091102,
        "sender_full_name": "Scott Morrison",
        "timestamp": 1684361466
    },
    {
        "content": "<p>The benchmarking queue is now at 99 commits <span aria-label=\"tear\" class=\"emoji emoji-1f972\" role=\"img\" title=\"tear\">:tear:</span> . Given that the running time has now exceeded one hour, I don't see it being emptied any time soon</p>",
        "id": 361002558,
        "sender_full_name": "Sebastian Ullrich",
        "timestamp": 1685007878
    },
    {
        "content": "<p>But since new commits are benchmarked first, we do still have trend data even if results and especially deltas for specific commits may be missing <br>\n<a href=\"/user_uploads/3121/sCmQWjN_DTq0VgYKRC1T5vHt/image.png\">image.png</a></p>\n<div class=\"message_inline_image\"><a href=\"/user_uploads/3121/sCmQWjN_DTq0VgYKRC1T5vHt/image.png\" title=\"image.png\"><img src=\"/user_uploads/3121/sCmQWjN_DTq0VgYKRC1T5vHt/image.png\"></a></div>",
        "id": 361002979,
        "sender_full_name": "Sebastian Ullrich",
        "timestamp": 1685007974
    },
    {
        "content": "<p>Typeclass inference is the only major component whose share of the build time has been slowly increasing, it is now at almost 50%<br>\n<a href=\"/user_uploads/3121/HxQY5vHY4-wfAeopx5qMLG-P/image.png\">image.png</a></p>\n<div class=\"message_inline_image\"><a href=\"/user_uploads/3121/HxQY5vHY4-wfAeopx5qMLG-P/image.png\" title=\"image.png\"><img src=\"/user_uploads/3121/HxQY5vHY4-wfAeopx5qMLG-P/image.png\"></a></div>",
        "id": 363750372,
        "sender_full_name": "Sebastian Ullrich",
        "timestamp": 1685976552
    },
    {
        "content": "<p>Can we say yet whether tabled typeclass inference is significantly more effective than the lean 3 way?</p>",
        "id": 363751748,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1685976758
    },
    {
        "content": "<p>It is weirdly ironic, because typeclass inference is really a part of the system which is completely trivial to the mathematician. Of course a normed field is a nonassoc-semiring and of course this is true in precisely one way. Part of me is still dumbfounded that there is any content here on the CS side needed to make it work, even though I've now read several papers which assure me that this is the case...</p>",
        "id": 363754301,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1685977249
    },
    {
        "content": "<p>It would be interesting to know how much percent are spent on TC inference in Lean 3.  I would expect it to be similarly high.</p>",
        "id": 363795680,
        "sender_full_name": "Gabriel Ebner",
        "timestamp": 1685986324
    },
    {
        "content": "<p>Is this percentage easy to compute though?</p>",
        "id": 363799563,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1685987205
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"110038\">@Kevin Buzzard</span>  I think it's not so obvious in the presence of diamonds (and if we only had linear type class graphs, I think TC synthesis would be blazingly fast <span aria-label=\"laughing\" class=\"emoji emoji-1f606\" role=\"img\" title=\"laughing\">:laughing:</span>). When you say things like \"Of course a normed field is a nonassoc-semiring and of course this is true in precisely one way\", I think what you are (or at least, I am) implicitly doing is something like \"well, all that matters is the data fields and they're the same no matter what because there is no reason to change them as you add structure\", the first part of which is essentially flat structures and proof irrelevance. The second part is of course borked if you choose to change one of the data fields to something propeq but not defeq, but even if not, Lean still has to check it, whereas a mathematician wouldn't because they generally only care about propeq anyway.</p>\n<p>However, when you have diamonds, especially with things that aren't just forgetful functors, I think it's less obvious, even for mathematicians, especially when what you really care about is defeq instead of propeq. As evidence, I'll point two several of the non-defeq diamonds we've accidentally inserted over the years and then later had to remove (e.g., <code>ℕ</code> smul), or the time a few months ago when I wanted to add an instance that every <code>ℂ</code>-algebra is an <code>ℝ</code>-algebra, but I did it in a naive way and then ended up with non-defeq diamonds, whereas I thought everything was fine. In this case, I actually contemplated briefly the possibility of diamonds ahead of time, but thought I would be okay, and I wasn't (this situation never appeared in mathlib, only locally).</p>\n<p>At the same time, it would be great if we could find a nice way to make this as easy for Lean as it seems to be for mathematicians. <span aria-label=\"smiley\" class=\"emoji emoji-1f603\" role=\"img\" title=\"smiley\">:smiley:</span></p>",
        "id": 363811372,
        "sender_full_name": "Jireh Loreaux",
        "timestamp": 1685990419
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110038\">Kevin Buzzard</span> <a href=\"#narrow/stream/287929-mathlib4/topic/mathlib4.20speedcenter/near/363799563\">said</a>:</p>\n<blockquote>\n<p>Is this percentage easy to compute though?</p>\n</blockquote>\n<p>Someone would need to record a build of mathlib3 with <code>--profile</code> and pass the output through <a href=\"https://github.com/leanprover/lean4/blob/master/tests/bench/accumulate_profile.py\">https://github.com/leanprover/lean4/blob/master/tests/bench/accumulate_profile.py</a></p>",
        "id": 363821129,
        "sender_full_name": "Sebastian Ullrich",
        "timestamp": 1685993055
    },
    {
        "content": "<p>The fact that propeq diamonds break the system is clearly a fault of the system and can't be used as an argument to justify that the problem is harder than I'm claiming it is. Yes I only care about propeq, of course, defeq is an artificial thing introduced by the computer scientists because they have issues with equality. Propeq is the only thing that matters in our work as mathematicians and the fact that we can't insert proofs into the typeclass inference system other than by artificial means such as bundling the topology into the definition of a metric space is something which is actually very weird but we've just forgotten how weird it is because we're now used to it.</p>",
        "id": 363840325,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1685999236
    },
    {
        "content": "<p>Do we have a way of getting benchmark results on a file by file basis? I would like to see which files got slower after the port (and persistently are over a few recent runs, normalized by the fact that on the whole of mathlib things are faster).</p>",
        "id": 366826129,
        "sender_full_name": "Alex J. Best",
        "timestamp": 1686921191
    },
    {
        "content": "<p>I guess the data is there in speedcenter, I just don't know which buttons to click to show me, e.g. the 10 worst slowdown files (alternatively if I could download all the data and process it myself that could be fine)</p>",
        "id": 366826923,
        "sender_full_name": "Alex J. Best",
        "timestamp": 1686921340
    },
    {
        "content": "<p>The speedcenter does not have any Lean 3 performance data. You should be able to adjust Scott's port benchmark script to your needs <a href=\"https://github.com/leanprover-community/mathlib4/blob/master/scripts/benchmark.sh\">https://github.com/leanprover-community/mathlib4/blob/master/scripts/benchmark.sh</a></p>",
        "id": 366939734,
        "sender_full_name": "Sebastian Ullrich",
        "timestamp": 1686947095
    },
    {
        "content": "<p>Is it possible to download the speedcenter data at least?</p>",
        "id": 366941738,
        "sender_full_name": "Alex J. Best",
        "timestamp": 1686947798
    },
    {
        "content": "<p>Maybe this could be combined with <span class=\"user-mention\" data-user-id=\"256311\">@Jannis Limperg</span>s bot data for mathlib 3 (does that still run?)</p>",
        "id": 366941857,
        "sender_full_name": "Alex J. Best",
        "timestamp": 1686947848
    },
    {
        "content": "<p>If you look at the server responses while loading the graph display, you should be able to retrieve some usable data from that</p>",
        "id": 366944468,
        "sender_full_name": "Sebastian Ullrich",
        "timestamp": 1686948818
    },
    {
        "content": "<p>My bot doesn't run at the moment because we were running out of money for the Azure VMs. Could be restarted if needed.</p>",
        "id": 367068565,
        "sender_full_name": "Jannis Limperg",
        "timestamp": 1686983216
    },
    {
        "content": "<p>And we're back <a href=\"http://speedcenter.informatik.kit.edu/mathlib4/repo-detail/e7b27246-a3e6-496a-b552-ff4b45c7236e?zoomXStart=1667260800000&amp;dimensions=size%3A.lean%3A%3Abuild%3Awall-clock&amp;dayEquidistant=true\">http://speedcenter.informatik.kit.edu/mathlib4/repo-detail/e7b27246-a3e6-496a-b552-ff4b45c7236e?zoomXStart=1667260800000&amp;dimensions=size%3A.lean%3A%3Abuild%3Awall-clock&amp;dayEquidistant=true</a></p>",
        "id": 368614301,
        "sender_full_name": "Sebastian Ullrich",
        "timestamp": 1687449243
    },
    {
        "content": "<p>If you click on \"Normalize\", you can see we didn't get any slower per line at least in the meantime</p>",
        "id": 368614438,
        "sender_full_name": "Sebastian Ullrich",
        "timestamp": 1687449270
    },
    {
        "content": "<p>I asked this in the meetings once known as porting meetings but I think I need more info than is on the <a href=\"https://github.com/IPDSnelting/velcom\">GitHub repo</a>. If I want to setup a copy of the speed center on a local machine to track mathlib (as exact as the existing as possible), what do I need to know specifically?</p>",
        "id": 380514531,
        "sender_full_name": "Matthew Ballard",
        "timestamp": 1690845176
    },
    {
        "content": "<p>I suppose I will soon need to set up the speedcenter on new machines at which point I can make notes</p>",
        "id": 380589759,
        "sender_full_name": "Sebastian Ullrich",
        "timestamp": 1690876218
    },
    {
        "content": "<p>I would love to have the capacity where this could be part of the standard CI package.</p>",
        "id": 380650661,
        "sender_full_name": "Matthew Ballard",
        "timestamp": 1690887545
    },
    {
        "content": "<p>We'll need to work on making it less costly then, ideally we only measure files that actually have to be recompiled and then simulate overall timings from the aggregate</p>",
        "id": 380671583,
        "sender_full_name": "Sebastian Ullrich",
        "timestamp": 1690891391
    },
    {
        "content": "<p>I am getting the <code>No worker registered :(</code> error from the speed center. Is it just me?</p>",
        "id": 382710730,
        "sender_full_name": "Matthew Ballard",
        "timestamp": 1691429006
    },
    {
        "content": "<p>The machine seems to be misbehaving, my bad</p>",
        "id": 382718893,
        "sender_full_name": "Sebastian Ullrich",
        "timestamp": 1691431004
    },
    {
        "content": "<p><span aria-label=\"robot\" class=\"emoji emoji-1f916\" role=\"img\" title=\"robot\">:robot:</span>'s bad</p>",
        "id": 382718973,
        "sender_full_name": "Matthew Ballard",
        "timestamp": 1691431023
    },
    {
        "content": "<p>Unfortunately there's no-one around to force-reboot it at this time of the day</p>",
        "id": 382719125,
        "sender_full_name": "Sebastian Ullrich",
        "timestamp": 1691431062
    },
    {
        "content": "<p>I had an issue with my office machine and it wasn't addressed for months :)</p>",
        "id": 382719624,
        "sender_full_name": "Matthew Ballard",
        "timestamp": 1691431202
    },
    {
        "content": "<p>Is there a way to get the speedcenter to run on mathlib with a local toolchain, eg one from <code>elan override</code>?</p>",
        "id": 385116787,
        "sender_full_name": "Matthew Ballard",
        "timestamp": 1692105038
    },
    {
        "content": "<p>How would the toolchain get to the speedcenter server?</p>",
        "id": 385117474,
        "sender_full_name": "Sebastian Ullrich",
        "timestamp": 1692105203
    },
    {
        "content": "<p>Hope?</p>",
        "id": 385117621,
        "sender_full_name": "Matthew Ballard",
        "timestamp": 1692105237
    },
    {
        "content": "<p><code>!bench</code> seems to be doing nothing on <a href=\"https://github.com/leanprover-community/mathlib4/pull/6562\">https://github.com/leanprover-community/mathlib4/pull/6562</a>; any idea why?</p>",
        "id": 385421161,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1692177639
    },
    {
        "content": "<p>Is there still no runner?</p>",
        "id": 385425542,
        "sender_full_name": "Matthew Ballard",
        "timestamp": 1692178981
    },
    {
        "content": "<p>Working on it!</p>",
        "id": 385426311,
        "sender_full_name": "Sebastian Ullrich",
        "timestamp": 1692179232
    },
    {
        "content": "<p>As <a href=\"#narrow/stream/113486-announce/topic/Lean.20FRO/near/385494466\">just announced</a>, the speedcenter is now running on a shiny new machine, with quite a remarkable improvement in speed and corresponding throughput: mathlib runs are now down from about 150 minutes to 30 minutes. I suggest to rebase any PRs before invoking <code>!bench</code> to make sure they are compared to a base commit run on the same machine.</p>",
        "id": 385495411,
        "sender_full_name": "Sebastian Ullrich",
        "timestamp": 1692201956
    },
    {
        "content": "<p>The old data is still there, so expect a significant jump in time-based graphs. It would be possible to down-scale the old values but as the relation is not perfectly linear across all time metrics, it is not clear to me whether that would be a good idea. <br>\n<a href=\"/user_uploads/3121/yPn8_3Toa7XNjNvZMgWzhVhb/image.png\">image.png</a></p>\n<div class=\"message_inline_image\"><a href=\"/user_uploads/3121/yPn8_3Toa7XNjNvZMgWzhVhb/image.png\" title=\"image.png\"><img src=\"/user_uploads/3121/yPn8_3Toa7XNjNvZMgWzhVhb/image.png\"></a></div>",
        "id": 385496368,
        "sender_full_name": "Sebastian Ullrich",
        "timestamp": 1692202257
    },
    {
        "content": "<p>what is the reason for the improvement? Is it more cores? I would assume most other metrics can't vary too much (clock speed can vary by 50% but it's mostly stable across the board these days, and I don't think we are RAM limited except insofar as it prevents additional parallel workers)</p>",
        "id": 385500388,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1692203659
    },
    {
        "content": "<p>Here is a comparison across the two machines (with some actual mathlib changes involved as well as seen in the file-level differences): <a href=\"http://speed.lean-fro.org/mathlib4/compare/e7b27246-a3e6-496a-b552-ff4b45c7236e/to/1946ae42-9a2d-41f2-98d6-225a79727430?hash1=3d6112b5c7d095d3088b359c611a5a2704c5dbdc\">http://speed.lean-fro.org/mathlib4/compare/e7b27246-a3e6-496a-b552-ff4b45c7236e/to/1946ae42-9a2d-41f2-98d6-225a79727430?hash1=3d6112b5c7d095d3088b359c611a5a2704c5dbdc</a><br>\nIt's not just wall-clock (-83%) but also task-clock (-48%). At the very end the two CPUs are listed, they basically play in different leagues. But yes, RAM is basically irrelevant.</p>",
        "id": 385502697,
        "sender_full_name": "Sebastian Ullrich",
        "timestamp": 1692204542
    },
    {
        "content": "<p>The old machine also was optimized for consistency, not throughput: boosting and hyperthreading were disabled and one core was reserved for the benchmark program itself. This did not turn out to help much on the new machine.</p>",
        "id": 385503151,
        "sender_full_name": "Sebastian Ullrich",
        "timestamp": 1692204727
    },
    {
        "content": "<p>Thank you so much for this! The speedcenter was really essential for me recently when trying to work out which changes in a PR were actually important</p>",
        "id": 385505291,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1692205565
    },
    {
        "content": "<p>It looks like the CI has been failing since <a href=\"https://github.com/leanprover-community/mathlib4/pull/6490\">#6490</a></p>",
        "id": 389192591,
        "sender_full_name": "Matthew Ballard",
        "timestamp": 1693921280
    },
    {
        "content": "<p>Disk space problems too? It fails with a Nix error trying to fetch a flake input (<code>failed to extract archive (truncated gzip input)</code>)</p>",
        "id": 389193689,
        "sender_full_name": "Mauricio Collares",
        "timestamp": 1693921569
    },
    {
        "content": "<p>Disk is fine, I assumed it was the GitHub outage. But that is supposed to be over and it's still failing.</p>",
        "id": 389230208,
        "sender_full_name": "Sebastian Ullrich",
        "timestamp": 1693931113
    },
    {
        "content": "<p>I re-benched an old(er) PR and it failed with the analogous error message</p>",
        "id": 389234702,
        "sender_full_name": "Matthew Ballard",
        "timestamp": 1693932451
    },
    {
        "content": "<p>And we're back. I had to clear a cache busted from the outage.</p>",
        "id": 389356804,
        "sender_full_name": "Sebastian Ullrich",
        "timestamp": 1693985772
    },
    {
        "content": "<p>I assume <a href=\"http://speed.lean-fro.org/mathlib4/run-detail/8f31bb53-ada8-4fe7-bd76-448771fdfa4b\">this</a> is not correct? Because otherwise it is wonderful (and I haven’t been paying attention).</p>",
        "id": 391198579,
        "sender_full_name": "Matthew Ballard",
        "timestamp": 1694791154
    },
    {
        "content": "<p>That's consistent with github, see <a href=\"https://github.com/leanprover-community/mathlib4/actions/runs/6198949800/job/16830464511#step:18:24\">https://github.com/leanprover-community/mathlib4/actions/runs/6198949800/job/16830464511#step:18:24</a></p>",
        "id": 391202861,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1694792190
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"110087\">@Scott Morrison</span>, are we sure that the latest release hasn't broken the linter in some way? 6s seems way to fast to be actually running the lint</p>",
        "id": 391202940,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1694792217
    },
    {
        "content": "<p>I get the same behavior locally</p>",
        "id": 391203328,
        "sender_full_name": "Matthew Ballard",
        "timestamp": 1694792335
    },
    {
        "content": "<p>There is no <code>lake exe runLinter -v</code> ?</p>",
        "id": 391203481,
        "sender_full_name": "Matthew Ballard",
        "timestamp": 1694792386
    },
    {
        "content": "<p>Hmm. Very limited testing and I can’t get <code>simpNF</code> to fire with <code>#lint</code>. Can others confirm or refute? I have to teach momentarily</p>",
        "id": 391205451,
        "sender_full_name": "Matthew Ballard",
        "timestamp": 1694792880
    },
    {
        "content": "<p>Do we have an example that is supposed to fire <code>simpNF</code>?</p>",
        "id": 391210392,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1694793990
    },
    {
        "content": "<p><code>#lint</code> works for me, but it seems <code>runLinter</code> doesn't</p>",
        "id": 391214470,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1694795023
    },
    {
        "content": "<p>I think this is a lake issue: <code>runLinter</code> now refers to <code>./lake-packages/std/build/bin/runLinter</code> not the <code>runLinter</code> in mathlib4</p>",
        "id": 391214828,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1694795124
    },
    {
        "content": "<p>I just copied a theorem with the simp attribute, changed the name, and added the simp attribute to the copy. I assumed it would be caught</p>",
        "id": 391221166,
        "sender_full_name": "Matthew Ballard",
        "timestamp": 1694797118
    },
    {
        "content": "<p>I guess it’s <a href=\"http://speed.lean-fro.org/mathlib4/run-detail/c5138347-9e96-43b7-a7fe-60e5e420a890\">working</a> again :)</p>",
        "id": 391234597,
        "sender_full_name": "Matthew Ballard",
        "timestamp": 1694801624
    },
    {
        "content": "<p><a href=\"http://speed.lean-fro.org/mathlib4/run-detail/e7b27246-a3e6-496a-b552-ff4b45c7236e/d9e7e897cb8ac01e1d7ac3edf2a7308039370fec\">http://speed.lean-fro.org/mathlib4/run-detail/e7b27246-a3e6-496a-b552-ff4b45c7236e/d9e7e897cb8ac01e1d7ac3edf2a7308039370fec</a> just resulted in an 18% increase in olean serialization for what seems like a fairly innocent file</p>",
        "id": 392004427,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1695162360
    },
    {
        "content": "<p><a href=\"https://github.com/leanprover-community/mathlib4/pull/7103\">#7103</a> ?</p>",
        "id": 392006473,
        "sender_full_name": "Matthew Ballard",
        "timestamp": 1695163513
    },
    {
        "content": "<p>Would it be possible to have the speedcenter show the<code>compilation</code> metric on a per-file basis, <span class=\"user-mention\" data-user-id=\"110024\">@Sebastian Ullrich</span>? The above somewhat suggests that we could have one or two more files that represent a majority of the memory usage</p>",
        "id": 392097895,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1695209685
    },
    {
        "content": "<p>Is there something like a <code>noncomputable! file</code> to make sure that Lean does not try to compile any definition in the file? I think it would make sense to have this in many files (maybe even most files, or all files outside the <code>Data</code> folder)</p>",
        "id": 392098485,
        "sender_full_name": "Sebastien Gouezel",
        "timestamp": 1695209893
    },
    {
        "content": "<p>I assume we're running into a bug here (that hopefully will eventually be diagnosed and fixed), so adding language features to work around it feels like overkill</p>",
        "id": 392098789,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1695210019
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"310045\">Eric Wieser</span> <a href=\"#narrow/stream/287929-mathlib4/topic/mathlib4.20speedcenter/near/392097895\">said</a>:</p>\n<blockquote>\n<p>Would it be possible to have the speedcenter show the<code>compilation</code> metric on a per-file basis, <span class=\"user-mention silent\" data-user-id=\"110024\">Sebastian Ullrich</span>? The above somewhat suggests that we could have one or two more files that represent a majority of the memory usage</p>\n</blockquote>\n<p>We are already stressing the server software to its limits with the current number of metrics, measuring anything else for each file might break it for good. It would probably be better for someone to measure that locally as a once-off/monthly/... run</p>",
        "id": 392098798,
        "sender_full_name": "Sebastian Ullrich",
        "timestamp": 1695210024
    },
    {
        "content": "<p>Alternatively, do you think the compilation time for a declaration could be stored in the info tree or similar, and then we could print a leaderboard in the lint step of CI?</p>",
        "id": 392098968,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1695210096
    },
    {
        "content": "<p>Doesn't <code>--profile</code> plus some bash mangling give you that?</p>",
        "id": 392099134,
        "sender_full_name": "Sebastian Ullrich",
        "timestamp": 1695210145
    },
    {
        "content": "<p>Is that an argument to <code>lake</code> or just <code>lean</code>?</p>",
        "id": 392099173,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1695210166
    },
    {
        "content": "<p>Eric, wouldn't that invalidate cache traces?</p>",
        "id": 392099212,
        "sender_full_name": "Jireh Loreaux",
        "timestamp": 1695210182
    },
    {
        "content": "<p>Lake knows about some <code>lean</code> options that don't affect the trace but I forgot the specifics</p>",
        "id": 392099294,
        "sender_full_name": "Sebastian Ullrich",
        "timestamp": 1695210218
    },
    {
        "content": "<p>(I'm not sure, I'm asking)</p>",
        "id": 392099323,
        "sender_full_name": "Jireh Loreaux",
        "timestamp": 1695210231
    },
    {
        "content": "<p>Yes, there's a <code>weakLeanArgs</code> flag to pass arguments that claim to not affect the oleans</p>",
        "id": 392099398,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1695210250
    },
    {
        "content": "<p>By the way, something about the maxrss metric I recently learned that I may have misrepresented before: it is not the sum of each <code>lean</code> process' maximum resident set running in parallel but the maximum of maxima. I.e. there is (at least) one Lean file somewhere in mathlib that uses the shown amount of memory by itself.</p>",
        "id": 392099459,
        "sender_full_name": "Sebastian Ullrich",
        "timestamp": 1695210276
    },
    {
        "content": "<p>That makes much more sense!</p>",
        "id": 392099625,
        "sender_full_name": "Matthew Ballard",
        "timestamp": 1695210340
    },
    {
        "content": "<p>Does it :) ? It's not the metric I hoped for but the one Linux provides</p>",
        "id": 392099742,
        "sender_full_name": "Sebastian Ullrich",
        "timestamp": 1695210379
    },
    {
        "content": "<p>Is it possible to find out which file achieves that maximum?</p>",
        "id": 392099750,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1695210383
    },
    {
        "content": "<p>Not without measuring yourself</p>",
        "id": 392099796,
        "sender_full_name": "Sebastian Ullrich",
        "timestamp": 1695210408
    },
    {
        "content": "<p>Things weren’t tracking together before. Compilation would jump in a file but max rss wouldn’t budge.</p>",
        "id": 392099884,
        "sender_full_name": "Matthew Ballard",
        "timestamp": 1695210448
    },
    {
        "content": "<p>Or profiling an individual file would show a huge max rss jump but the speed center would report nothing</p>",
        "id": 392100043,
        "sender_full_name": "Matthew Ballard",
        "timestamp": 1695210495
    },
    {
        "content": "<p>Is <a href=\"http://speed.lean-fro.org/mathlib4/run-detail/04b46711-3605-4c1e-93ad-263e91a14df7\">this</a> from bumping aesop?</p>",
        "id": 395037424,
        "sender_full_name": "Matthew Ballard",
        "timestamp": 1696510568
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"256311\">@Jannis Limperg</span></p>",
        "id": 395037844,
        "sender_full_name": "Matthew Ballard",
        "timestamp": 1696510692
    },
    {
        "content": "<p>Lol <span class=\"user-mention\" data-user-id=\"110031\">@Patrick Massot</span> I didn't know you'd also jumped on the \"make mathlib faster\" bandwagon</p>",
        "id": 395045297,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1696512978
    },
    {
        "content": "<p>I didn't know either, but I'm proud of this achievement. I didn't intend to bump aesop in this PR, but I bumped proofwidgets four times and I guess one of them was running <code>lake update</code> instead of <code>lake update proofwidgets</code>.</p>",
        "id": 395050665,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1696514550
    },
    {
        "content": "<p>Not sure whether this is Aesop-related. I didn't do any intentional optimisation. But I'll be happy to claim it (jointly with Patrick of course).</p>",
        "id": 395079535,
        "sender_full_name": "Jannis Limperg",
        "timestamp": 1696523315
    },
    {
        "content": "<p>The -54% aesop seem to suggest it is Aesop related :)</p>",
        "id": 395080702,
        "sender_full_name": "Sebastian Ullrich",
        "timestamp": 1696523723
    },
    {
        "content": "<p>The libraries are ones that make heavy use also, eg Category Theory</p>",
        "id": 395080939,
        "sender_full_name": "Matthew Ballard",
        "timestamp": 1696523804
    },
    {
        "content": "<p>I'm really confused. There was absolutely nothing in the bump that I can imagine being responsible for a 50% speedup. But the numbers haven't gone up again afterwards, so I guess it wasn't a fluke.</p>",
        "id": 395109844,
        "sender_full_name": "Jannis Limperg",
        "timestamp": 1696535724
    },
    {
        "content": "<p><a href=\"/user_uploads/3121/KOQyoInoLjDYwbbjkBd_8snN/Screenshot-2023-10-05-at-4.09.41PM.png\">Current trend</a></p>\n<div class=\"message_inline_image\"><a href=\"/user_uploads/3121/KOQyoInoLjDYwbbjkBd_8snN/Screenshot-2023-10-05-at-4.09.41PM.png\" title=\"Current trend\"><img src=\"/user_uploads/3121/KOQyoInoLjDYwbbjkBd_8snN/Screenshot-2023-10-05-at-4.09.41PM.png\"></a></div>",
        "id": 395111851,
        "sender_full_name": "Matthew Ballard",
        "timestamp": 1696536651
    },
    {
        "content": "<p>It kind of seems a shame that a big speedup has happened and nobody can put their finger on what caused it. Understanding it better might make an even bigger speedup possible.</p>",
        "id": 395111880,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1696536670
    },
    {
        "content": "<p><a href=\"http://speed.lean-fro.org/mathlib4/repo-detail/e7b27246-a3e6-496a-b552-ff4b45c7236e?zoomXStart=1695091003015.0515&amp;zoomXEnd=1696564800000&amp;dimensions=build%3Ainstructions&amp;dayEquidistant=true\">Link</a></p>",
        "id": 395112049,
        "sender_full_name": "Matthew Ballard",
        "timestamp": 1696536751
    },
    {
        "content": "<p>All progress starts with confusion</p>",
        "id": 395112087,
        "sender_full_name": "Matthew Ballard",
        "timestamp": 1696536775
    },
    {
        "content": "<p>Between suppress compliation, cleaning up instances, and <a href=\"https://github.com/leanprover/lean4/pull/2478\">lean4#2478</a>, it will be going down a good deal more</p>",
        "id": 395112222,
        "sender_full_name": "Matthew Ballard",
        "timestamp": 1696536843
    },
    {
        "content": "<p>Was it perhaps the previous commit that changed something to do with CI, but it only showed up on the following commit or something? It seems a little unlikely given what the PR was, but it's a possibility.</p>",
        "id": 395198031,
        "sender_full_name": "Chris Hughes",
        "timestamp": 1696577859
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"256311\">Jannis Limperg</span> <a href=\"#narrow/stream/287929-mathlib4/topic/mathlib4.20speedcenter/near/395109844\">said</a>:</p>\n<blockquote>\n<p>I'm really confused. There was absolutely nothing in the bump that I can imagine being responsible for a 50% speedup. But the numbers haven't gone up again afterwards, so I guess it wasn't a fluke.</p>\n</blockquote>\n<p>Could <a href=\"https://github.com/JLimperg/aesop/commit/f4fa2b5a0b76de43ecf490ff0916f8a196ed5ab2\">https://github.com/JLimperg/aesop/commit/f4fa2b5a0b76de43ecf490ff0916f8a196ed5ab2</a> be the source of this improvement?</p>",
        "id": 395212987,
        "sender_full_name": "Mauricio Collares",
        "timestamp": 1696583033
    },
    {
        "content": "<p>Unlikely because that function is only called when erasing rules, which Aesop calls in mathlib rarely do.</p>",
        "id": 395214253,
        "sender_full_name": "Jannis Limperg",
        "timestamp": 1696583483
    },
    {
        "content": "<p>If I wanted to invest some time into investigating which commit was responsible for the speedup, how would I do that? I guess I could create Aesop branches with some of the relevant commits reverted, and then a mathlib branch that tries out the different Aesop variants. Then make a PR and !bench that.</p>",
        "id": 395215225,
        "sender_full_name": "Jannis Limperg",
        "timestamp": 1696583843
    },
    {
        "content": "<p>Do you know about <code>git bisect</code>? An almost magical tool for finding which commit causes something.</p>",
        "id": 395221676,
        "sender_full_name": "Joachim Breitner",
        "timestamp": 1696585986
    },
    {
        "content": "<p>I have never tried running <a href=\"https://github.com/leanprover-community/mathlib4/blob/master/scripts/bench/run\">https://github.com/leanprover-community/mathlib4/blob/master/scripts/bench/run</a> locally, but maybe it is possible to get instruction counts with it.</p>",
        "id": 395222189,
        "sender_full_name": "Mauricio Collares",
        "timestamp": 1696586164
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"470149\">Joachim Breitner</span> <a href=\"#narrow/stream/287929-mathlib4/topic/mathlib4.20speedcenter/near/395221676\">said</a>:</p>\n<blockquote>\n<p>Do you know about <code>git bisect</code>? An almost magical tool for finding which commit causes something.</p>\n</blockquote>\n<p>Yes, though I never remember how exactly to use it. Perhaps it's time for another try.</p>",
        "id": 395223517,
        "sender_full_name": "Jannis Limperg",
        "timestamp": 1696586627
    },
    {
        "content": "<p>I deployed a quick hack that formats mathlib per-file instruction differences as absolute numbers with sensible suffixes, and uses 1 billion instructions as a cut-off for significance (edit: moved up to 10B because of noise)<br>\n<a href=\"/user_uploads/3121/BB_Lw5NYDy8Z4H7k03TnSuUt/image.png\">image.png</a></p>\n<div class=\"message_inline_image\"><a href=\"/user_uploads/3121/BB_Lw5NYDy8Z4H7k03TnSuUt/image.png\" title=\"image.png\"><img src=\"/user_uploads/3121/BB_Lw5NYDy8Z4H7k03TnSuUt/image.png\"></a></div>",
        "id": 396109357,
        "sender_full_name": "Sebastian Ullrich",
        "timestamp": 1697036678
    },
    {
        "content": "<p>Very rough guideline: 10 billion instructions = ~1s</p>",
        "id": 396109482,
        "sender_full_name": "Sebastian Ullrich",
        "timestamp": 1697036713
    },
    {
        "content": "<p>So that means any file with a ~0.1 second difference in compile time will appear in the list of significant changes?</p>",
        "id": 396119896,
        "sender_full_name": "Jireh Loreaux",
        "timestamp": 1697039753
    },
    {
        "content": "<p>Yes. Does it sound reasonable?</p>",
        "id": 396120920,
        "sender_full_name": "Sebastian Ullrich",
        "timestamp": 1697040049
    },
    {
        "content": "<p>My guess is that it's far too sensititive. Even simple files can take &gt; 2 seconds, so this is well below the previous 5% cutoff. And for the awful files which take several minutes to compile, they will be marked significant ~ every time.</p>",
        "id": 396121501,
        "sender_full_name": "Jireh Loreaux",
        "timestamp": 1697040191
    },
    {
        "content": "<p>I think what would make more sense is to still use the 5% cutoff, but <em>display</em> absolute instructions.</p>",
        "id": 396121634,
        "sender_full_name": "Jireh Loreaux",
        "timestamp": 1697040211
    },
    {
        "content": "<p>The percentage cutoff was awkward for very small files. It sounds like we might want the conjunction of both.</p>",
        "id": 396122160,
        "sender_full_name": "Sebastian Ullrich",
        "timestamp": 1697040307
    },
    {
        "content": "<p>Though \"marked significant ~ every time\" is clearly untrue if you look at the current page</p>",
        "id": 396122414,
        "sender_full_name": "Sebastian Ullrich",
        "timestamp": 1697040377
    },
    {
        "content": "<p>Well, yes, it was awkward for very small files, but by displaying the absolute instructions, it becomes clear that the file must have been small.</p>",
        "id": 396122418,
        "sender_full_name": "Jireh Loreaux",
        "timestamp": 1697040378
    },
    {
        "content": "<p>(I stand corrected about my claim.)</p>",
        "id": 396122616,
        "sender_full_name": "Jireh Loreaux",
        "timestamp": 1697040438
    },
    {
        "content": "<p>Perhaps my feeling about sensitivity is just completely wrong then and should be ignored.</p>",
        "id": 396122885,
        "sender_full_name": "Jireh Loreaux",
        "timestamp": 1697040502
    },
    {
        "content": "<p>I'd say let's give the current version a try first</p>",
        "id": 396122953,
        "sender_full_name": "Sebastian Ullrich",
        "timestamp": 1697040523
    },
    {
        "content": "<p>I've bumped the cutoff to 10B because we have some files with surprisingly high deviation. There's always the full table for details.</p>",
        "id": 396230093,
        "sender_full_name": "Sebastian Ullrich",
        "timestamp": 1697095430
    },
    {
        "content": "<p>Hey I just had an idea for anyone who likes to do data analysis: If we treat the time-series of runtimes of file i across all commits as an n-dimensional vector (one dim per commit), we may be able to find clusters in the resulting data, corresponding to files that stress different parts of the system. We probably don't need all commits, it is probably sufficient to capture some representative noise spread as well as any major perf changes in lean. If we can find good clusters, that might be one way to significantly reduce the number of benchmark variables, which would help make it more informative compared to the current wall of numbers with unclear significance</p>",
        "id": 396236248,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1697097997
    },
    {
        "content": "<p>Something is up because <a href=\"http://speed.lean-fro.org/mathlib4/compare/1367ad5c-c959-46b8-8475-15d3d1210f0e/to/27b72717-b7f2-4755-b932-9fdc34a159d4\">http://speed.lean-fro.org/mathlib4/compare/1367ad5c-c959-46b8-8475-15d3d1210f0e/to/27b72717-b7f2-4755-b932-9fdc34a159d4</a> doesn't report the improvements in individual files </p>\n<p>Personally, I don't think knowing that <code>CategoryTheory.Abelian.Projective</code> changed 0.4% is useful information. I care if big files (measured via CPU instructions) move a reasonable amount and smaller files have dramatic changes. And percentages are easier to consume than raw instructions. My two <span aria-label=\"coin\" class=\"emoji emoji-1fa99\" role=\"img\" title=\"coin\">:coin:</span></p>",
        "id": 396284198,
        "sender_full_name": "Matthew Ballard",
        "timestamp": 1697115973
    },
    {
        "content": "<p>You may need to Ctrl+F5 if you don't see individual green files</p>",
        "id": 396284437,
        "sender_full_name": "Sebastian Ullrich",
        "timestamp": 1697116070
    },
    {
        "content": "<p>The GitHub <a href=\"https://github.com/leanprover-community/mathlib4/pull/7634#issuecomment-1758912243\">comment</a> suffered from this issue also</p>",
        "id": 396288314,
        "sender_full_name": "Matthew Ballard",
        "timestamp": 1697117349
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"110087\">@Scott Morrison</span> promised me 15%. I want my money <a href=\"http://speed.lean-fro.org/mathlib4/run-detail/7f1a0bb6-869c-490b-b1b3-319870f75f70\">back</a>. <span aria-label=\"lol\" class=\"emoji emoji-1f606\" role=\"img\" title=\"lol\">:lol:</span> </p>\n<p>But seriously, this is excellent!</p>",
        "id": 396905818,
        "sender_full_name": "Matthew Ballard",
        "timestamp": 1697463688
    },
    {
        "content": "<p>It doesn't work after bumping to v4.3.0-rc2.</p>",
        "id": 402665079,
        "sender_full_name": "Yuyang Zhao",
        "timestamp": 1700216784
    },
    {
        "content": "<p>That's because <code>build/</code> is now <code>.lake/build/</code></p>",
        "id": 402666051,
        "sender_full_name": "Mauricio Collares",
        "timestamp": 1700217013
    },
    {
        "content": "<p>Here, I think: <a href=\"https://github.com/leanprover-community/mathlib4/blob/master/scripts/bench/temci-config.run.yml#L39\">https://github.com/leanprover-community/mathlib4/blob/master/scripts/bench/temci-config.run.yml#L39</a></p>",
        "id": 402666582,
        "sender_full_name": "Mauricio Collares",
        "timestamp": 1700217171
    },
    {
        "content": "<p>Yes, please PR!</p>",
        "id": 402668481,
        "sender_full_name": "Sebastian Ullrich",
        "timestamp": 1700217715
    },
    {
        "content": "<p>Untested because I don't know how: <a href=\"https://github.com/leanprover-community/mathlib4/pull/8467\">#8467</a></p>",
        "id": 402669021,
        "sender_full_name": "Mauricio Collares",
        "timestamp": 1700217851
    },
    {
        "content": "<p>I guess I can just run <code>!bench</code></p>",
        "id": 402669041,
        "sender_full_name": "Mauricio Collares",
        "timestamp": 1700217860
    },
    {
        "content": "<p>By the way, this is the bump comparison (-2% build instructions, -3.7% build wall-clock): <a href=\"http://speed.lean-fro.org/mathlib4/compare/b02f639c-050f-43ce-88b1-019aa70ab371/to/263f3a9d-06a8-40ab-9b11-123857b983d9\">http://speed.lean-fro.org/mathlib4/compare/b02f639c-050f-43ce-88b1-019aa70ab371/to/263f3a9d-06a8-40ab-9b11-123857b983d9</a></p>",
        "id": 402674251,
        "sender_full_name": "Mauricio Collares",
        "timestamp": 1700219590
    },
    {
        "content": "<p>Could we expedite this PR? <span class=\"user-mention\" data-user-id=\"110087\">@Scott Morrison</span></p>",
        "id": 402687286,
        "sender_full_name": "Sebastian Ullrich",
        "timestamp": 1700223996
    },
    {
        "content": "<p>The runner is unavailable again :(</p>",
        "id": 402732336,
        "sender_full_name": "Mauricio Collares",
        "timestamp": 1700237917
    },
    {
        "content": "<p>That one was deliberate, it's back now</p>",
        "id": 402739409,
        "sender_full_name": "Sebastian Ullrich",
        "timestamp": 1700240332
    },
    {
        "content": "<p>I've backdated the fix so it shows the correct per-commit timings: <a href=\"http://speed.lean-fro.org/mathlib4/run-detail/5ae134c7-b878-4420-9bd9-359862465a32\">http://speed.lean-fro.org/mathlib4/run-detail/5ae134c7-b878-4420-9bd9-359862465a32</a>. The other commits between bump and fix are requeued now.</p>",
        "id": 402739679,
        "sender_full_name": "Sebastian Ullrich",
        "timestamp": 1700240417
    },
    {
        "content": "<p><code>open Mathlib -- wall-clock</code> seems to be a lot of noise in the <code>Recent Significant Runs</code></p>",
        "id": 407981206,
        "sender_full_name": "Matthew Ballard",
        "timestamp": 1702566651
    },
    {
        "content": "<p>Not after <a href=\"https://github.com/leanprover-community/mathlib4/pull/8891\">#8891</a></p>",
        "id": 407982600,
        "sender_full_name": "Sebastian Ullrich",
        "timestamp": 1702567012
    },
    {
        "content": "<p>Great.</p>",
        "id": 407983874,
        "sender_full_name": "Matthew Ballard",
        "timestamp": 1702567361
    }
]