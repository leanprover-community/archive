[
    {
        "content": "<p>In light of the bug found by DeepSeek, I’m curious what Mathlib does to check against the following possible issues:</p>\n<ul>\n<li>check that the proof is indeed correct by the kernel</li>\n<li>check that no sorry or other axioms were used (besides the usual ones)</li>\n<li>check that theorems made it into the environment </li>\n<li>check that the theorem statement in the environment is as expected.</li>\n</ul>\n<p>I assume the first is done by lean4checker.  Does it also cover the second?  Is there anything for the  last two?  If a theorem is used, then that would probably work, but if a theorem is a leaf theorem, it could be skipped without lean4checker noticing, right?</p>",
        "id": 515812769,
        "sender_full_name": "Jason Rute",
        "timestamp": 1746227241
    },
    {
        "content": "<p>If it didn't make it into the environment, I wouldn't expect to see it in the docs</p>",
        "id": 515818619,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1746230798
    },
    {
        "content": "<ul>\n<li>AFAIK, axioms aren't covered. There is a (pretty straightforward) meta code for this, and we're waiting for people who care about avoiding <code>Classical</code> to turn it into a linter.</li>\n<li>If Lean silently fails on a theorem, then we won't see it until someone tries to use it.</li>\n<li>We have nothing to compare the statement in the environment to, so we don't implement any checks here.</li>\n</ul>",
        "id": 515824134,
        "sender_full_name": "Yury G. Kudryashov",
        "timestamp": 1746234210
    },
    {
        "content": "<p>Thanks!  I’m surprised about not checking for axioms or sorry, but I saw that <span class=\"user-mention\" data-user-id=\"310045\">@Eric Wieser</span> made a request to add that to lean4checker.</p>",
        "id": 515825379,
        "sender_full_name": "Jason Rute",
        "timestamp": 1746234948
    },
    {
        "content": "<p>AFAIK, Lean issues a warning if a declaration uses <code>sorry</code>, so we rely on this for now.</p>",
        "id": 515833621,
        "sender_full_name": "Yury G. Kudryashov",
        "timestamp": 1746240045
    },
    {
        "content": "<p>As for axioms, we will definitely decline a PR with an <code>axiom</code> command. Of course, someone can deliberately sneak it in using some meta programming, but meta code goes through review too.</p>",
        "id": 515833774,
        "sender_full_name": "Yury G. Kudryashov",
        "timestamp": 1746240149
    },
    {
        "content": "<p>This isn't a 100% guarantee, but works well at least until someone doesn't try to deliberately fool us.</p>",
        "id": 515833824,
        "sender_full_name": "Yury G. Kudryashov",
        "timestamp": 1746240204
    },
    {
        "content": "<p>For DeepSeek, AFAICT they didn't run the final proof through a normal Lean compilation process, otherwise they would've caught this.</p>",
        "id": 515833918,
        "sender_full_name": "Yury G. Kudryashov",
        "timestamp": 1746240258
    },
    {
        "content": "<p>Yeah, I think your meticulous review process is the best safe guard to be honest.  The bug which the DeepSeek model seems to have found did pass the vs code infoview, lean build, and lean4checker.  (I’m not saying they tested all that, but even if they did it wouldn’t have caught it.)  The normal warning about sorries didn’t print and also the theorem wasn’t added to the environment so lean4checker was happy.</p>",
        "id": 515834237,
        "sender_full_name": "Jason Rute",
        "timestamp": 1746240483
    },
    {
        "content": "<p>That is why I brought up this conversation.  I’m trying to understand the recommended way to avoid this issue in the future, and I assume mathlib was the place with the most rigorous checking process.</p>",
        "id": 515834450,
        "sender_full_name": "Jason Rute",
        "timestamp": 1746240624
    },
    {
        "content": "<p>Here is the link to the discussion of the error: <a class=\"stream-topic\" data-stream-id=\"270676\" href=\"/#narrow/channel/270676-lean4/topic/apply.3F.20might.20suppress.20other.20warnings.2Ferrors/with/515641973\">#lean4 &gt; apply? might suppress other warnings/errors</a></p>",
        "id": 515834814,
        "sender_full_name": "Jason Rute",
        "timestamp": 1746240892
    },
    {
        "content": "<p>It's good to keep in mind here that's it's only a couple of lines to write a macro that turns subsequent <code>theorem</code>s into a no-op. Lean's metaprogramming is intentionally very powerful.</p>\n<p>Obviously you can't use such \"theorems\", nor will they appear in docs.</p>\n<p>It's easy to check for the presence of a named theorem, or to check for a named theorem with a specified type, using metaprogramming, and e.g. autograders illustrate how to do this (as in the linked thread above).</p>\n<p>At the end of the day, skeptical review by humans is very helpful, and if you're going to claim any big results (especially <code>False</code>), at least a superficial sanity check by a human is obviously necessary. The same applies to all AI teams claiming \"state of the art\" benchmark results, and this last episode will hopefully raise standards there!</p>\n<p>(Presumably there will need to be a retraction, and this should help increase caution in future claims, and in particular not to claim things like \"Ooh, the model magically manages to use result X to prove many things\" without giving some thought about whether that makes an mathematical sense.)</p>",
        "id": 515884063,
        "sender_full_name": "Kim Morrison",
        "timestamp": 1746271044
    },
    {
        "content": "<p>(As for the DeepSeek paper, I think the results mostly hold with just a few false examples.  A major edit more than a retraction I think is needed.)</p>\n<p>But I think the standards of how to check this stuff may need to increase across the board including in mathlib. People are going to use AI to fill in Lean blueprint project lemmas, to prove the correctness of their code, to prove the correctness of smart contracts, and to build autoformalized libraries of math.  The promise of Lean (very possibly false) is that you don’t have to check every little detail, and I don’t think real users are going to realize all the pitfalls.  Of course this is a learning curve for all of us, but again it is noteworthy that some of these non-proofs would (seem to) have at least passed the CI of Mathlib on Lean 4.9.0 (although not the review process), not to mention the CI of a mathematician’s random blueprint project.</p>",
        "id": 515885589,
        "sender_full_name": "Jason Rute",
        "timestamp": 1746272034
    },
    {
        "content": "<p>Maybe I’m making too big a deal of this.  (Everyone is right that this would have been caught if one tried to use the lemmas or print the axioms.) I really just wanted to ask here about what Mathlib does.</p>",
        "id": 515885931,
        "sender_full_name": "Jason Rute",
        "timestamp": 1746272250
    },
    {
        "content": "<p>We have leanchecker, btw</p>",
        "id": 515888214,
        "sender_full_name": "Ruben Van de Velde",
        "timestamp": 1746273653
    },
    {
        "content": "<p>The <code>apply?</code> trick would not make it into mathlib because CI lints for tactics which produce blue noise (whatever it's called officially, I mean blue squiggles which give output) and fails if there is any.</p>",
        "id": 515888858,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1746273973
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"307953\">@Ruben Van de Velde</span> see above and in the other threads.  Lean4checker doesn’t always catch stuff including the DeepSeek example</p>",
        "id": 515889077,
        "sender_full_name": "Jason Rute",
        "timestamp": 1746274092
    }
]