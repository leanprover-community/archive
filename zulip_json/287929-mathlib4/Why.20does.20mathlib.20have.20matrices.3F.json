[
    {
        "content": "<p>This is probably off-topic but I'm quite surprised we even have matrices in Mathlib. I'm of the personal opinion that a basis-free approach to linear algebra ends up being more elegant and often simpler.</p>",
        "id": 567051216,
        "sender_full_name": "Violeta Hernández",
        "timestamp": 1767915941
    },
    {
        "content": "<p>some things are basic invariant but still really hard to define without matrices</p>",
        "id": 567051433,
        "sender_full_name": "Aaron Liu",
        "timestamp": 1767916110
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"816344\">Aaron Liu</span> <a href=\"#narrow/channel/287929-mathlib4/topic/Use.20.60Vector.60.20more.3F/near/567051433\">said</a>:</p>\n<blockquote>\n<p>some things are basic invariant but still really hard to define without matrices</p>\n</blockquote>\n<p>Examples?</p>",
        "id": 567063956,
        "sender_full_name": "Violeta Hernández",
        "timestamp": 1767926086
    },
    {
        "content": "<p>like I guess the determinant or the trace</p>",
        "id": 567064446,
        "sender_full_name": "Aaron Liu",
        "timestamp": 1767926547
    },
    {
        "content": "<p>maybe \"really hard\" was an exaggeration</p>",
        "id": 567064476,
        "sender_full_name": "Aaron Liu",
        "timestamp": 1767926579
    },
    {
        "content": "<p>Here are at least 3 reasons to have matrices.</p>\n<ul>\n<li>Sometimes, it is easier to define something for matrices and prove that it doesn't depend on a choice of coordinates.</li>\n<li>For some theorems, the basis is important. We can try to formulate them for a pair of (linear operator, basis), but this is worse than talking about matrices.</li>\n<li>We want to support undergrad curriculum.</li>\n</ul>",
        "id": 567066091,
        "sender_full_name": "Yury G. Kudryashov",
        "timestamp": 1767928131
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"816344\">Aaron Liu</span> <a href=\"#narrow/channel/287929-mathlib4/topic/Use.20.60Vector.60.20more.3F/near/567064446\">said</a>:</p>\n<blockquote>\n<p>like I guess the determinant or the trace</p>\n</blockquote>\n<p>Determinant is the scale factor of the n-th exterior power, trace is the contraction map on tensors</p>",
        "id": 567069882,
        "sender_full_name": "Violeta Hernández",
        "timestamp": 1767931416
    },
    {
        "content": "<p>Fair enough, it's not like matrices are categorically unuseful in math. Though I'd argue we could be quite more liberal with their use if we so wanted.</p>",
        "id": 567069983,
        "sender_full_name": "Violeta Hernández",
        "timestamp": 1767931498
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"816344\">Aaron Liu</span> <a href=\"#narrow/channel/287929-mathlib4/topic/Use.20.60Vector.60.20more.3F/near/567064476\">said</a>:</p>\n<blockquote>\n<p>maybe \"really hard\" was an exaggeration</p>\n</blockquote>\n<p>I'm not so sure it's an exaggeration. I don't know of any way of defining the trace of a linear map from a finite-dimensional vector space to itself without picking a basis and taking the trace of the corresponding matrix (my confused thoughts about it in 2021 are <a href=\"https://xenaproject.wordpress.com/2021/05/19/the-trace-of-an-endomorphism-without-picking-a-basis/\">here</a>).</p>\n<p>I have just spent the week picking bases for vector spaces for FLT and using matrices, because sometimes the way to prove things about constructions for finite-dimensional vector spaces is to prove things about matrices first. Example: I don't know of any proof that a linear isomorphism from a finite-dimensional real vector space to itself scales Lebesgue measure by its determinant which doesn't involve picking a basis and then doing a pretty gruelling calculation with matrices, as we do here in <a href=\"https://leanprover-community.github.io/mathlib4_docs/find/?pattern=Real.map_matrix_volume_pi_eq_smul_volume_pi#doc\">docs#Real.map_matrix_volume_pi_eq_smul_volume_pi</a> in mathlib . If I knew a conceptual proof of this then I'd be able to answer <a href=\"https://mathoverflow.net/questions/506537/how-does-an-automorphism-of-a-free-module-scale-haar-measure\">my own recent mathoverflow question</a>. </p>\n<p>All this is off-topic for this thread (edit: not any more because I moved it to a more appropriate thread) but there is definitely a point to matrices. They are a model for linear maps and sometimes to prove theorems or make definitions, you need a model; conceptually I am not sure why but in practice this seems to be definitely true.</p>",
        "id": 567117906,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1767956666
    },
    {
        "content": "<p>How much is it allowed to use the existence of a basis? If it is allowed to use the dimensions of subspaces, how about defining trace as the sum of generalized eigenvalues times multilicity?</p>",
        "id": 567128221,
        "sender_full_name": "Yoh Tanimoto",
        "timestamp": 1767960569
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110038\">Kevin Buzzard</span> <a href=\"#narrow/channel/287929-mathlib4/topic/Use.20.60Vector.60.20more.3F/near/567117906\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"816344\">Aaron Liu</span> <a href=\"#narrow/channel/287929-mathlib4/topic/Use.20.60Vector.60.20more.3F/near/567064476\">said</a>:</p>\n<blockquote>\n<p>maybe \"really hard\" was an exaggeration</p>\n</blockquote>\n<p>I'm not so sure it's an exaggeration. I don't know of any way of defining the trace of a linear map from a finite-dimensional vector space to itself without picking a basis and taking the trace of the corresponding matrix (my confused thoughts about it in 2021 are <a href=\"https://xenaproject.wordpress.com/2021/05/19/the-trace-of-an-endomorphism-without-picking-a-basis/\">here</a>).</p>\n</blockquote>\n<p>Endomorphisms of <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>E</mi></mrow><annotation encoding=\"application/x-tex\">E</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.05764em;\">E</span></span></span></span> are isomorphic to <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>E</mi><mo>⊗</mo><msup><mi>E</mi><mo>∗</mo></msup></mrow><annotation encoding=\"application/x-tex\">E \\otimes E^*</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.7667em;vertical-align:-0.0833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.05764em;\">E</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">⊗</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6887em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.05764em;\">E</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6887em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mbin mtight\">∗</span></span></span></span></span></span></span></span></span></span></span> (where <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>v</mi><mo>⊗</mo><mi>ξ</mi></mrow><annotation encoding=\"application/x-tex\">v \\otimes \\xi</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6667em;vertical-align:-0.0833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">v</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">⊗</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.04601em;\">ξ</span></span></span></span> is the rank-one map mapping <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>x</mi></mrow><annotation encoding=\"application/x-tex\">x</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.4306em;\"></span><span class=\"mord mathnormal\">x</span></span></span></span> to <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>ξ</mi><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo><mi>v</mi></mrow><annotation encoding=\"application/x-tex\">\\xi(x) v</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.04601em;\">ξ</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">x</span><span class=\"mclose\">)</span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">v</span></span></span></span>). There is a canonical linear mapping from <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>E</mi><mo>⊗</mo><msup><mi>E</mi><mo>∗</mo></msup></mrow><annotation encoding=\"application/x-tex\">E \\otimes E^*</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.7667em;vertical-align:-0.0833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.05764em;\">E</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">⊗</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6887em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.05764em;\">E</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6887em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mbin mtight\">∗</span></span></span></span></span></span></span></span></span></span></span> to the scalar field, sending <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>v</mi><mo>⊗</mo><mi>ξ</mi></mrow><annotation encoding=\"application/x-tex\">v \\otimes \\xi</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6667em;vertical-align:-0.0833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">v</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">⊗</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.04601em;\">ξ</span></span></span></span> to <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>ξ</mi><mo stretchy=\"false\">(</mo><mi>v</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">\\xi(v)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.04601em;\">ξ</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">v</span><span class=\"mclose\">)</span></span></span></span> (obviously well defined by the universal property of the tensor product). Let's call it the trace. To me, it doesn't depend on a basis (and it also shows why the trace of finite-rank endomorphisms is also well defined in infinite dimension).</p>",
        "id": 567132951,
        "sender_full_name": "Sébastien Gouëzel",
        "timestamp": 1767962360
    },
    {
        "content": "<p>(I see that you mention in your post that you still need to pick a basis to show that the map from <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>E</mi><mo>⊗</mo><msup><mi>E</mi><mo>∗</mo></msup></mrow><annotation encoding=\"application/x-tex\">E \\otimes E^*</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.7667em;vertical-align:-0.0833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.05764em;\">E</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">⊗</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6887em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.05764em;\">E</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6887em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mbin mtight\">∗</span></span></span></span></span></span></span></span></span></span></span> is onto, but I'm not sure I agree with that: the image are the finite rank maps, and in finite dimension all maps are automatically finite rank, right? Of course at some point you need to use that the dimension is finite, but I'd say what is relevant is not that you have a basis, only a finite generating family)</p>",
        "id": 567133400,
        "sender_full_name": "Sébastien Gouëzel",
        "timestamp": 1767962530
    },
    {
        "content": "<p>I don't want to get too far off topic, but I'll just say that I have a hard time imagining formalizing most of numerical linear algebra without matrices.</p>",
        "id": 567152435,
        "sender_full_name": "Timothy Chow",
        "timestamp": 1767968539
    },
    {
        "content": "<p>And spectral graph theory</p>",
        "id": 567154881,
        "sender_full_name": "Shreyas Srinivas",
        "timestamp": 1767969251
    },
    {
        "content": "<p>Of which we have a bunch of basic definitions in mathlib</p>",
        "id": 567155360,
        "sender_full_name": "Shreyas Srinivas",
        "timestamp": 1767969388
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110038\">Kevin Buzzard</span> <a href=\"#narrow/channel/287929-mathlib4/topic/Use.20.60Vector.60.20more.3F/near/567117906\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"816344\">Aaron Liu</span> <a href=\"#narrow/channel/287929-mathlib4/topic/Use.20.60Vector.60.20more.3F/near/567064476\">said</a>:</p>\n<blockquote>\n<p>maybe \"really hard\" was an exaggeration</p>\n</blockquote>\n<p>Example: I don't know of any proof that a linear isomorphism from a finite-dimensional real vector space to itself scales Lebesgue measure by its determinant which doesn't involve picking a basis and then doing a pretty gruelling calculation with matrices, as we do here in <a href=\"https://leanprover-community.github.io/mathlib4_docs/find/?pattern=Real.map_matrix_volume_pi_eq_smul_volume_pi#doc\">docs#Real.map_matrix_volume_pi_eq_smul_volume_pi</a> in mathlib .</p>\n</blockquote>\n<p>Lebesgue measure on R^n is the unique locally finite translation invariant Borel measure up to a scaling factor. In particular, for linear map T : R^n -&gt; R^n, one has λ(T(E)) = f(T) λ(E) for every Borel E, for some constant f(T) ≥ 0. Clearly f is multiplicative. </p>\n<p>Choose an inner product on R^n. Since orthogonal maps preserve the unit sphere, they must have f(T) = 1. For maps with an orthogonal basis of eigenvectors, one has f(T) = |product of eigenvalues|. Finally, SVD tells you that these two properties uniquely define f(T) = |det(T)|.</p>\n<p>You certainly do have to define a basis for this argument, but you don't need to use the specific language of matrices.</p>",
        "id": 567310895,
        "sender_full_name": "Violeta Hernández",
        "timestamp": 1768042605
    },
    {
        "content": "<p>But I claim that you do, because you need to prove that all linear maps can be expressed as a product of linear maps for which you understand the scaling factor, and that is proved using matrices.</p>",
        "id": 567332110,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1768063286
    },
    {
        "content": "<p>Fair enough. I guess the Lebesgue measure is not a priori an entity in linear algebra since you only know how it works on rectangles with a very specific orientation. So it makes sense matrices with their builtin bases end up a useful tool for working with it.</p>",
        "id": 567351825,
        "sender_full_name": "Violeta Hernández",
        "timestamp": 1768085059
    },
    {
        "content": "<p>Lebesgue measure is much more algebraic than that because it's Haar measure (at least on Borel subsets, which are enough), so all you need is the topology -- you don't need a basis for this.</p>",
        "id": 567353074,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1768086839
    },
    {
        "content": "<p>In Seymour's project, we use explicit matrices representations extensively in the proof, even though the result itself is not about matrices. I think the whole work could have been done without matrices but it is not clear to me that it would have resulted in a better proof, representing regular matroids as totally unimodular matrices helps when taking their sums.</p>",
        "id": 567420865,
        "sender_full_name": "Rida Hamadani",
        "timestamp": 1768171329
    },
    {
        "content": "<p>But also the study of matrices itself is an area that needs a venue to be formalized in, complexity of matrix multiplication, existence of hadamard matrices, and so on: How would we go about formalizing new results in these areas if we don't have a functioning language of matrices in mathlib?</p>",
        "id": 567421158,
        "sender_full_name": "Rida Hamadani",
        "timestamp": 1768171627
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110050\">Sébastien Gouëzel</span> <a href=\"#narrow/channel/287929-mathlib4/topic/Why.20does.20mathlib.20have.20matrices.3F/near/567133400\">said</a>:</p>\n<blockquote>\n<p>(I see that you mention in your post that you still need to pick a basis to show that the map from <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>E</mi><mo>⊗</mo><msup><mi>E</mi><mo>∗</mo></msup></mrow><annotation encoding=\"application/x-tex\">E \\otimes E^*</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.7667em;vertical-align:-0.0833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.05764em;\">E</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">⊗</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6887em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.05764em;\">E</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6887em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mbin mtight\">∗</span></span></span></span></span></span></span></span></span></span></span> is onto, but I'm not sure I agree with that: the image are the finite rank maps, and in finite dimension all maps are automatically finite rank, right? Of course at some point you need to use that the dimension is finite, but I'd say what is relevant is not that you have a basis, only a finite generating family)</p>\n</blockquote>\n<p>So it seems to me that:</p>\n<p>1) You can define what it means for a vector space to be finite-dimensional without choosing a basis (just say it's finitely-generated)</p>\n<p>2) If E is finite-dimensional then the map <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>E</mi><mo>⊗</mo><msup><mi>E</mi><mo>∗</mo></msup><mo>→</mo><mi>E</mi><mi>n</mi><mi>d</mi><mo stretchy=\"false\">(</mo><mi>E</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">E\\otimes E^*\\to End(E)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.7667em;vertical-align:-0.0833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.05764em;\">E</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">⊗</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6887em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.05764em;\">E</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6887em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mbin mtight\">∗</span></span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">→</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.05764em;\">E</span><span class=\"mord mathnormal\">n</span><span class=\"mord mathnormal\">d</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.05764em;\">E</span><span class=\"mclose\">)</span></span></span></span> is a computable function, but the proof that it's a bijection is a dimension-count and it might be hard to do this without picking a basis;</p>\n<p>3) the inverse of this computable function is probably non-computable in general, so</p>\n<p>4) if you attempt to define trace this way without picking a basis then (a) it will be noncomputable and (b) you'll still have to convince me that you can prove that the map <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>E</mi><mo>⊗</mo><msup><mi>E</mi><mo>∗</mo></msup><mo>→</mo><mi>E</mi><mi>n</mi><mi>d</mi><mo stretchy=\"false\">(</mo><mi>E</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">E\\otimes E^*\\to End(E)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.7667em;vertical-align:-0.0833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.05764em;\">E</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">⊗</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6887em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.05764em;\">E</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6887em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mbin mtight\">∗</span></span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">→</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.05764em;\">E</span><span class=\"mord mathnormal\">n</span><span class=\"mord mathnormal\">d</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.05764em;\">E</span><span class=\"mclose\">)</span></span></span></span> is a bijection without picking a basis. Note that I won't give you the dimension of the space; I'll only tell you that it's finitely-generated as a module.</p>\n<p>Maybe it's possible to prove that it's a bijection without picking a basis though, or maybe you don't care because you will allow yourself to pick a basis in a proof.</p>\n<p>So perhaps a summary is that trace of a linear map is noncomputable unless you pick a basis?</p>",
        "id": 567421468,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1768171996
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110038\">Kevin Buzzard</span> <a href=\"#narrow/channel/287929-mathlib4/topic/Why.20does.20mathlib.20have.20matrices.3F/near/567421468\">said</a>:</p>\n<blockquote>\n<p>2) If E is finite-dimensional then the map <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>E</mi><mo>⊗</mo><msup><mi>E</mi><mo>∗</mo></msup><mo>→</mo><mi>E</mi><mi>n</mi><mi>d</mi><mo stretchy=\"false\">(</mo><mi>E</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">E\\otimes E^*\\to End(E)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.7667em;vertical-align:-0.0833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.05764em;\">E</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">⊗</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6887em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.05764em;\">E</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6887em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mbin mtight\">∗</span></span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">→</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.05764em;\">E</span><span class=\"mord mathnormal\">n</span><span class=\"mord mathnormal\">d</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.05764em;\">E</span><span class=\"mclose\">)</span></span></span></span> is a computable function, but the proof that it's a bijection is a dimension-count and it might be hard to do this without picking a basis (I agree surjectivity is fine though);<br>\n</p>\n</blockquote>\n<p>Isn't this function injective without assuming finite-dimensionality?</p>",
        "id": 567426145,
        "sender_full_name": "Stepan Nesterov",
        "timestamp": 1768177205
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110038\">Kevin Buzzard</span> <a href=\"#narrow/channel/287929-mathlib4/topic/Why.20does.20mathlib.20have.20matrices.3F/near/567421468\">said</a>:</p>\n<blockquote>\n<p>So perhaps a summary is that trace of a linear map is noncomputable unless you pick a basis?</p>\n</blockquote>\n<p>I wonder if some of these observations can be made formal. Perhaps a starting point would be the paper <a href=\"https://www.uni-muenster.de/FB10/mjm/acc/mjm-FarahBK.pdf\">Hilbert spaces without the Countable Axiom of Choice</a>, which explores what can be said about Hilbert spaces without the axiom of choice. Without choice, a Hilbert space may lack a basis, which gives a precise meaning to \"not picking a basis.\" Also in the absence of choice, some of the funny things that can happen with Dedekind-finiteness may give some insight into what can and cannot be proved in the finite-dimensional case.</p>",
        "id": 567427819,
        "sender_full_name": "Timothy Chow",
        "timestamp": 1768179202
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"580947\">Rida Hamadani</span> <a href=\"#narrow/channel/287929-mathlib4/topic/Why.20does.20mathlib.20have.20matrices.3F/near/567420865\">said</a>:</p>\n<blockquote>\n<p>In Seymour's project, we use explicit matrices representations extensively in the proof, even though the result itself is not about matrices. I think the whole work could have been done without matrices but it is not clear to me that it would have resulted in a better proof, representing regular matroids as totally unimodular matrices helps when taking their sums.</p>\n</blockquote>\n<p>Actually, is does the concept of total unimodularity exist on linear maps beyond matrices?</p>",
        "id": 567584796,
        "sender_full_name": "Martin Dvořák",
        "timestamp": 1768235567
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"459227\">Violeta Hernández</span> <a href=\"#narrow/channel/287929-mathlib4/topic/Why.20does.20mathlib.20have.20matrices.3F/near/567069882\">said</a>:</p>\n<blockquote>\n<p>Determinant is the scale factor of the n-th exterior power, trace is the contraction map on tensors</p>\n</blockquote>\n<p>Sounds like some very fancy math. Unfortunately, I don't have any idea what it means.</p>\n<p>Without understanding the topic (maybe I am entirely wrong, please, let me know), it seems to me that you are mentioning two theorems. Maybe you can state them in Lean and add them with <code>proof_wanted</code> to Mathlib? Or perhaps also prove them yourself?</p>\n<p>I think the goal should be connecting the concepts of determinant and trace of matrices to those more abstract concepts rather than removing them because they can be expressed in terms of those more abstract concepts. Again, I am commenting on something that I don't understand, so I might be completely wrong.</p>",
        "id": 567587905,
        "sender_full_name": "Martin Dvořák",
        "timestamp": 1768236258
    },
    {
        "content": "<p>Do we have exterior powers (or the exterior algebra to begin with) in Mathlib?</p>",
        "id": 567593601,
        "sender_full_name": "Violeta Hernández",
        "timestamp": 1768237570
    },
    {
        "content": "<p><a href=\"https://leanprover-community.github.io/mathlib4_docs/find/?pattern=ExteriorAlgebra#doc\">docs#ExteriorAlgebra</a></p>",
        "id": 567594418,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1768237757
    },
    {
        "content": "<p>ExteriorPower is I believe in some open PRs (as a subtype)</p>",
        "id": 567594533,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1768237788
    },
    {
        "content": "<p>I'm specifically talking about the exterior power of a linear map</p>",
        "id": 567594613,
        "sender_full_name": "Violeta Hernández",
        "timestamp": 1768237807
    },
    {
        "content": "<p>If T : V → V with dim(V) = n then ∧ⁿ(T) = det(T)</p>",
        "id": 567594746,
        "sender_full_name": "Violeta Hernández",
        "timestamp": 1768237836
    },
    {
        "content": "<p>How far could we get by defining \"finite dimensional\" as \"dualizable\" in the monoidal closed category sense? Then trace works but idk about determinants. The benefit is it kind of generalizes to modules and vector bundles.</p>",
        "id": 567594773,
        "sender_full_name": "Trebor Huang",
        "timestamp": 1768237841
    },
    {
        "content": "<p>(For anyone just opening this thread, I'm now quite convinced that matrices do belong in Mathlib, even if my preferred approach to linear algebra is to avoid them)</p>",
        "id": 567600134,
        "sender_full_name": "Violeta Hernández",
        "timestamp": 1768239169
    },
    {
        "content": "<p>I guess a related question is: suppose all the desirable facts about trace, dimensionality, scaling of Lebesgue measure, etc were easily provable without matrices.</p>\n<p>Would mathlib have matrices then?</p>",
        "id": 567643065,
        "sender_full_name": "Boris Alexeev",
        "timestamp": 1768251882
    },
    {
        "content": "<p>If that were the case I'd suggest moving them to Batteries. And over there we could do all the fun computational stuff like implementing Karatsuba or sparse matrices. But I suspect that would be an unpopular opinion.</p>",
        "id": 567643520,
        "sender_full_name": "Violeta Hernández",
        "timestamp": 1768252022
    },
    {
        "content": "<p>I doubt that somebody would argue that the mathlib correct way to define <a href=\"https://leanprover-community.github.io/mathlib4_docs/Mathlib/LinearAlgebra/RootSystem/CartanMatrix.html#RootPairing.Base.cartanMatrixIn\">https://leanprover-community.github.io/mathlib4_docs/Mathlib/LinearAlgebra/RootSystem/CartanMatrix.html#RootPairing.Base.cartanMatrixIn</a> is as an endomorphism of the space of formal linear combinations on a set in bijection with a set of simple roots of a root system</p>",
        "id": 567644095,
        "sender_full_name": "Stepan Nesterov",
        "timestamp": 1768252233
    },
    {
        "content": "<p>Just for fun, here's something about linear maps in mathlib that really needs matrices, I think: <code>f ∘ g = id ↔ g ∘ f = id</code> for linear endomorphisms of a finite free module over a commutative semiring (this is <a href=\"https://leanprover-community.github.io/mathlib4_docs/find/?pattern=LinearMap.comp_eq_id_comm#doc\">docs#LinearMap.comp_eq_id_comm</a> + <a href=\"https://leanprover-community.github.io/mathlib4_docs/find/?pattern=Matrix.instIsStablyFiniteRingOfCommSemiring#doc\">docs#Matrix.instIsStablyFiniteRingOfCommSemiring</a>).</p>",
        "id": 567644340,
        "sender_full_name": "Thomas Browning",
        "timestamp": 1768252341
    },
    {
        "content": "<p>(at least, the proof is 200 lines of horrid mucking around with explicit matrix entries)</p>",
        "id": 567644462,
        "sender_full_name": "Thomas Browning",
        "timestamp": 1768252395
    },
    {
        "content": "<p>That one works for any noetherian ring I think</p>",
        "id": 567644870,
        "sender_full_name": "Aaron Liu",
        "timestamp": 1768252575
    },
    {
        "content": "<p>not just the matrix ring</p>",
        "id": 567644917,
        "sender_full_name": "Aaron Liu",
        "timestamp": 1768252599
    },
    {
        "content": "<p>Every Noetherian ring is Dedekind finite?</p>",
        "id": 567644937,
        "sender_full_name": "Violeta Hernández",
        "timestamp": 1768252615
    },
    {
        "content": "<p>Maybe I'm remembering wrong?</p>",
        "id": 567644961,
        "sender_full_name": "Aaron Liu",
        "timestamp": 1768252628
    },
    {
        "content": "<p>oh for semirings the proof I know doesn't work</p>",
        "id": 567645012,
        "sender_full_name": "Aaron Liu",
        "timestamp": 1768252653
    },
    {
        "content": "<p>so idk about semirings</p>",
        "id": 567645050,
        "sender_full_name": "Aaron Liu",
        "timestamp": 1768252670
    },
    {
        "content": "<p>Yeah, in the field case this result is nice since you can just use injective ↔ surjective on endomorphisms. If you tell me the semiring case can't be done any nicer than explicit matrix calculations I'll sadly concede that they're not at all unavoidable.</p>",
        "id": 567645227,
        "sender_full_name": "Violeta Hernández",
        "timestamp": 1768252766
    },
    {
        "content": "<p>I would add: there's a good chunk of important math in the literature regarding sparse matrices, tridiagonal matrices, and matrix norms that are not basis independent. These could be formalized using linear operators where everything is basis-dependent, but then really I think just using matrices is much more reasonable.</p>",
        "id": 567648182,
        "sender_full_name": "Alex Meiburg",
        "timestamp": 1768254001
    },
    {
        "content": "<p>Matrices are very much needed for Lie algebras (or it would very difficult to avoid them).</p>",
        "id": 567652691,
        "sender_full_name": "Riccardo Brasca",
        "timestamp": 1768255978
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"419930\">Boris Alexeev</span> <a href=\"#narrow/channel/287929-mathlib4/topic/Why.20does.20mathlib.20have.20matrices.3F/near/567643065\">said</a>:</p>\n<blockquote>\n<p>I guess a related question is: suppose all the desirable facts about trace, dimensionality, scaling of Lebesgue measure, etc were easily provable without matrices.</p>\n<p>Would mathlib have matrices then?</p>\n</blockquote>\n<p>I think it should. Rida Hamadani put it well: matrices are not just \"what you get from a linear transformation when you pick a basis.\" They are objects of study in their own right. It seems that mathlib currently has a bias toward (for lack of a better word) \"abstract\" rather than \"numerical\" mathematics, but if the goal of mathlib is to formalize \"all of math\" then numerical mathematics is also part of math.</p>\n<p>Slightly off topic, but Nick Trefethen's <a href=\"https://sites.math.rutgers.edu/~zeilberg/akherim/NickApology.pdf\">Applied Mathematician's Apology</a> is an excellent read.</p>",
        "id": 567662851,
        "sender_full_name": "Timothy Chow",
        "timestamp": 1768262171
    },
    {
        "content": "<p>I don’t think mathlib’s goal is to formalize all of the math.</p>",
        "id": 567667731,
        "sender_full_name": "Etienne Marion",
        "timestamp": 1768265856
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"703970\">Etienne Marion</span> <a href=\"#narrow/channel/287929-mathlib4/topic/Why.20does.20mathlib.20have.20matrices.3F/near/567667731\">said</a>:</p>\n<blockquote>\n<p>I don’t think mathlib’s goal is to formalize all of the math.</p>\n</blockquote>\n<p>What do you think the goal of mathlib is? This is a real question.</p>",
        "id": 567669874,
        "sender_full_name": "Timothy Chow",
        "timestamp": 1768267376
    },
    {
        "content": "<p>I think Mathlib's goal is to formalize the most useful and well-known mathmatics. And whatever outliers remain can be placed in the other projects of the Lean ecosystem.</p>",
        "id": 567689301,
        "sender_full_name": "Violeta Hernández",
        "timestamp": 1768284166
    },
    {
        "content": "<p>There was a recent paper published in the Annals of Mathematics about behaviour of eigenvalues of a matrix which had random entries of either +1 or -1 in each slot. Not sure you could do this with linear maps:-)</p>",
        "id": 567698293,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1768289351
    },
    {
        "content": "<p>I'm coming late to this thread here, but I can't help asking the counter-question: why do some people here regard it as desirable to <em>actively avoid</em> the use of matrices? I feel there's a little bit of mathematical virtue-signalling going on here: \"<em>real</em> mathematicians don't use matrices\", and anything that requires explicit matrix calculations is an \"outlier\" (a classic <a href=\"https://en.wikipedia.org/wiki/No_true_Scotsman\">\"no true Scotsman\" fallacy</a>).</p>\n<p>I can understand the psychology behind this, since I went through the same phase myself. Like most mathematicians I initially learned linear algebra with explicit matrices and vectors (in school). When I encountered the basis-free, linear-transformations approach (in my first year at university) it initially seemed very strange and difficult to me, and I had to work quite hard to really master it. Once I'd fully learned this new approach, I naturally wanted to convince myself that the sacrifice I had made was worthwhile, by embracing the view that anything involving explicit matrices and vectors was clumsy, inelegant, intrinsically inferior.</p>\n<p>But that phase didn't last: as I matured as a mathematician, I came to the conclusion that the explicit matrix-based approach and the abstract vector-space approach are both just tools, and you use whichever tool suits your problem better – you don't hear carpenters arguing over whether screwdrivers are better than hammers. </p>\n<p>(I went through several such cycles in my mathematical training – another one involved category theory. There are also examples of the entire mathematical community collectively going through a similar cycle over a much longer time-scale, e.g. the see-saw between explicit vs. abstract methods in commutative algebra.)</p>",
        "id": 567716088,
        "sender_full_name": "David Loeffler",
        "timestamp": 1768295958
    },
    {
        "content": "<p>My advisor basically spent his career working with matrices. Of special interest to him were commutators of compact operators (on a Hilbert space). In the 70's, Joel Anderson exhibited that a rank-one projection is a commutator of compact operators. I would be rather astounded if anyone could give a proof of that without matrices. The construction consists of a pair of block tri-diagonal matrices, and the sizes of the blocks grow arithmetically.</p>",
        "id": 567752553,
        "sender_full_name": "Jireh Loreaux",
        "timestamp": 1768307792
    },
    {
        "content": "<p>At the risk of beating a dead horse, let me list a few examples to underline the point that a matrix is not just \"what you get from a linear transformation by picking a basis\" but a concept without which it would be difficult to even state many fundamental results.</p>\n<ol>\n<li>The theory of matrices with nonnegative (or positive) entries (the <a href=\"https://en.wikipedia.org/wiki/Perron%E2%80%93Frobenius_theorem\">Perron–Frobenius theorem</a>, <a href=\"https://en.wikipedia.org/wiki/Sinkhorn%27s_theorem\">Sinkhorn's theorem</a>, <a href=\"https://en.wikipedia.org/wiki/Totally_positive_matrix\">total positivity</a>, etc.) Entire books have been written on this subject.</li>\n<li>Random matrix theory. In many applications, such as <a href=\"https://www.mathc.rwth-aachen.de/~rauhut/files/LinzRauhut.pdf\">compressed sensing</a>, the actual entries are important and it's not just \"random linear transformation theory.\"</li>\n<li>As already mentioned earlier in this thread, the computational complexity of matrix algorithms is an active area of research. Just one example: AlphaEvolve's <a href=\"https://deepmind.google/blog/alphaevolve-a-gemini-powered-coding-agent-for-designing-advanced-algorithms/\">recent discovery</a> of an algorithm to multiply two 4x4 complex-valued matrices using only 48 multiplications, the first improvement since 1969.</li>\n<li>A matrix can arise from a combinatorial object such as a graph or a polytope or a finite Markov chain. As someone else already said, it would be difficult to state, let alone prove, Kirchhoff's <a href=\"https://en.wikipedia.org/wiki/Kirchhoff%27s_theorem\">matrix-tree theorem</a> and other results in spectral graph theory without matrices.</li>\n<li><a href=\"https://en.wikipedia.org/wiki/Pfaffian\">Pfaffians</a> and <a href=\"https://en.wikipedia.org/wiki/Permanent_(mathematics)\">permanents</a>. These can be defined graph-theoretically but it would be extremely awkward to prove much about them if one were not allowed to use matrices.</li>\n</ol>\n<p>It would be easy to extend this list. I'm fond of the <a href=\"https://arxiv.org/abs/math/0404396\">non-messing-up theorem</a> for rectangular arrays, though one could argue that this is not really a central topic in mathematics. Ditto for the <a href=\"https://en.wikipedia.org/wiki/Hadamard_matrix#Hadamard_conjecture\">Hadamard conjecture</a> that was mentioned earlier.</p>",
        "id": 567763540,
        "sender_full_name": "Timothy Chow",
        "timestamp": 1768310932
    },
    {
        "content": "<p>I wouldn't want to remove matrices from mathlib, but I did find it an interesting exercise upthread to see how far we could get without them</p>",
        "id": 567801831,
        "sender_full_name": "Ruben Van de Velde",
        "timestamp": 1768319908
    },
    {
        "content": "<p>In general, I do think it is valuable to ask whether a theorem that makes no mention of X can be proved without X. (That's quite different from asking whether mathematics as a whole can do without X.) Regardless of whether the answer is yes, no, or somewhere in between, we often learn something valuable in the process. Examples:</p>\n<ul>\n<li>Can an elementary statement about prime numbers (e.g., the prime number theorem) always be proved by elementary means?</li>\n<li>Can <a href=\"https://en.wikipedia.org/wiki/Burnside%27s_theorem\">Burnside's <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msup><mi>p</mi><mi>a</mi></msup><msup><mi>q</mi><mi>b</mi></msup></mrow><annotation encoding=\"application/x-tex\"> p^aq^b </annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.0435em;vertical-align:-0.1944em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">p</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6644em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">a</span></span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">q</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8491em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">b</span></span></span></span></span></span></span></span></span></span></span> theorem</a> be proved without character theory?</li>\n<li>Can a theorem about Lie groups (or finite groups) be proved \"directly\" as opposed to by checking each case in the classification individually?</li>\n<li>Does a <a href=\"https://mathoverflow.net/q/5449\">combinatorial theorem always admit a combinatorial proof</a>? This one is particularly relevant to the matrix discussion because in many cases, one is seeking a proof (of a basis-independent result) that picks a basis! That is, one seeks to \"explain\" a result obtained via dimension counting by constructing a basis indexed by combinatorial objects that yield additional insight into the structure.</li>\n</ul>\n<p>Sometimes, these kinds of questions can lead to new axioms (e.g., asking which theorems about linear independence can be formulated and proved without vector spaces could lead to the axioms for matroids) or reverse-mathematical insights (e.g., asking whether arithmetical theorems of ZFC can always be proved in ZF could lead to <a href=\"https://en.wikipedia.org/wiki/Absoluteness_(logic)#Shoenfield's_absoluteness_theorem\">Shoenfield's absoluteness theorem</a>). That's why I asked above if there might be a way to be more formal about what \"picking a basis\" really means.</p>\n<p>But even if there's no way to completely formalize such a question, pursuing it can certainly be insightful. Of course, if one is trying to attack an unproven conjecture, it makes sense to use all tools available, since any proof is better than no proof. That doesn't mean that there aren't sometimes advantages to proofs that intentionally avoid X.</p>",
        "id": 567869237,
        "sender_full_name": "Timothy Chow",
        "timestamp": 1768342795
    },
    {
        "content": "<p>Is “can a theorem in mathlib be proved without importing a certain very large file” ever a formal question that maintainers ask for performance reasons?</p>",
        "id": 567873005,
        "sender_full_name": "Stepan Nesterov",
        "timestamp": 1768344821
    },
    {
        "content": "<p>Import sizes are certainly considered when evaluating PRs.  The summary also has some statistics about the import changes of PRs.</p>",
        "id": 567882229,
        "sender_full_name": "Damiano Testa",
        "timestamp": 1768349592
    },
    {
        "content": "<p>I've learned a lot from this thread. I think my personal preference against matrices hasn't really changed much, and I think matrix-free approaches can yield a lot of clarity into definitions like the trace or the determinant which are somewhat unmotivated otherwise. But now I see that this isn't the end of the story.</p>",
        "id": 567891417,
        "sender_full_name": "Violeta Hernández",
        "timestamp": 1768356441
    },
    {
        "content": "<p>Since I am the person whose 3 out of 4 Ph.D.-thesis projects are essentially about matrices, I cannot help but add one more remark.</p>\n<p>I won't bother me if you consider me an inferior person for the reason that I work with matrices. It will bother me, however, if you make working with matrices in Lean harder (regardless of the motivation).</p>",
        "id": 568451380,
        "sender_full_name": "Martin Dvořák",
        "timestamp": 1768574813
    },
    {
        "content": "<p>I don't consider anyone here inferior for their tastes in mathematics.</p>",
        "id": 568480495,
        "sender_full_name": "Violeta Hernández",
        "timestamp": 1768582663
    },
    {
        "content": "<p>On MathOverflow, I asked about the <a href=\"https://mathoverflow.net/q/507049\">precise meaning of \"picking a basis\"</a>. It was not really a discussion about Lean, so I won't elaborate here, other than to highlight that Todd Trimble proposed a way to define the trace without picking a basis</p>",
        "id": 568618946,
        "sender_full_name": "Timothy Chow",
        "timestamp": 1768687303
    }
]