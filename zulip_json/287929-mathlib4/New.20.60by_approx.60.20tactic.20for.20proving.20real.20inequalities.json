[
    {
        "content": "<p>Work in progress new tactic: <a href=\"https://github.com/leanprover-community/mathlib4/pull/8949\">https://github.com/leanprover-community/mathlib4/pull/8949</a></p>\n<p>It proves goals like</p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"kd\">example</span> <span class=\"o\">:</span> <span class=\"bp\">|</span><span class=\"n\">sqrt</span> <span class=\"mi\">2</span> <span class=\"bp\">-</span> <span class=\"mi\">1</span><span class=\"bp\">.</span><span class=\"mi\">414</span><span class=\"bp\">|</span> <span class=\"bp\">&lt;</span> <span class=\"mi\">0</span><span class=\"bp\">.</span><span class=\"mi\">001</span> <span class=\"o\">:=</span> <span class=\"kd\">by</span> <span class=\"n\">by_approx</span>\n\n<span class=\"kd\">example</span> <span class=\"o\">:</span> <span class=\"n\">exp</span> <span class=\"o\">(</span><span class=\"n\">sqrt</span> <span class=\"mi\">10</span><span class=\"o\">)</span> <span class=\"bp\">&gt;</span> <span class=\"mi\">23</span><span class=\"bp\">.</span><span class=\"mi\">6243</span> <span class=\"o\">:=</span> <span class=\"kd\">by</span> <span class=\"n\">by_approx</span>\n</code></pre></div>\n<p>by searching for successively precise rational approximations of both sides.</p>\n<p>Currently it is really inefficient. This is for the following reasons:</p>\n<ul>\n<li>\n<p>It has a global <code>precision</code> value which gets increased each iteration across the entire expression. For example, if you have an expression like <code>1000 * sqrt 2 + exp 0.5</code> it will might expend loads of effort coming up with accurate approximations for <code>exp 0.5</code>, even though the accuracy of the <code>sqrt</code> term is much more important.</p>\n</li>\n<li>\n<p>It throws away lots of information after each iteration. This doesn't matter as much as it sounds because only on the final iteration does it actually produce a proof term, and this is often the majority of the runtime of the tactic.</p>\n</li>\n<li>\n<p>It does no rounding on the rational numbers which appear as intermediate terms. This means that really big integers show up in calculations when they don't really need to.</p>\n</li>\n<li>\n<p>It uses the norm_num tactic many times to produce the final proof. Previously I was doing as much as I could with <code>reduce</code> which was much faster for <code>Nat</code> expressions but didn't work at all for rational ones.</p>\n</li>\n<li>\n<p>I have not put any effort into making sure the computed approximations are actually reasonable. I think the <code>exp</code> one is probably fine, but <code>sqrt</code> is more questionable</p>\n</li>\n</ul>",
        "id": 407069390,
        "sender_full_name": "Sebastian Zimmer",
        "timestamp": 1702215266
    },
    {
        "content": "<p>My vision for the tactic is that it should build a tree of approximations for each side of the expression. Then on each iteration it should only work on the section of the tree that is responsible for the largest share of the error.</p>\n<p>I think I want to implement more extensions (especially <code>log</code>, which was the reason I made this in the first place) before I change the approach though. That way I can measure what works best, and the tactic is already fast enough for some usecases.</p>",
        "id": 407069700,
        "sender_full_name": "Sebastian Zimmer",
        "timestamp": 1702215555
    },
    {
        "content": "<p>A long tim ago, I have written an implementation of \"lazy computable reals\" in Common Lisp; see \"reals.lsp\" near the bottom of <a href=\"https://www.mathe2.uni-bayreuth.de/stoll/programs/index.html\">this page</a>. This could perhaps provide some inspriration on how evaluation with the necessary precision can be implemented.</p>",
        "id": 407082970,
        "sender_full_name": "Michael Stoll",
        "timestamp": 1702224697
    }
]