[
    {
        "content": "<p>This is a slightly vague request but I'm wondering if there's any way to improve this situation:</p>\n<p><a href=\"/user_uploads/3121/D38Yq9eE3K8WPRV52dYtsBn4/Screenshot-2025-07-04-at-17.16.04.png\">Screenshot 2025-07-04 at 17.16.04.png</a></p>\n<div class=\"message_inline_image\"><a href=\"/user_uploads/3121/D38Yq9eE3K8WPRV52dYtsBn4/Screenshot-2025-07-04-at-17.16.04.png\" title=\"Screenshot 2025-07-04 at 17.16.04.png\"><img data-original-content-type=\"image/png\" data-original-dimensions=\"1710x798\" src=\"/user_uploads/thumbnail/3121/D38Yq9eE3K8WPRV52dYtsBn4/Screenshot-2025-07-04-at-17.16.04.png/840x560.webp\"></a></div><p>When you don't know the theorem you want to use, the LSP doesn't help in any way — i.e. it doesn't prioritize \"matching\" shapes. I wonder if it should?</p>\n<p>This is particularly noticeable with AI — I'm trying to connect Claude Code to Lean LSP via <a href=\"https://github.com/oOo0oOo/lean-lsp-mcp\">https://github.com/oOo0oOo/lean-lsp-mcp</a>, <em>and it works</em>, but the completions it gets are almost always irrelevant:</p>\n<p><a href=\"user_uploads/3121/dseeB6zA0WNrTGtMadFZKUs7/Screenshot-2025-07-04-at-16.47.13.png\">screenshot</a></p>\n<div class=\"message_inline_image\"><a href=\"user_uploads/3121/dseeB6zA0WNrTGtMadFZKUs7/Screenshot-2025-07-04-at-16.47.13.png\" title=\"screenshot\"><img src=\"user_uploads/3121/dseeB6zA0WNrTGtMadFZKUs7/Screenshot-2025-07-04-at-16.47.13.png\"></a></div><p>If \"matching goal\" completions were prioritized (and same for <code>rw</code>), I think it could provide a productivity boost both to humans and to AI.</p>\n<p>Has there been any existing thinking on this? Are there plans to improve autocomplete to be more \"relevant\" in any way? The question I think it should get better at answering is \"what stuff that's locally available to me may help resolve the problem I have on the current line\". I don't think the current tools are good at that.</p>",
        "id": 527206880,
        "sender_full_name": "Dan Abramov",
        "timestamp": 1751646004
    },
    {
        "content": "<p>Filed <a href=\"https://github.com/oOo0oOo/lean-lsp-mcp/issues/5\">https://github.com/oOo0oOo/lean-lsp-mcp/issues/5</a> for a more concrete issue but the broader point stands</p>",
        "id": 527208100,
        "sender_full_name": "Dan Abramov",
        "timestamp": 1751646429
    },
    {
        "content": "<p>Improvements are always possible but there are some very real limitations VS Code puts on completion regarding reasonable time budget and presentation. Thus tactics like <code>apply?</code> and <code>rw?</code> using the info view have a lot more freedom in this regard and AI systems should likely prefer them as well for their specific use cases.</p>",
        "id": 527219017,
        "sender_full_name": "Sebastian Ullrich",
        "timestamp": 1751651846
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"418569\">@Dan Abramov</span> <br>\nThe specific completions that you get in your screenshots are provided by VS Code itself when the language server doesn't provide any, not Lean. You can disable them using the 'Editor: Word Based Suggestions' setting.<br>\nI've mulled over disabling them by default a couple of times but I've heard from several users that they use these word-based suggestions when using auto-completion for completion, not discovery, so I've been holding off on it.</p>\n<p>The specific issue for having the language server provide completions in this particular example is <a href=\"https://github.com/leanprover/lean4/pull/7696\">lean4#7696</a>. It's a bit tricky, though.</p>\n<blockquote>\n<p>what stuff that's locally available to me may help resolve the problem I have on the current line</p>\n</blockquote>\n<p>One problem with this occurs even before the language server is involved: The expected type at some source location is quite unstable in a partial program. I've played around with prioritizing \"matching\" completions in the past, but it didn't feel consistent enough to be very useful. <br>\nUltimately, I think that there would have to be some significant improvements to the error recovery in the elaborator before something like this becomes feasible. There's a couple of issues on GitHub already to track some ideas for improving it.</p>",
        "id": 530347533,
        "sender_full_name": "Marc Huisinga",
        "timestamp": 1753278122
    }
]