[
    {
        "content": "<p>Hi, I am working on improving the efficiency of initializing a library search database.  This is in <a href=\"https://github.com/leanprover/std4/pull/421\">std4#421</a>.   I thought I'd start a topic here to get feedback.</p>\n<p>To do this, I have a \"lazy\" discriminator tree.  It uses the logic of the existing Lean discriminator tree and doesn't explore any of the higher order features of <a href=\"#narrow/stream/341532-lean4-dev/topic/Indexing.20lambdas.20with.20.60DiscrTree.60/near/401219893\">this discussion</a>.  However, that is largely orthogonal and there's a primitive mechanism for swapping out the <code>exact?</code> and <code>apply?</code> candidate selection operation.</p>\n<p>Performance seem to be about 4-5x faster.  It takes about 8.5 seconds for Lean to process a file that imports Mathlib and calls <code>exact?</code> on a simple lemma.  Without the new discriminator tree, the same test takes 41 seconds.  Projects not using Mathlib should see sub second responses, but I have a relatively fast machine so more testing is needed.</p>\n<p>One other difference is that the cache-less approach doesn't know about names that aren't in the current environment.  For <code>exact?</code> and <code>apply?</code> this shouldn't matter.   There may be other tactics in Mathlib that use <code>library_search</code> and would want all names though.</p>",
        "id": 406442450,
        "sender_full_name": "Joe Hendrix",
        "timestamp": 1701919045
    }
]